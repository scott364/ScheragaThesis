{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor env in gym.envs.registry.env_specs:\\n     if 'MainEnvRL-v0' in env:\\n        print('Remove {} from registry'.format(env))\\n        del gym.registry.env_specs[env]\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To register MainEnvRL with local copy of Gym\n",
    "\"\"\"\n",
    "from gym.envs.registration import register\n",
    " \n",
    "register(\n",
    "    id='MainEnvRL-v2',\n",
    "    #entry_point='balance_bot.envs:BalancebotEnv',\n",
    "    entry_point='MainEnv_RL.envs:MainEnvRL',\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "#import gym\n",
    "#for env in gym.envs.registry.env_specs:\n",
    "#    print(env)\n",
    "    \n",
    "    #if 'MainEnvRL-v1' == env:\n",
    "    #     print('Remove {} from registry'.format(env))\n",
    "         #del gym.envs.registry.env_specs[env]\n",
    "            \n",
    "            \n",
    "#import MainEnv_RL\n",
    "\n",
    "#env = gym.make('MainEnvRL-v2')\n",
    "#env.reset()\n",
    "\"\"\"\n",
    "for env in gym.envs.registry.env_specs:\n",
    "     if 'MainEnvRL-v0' in env:\n",
    "        print('Remove {} from registry'.format(env))\n",
    "        del gym.registry.env_specs[env]\n",
    "\"\"\"                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep: 40   Total Steps taken: 1094\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep: 40  tStep: 1 Z difference 0.0013334786489607175  Reward: -1.9986665213510393\n",
      "Ep: 40  tStep: 2 Z difference 0.0007560583408920962  Reward: -1.999243941659108\n",
      "Ep: 40  tStep: 3 Z difference 0.002852781918272207  Reward: -1.9971472180817278\n",
      "Ep: 40  tStep: 4 Z difference 0.005720377006754429  Reward: -1.9942796229932456\n",
      "Ep: 40  tStep: 5 Z difference 0.006815964942052943  Reward: -1.993184035057947\n",
      "Ep: 40  tStep: 6 Z difference 0.008467266757786085  Reward: -1.991532733242214\n",
      "Ep: 40  tStep: 7 Z difference 0.006950163464248149  Reward: -1.9930498365357519\n",
      "Ep: 40  tStep: 8 Z difference 0.005705563836544858  Reward: -1.9942944361634551\n",
      "Ep: 40  tStep: 9 Z difference 0.006031013585999556  Reward: -1.9939689864140004\n",
      "Ep: 40  tStep: 10 Z difference 0.006763312188535764  Reward: -1.9932366878114642\n",
      "Ep: 40  tStep: 11 Z difference 0.0058642554223538035  Reward: -1.9941357445776462\n",
      "Ep: 40  tStep: 12 Z difference 0.005278328541293842  Reward: -1.9947216714587062\n",
      "Ep: 40  tStep: 13 Z difference 0.00544215340390819  Reward: -1.9945578465960918\n",
      "Ep: 40  tStep: 14 Z difference 0.005183142922818629  Reward: -1.9948168570771814\n",
      "Ep: 40  tStep: 15 Z difference 0.005482339628040567  Reward: -1.9945176603719594\n",
      "Ep: 40  tStep: 16 Z difference 0.0038547975506633136  Reward: -50\n",
      "-------------------------------------\n",
      "| approxkl           | 0.030945156  |\n",
      "| clipfrac           | 0.08333334   |\n",
      "| explained_variance | -9.54e-07    |\n",
      "| fps                | 0            |\n",
      "| n_updates          | 37           |\n",
      "| policy_entropy     | 0.23687196   |\n",
      "| policy_loss        | 0.0046733855 |\n",
      "| serial_timesteps   | 1110         |\n",
      "| time_elapsed       | 1.58e+03     |\n",
      "| total_timesteps    | 1110         |\n",
      "| value_loss         | 23178.742    |\n",
      "-------------------------------------\n",
      "Ep: 40  tStep: 17 Z difference 0.007065148864686677  Reward: -50\n",
      "Ep: 40  tStep: 18 Z difference 0.006745712382346447  Reward: -50\n",
      "Ep: 40  tStep: 19 Z difference 0.008574625575542338  Reward: -50\n",
      "Ep: 40  tStep: 20 Z difference 0.006927283716201771  Reward: -50\n",
      "Ep: 40  tStep: 21 Z difference 0.006744539061933619  Reward: -50\n",
      "Ep: 40  tStep: 22 Z difference 0.010154794841259474  Reward: -50\n",
      "Ep: 40  tStep: 23 Z difference 0.007517463883757625  Reward: -50\n",
      "Ep: 40  tStep: 24 Z difference 0.0073199060592799015  Reward: -50\n",
      "Ep: 40  tStep: 25 Z difference 0.008672011169791105  Reward: -50\n",
      "Ep: 40  tStep: 26 Z difference 0.009792825493961654  Reward: -50\n",
      "Ep: 40  tStep: 27 Z difference 0.009536161653697306  Reward: -50\n",
      "Ep: 40  tStep: 28 Z difference 0.0106459760989992  Reward: -50\n",
      "Ep: 40  tStep: 29 Z difference 0.009935823919251519  Reward: -50\n",
      "Ep: 40  tStep: 30 Z difference 0.01049725773669774  Reward: -50\n",
      "   Actionlist: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Ep: 41  tStep: 1 Z difference 0.0014977435067295986  Reward: -1.9985022564932704\n",
      "Ep: 41  tStep: 2 Z difference -0.0019378853265195062  Reward: -2.0019378853265195\n",
      "Ep: 41  tStep: 3 Z difference -0.0007415385007858433  Reward: -2.000741538500786\n",
      "Ep: 41  tStep: 4 Z difference 0.001024748715385826  Reward: -1.9989752512846142\n",
      "Ep: 41  tStep: 5 Z difference 0.001040148545801589  Reward: -1.9989598514541984\n",
      "Ep: 41  tStep: 6 Z difference 2.757302969724762e-05  Reward: -1.9999724269703028\n",
      "Ep: 41  tStep: 7 Z difference 0.0017646739006043077  Reward: -1.9982353260993957\n",
      "Ep: 41  tStep: 8 Z difference 0.0015420363523066527  Reward: -1.9984579636476933\n",
      "Ep: 41  tStep: 9 Z difference 0.051738443585485516  Reward: -1.9482615564145145\n",
      "Ep: 41  tStep: 10 Z difference 0.05514547273367665  Reward: -1.9448545272663234\n",
      "Ep: 41  tStep: 11 Z difference 0.0522803709510713  Reward: -1.9477196290489287\n",
      "Ep: 41  tStep: 12 Z difference 0.05262503382228312  Reward: -1.9473749661777169\n",
      "Ep: 41  tStep: 13 Z difference 0.053167841178178854  Reward: -1.9468321588218211\n",
      "Ep: 41  tStep: 14 Z difference 0.052347250214591856  Reward: -1.9476527497854081\n",
      "Ep: 41  tStep: 15 Z difference 0.052373503258824616  Reward: -1.9476264967411754\n",
      "Ep: 41  tStep: 16 Z difference 0.05304141590371758  Reward: -1.9469585840962824\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0042193457 |\n",
      "| clipfrac           | 0.025000002  |\n",
      "| explained_variance | -5.96e-07    |\n",
      "| fps                | 0            |\n",
      "| n_updates          | 38           |\n",
      "| policy_entropy     | 0.0662132    |\n",
      "| policy_loss        | 0.008408706  |\n",
      "| serial_timesteps   | 1140         |\n",
      "| time_elapsed       | 1.62e+03     |\n",
      "| total_timesteps    | 1140         |\n",
      "| value_loss         | 22658.867    |\n",
      "-------------------------------------\n",
      "Ep: 41  tStep: 17 Z difference 0.054517599647864845  Reward: -50\n",
      "Ep: 41  tStep: 18 Z difference 0.05424436265677235  Reward: -50\n",
      "Ep: 41  tStep: 19 Z difference 0.05484876933433114  Reward: -50\n",
      "Ep: 41  tStep: 20 Z difference 0.055430736258998525  Reward: -50\n",
      "Ep: 41  tStep: 21 Z difference 0.05493896834105261  Reward: -50\n",
      "Ep: 41  tStep: 22 Z difference 0.05625000723712148  Reward: -50\n",
      "Ep: 41  tStep: 23 Z difference 0.05494380828775469  Reward: -50\n",
      "Ep: 41  tStep: 24 Z difference 0.10504898985885092  Reward: -50\n",
      "Ep: 41  tStep: 25 Z difference 0.1047232467792929  Reward: -50\n",
      "Ep: 41  tStep: 26 Z difference 0.10734180461019305  Reward: -50\n",
      "Ep: 41  tStep: 27 Z difference 0.10503666999451822  Reward: -50\n",
      "Ep: 41  tStep: 28 Z difference 0.10780511950813265  Reward: -50\n",
      "Ep: 41  tStep: 29 Z difference 0.10690342277102172  Reward: -50\n",
      "Ep: 41  tStep: 30 Z difference 0.10534055998139102  Reward: -50\n",
      "   Actionlist: [0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0]\n",
      "Ep: 42  tStep: 1 Z difference 0.0015523029059174576  Reward: -1.9984476970940825\n",
      "Ep: 42  tStep: 2 Z difference -0.00124019967615574  Reward: -2.0012401996761557\n",
      "Ep: 42  tStep: 3 Z difference 0.0013742515332997307  Reward: -1.9986257484667003\n",
      "Ep: 42  tStep: 4 Z difference 0.0023910803359004085  Reward: -1.9976089196640996\n",
      "Ep: 42  tStep: 5 Z difference 0.0029605807311834376  Reward: -1.9970394192688166\n",
      "Ep: 42  tStep: 6 Z difference 0.0029495808523152256  Reward: -1.9970504191476848\n",
      "Ep: 42  tStep: 7 Z difference 0.0011315208729358872  Reward: -1.9988684791270641\n",
      "Ep: 42  tStep: 8 Z difference 0.0015671160761270286  Reward: -1.998432883923873\n",
      "Ep: 42  tStep: 9 Z difference 0.0007685248702764547  Reward: -1.9992314751297235\n",
      "Ep: 42  tStep: 10 Z difference 0.00013434518724686484  Reward: -1.9998656548127531\n",
      "Ep: 42  tStep: 11 Z difference 0.0017790470756593457  Reward: -1.9982209529243407\n",
      "Ep: 42  tStep: 12 Z difference 0.0013218921098858694  Reward: -1.9986781078901141\n",
      "Ep: 42  tStep: 13 Z difference 0.0009641760490834983  Reward: -1.9990358239509165\n",
      "Ep: 42  tStep: 14 Z difference 0.0015149033177648263  Reward: -1.9984850966822352\n",
      "Ep: 42  tStep: 15 Z difference 0.0022860681589693677  Reward: -1.9977139318410306\n",
      "Ep: 42  tStep: 16 Z difference 0.00311883232183785  Reward: -50\n",
      "--------------------------------------\n",
      "| approxkl           | 0.001475143   |\n",
      "| clipfrac           | 0.008333334   |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 0             |\n",
      "| n_updates          | 39            |\n",
      "| policy_entropy     | 0.0537677     |\n",
      "| policy_loss        | -0.0014115095 |\n",
      "| serial_timesteps   | 1170          |\n",
      "| time_elapsed       | 1.66e+03      |\n",
      "| total_timesteps    | 1170          |\n",
      "| value_loss         | 23044.465     |\n",
      "--------------------------------------\n",
      "Ep: 42  tStep: 17 Z difference 0.004275139588490351  Reward: -50\n",
      "Ep: 42  tStep: 18 Z difference 0.004063501919061352  Reward: -50\n",
      "Ep: 42  tStep: 19 Z difference 0.004157514217123737  Reward: -50\n",
      "Ep: 42  tStep: 20 Z difference 0.002853368578478843  Reward: -50\n",
      "Ep: 42  tStep: 21 Z difference 0.0023844804085793037  Reward: -50\n",
      "Ep: 42  tStep: 22 Z difference 0.0026351309817287394  Reward: -50\n",
      "Ep: 42  tStep: 23 Z difference 0.002986980440467857  Reward: -50\n",
      "Ep: 42  tStep: 24 Z difference 0.0035082280337812577  Reward: -50\n",
      "Ep: 42  tStep: 25 Z difference 0.0025041590906682565  Reward: -50\n",
      "Ep: 42  tStep: 26 Z difference 0.002601544684917023  Reward: -50\n",
      "Ep: 42  tStep: 27 Z difference 0.0014090111505242753  Reward: -50\n",
      "Ep: 42  tStep: 28 Z difference 0.001948005215078652  Reward: -50\n",
      "Ep: 42  tStep: 29 Z difference 0.001294612410292384  Reward: -50\n",
      "Ep: 42  tStep: 30 Z difference 0.0028061424318703843  Reward: -50\n",
      "   Actionlist: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Ep: 43  tStep: 1 Z difference 0.0011466273732483323  Reward: -1.9988533726267517\n",
      "Ep: 43  tStep: 2 Z difference 0.002214788943901702  Reward: -1.9977852110560983\n",
      "Ep: 43  tStep: 3 Z difference -0.000988229117542705  Reward: -2.0009882291175427\n",
      "Ep: 43  tStep: 4 Z difference 0.0032052180372179606  Reward: -1.996794781962782\n",
      "Ep: 43  tStep: 5 Z difference 0.0024861192893235184  Reward: -1.9975138807106765\n",
      "Ep: 43  tStep: 6 Z difference 0.005957241065055019  Reward: -1.994042758934945\n",
      "Ep: 43  tStep: 7 Z difference 0.003454548624902909  Reward: -1.996545451375097\n",
      "Ep: 43  tStep: 8 Z difference 0.006013120449706921  Reward: -1.993986879550293\n",
      "Ep: 43  tStep: 9 Z difference 0.004371058532222971  Reward: -1.995628941467777\n",
      "Ep: 43  tStep: 10 Z difference 0.009250164803117578  Reward: -1.9907498351968824\n",
      "Ep: 43  tStep: 11 Z difference 0.004345392148196847  Reward: -1.9956546078518032\n",
      "Ep: 43  tStep: 12 Z difference 0.009147792597115068  Reward: -1.990852207402885\n",
      "Ep: 43  tStep: 13 Z difference 0.0073567189872263405  Reward: -1.9926432810127737\n",
      "Ep: 43  tStep: 14 Z difference 0.009037207148224091  Reward: -1.990962792851776\n",
      "Ep: 43  tStep: 15 Z difference 0.01028122011572119  Reward: -1.9897187798842788\n",
      "Ep: 43  tStep: 16 Z difference 0.009406216417997992  Reward: -50\n",
      "--------------------------------------\n",
      "| approxkl           | 1.3872665e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 0             |\n",
      "| n_updates          | 40            |\n",
      "| policy_entropy     | 0.018190993   |\n",
      "| policy_loss        | -9.298325e-07 |\n",
      "| serial_timesteps   | 1200          |\n",
      "| time_elapsed       | 1.7e+03       |\n",
      "| total_timesteps    | 1200          |\n",
      "| value_loss         | 22969.627     |\n",
      "--------------------------------------\n",
      "Ep: 43  tStep: 17 Z difference 0.010825787452235947  Reward: -50\n",
      "Ep: 43  tStep: 18 Z difference 0.011990161296725255  Reward: -50\n",
      "Ep: 43  tStep: 19 Z difference 0.011927975314855566  Reward: -50\n",
      "Ep: 43  tStep: 20 Z difference 0.012929844282195013  Reward: -50\n",
      "Ep: 43  tStep: 21 Z difference 0.012782885900512575  Reward: -50\n",
      "Ep: 43  tStep: 22 Z difference 0.012208985553681995  Reward: -50\n",
      "Ep: 43  tStep: 23 Z difference 0.012180532533675237  Reward: -50\n",
      "Ep: 43  tStep: 24 Z difference 0.012530768676847437  Reward: -50\n",
      "Ep: 43  tStep: 25 Z difference 0.013216721123084252  Reward: -50\n",
      "Ep: 43  tStep: 26 Z difference 0.01276997937597324  Reward: -50\n",
      "Ep: 43  tStep: 27 Z difference 0.011405847731232654  Reward: -50\n",
      "Ep: 43  tStep: 28 Z difference 0.011627018629014607  Reward: -50\n",
      "Ep: 43  tStep: 29 Z difference 0.011925335343927035  Reward: -50\n",
      "Ep: 43  tStep: 30 Z difference 0.012795645759999807  Reward: -50\n",
      "   Actionlist: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Ep: 44  tStep: 1 Z difference 0.00254977192170891  Reward: -1.997450228078291\n",
      "Ep: 44  tStep: 2 Z difference 0.0013481451541181855  Reward: -1.9986518548458818\n",
      "Ep: 44  tStep: 3 Z difference 0.00304945975244042  Reward: -1.9969505402475596\n",
      "Ep: 44  tStep: 4 Z difference 0.004986171758547098  Reward: -1.995013828241453\n",
      "Ep: 44  tStep: 5 Z difference 0.004297286011278434  Reward: -1.9957027139887216\n",
      "Ep: 44  tStep: 6 Z difference 0.004610122566297559  Reward: -1.9953898774337024\n",
      "Ep: 44  tStep: 7 Z difference 0.005257062108814381  Reward: -1.9947429378911856\n",
      "Ep: 44  tStep: 8 Z difference 0.0041827406059948835  Reward: -1.9958172593940051\n",
      "Ep: 44  tStep: 9 Z difference 0.0033649362783876313  Reward: -1.9966350637216124\n",
      "Ep: 44  tStep: 10 Z difference 0.0021688827827572865  Reward: -1.9978311172172427\n",
      "Ep: 44  tStep: 11 Z difference 0.003754185325279824  Reward: -1.9962458146747202\n",
      "Ep: 44  tStep: 12 Z difference 0.0031286588802932336  Reward: -1.9968713411197068\n",
      "Ep: 44  tStep: 13 Z difference 0.00335202975384874  Reward: -1.9966479702461513\n",
      "Ep: 44  tStep: 14 Z difference 0.0031939248282459864  Reward: -1.996806075171754\n",
      "Ep: 44  tStep: 15 Z difference 0.0028513152677565046  Reward: -1.9971486847322435\n",
      "Ep: 44  tStep: 16 Z difference 0.0023985602535305794  Reward: -50\n",
      "---------------------------------------\n",
      "| approxkl           | 6.3002055e-08  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0              |\n",
      "| fps                | 0              |\n",
      "| n_updates          | 41             |\n",
      "| policy_entropy     | 0.00710656     |\n",
      "| policy_loss        | -2.4636586e-07 |\n",
      "| serial_timesteps   | 1230           |\n",
      "| time_elapsed       | 1.74e+03       |\n",
      "| total_timesteps    | 1230           |\n",
      "| value_loss         | 22893.043      |\n",
      "---------------------------------------\n",
      "Ep: 44  tStep: 17 Z difference 0.002878008307143798  Reward: -50\n",
      "Ep: 44  tStep: 18 Z difference 0.0015958624262362164  Reward: -50\n",
      "Ep: 44  tStep: 19 Z difference 0.003148751992359422  Reward: -50\n",
      "Ep: 44  tStep: 20 Z difference 0.003484028300270392  Reward: -50\n",
      "Ep: 44  tStep: 21 Z difference 0.004208553655073111  Reward: -50\n",
      "Ep: 44  tStep: 22 Z difference 0.0031421520650383172  Reward: -50\n",
      "Ep: 44  tStep: 23 Z difference 0.003064126257598332  Reward: -50\n",
      "Ep: 44  tStep: 24 Z difference 0.003703292552381665  Reward: -50\n",
      "Ep: 44  tStep: 25 Z difference 0.0035121879901733877  Reward: -50\n",
      "Ep: 44  tStep: 26 Z difference 0.004227913441881448  Reward: -50\n",
      "Ep: 44  tStep: 27 Z difference 0.0046567620526998255  Reward: -50\n",
      "Ep: 44  tStep: 28 Z difference 0.0045549765069035075  Reward: -50\n",
      "Ep: 44  tStep: 29 Z difference 0.005268061987683037  Reward: -50\n",
      "Ep: 44  tStep: 30 Z difference 0.004624642406403812  Reward: -50\n",
      "   Actionlist: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Ep: 45  tStep: 1 Z difference -0.0008821902852504948  Reward: -2.0008821902852505\n",
      "Ep: 45  tStep: 2 Z difference -8.213242888466254e-05  Reward: -2.0000821324288847\n",
      "Ep: 45  tStep: 3 Z difference 0.000784364695847195  Reward: -1.9992156353041528\n",
      "Ep: 45  tStep: 4 Z difference 0.0008735370472074955  Reward: -1.9991264629527925\n",
      "Ep: 45  tStep: 5 Z difference -0.0003797158185392391  Reward: -2.0003797158185392\n",
      "Ep: 45  tStep: 6 Z difference 0.0008550572507082244  Reward: -1.9991449427492918\n",
      "Ep: 45  tStep: 7 Z difference 0.003304656942188622  Reward: -1.9966953430578114\n",
      "Ep: 45  tStep: 8 Z difference 0.004140061075985635  Reward: -1.9958599389240144\n",
      "Ep: 45  tStep: 9 Z difference 0.0027379431828857825  Reward: -1.9972620568171142\n",
      "Ep: 45  tStep: 10 Z difference 0.0026651973173024146  Reward: -1.9973348026826976\n",
      "Ep: 45  tStep: 11 Z difference 0.002925821113958893  Reward: -1.997074178886041\n",
      "Ep: 45  tStep: 12 Z difference 0.0045582031380386745  Reward: -1.9954417968619613\n",
      "Ep: 45  tStep: 13 Z difference 0.004882626232132203  Reward: -1.9951173737678678\n",
      "Ep: 45  tStep: 14 Z difference 0.006703766177594606  Reward: -1.9932962338224054\n",
      "Ep: 45  tStep: 15 Z difference 0.00746099783889953  Reward: -1.9925390021611005\n",
      "Ep: 45  tStep: 16 Z difference 0.008642091499269089  Reward: -50\n",
      "--------------------------------------\n",
      "| approxkl           | 6.3568892e-09 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 0             |\n",
      "| n_updates          | 42            |\n",
      "| policy_entropy     | 0.0038387491  |\n",
      "| policy_loss        | -7.947286e-09 |\n",
      "| serial_timesteps   | 1260          |\n",
      "| time_elapsed       | 1.79e+03      |\n",
      "| total_timesteps    | 1260          |\n",
      "| value_loss         | 22814.043     |\n",
      "--------------------------------------\n",
      "Ep: 45  tStep: 17 Z difference 0.008095324186980779  Reward: -50\n",
      "Ep: 45  tStep: 18 Z difference 0.009354736984893641  Reward: -50\n",
      "Ep: 45  tStep: 19 Z difference 0.010443724992871495  Reward: -50\n",
      "Ep: 45  tStep: 20 Z difference 0.011061038194969175  Reward: -50\n",
      "Ep: 45  tStep: 21 Z difference 0.012174959261715301  Reward: -50\n",
      "Ep: 45  tStep: 22 Z difference 0.011077611345797767  Reward: -50\n",
      "Ep: 45  tStep: 23 Z difference 0.011234249620884817  Reward: -50\n",
      "Ep: 45  tStep: 24 Z difference 0.01157495253570362  Reward: -50\n",
      "Ep: 45  tStep: 25 Z difference 0.01135216832235475  Reward: -50\n",
      "Ep: 45  tStep: 26 Z difference 0.012409476679191123  Reward: -50\n",
      "Ep: 45  tStep: 27 Z difference 0.013951953026652308  Reward: -50\n",
      "Ep: 45  tStep: 28 Z difference 0.013195748020708553  Reward: -50\n",
      "Ep: 45  tStep: 29 Z difference 0.013051136279851328  Reward: -50\n",
      "Ep: 45  tStep: 30 Z difference 0.012585474741086511  Reward: -50\n",
      "   Actionlist: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Ep: 46  tStep: 1 Z difference 0.000674659237265729  Reward: -1.9993253407627343\n",
      "Ep: 46  tStep: 2 Z difference -0.002083523722737901  Reward: -2.002083523722738\n",
      "Ep: 46  tStep: 3 Z difference -0.002119896655529807  Reward: -2.00211989665553\n",
      "Ep: 46  tStep: 4 Z difference -0.001342571882158694  Reward: -2.0013425718821587\n",
      "Ep: 46  tStep: 5 Z difference -0.0009663760248570519  Reward: -2.000966376024857\n",
      "Ep: 46  tStep: 6 Z difference 0.00028834349140538507  Reward: -1.9997116565085946\n",
      "Ep: 46  tStep: 7 Z difference -0.0004801813788710696  Reward: -2.000480181378871\n",
      "Ep: 46  tStep: 8 Z difference -0.0009979090109468736  Reward: -2.000997909010947\n",
      "Ep: 46  tStep: 9 Z difference -0.0022452952746303545  Reward: -2.0022452952746304\n",
      "Ep: 46  tStep: 10 Z difference -0.0002034244265409768  Reward: -2.000203424426541\n",
      "Ep: 46  tStep: 11 Z difference 0.0008420040611176738  Reward: -1.9991579959388823\n",
      "Ep: 46  tStep: 12 Z difference 0.001467090510949287  Reward: -1.9985329094890507\n",
      "Ep: 46  tStep: 13 Z difference 0.001864406135678287  Reward: -1.9981355938643217\n",
      "Ep: 46  tStep: 14 Z difference 0.0005524872492999044  Reward: -1.9994475127507\n",
      "Ep: 46  tStep: 15 Z difference 0.001288012482970835  Reward: -1.9987119875170292\n",
      "Ep: 46  tStep: 16 Z difference 0.0019911247402428778  Reward: -50\n",
      "--------------------------------------\n",
      "| approxkl           | 1.0687701e-09 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.19e-07     |\n",
      "| fps                | 0             |\n",
      "| n_updates          | 43            |\n",
      "| policy_entropy     | 0.0025657676  |\n",
      "| policy_loss        | 1.5894575e-08 |\n",
      "| serial_timesteps   | 1290          |\n",
      "| time_elapsed       | 1.83e+03      |\n",
      "| total_timesteps    | 1290          |\n",
      "| value_loss         | 22734.076     |\n",
      "--------------------------------------\n",
      "Ep: 46  tStep: 17 Z difference 0.001813366697728469  Reward: -50\n",
      "Ep: 46  tStep: 18 Z difference 0.001280385900288561  Reward: -50\n",
      "Ep: 46  tStep: 19 Z difference 0.0022530685223638436  Reward: -50\n",
      "Ep: 46  tStep: 20 Z difference 0.0011664271552116467  Reward: -50\n",
      "Ep: 46  tStep: 21 Z difference 0.00348432163037371  Reward: -50\n",
      "Ep: 46  tStep: 22 Z difference 0.0021649228263647124  Reward: -50\n",
      "Ep: 46  tStep: 23 Z difference 0.0031461120214313354  Reward: -50\n",
      "Ep: 46  tStep: 24 Z difference 0.0028541019037366944  Reward: -50\n",
      "Ep: 46  tStep: 25 Z difference 0.005064930891245378  Reward: -50\n",
      "Ep: 46  tStep: 26 Z difference 0.005207195991277835  Reward: -50\n",
      "Ep: 46  tStep: 27 Z difference 0.0062436779107897245  Reward: -50\n",
      "Ep: 46  tStep: 28 Z difference 0.006445195691660022  Reward: -50\n",
      "Ep: 46  tStep: 29 Z difference 0.005012864797934835  Reward: -50\n",
      "Ep: 46  tStep: 30 Z difference 0.006330063626170279  Reward: -50\n",
      "   Actionlist: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Ep: 47  tStep: 1 Z difference 0.0016174221888185514  Reward: -1.9983825778111814\n",
      "Ep: 47  tStep: 2 Z difference 0.00011073211394263538  Reward: -1.9998892678860574\n",
      "Ep: 47  tStep: 3 Z difference 0.0015179832838478902  Reward: -1.998482016716152\n",
      "Ep: 47  tStep: 4 Z difference 0.0032927770730108996  Reward: -1.996707222926989\n",
      "Ep: 47  tStep: 5 Z difference 0.004337912230566232  Reward: -1.9956620877694338\n",
      "Ep: 47  tStep: 6 Z difference 0.005048944400623423  Reward: -1.9949510555993766\n",
      "Ep: 47  tStep: 7 Z difference 0.005739443463459892  Reward: -1.99426055653654\n",
      "Ep: 47  tStep: 8 Z difference 0.004720414685085661  Reward: -1.9952795853149143\n",
      "Ep: 47  tStep: 9 Z difference 0.004072008492052692  Reward: -1.9959279915079473\n",
      "Ep: 47  tStep: 10 Z difference 0.004357418682426228  Reward: -1.9956425813175738\n",
      "Ep: 47  tStep: 11 Z difference 0.004480910655856096  Reward: -1.995519089344144\n",
      "Ep: 47  tStep: 12 Z difference 0.006679126448929207  Reward: -1.9933208735510708\n",
      "Ep: 47  tStep: 13 Z difference 0.006405302797630519  Reward: -1.9935946972023695\n",
      "Ep: 47  tStep: 14 Z difference 0.006846177942678278  Reward: -1.9931538220573217\n",
      "Ep: 47  tStep: 15 Z difference 0.007759607883915276  Reward: -1.9922403921160847\n",
      "Ep: 47  tStep: 16 Z difference 0.008674211145565103  Reward: -50\n",
      "--------------------------------------\n",
      "| approxkl           | 2.4643773e-10 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 0             |\n",
      "| n_updates          | 44            |\n",
      "| policy_entropy     | 0.0019709854  |\n",
      "| policy_loss        | 7.152558e-08  |\n",
      "| serial_timesteps   | 1320          |\n",
      "| time_elapsed       | 1.87e+03      |\n",
      "| total_timesteps    | 1320          |\n",
      "| value_loss         | 22651.887     |\n",
      "--------------------------------------\n",
      "Ep: 47  tStep: 17 Z difference 0.008938941563665814  Reward: -50\n",
      "Ep: 47  tStep: 18 Z difference 0.008628158319369028  Reward: -50\n",
      "Ep: 47  tStep: 19 Z difference 0.008452600252628617  Reward: -50\n",
      "Ep: 47  tStep: 20 Z difference 0.008584598799049825  Reward: -50\n",
      "Ep: 47  tStep: 21 Z difference 0.007813580622896499  Reward: -50\n",
      "Ep: 47  tStep: 22 Z difference 0.008846982576325768  Reward: -50\n",
      "Ep: 47  tStep: 23 Z difference 0.009466055759042469  Reward: -50\n",
      "Ep: 47  tStep: 24 Z difference 0.009426309530064625  Reward: -50\n",
      "Ep: 47  tStep: 25 Z difference 0.00995049042440943  Reward: -50\n",
      "Ep: 47  tStep: 26 Z difference 0.010184127851575742  Reward: -50\n",
      "Ep: 47  tStep: 27 Z difference 0.009487468856573145  Reward: -50\n",
      "Ep: 47  tStep: 28 Z difference 0.009842251616344111  Reward: -50\n",
      "Ep: 47  tStep: 29 Z difference 0.006968203265592443  Reward: -50\n",
      "Ep: 47  tStep: 30 Z difference 0.007471264392510335  Reward: -50\n",
      "   Actionlist: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Ep: 48  tStep: 1 Z difference 0.000317236506566676  Reward: -1.9996827634934333\n",
      "Ep: 48  tStep: 2 Z difference 0.0021256165925414017  Reward: -1.9978743834074586\n",
      "Ep: 48  tStep: 3 Z difference 0.004348472114279911  Reward: -1.99565152788572\n",
      "Ep: 48  tStep: 4 Z difference 0.004460670878738249  Reward: -1.9955393291212618\n",
      "Ep: 48  tStep: 5 Z difference 0.00511333035826711  Reward: -1.994886669641733\n",
      "Ep: 48  tStep: 6 Z difference 0.006582034184783758  Reward: -1.9934179658152162\n",
      "Ep: 48  tStep: 7 Z difference 0.006405596127733837  Reward: -1.9935944038722662\n",
      "Ep: 48  tStep: 8 Z difference 0.005283315153047585  Reward: -1.9947166848469524\n",
      "Ep: 48  tStep: 9 Z difference 0.004809293706342643  Reward: -1.9951907062936574\n",
      "Ep: 48  tStep: 10 Z difference 0.0031308588560672312  Reward: -1.9968691411439328\n",
      "Ep: 48  tStep: 11 Z difference 0.0026496508218349923  Reward: -1.997350349178165\n",
      "Ep: 48  tStep: 12 Z difference 0.0026543441034854176  Reward: -1.9973456558965146\n",
      "Ep: 48  tStep: 13 Z difference 0.0025040124256165974  Reward: -1.9974959875743834\n",
      "Ep: 48  tStep: 14 Z difference 0.0017608606092633927  Reward: -1.9982391393907366\n",
      "Ep: 48  tStep: 15 Z difference 0.0009286831066015466  Reward: -1.9990713168933985\n",
      "Ep: 48  tStep: 16 Z difference 0.0010313486427069307  Reward: -50\n",
      "-------------------------------------\n",
      "| approxkl           | 7.124178e-11 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 0            |\n",
      "| n_updates          | 45           |\n",
      "| policy_entropy     | 0.0016585088 |\n",
      "| policy_loss        | 4.768372e-08 |\n",
      "| serial_timesteps   | 1350         |\n",
      "| time_elapsed       | 1.91e+03     |\n",
      "| total_timesteps    | 1350         |\n",
      "| value_loss         | 22569.736    |\n",
      "-------------------------------------\n",
      "Ep: 48  tStep: 17 Z difference 0.0021986557882280877  Reward: -50\n",
      "Ep: 48  tStep: 18 Z difference 0.0035193745777011287  Reward: -50\n",
      "Ep: 48  tStep: 19 Z difference 0.003641399900615294  Reward: -50\n",
      "Ep: 48  tStep: 20 Z difference 0.002886221550032708  Reward: -50\n",
      "Ep: 48  tStep: 21 Z difference 0.0024526796575634613  Reward: -50\n",
      "Ep: 48  tStep: 22 Z difference 0.002441386448591931  Reward: -50\n",
      "Ep: 48  tStep: 23 Z difference 0.0031399520892652077  Reward: -50\n",
      "Ep: 48  tStep: 24 Z difference 0.0027925025820731975  Reward: -50\n",
      "Ep: 48  tStep: 25 Z difference 0.0018800992961973684  Reward: -50\n",
      "Ep: 48  tStep: 26 Z difference 0.0045328300841154245  Reward: -50\n",
      "Ep: 48  tStep: 27 Z difference 0.004411391421407451  Reward: -50\n",
      "Ep: 48  tStep: 28 Z difference 0.0035338944178073817  Reward: -50\n",
      "Ep: 48  tStep: 29 Z difference 0.004327645676955871  Reward: -50\n",
      "Ep: 48  tStep: 30 Z difference 0.004194180480018517  Reward: -50\n",
      "   Actionlist: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Ep: 49  tStep: 1 Z difference 0.0020954035919160674  Reward: -1.997904596408084\n",
      "Ep: 49  tStep: 2 Z difference 0.0005316608119754207  Reward: -1.9994683391880246\n",
      "Ep: 49  tStep: 3 Z difference 0.0032850038252769664  Reward: -1.996714996174723\n",
      "Ep: 49  tStep: 4 Z difference 0.0033505631033330374  Reward: -1.996649436896667\n",
      "Ep: 49  tStep: 5 Z difference 0.0015844225522130273  Reward: -1.998415577447787\n",
      "Ep: 49  tStep: 6 Z difference 0.0015379297308624196  Reward: -1.9984620702691376\n",
      "Ep: 49  tStep: 7 Z difference 0.0006799391791223464  Reward: -1.9993200608208777\n",
      "Ep: 49  tStep: 8 Z difference 0.0017231676910074434  Reward: -1.9982768323089926\n",
      "Ep: 49  tStep: 9 Z difference 0.0027006902597843663  Reward: -1.9972993097402156\n",
      "Ep: 49  tStep: 10 Z difference 0.003331349981576359  Reward: -1.9966686500184236\n",
      "Ep: 49  tStep: 11 Z difference 0.0016247554413975074  Reward: -1.9983752445586025\n",
      "Ep: 49  tStep: 12 Z difference -0.0005021811366079376  Reward: -2.000502181136608\n",
      "Ep: 49  tStep: 13 Z difference -0.0006073399785906375  Reward: -2.0006073399785906\n",
      "Ep: 49  tStep: 14 Z difference -0.0015567028574645647  Reward: -2.0015567028574646\n",
      "Ep: 49  tStep: 15 Z difference 0.001010815535485765  Reward: -1.9989891844645142\n",
      "Ep: 49  tStep: 16 Z difference 0.0008072444438935733  Reward: -50\n",
      "--------------------------------------\n",
      "| approxkl           | 2.3265665e-11 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 0             |\n",
      "| n_updates          | 46            |\n",
      "| policy_entropy     | 0.0014815676  |\n",
      "| policy_loss        | -7.947286e-08 |\n",
      "| serial_timesteps   | 1380          |\n",
      "| time_elapsed       | 1.95e+03      |\n",
      "| total_timesteps    | 1380          |\n",
      "| value_loss         | 22486.918     |\n",
      "--------------------------------------\n",
      "Ep: 49  tStep: 17 Z difference 0.0009080033343287219  Reward: -50\n",
      "Ep: 49  tStep: 18 Z difference 0.001791366939991601  Reward: -50\n",
      "Ep: 49  tStep: 19 Z difference 0.0009326430629936766  Reward: -50\n",
      "Ep: 49  tStep: 20 Z difference -0.0004552483201027968  Reward: -50\n",
      "Ep: 49  tStep: 21 Z difference 6.438595764324262e-05  Reward: -50\n",
      "Ep: 49  tStep: 22 Z difference 0.0003974622897802149  Reward: -50\n",
      "Ep: 49  tStep: 23 Z difference 0.001207346704602319  Reward: -50\n",
      "Ep: 49  tStep: 24 Z difference 0.0013776248294861126  Reward: -50\n",
      "Ep: 49  tStep: 25 Z difference 0.00266710396297265  Reward: -50\n",
      "Ep: 49  tStep: 26 Z difference 0.003947489863261655  Reward: -50\n",
      "Ep: 49  tStep: 27 Z difference 0.0036311333470044893  Reward: -50\n",
      "Ep: 49  tStep: 28 Z difference 0.0020408441927282084  Reward: -50\n",
      "Ep: 49  tStep: 29 Z difference 0.0022090690068901075  Reward: -50\n",
      "Ep: 49  tStep: 30 Z difference 0.003820331263542087  Reward: -50\n",
      "   Actionlist: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Ep: 50  tStep: 1 Z difference 0.0016640616752208182  Reward: -1.9983359383247792\n",
      "Ep: 50  tStep: 2 Z difference -0.0013249720759689332  Reward: -2.001324972075969\n",
      "Ep: 50  tStep: 3 Z difference -0.00024742394201471285  Reward: -2.0002474239420147\n",
      "Ep: 50  tStep: 4 Z difference 0.0007500450737776276  Reward: -1.9992499549262224\n",
      "Ep: 50  tStep: 5 Z difference 0.0017539673518389698  Reward: -1.998246032648161\n",
      "Ep: 50  tStep: 6 Z difference 0.0019573917783799466  Reward: -1.99804260822162\n",
      "Ep: 50  tStep: 7 Z difference 0.00386301079355178  Reward: -1.9961369892064482\n",
      "Ep: 50  tStep: 8 Z difference 0.0031054858021439813  Reward: -1.996894514197856\n",
      "Ep: 50  tStep: 9 Z difference 0.004848159945011421  Reward: -1.9951518400549886\n",
      "Ep: 50  tStep: 10 Z difference 0.005672124204784801  Reward: -1.9943278757952152\n",
      "Ep: 50  tStep: 11 Z difference 0.0041314078379421915  Reward: -1.9958685921620578\n",
      "Ep: 50  tStep: 12 Z difference 0.004996438312157903  Reward: -1.995003561687842\n",
      "Ep: 50  tStep: 13 Z difference 0.005865282077714973  Reward: -1.994134717922285\n",
      "Ep: 50  tStep: 14 Z difference 0.005437166792154446  Reward: -1.9945628332078456\n",
      "Ep: 50  tStep: 15 Z difference 0.005596445038169584  Reward: -1.9944035549618304\n",
      "Ep: 50  tStep: 16 Z difference 0.0059372946180404895  Reward: -50\n",
      "--------------------------------------\n",
      "| approxkl           | 8.696979e-12  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 0             |\n",
      "| n_updates          | 47            |\n",
      "| policy_entropy     | 0.0013766761  |\n",
      "| policy_loss        | -7.947286e-09 |\n",
      "| serial_timesteps   | 1410          |\n",
      "| time_elapsed       | 1.99e+03      |\n",
      "| total_timesteps    | 1410          |\n",
      "| value_loss         | 22402.83      |\n",
      "--------------------------------------\n",
      "Ep: 50  tStep: 17 Z difference 0.007508370650559648  Reward: -50\n",
      "Ep: 50  tStep: 18 Z difference 0.0071521212402729795  Reward: -50\n",
      "Ep: 50  tStep: 19 Z difference 0.007023935985192686  Reward: -50\n",
      "Ep: 50  tStep: 20 Z difference 0.006982576440647481  Reward: -50\n",
      "Ep: 50  tStep: 21 Z difference 0.0056270980339498955  Reward: -50\n",
      "Ep: 50  tStep: 22 Z difference 0.006538474664464555  Reward: -50\n",
      "Ep: 50  tStep: 23 Z difference 0.006319210412353282  Reward: -50\n",
      "Ep: 50  tStep: 24 Z difference 0.007014109426736859  Reward: -50\n",
      "Ep: 50  tStep: 25 Z difference 0.005844895635545466  Reward: -50\n",
      "Ep: 50  tStep: 26 Z difference 0.005368527548015312  Reward: -50\n",
      "Ep: 50  tStep: 27 Z difference 0.007769874437526081  Reward: -50\n",
      "Ep: 50  tStep: 28 Z difference 0.007291013044119055  Reward: -50\n",
      "Ep: 50  tStep: 29 Z difference 0.005998600609600668  Reward: -50\n",
      "Ep: 50  tStep: 30 Z difference 0.007743621393293321  Reward: -50\n",
      "   Actionlist: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Ep: 51  tStep: 1 Z difference 0.000496167869493469  Reward: -1.9995038321305065\n",
      "Ep: 51  tStep: 2 Z difference 0.001448317384347586  Reward: -1.9985516826156524\n",
      "Ep: 51  tStep: 3 Z difference 0.0017652605608104999  Reward: -1.9982347394391895\n",
      "Ep: 51  tStep: 4 Z difference 0.0051964894425124974  Reward: -1.9948035105574875\n",
      "Ep: 51  tStep: 5 Z difference 0.004139327750727784  Reward: -1.9958606722492722\n",
      "Ep: 51  tStep: 6 Z difference 0.003826344530657  Reward: -1.996173655469343\n",
      "Ep: 51  tStep: 7 Z difference 0.004379125110060222  Reward: -1.9956208748899398\n",
      "Ep: 51  tStep: 8 Z difference 0.0034793350186199667  Reward: -1.99652066498138\n",
      "Ep: 51  tStep: 9 Z difference 0.003772371791675777  Reward: -1.9962276282083242\n",
      "Ep: 51  tStep: 10 Z difference 0.004771894118190012  Reward: -1.99522810588181\n",
      "Ep: 51  tStep: 11 Z difference 0.002882261593640134  Reward: -1.9971177384063599\n",
      "Ep: 51  tStep: 12 Z difference 0.0024471063856035258  Reward: -1.9975528936143965\n",
      "Ep: 51  tStep: 13 Z difference 0.004423711285740151  Reward: -1.9955762887142598\n",
      "Ep: 51  tStep: 14 Z difference 0.003129978865757721  Reward: -1.9968700211342423\n",
      "Ep: 51  tStep: 15 Z difference 0.0030925792776050898  Reward: -1.996907420722395\n",
      "Ep: 51  tStep: 16 Z difference 0.003267990679293842  Reward: -50\n",
      "---------------------------------------\n",
      "| approxkl           | 3.1737523e-12  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 1.79e-07       |\n",
      "| fps                | 0              |\n",
      "| n_updates          | 48             |\n",
      "| policy_entropy     | 0.0013128079   |\n",
      "| policy_loss        | -5.5631006e-08 |\n",
      "| serial_timesteps   | 1440           |\n",
      "| time_elapsed       | 2.03e+03       |\n",
      "| total_timesteps    | 1440           |\n",
      "| value_loss         | 22318.71       |\n",
      "---------------------------------------\n",
      "Ep: 51  tStep: 17 Z difference 0.005434820151329234  Reward: -50\n",
      "Ep: 51  tStep: 18 Z difference 0.0024239333074542735  Reward: -50\n",
      "Ep: 51  tStep: 19 Z difference 0.0025043057557194714  Reward: -50\n",
      "Ep: 51  tStep: 20 Z difference 0.0046970949418843055  Reward: -50\n",
      "Ep: 51  tStep: 21 Z difference 0.004243606602400529  Reward: -50\n",
      "Ep: 51  tStep: 22 Z difference 0.004197847106307773  Reward: -50\n",
      "Ep: 51  tStep: 23 Z difference 0.002228575458750104  Reward: -50\n",
      "Ep: 51  tStep: 24 Z difference 0.004283352831378817  Reward: -50\n",
      "Ep: 51  tStep: 25 Z difference 0.0058532555434855915  Reward: -50\n",
      "Ep: 51  tStep: 26 Z difference 0.00450364373885126  Reward: -50\n",
      "Ep: 51  tStep: 27 Z difference 0.005402553839981561  Reward: -50\n",
      "Ep: 51  tStep: 28 Z difference 0.0055833918485790335  Reward: -50\n",
      "Ep: 51  tStep: 29 Z difference 0.005061410930007781  Reward: -50\n",
      "Ep: 51  tStep: 30 Z difference 0.005563298736512845  Reward: -50\n",
      "   Actionlist: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Ep: 52  tStep: 1 Z difference 0.0011548406161367986  Reward: -1.9988451593838632\n",
      "Ep: 52  tStep: 2 Z difference 0.0020744304895399246  Reward: -1.99792556951046\n",
      "Ep: 52  tStep: 3 Z difference 0.0012830258712170917  Reward: -1.998716974128783\n",
      "Ep: 52  tStep: 4 Z difference 0.006218011526763156  Reward: -1.9937819884732368\n",
      "Ep: 52  tStep: 5 Z difference 0.0018856725681573039  Reward: -1.9981143274318427\n",
      "Ep: 52  tStep: 6 Z difference 0.0065578344512728926  Reward: -1.993442165548727\n",
      "Ep: 52  tStep: 7 Z difference 0.002906901322305089  Reward: -1.997093098677695\n",
      "Ep: 52  tStep: 8 Z difference 0.006612980510666944  Reward: -1.993387019489333\n",
      "Ep: 52  tStep: 9 Z difference 0.0017976735372093877  Reward: -1.9982023264627906\n",
      "Ep: 52  tStep: 10 Z difference 0.0028919414870438587  Reward: -1.9971080585129561\n",
      "Ep: 52  tStep: 11 Z difference 0.0010938279546794938  Reward: -1.9989061720453205\n",
      "Ep: 52  tStep: 12 Z difference 0.0010292953319845921  Reward: -1.9989707046680154\n",
      "Ep: 52  tStep: 13 Z difference -0.0005172876369208268  Reward: -2.000517287636921\n",
      "Ep: 52  tStep: 14 Z difference 0.004008062529563539  Reward: -1.9959919374704365\n",
      "Ep: 52  tStep: 15 Z difference -0.0013296653576198025  Reward: -2.00132966535762\n",
      "Ep: 52  tStep: 16 Z difference 0.0026437842197712946  Reward: -50\n",
      "--------------------------------------\n",
      "| approxkl           | 1.1316847e-12 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0             |\n",
      "| fps                | 0             |\n",
      "| n_updates          | 49            |\n",
      "| policy_entropy     | 0.0012735617  |\n",
      "| policy_loss        | 5.5631006e-08 |\n",
      "| serial_timesteps   | 1470          |\n",
      "| time_elapsed       | 2.07e+03      |\n",
      "| total_timesteps    | 1470          |\n",
      "| value_loss         | 22234.23      |\n",
      "--------------------------------------\n",
      "Ep: 52  tStep: 17 Z difference -0.00013463851735018295  Reward: -50\n",
      "Ep: 52  tStep: 18 Z difference 0.005759683240577296  Reward: -50\n",
      "Ep: 52  tStep: 19 Z difference 0.0005894468422975585  Reward: -50\n",
      "Ep: 52  tStep: 20 Z difference 0.0026030113354322815  Reward: -50\n",
      "Ep: 52  tStep: 21 Z difference 0.0026426108993589104  Reward: -50\n",
      "Ep: 52  tStep: 22 Z difference 0.006540674640238109  Reward: -50\n",
      "Ep: 52  tStep: 23 Z difference 0.002878448302298775  Reward: -50\n",
      "Ep: 52  tStep: 24 Z difference 0.0077321815192696874  Reward: -50\n",
      "Ep: 52  tStep: 25 Z difference 0.00513225014992047  Reward: -50\n",
      "Ep: 52  tStep: 26 Z difference 0.010096568815782359  Reward: -50\n",
      "Ep: 52  tStep: 27 Z difference 0.00541311372369524  Reward: -50\n",
      "Ep: 52  tStep: 28 Z difference 0.008925155048816968  Reward: -50\n",
      "Ep: 52  tStep: 29 Z difference 0.007605462914705097  Reward: -50\n",
      "Ep: 52  tStep: 30 Z difference 0.010440058366581795  Reward: -50\n",
      "   Actionlist: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Ep: 53  tStep: 1 Z difference 0.000488834616914513  Reward: -1.9995111653830855\n",
      "Ep: 53  tStep: 2 Z difference 0.0005938467938451097  Reward: -1.999406153206155\n",
      "Ep: 53  tStep: 3 Z difference 0.0011560139365491828  Reward: -1.9988439860634508\n",
      "Ep: 53  tStep: 4 Z difference 0.005786229614913374  Reward: -1.9942137703850866\n",
      "Ep: 53  tStep: 5 Z difference 0.003608840259164303  Reward: -1.9963911597408357\n",
      "Ep: 53  tStep: 6 Z difference 0.004661455334350251  Reward: -1.9953385446656497\n",
      "Ep: 53  tStep: 7 Z difference 0.004672308548167248  Reward: -1.9953276914518328\n",
      "Ep: 53  tStep: 8 Z difference 0.005446260025351979  Reward: -1.994553739974648\n",
      "Ep: 53  tStep: 9 Z difference 0.002098336892947472  Reward: -1.9979016631070525\n",
      "Ep: 53  tStep: 10 Z difference 0.006154212229326106  Reward: -1.993845787770674\n",
      "Ep: 53  tStep: 11 Z difference 0.005579725222289333  Reward: -1.9944202747777107\n",
      "Ep: 53  tStep: 12 Z difference 0.005933187996595812  Reward: -1.9940668120034042\n",
      "Ep: 53  tStep: 13 Z difference 0.006847937923297298  Reward: -1.9931520620767027\n",
      "Ep: 53  tStep: 14 Z difference 0.008117470609769306  Reward: -1.9918825293902307\n",
      "Ep: 53  tStep: 15 Z difference 0.005382020732760395  Reward: -1.9946179792672396\n",
      "Ep: 53  tStep: 16 Z difference 0.006104786106944093  Reward: -50\n",
      "--------------------------------------\n",
      "| approxkl           | 4.706232e-13  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 5.96e-08      |\n",
      "| fps                | 0             |\n",
      "| n_updates          | 50            |\n",
      "| policy_entropy     | 0.0012495437  |\n",
      "| policy_loss        | 1.5894572e-07 |\n",
      "| serial_timesteps   | 1500          |\n",
      "| time_elapsed       | 2.11e+03      |\n",
      "| total_timesteps    | 1500          |\n",
      "| value_loss         | 22148.799     |\n",
      "--------------------------------------\n",
      "Ep: 53  tStep: 17 Z difference 0.008381761032715485  Reward: -50\n",
      "Ep: 53  tStep: 18 Z difference 0.009704533132910864  Reward: -50\n",
      "Ep: 53  tStep: 19 Z difference 0.008883062179013912  Reward: -50\n",
      "Ep: 53  tStep: 20 Z difference 0.010217567483335799  Reward: -50\n",
      "Ep: 53  tStep: 21 Z difference 0.010092902189493103  Reward: -50\n",
      "Ep: 53  tStep: 22 Z difference 0.00992071741893863  Reward: -50\n",
      "Ep: 53  tStep: 23 Z difference 0.01168861795067766  Reward: -50\n",
      "Ep: 53  tStep: 24 Z difference 0.012281584754213704  Reward: -50\n",
      "Ep: 53  tStep: 25 Z difference 0.010895453351735807  Reward: -50\n",
      "Ep: 53  tStep: 26 Z difference 0.014452667512744544  Reward: -50\n",
      "Ep: 53  tStep: 27 Z difference 0.014974941761419114  Reward: -50\n",
      "Ep: 53  tStep: 28 Z difference 0.014841769894585077  Reward: -50\n",
      "Ep: 53  tStep: 29 Z difference 0.014966728518530648  Reward: -50\n",
      "Ep: 53  tStep: 30 Z difference 0.014958075280487648  Reward: -50\n",
      "   Actionlist: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Ep: 54  tStep: 1 Z difference 0.0025163322899488527  Reward: -1.9974836677100511\n",
      "Ep: 54  tStep: 2 Z difference -3.563960753361073e-05  Reward: -2.0000356396075336\n",
      "Ep: 54  tStep: 3 Z difference 0.0021839892830701757  Reward: -1.9978160107169298\n",
      "Ep: 54  tStep: 4 Z difference 0.0027715294796974987  Reward: -1.9972284705203025\n",
      "Ep: 54  tStep: 5 Z difference 0.003367722914367821  Reward: -1.9966322770856322\n",
      "Ep: 54  tStep: 6 Z difference 0.0038613974779844185  Reward: -1.9961386025220156\n",
      "Ep: 54  tStep: 7 Z difference 0.004781280681490863  Reward: -1.9952187193185091\n",
      "Ep: 54  tStep: 8 Z difference 0.004413004736974813  Reward: -1.9955869952630252\n",
      "Ep: 54  tStep: 9 Z difference 0.005640884548798297  Reward: -1.9943591154512017\n",
      "Ep: 54  tStep: 10 Z difference 0.004169980746507651  Reward: -1.9958300192534923\n",
      "Ep: 54  tStep: 11 Z difference 0.005821869222447429  Reward: -1.9941781307775526\n",
      "Ep: 54  tStep: 12 Z difference 0.005103943794965815  Reward: -1.9948960562050342\n",
      "Ep: 54  tStep: 13 Z difference 0.005653791073337189  Reward: -1.9943462089266628\n",
      "Ep: 54  tStep: 14 Z difference 0.007490330849215354  Reward: -1.9925096691507846\n",
      "Ep: 54  tStep: 15 Z difference 0.007962885645404594  Reward: -1.9920371143545954\n",
      "Ep: 54  tStep: 16 Z difference 0.008648838091641853  Reward: -50\n",
      "---------------------------------------\n",
      "| approxkl           | 1.5095604e-13  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 5.96e-08       |\n",
      "| fps                | 0              |\n",
      "| n_updates          | 51             |\n",
      "| policy_entropy     | 0.0012352406   |\n",
      "| policy_loss        | -1.2715658e-07 |\n",
      "| serial_timesteps   | 1530           |\n",
      "| time_elapsed       | 2.16e+03       |\n",
      "| total_timesteps    | 1530           |\n",
      "| value_loss         | 22063.396      |\n",
      "---------------------------------------\n",
      "Ep: 54  tStep: 17 Z difference 0.008567438988015041  Reward: -50\n",
      "Ep: 54  tStep: 18 Z difference 0.007523623815923752  Reward: -50\n",
      "Ep: 54  tStep: 19 Z difference 0.007846580259502023  Reward: -50\n",
      "Ep: 54  tStep: 20 Z difference 0.007912139537558094  Reward: -50\n",
      "Ep: 54  tStep: 21 Z difference 0.008688144325465164  Reward: -50\n",
      "Ep: 54  tStep: 22 Z difference 0.009680920059606635  Reward: -50\n",
      "Ep: 54  tStep: 23 Z difference 0.008337028191983897  Reward: -50\n",
      "Ep: 54  tStep: 24 Z difference 0.007280599825456591  Reward: -50\n",
      "Ep: 54  tStep: 25 Z difference 0.00775506126731651  Reward: -50\n",
      "Ep: 54  tStep: 26 Z difference 0.007515703903138604  Reward: -50\n",
      "Ep: 54  tStep: 27 Z difference 0.008356534643843894  Reward: -50\n",
      "Ep: 54  tStep: 28 Z difference 0.008975461161508935  Reward: -50\n",
      "Ep: 54  tStep: 29 Z difference 0.009562268032878851  Reward: -50\n",
      "Ep: 54  tStep: 30 Z difference 0.007950565781071894  Reward: -50\n",
      "   Actionlist: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Ep: 55  tStep: 1 Z difference 0.0011913602139803636  Reward: -1.9988086397860196\n",
      "Ep: 55  tStep: 2 Z difference -0.001240639671310717  Reward: -2.0012406396713107\n",
      "Ep: 55  tStep: 3 Z difference 0.001426464291661933  Reward: -1.998573535708338\n",
      "Ep: 55  tStep: 4 Z difference 0.0025268921736629757  Reward: -1.997473107826337\n",
      "Ep: 55  tStep: 5 Z difference 0.0018865525584668141  Reward: -1.9981134474415332\n",
      "Ep: 55  tStep: 6 Z difference 4.23861999063746e-05  Reward: -1.9999576138000936\n",
      "Ep: 55  tStep: 7 Z difference 0.001743994128331483  Reward: -1.9982560058716685\n",
      "Ep: 55  tStep: 8 Z difference 0.00258335821852107  Reward: -1.997416641781479\n",
      "Ep: 55  tStep: 9 Z difference 0.0028394353985787824  Reward: -1.9971605646014212\n",
      "Ep: 55  tStep: 10 Z difference 0.005012424802780302  Reward: -1.9949875751972197\n",
      "Ep: 55  tStep: 11 Z difference 0.005170089733228078  Reward: -1.994829910266772\n",
      "Ep: 55  tStep: 12 Z difference 0.0046020559884607515  Reward: -1.9953979440115392\n",
      "Ep: 55  tStep: 13 Z difference 0.005913388214632942  Reward: -1.994086611785367\n",
      "Ep: 55  tStep: 14 Z difference 0.007441784717142852  Reward: -1.9925582152828571\n",
      "Ep: 55  tStep: 15 Z difference 0.007044322427362193  Reward: -1.9929556775726378\n",
      "Ep: 55  tStep: 16 Z difference 0.007303332908451754  Reward: -50\n",
      "---------------------------------------\n",
      "| approxkl           | 5.0081704e-14  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 5.96e-08       |\n",
      "| fps                | 0              |\n",
      "| n_updates          | 52             |\n",
      "| policy_entropy     | 0.0012271693   |\n",
      "| policy_loss        | -1.3510386e-07 |\n",
      "| serial_timesteps   | 1560           |\n",
      "| time_elapsed       | 2.2e+03        |\n",
      "| total_timesteps    | 1560           |\n",
      "| value_loss         | 21977.771      |\n",
      "---------------------------------------\n",
      "Ep: 55  tStep: 17 Z difference 0.008833782721683558  Reward: -50\n",
      "Ep: 55  tStep: 18 Z difference 0.008651038067415406  Reward: -50\n",
      "Ep: 55  tStep: 19 Z difference 0.008805329701677245  Reward: -50\n",
      "Ep: 55  tStep: 20 Z difference 0.009861611403152448  Reward: -50\n",
      "Ep: 55  tStep: 21 Z difference 0.011150357211381134  Reward: -50\n",
      "Ep: 55  tStep: 22 Z difference 0.007946165829524343  Reward: -50\n",
      "Ep: 55  tStep: 23 Z difference 0.009662586928159023  Reward: -50\n",
      "Ep: 55  tStep: 24 Z difference 0.009234471642598496  Reward: -50\n",
      "Ep: 55  tStep: 25 Z difference 0.009117579596489733  Reward: -50\n",
      "Ep: 55  tStep: 26 Z difference 0.010679122400656382  Reward: -50\n",
      "Ep: 55  tStep: 27 Z difference 0.010559003723412896  Reward: -50\n",
      "Ep: 55  tStep: 28 Z difference 0.010579096835479085  Reward: -50\n",
      "Ep: 55  tStep: 29 Z difference 0.009113032979890967  Reward: -50\n",
      "Ep: 55  tStep: 30 Z difference 0.00790436628982416  Reward: -50\n",
      "   Actionlist: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Ep: 56  tStep: 1 Z difference 0.000288196826353726  Reward: -1.9997118031736463\n",
      "Ep: 56  tStep: 2 Z difference -0.0010791614495215818  Reward: -2.0010791614495216\n",
      "Ep: 56  tStep: 3 Z difference -0.002765662877634245  Reward: -2.0027656628776342\n",
      "Ep: 56  tStep: 4 Z difference 0.00021691761128606046  Reward: -1.999783082388714\n",
      "Ep: 56  tStep: 5 Z difference -0.002926407774165085  Reward: -2.002926407774165\n",
      "Ep: 56  tStep: 6 Z difference 0.000777178108319454  Reward: -1.9992228218916805\n",
      "Ep: 56  tStep: 7 Z difference 0.0019270321127025092  Reward: -1.9980729678872975\n",
      "Ep: 56  tStep: 8 Z difference -0.0007717515014111775  Reward: -2.000771751501411\n",
      "Ep: 56  tStep: 9 Z difference -0.0012680660359563056  Reward: -2.0012680660359563\n",
      "Ep: 56  tStep: 10 Z difference -0.0015525962360203316  Reward: -2.0015525962360203\n",
      "Ep: 56  tStep: 11 Z difference -0.0014342375393958662  Reward: -2.001434237539396\n",
      "Ep: 56  tStep: 12 Z difference -0.0006790591888128361  Reward: -2.000679059188813\n",
      "Ep: 56  tStep: 13 Z difference -0.0011285875719040384  Reward: -2.001128587571904\n",
      "Ep: 56  tStep: 14 Z difference -0.00029465008862317177  Reward: -2.000294650088623\n",
      "Ep: 56  tStep: 15 Z difference -0.0003803024787454312  Reward: -2.0003803024787454\n",
      "Ep: 56  tStep: 16 Z difference 0.00012349197342986784  Reward: -50\n",
      "-------------------------------------\n",
      "| approxkl           | 8.820476e-15 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0            |\n",
      "| fps                | 0            |\n",
      "| n_updates          | 53           |\n",
      "| policy_entropy     | 0.0012232525 |\n",
      "| policy_loss        | 7.152558e-08 |\n",
      "| serial_timesteps   | 1590         |\n",
      "| time_elapsed       | 2.24e+03     |\n",
      "| total_timesteps    | 1590         |\n",
      "| value_loss         | 21892.332    |\n",
      "-------------------------------------\n",
      "Ep: 56  tStep: 17 Z difference 0.001918525539711169  Reward: -50\n",
      "Ep: 56  tStep: 18 Z difference 0.0022203622158616376  Reward: -50\n",
      "Ep: 56  tStep: 19 Z difference 0.0027530496831982276  Reward: -50\n",
      "Ep: 56  tStep: 20 Z difference 0.001969711642712202  Reward: -50\n",
      "Ep: 56  tStep: 21 Z difference 0.00425665979199108  Reward: -50\n",
      "Ep: 56  tStep: 22 Z difference 0.002101710189133854  Reward: -50\n",
      "Ep: 56  tStep: 23 Z difference 0.0027898626111446667  Reward: -50\n",
      "Ep: 56  tStep: 24 Z difference 0.002042604173347229  Reward: -50\n",
      "Ep: 56  tStep: 25 Z difference 0.0029101279534398117  Reward: -50\n",
      "Ep: 56  tStep: 26 Z difference 0.0049050659850240486  Reward: -50\n",
      "Ep: 56  tStep: 27 Z difference 0.005073730794340481  Reward: -50\n",
      "Ep: 56  tStep: 28 Z difference 0.0052626353807747606  Reward: -50\n",
      "Ep: 56  tStep: 29 Z difference 0.003922410139441279  Reward: -50\n",
      "Ep: 56  tStep: 30 Z difference 0.004596042721345839  Reward: -50\n",
      "   Actionlist: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Ep: 57  tStep: 1 Z difference -0.0009671093501153472  Reward: -2.0009671093501153\n",
      "Ep: 57  tStep: 2 Z difference -0.0004135954454542734  Reward: -2.0004135954454543\n",
      "Ep: 57  tStep: 3 Z difference 0.0001523849885907147  Reward: -1.9998476150114093\n",
      "Ep: 57  tStep: 4 Z difference 0.0012209865543990617  Reward: -1.998779013445601\n",
      "Ep: 57  tStep: 5 Z difference 0.0012028000880031087  Reward: -1.998797199911997\n",
      "Ep: 57  tStep: 6 Z difference 0.0026112245783207477  Reward: -1.9973887754216793\n",
      "Ep: 57  tStep: 7 Z difference 0.0018736460339274785  Reward: -1.9981263539660725\n",
      "Ep: 57  tStep: 8 Z difference 0.001576502639427435  Reward: -1.9984234973605726\n",
      "Ep: 57  tStep: 9 Z difference 0.0030559130147098656  Reward: -1.9969440869852901\n",
      "Ep: 57  tStep: 10 Z difference 0.00451127032153309  Reward: -1.995488729678467\n",
      "Ep: 57  tStep: 11 Z difference 0.0038147579915821517  Reward: -1.9961852420084178\n",
      "Ep: 57  tStep: 12 Z difference 0.005673297525197185  Reward: -1.9943267024748028\n",
      "Ep: 57  tStep: 13 Z difference 0.007337945860624195  Reward: -1.9926620541393758\n",
      "Ep: 57  tStep: 14 Z difference 0.007120588254183158  Reward: -1.9928794117458168\n",
      "Ep: 57  tStep: 15 Z difference 0.010229007357358544  Reward: -1.9897709926426415\n",
      "Ep: 57  tStep: 16 Z difference 0.010628816287964415  Reward: -50\n",
      "--------------------------------------\n",
      "| approxkl           | 1.3023436e-15 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 1.19e-07      |\n",
      "| fps                | 0             |\n",
      "| n_updates          | 54            |\n",
      "| policy_entropy     | 0.0012220176  |\n",
      "| policy_loss        | -7.947286e-09 |\n",
      "| serial_timesteps   | 1620          |\n",
      "| time_elapsed       | 2.28e+03      |\n",
      "| total_timesteps    | 1620          |\n",
      "| value_loss         | 21805.326     |\n",
      "--------------------------------------\n",
      "Ep: 57  tStep: 17 Z difference 0.010319499694183332  Reward: -50\n",
      "Ep: 57  tStep: 18 Z difference 0.010146288268268133  Reward: -50\n",
      "Ep: 57  tStep: 19 Z difference 0.010388578933477444  Reward: -50\n",
      "Ep: 57  tStep: 20 Z difference 0.011309195462241739  Reward: -50\n",
      "Ep: 57  tStep: 21 Z difference 0.012275278156995473  Reward: -50\n",
      "Ep: 57  tStep: 22 Z difference 0.012528275370970121  Reward: -50\n",
      "Ep: 57  tStep: 23 Z difference 0.01247870258353645  Reward: -50\n",
      "Ep: 57  tStep: 24 Z difference 0.01372066224031121  Reward: -50\n",
      "Ep: 57  tStep: 25 Z difference 0.013283893716707684  Reward: -50\n",
      "Ep: 57  tStep: 26 Z difference 0.014425387813150614  Reward: -50\n",
      "Ep: 57  tStep: 27 Z difference 0.015837918924912486  Reward: -50\n",
      "Ep: 57  tStep: 28 Z difference 0.01641401924751662  Reward: -50\n",
      "Ep: 57  tStep: 29 Z difference 0.013440971986949268  Reward: -50\n",
      "Ep: 57  tStep: 30 Z difference 0.014604319176077851  Reward: -50\n",
      "   Actionlist: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Ep: 58  tStep: 1 Z difference 0.001093974619731597  Reward: -1.9989060253802684\n",
      "Ep: 58  tStep: 2 Z difference 0.0003159165211021886  Reward: -1.9996840834788978\n",
      "Ep: 58  tStep: 3 Z difference -0.0006765658829359644  Reward: -2.000676565882936\n",
      "Ep: 58  tStep: 4 Z difference 0.004057928647100972  Reward: -1.995942071352899\n",
      "Ep: 58  tStep: 5 Z difference -0.000521687588467934  Reward: -2.000521687588468\n",
      "Ep: 58  tStep: 6 Z difference 0.0033869360361249434  Reward: -1.996613063963875\n",
      "Ep: 58  tStep: 7 Z difference 0.0026695972688495218  Reward: -1.9973304027311505\n",
      "Ep: 58  tStep: 8 Z difference 0.007338972515985365  Reward: -1.9926610274840146\n",
      "Ep: 58  tStep: 9 Z difference 0.005986280745267969  Reward: -1.994013719254732\n",
      "Ep: 58  tStep: 10 Z difference 0.005025917987525386  Reward: -1.9949740820124746\n",
      "Ep: 58  tStep: 11 Z difference 0.00447181742265812  Reward: -1.9955281825773419\n",
      "Ep: 58  tStep: 12 Z difference 0.0031327655017374667  Reward: -1.9968672344982625\n",
      "Ep: 58  tStep: 13 Z difference 0.0030845126997678385  Reward: -1.9969154873002322\n",
      "Ep: 58  tStep: 14 Z difference 0.0018404997322707395  Reward: -1.9981595002677293\n",
      "Ep: 58  tStep: 15 Z difference 0.0006173132020981242  Reward: -1.9993826867979019\n",
      "Ep: 58  tStep: 16 Z difference 0.0021768026955424347  Reward: -50\n",
      "---------------------------------------\n",
      "| approxkl           | 2.3087001e-15  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 1.19e-07       |\n",
      "| fps                | 0              |\n",
      "| n_updates          | 55             |\n",
      "| policy_entropy     | 0.0012225372   |\n",
      "| policy_loss        | -1.5099843e-07 |\n",
      "| serial_timesteps   | 1650           |\n",
      "| time_elapsed       | 2.32e+03       |\n",
      "| total_timesteps    | 1650           |\n",
      "| value_loss         | 21718.9        |\n",
      "---------------------------------------\n",
      "Ep: 58  tStep: 17 Z difference 0.0034026291966440247  Reward: -50\n",
      "Ep: 58  tStep: 18 Z difference 0.004496750481426837  Reward: -50\n",
      "Ep: 58  tStep: 19 Z difference 0.006389316307008119  Reward: -50\n",
      "Ep: 58  tStep: 20 Z difference 0.007008242824673605  Reward: -50\n",
      "Ep: 58  tStep: 21 Z difference 0.00817217667400838  Reward: -50\n",
      "Ep: 58  tStep: 22 Z difference 0.0074766909994186115  Reward: -50\n",
      "Ep: 58  tStep: 23 Z difference 0.006111826029420175  Reward: -50\n",
      "Ep: 58  tStep: 24 Z difference 0.005257062108814825  Reward: -50\n",
      "Ep: 58  tStep: 25 Z difference 0.004644002193212593  Reward: -50\n",
      "Ep: 58  tStep: 26 Z difference 0.006047733401879807  Reward: -50\n",
      "Ep: 58  tStep: 27 Z difference 0.0060830796793105435  Reward: -50\n",
      "Ep: 58  tStep: 28 Z difference 0.005569458668678973  Reward: -50\n",
      "Ep: 58  tStep: 29 Z difference 0.006630726981908364  Reward: -50\n",
      "Ep: 58  tStep: 30 Z difference 0.007188200842961567  Reward: -50\n",
      "   Actionlist: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "closing SnS socket\n",
      "socket DC Closed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-04329d2daf96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;31m#model.learn(total_timesteps=timesteps,b_log_name=\"first_run\", reset_num_timesteps=False)#50000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#50000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mtoday\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_rollout_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0;31m# true_reward is the reward without discount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 \u001b[0mrollout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m                 \u001b[0;31m# Unpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneglogpacs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep_infos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrollout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/stable_baselines/common/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callback)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m                 \u001b[0mclipped_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/stable_baselines/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/stable_baselines/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;31m# save final observation where user can get it, then reset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_infos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'terminal_observation'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         return (self._obs_from_buf(), np.copy(self.buf_rews), np.copy(self.buf_dones),\n",
      "\u001b[0;32m~/ScheragaThesis/UR5-RL/UR5_RL/envs/ur5_env_0.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m#if self.totalstepstaken>=410:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;31m#    print(\"reset\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresetEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#you *have* to compute and return the observation from reset()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisodeinitialpose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentpose\u001b[0m \u001b[0;31m#contains just initial xyz poses IN INCHES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ScheragaThesis/UR5-RL/UR5_RL/envs/ur5_env_0.py\u001b[0m in \u001b[0;36mresetEnvironment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock_DC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#receive the \"done\" command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock_DC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#48 bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://github.com/ZhizhenQin/BalancingBot/blob/master/balance-bot/balance_bot/balancebot_task.py\n",
    "\n",
    "\n",
    "#%load_ext tensorboard\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "import gym\n",
    "from stable_baselines import DQN, PPO2\n",
    "from stable_baselines import results_plotter\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines.results_plotter import load_results, ts2xy\n",
    "from stable_baselines.common.noise import AdaptiveParamNoiseSpec\n",
    "from stable_baselines.common.callbacks import BaseCallback\n",
    "from stable_baselines.deepq.policies import MlpPolicy\n",
    "from stable_baselines.common.policies import FeedForwardPolicy, register_policy,LstmPolicy\n",
    "from stable_baselines.common.tf_layers import conv, linear, conv_to_fc, lstm\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "from datetime import date\n",
    "import csv\n",
    "#import balance_bot\n",
    "import socket\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import UR5_RL\n",
    "\n",
    "HOST_SnS = '192.168.0.103'\n",
    "PORT_SnS= 65498\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    # Create a TCP/IP socket\n",
    "    sock_SnS = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    #sock_SnS.setblocking(False)\n",
    "    # Connect the socket to the port where the server is listening\n",
    "    server_address_SnS = (HOST_SnS, PORT_SnS)\n",
    "    print('connecting to {} port {}'.format(*server_address_SnS))\n",
    "    sock_SnS.connect(server_address_SnS)\n",
    "\n",
    "\n",
    "    #def callback(lcl, glb):\n",
    "         #stop training if reward exceeds 199\n",
    "    #    is_solved = lcl['t'] > 1000 and sum(lcl['episode_rewards'][-101:-1]) / 100 >= 1\n",
    "    #    return is_solved\n",
    "\n",
    "    #https://stable-baselines.readthedocs.io/en/master/guide/custom_policy.html\n",
    "    #Layers of 20 and 15\n",
    "\n",
    "    #Do this only after restarting the notebook!! \n",
    "    #register_policy('ScottLSTMPolicy', ScottLSTMPolicy)    \n",
    "    #print(\"lstm registered\")\n",
    "\n",
    "    #try:\n",
    "    \n",
    "    #code stopped at ep 36 at 10steps per ep, 80 ep\n",
    "    StepsPerEpisode=30 #was 10\n",
    "    TotalEpisodes=700  #was 80\n",
    "    env= gym.make(\"ur5-rl-v0\",StepsPerEpisode=StepsPerEpisode,TotalEpisodes=TotalEpisodes,\n",
    "                 continuousactionspace=False)\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "\n",
    "    timesteps=(StepsPerEpisode*TotalEpisodes)\n",
    "    print(\"Total timesteps:\",timesteps)\n",
    "    \n",
    "    class ScottLSTMPolicy(LstmPolicy):\n",
    "        def __init__(self, sess, ob_space, ac_space, n_env=1, n_steps=StepsPerEpisode,\n",
    "                     n_batch=StepsPerEpisode, n_lstm=StepsPerEpisode, reuse=False,  **_kwargs):\n",
    "            super().__init__(sess, ob_space, ac_space, n_env, n_steps, n_batch, n_lstm, reuse,\n",
    "                             net_arch=[7,'lstm',dict(vf=[20, 15],pi=[20,15])],\n",
    "                             layer_norm=True, feature_extraction=\"mlp\", **_kwargs)\n",
    "            \n",
    "    #model = DQN(\"LnMlpPolicy\", env, learning_rate=1e-3, prioritized_replay=True,gamma=1 , buffer_size=50000,param_noise=False,\n",
    "    # exploration_initial_eps=0.1, exploration_final_eps=0.1,learning_starts=1, verbose=1)\n",
    "\n",
    "\n",
    "    #model = PPO2(\"MlpPolicy\", env,verboThe new research shows that \"we must expect extreme event records to be broken - not just by small marse=0)\n",
    "    #model = PPO2(\"MlpLstmPolicy\", env,nminibatches=1, n_steps=80, #exploration_initial_eps=1, exploration_final_eps=0.1,\n",
    "    #             verbose=0,tensorboard_log=\"./ScottPPOLstm/\") #n_lstm=2, n_batch=80, nminibatches=10,\n",
    "\n",
    "    model = PPO2(ScottLSTMPolicy, env,nminibatches=1, n_steps=StepsPerEpisode,learning_rate=0.1,\n",
    "                 verbose=2)# DEFAULT learning_rate=0.00025  #n_lstm=2, n_batch=80, nminibatches=10,\n",
    "    ##exploration_initial_eps=1, exploration_final_eps=0.1,\n",
    "\n",
    "    #model.learn(total_timesteps=timesteps,b_log_name=\"first_run\", reset_num_timesteps=False)#50000\n",
    "    model.learn(total_timesteps=timesteps,reset_num_timesteps=False)#50000\n",
    "    \n",
    "    today = date.today()\n",
    "    todaydate = today.strftime(\"%m_%d_%Y\")\n",
    "    RLmodelfilename=\"UR5-RL_savedpolicy_\"+todaydate\n",
    "    model.save(RLmodelfilename)# save trained model\n",
    "    \n",
    "    del model\n",
    "    print(\"training complete\")\n",
    "    \n",
    "\n",
    "finally:\n",
    "    endmsg='end'\n",
    "    data1=endmsg.encode('ascii')    \n",
    "    sock_SnS.sendall(data1)\n",
    "    sock_SnS.sendall(data1)\n",
    "    print('closing SnS socket')\n",
    "    sock_SnS.close()\n",
    "    \n",
    "    HOST2 = '192.168.0.103'\n",
    "    PORT2= PORT_SnS-10 #65481\n",
    "    sock_DC = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    server_address_DC = (HOST2, PORT2)\n",
    "    sock_DC.close()\n",
    "    print(\"socket DC Closed\")\n",
    "      \n",
    "    #gitkraken\n",
    "    \n",
    "    #check_env(env)\n",
    "    #https://stable-baselines.readthedocs.io/en/master/modules/dqn.html\n",
    "    #model.learn(total_timesteps=25000)\n",
    "    #del model # remove to demonstrate saving and loading\n",
    "    #model = DQN.load(\"deepq_cartpole\")\n",
    "\n",
    "    \n",
    "    #Starting at 11:02AM\n",
    "    #80 episodes in 45 min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved!\n"
     ]
    }
   ],
   "source": [
    "model.save(\"UR5-RL_savedpolicy-8-5to6-2021\")\n",
    "print(\"saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST2 = '192.168.0.103'learning_rate=0.00025\n",
    "PORT2= 65485\n",
    "sock_DC = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "server_address_DC = (HOST2, PORT2)\n",
    "sock_DC.close()\n",
    "print(\"socket DC Closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 9] Bad file descriptor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5c92c6e2c5c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mendmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'end'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msock_SnS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'closing SnS socket'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msock_SnS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 9] Bad file descriptor"
     ]
    }
   ],
   "source": [
    "endmsg='end'\n",
    "data1=endmsg.encode('ascii')    \n",
    "sock_SnS.sendall(data1)\n",
    "\n",
    "\n",
    "#print('closing SnS socket')\n",
    "#sock_SnS.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "/home/scott/.local/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/stable_baselines/common/policies.py:346: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/stable_baselines/common/policies.py:442: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/stable_baselines/common/tf_layers.py:121: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/stable_baselines/common/distributions.py:326: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/stable_baselines/common/distributions.py:327: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "#import tensorflow.contrib.layers as layers\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#from tensorflow.keras import layers\n",
    "#from keras.utils import to_categorical\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense, Dropout, Embedding, LSTM, GlobalMaxPooling1D, SpatialDropout1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "import gym\n",
    "from stable_baselines import DQN,PPO2\n",
    "from stable_baselines import results_plotter\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines.results_plotter import load_results, ts2xy\n",
    "from stable_baselines.common.noise import AdaptiveParamNoiseSpec\n",
    "from stable_baselines.common.callbacks import BaseCallback\n",
    "from stable_baselines.deepq.policies import MlpPolicy\n",
    "from stable_baselines.common.policies import FeedForwardPolicy, register_policy,LstmPolicy\n",
    "from stable_baselines.common.tf_layers import conv, linear, conv_to_fc, lstm\n",
    "#from stable_baselines.common import get_vec_normalize_env\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "#import balance_bot\n",
    "import MainEnv_RL\n",
    "\n",
    "env= gym.make(\"UR5-RL-env\", render=True)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "#env=get_vec_normalize_env(env) \n",
    "#model = DQN.load(\"MainScott_RL\")\n",
    "model = PPO2.load(\"UR5-RL_savedpolicy\")\n",
    "#env=model.get_env()\n",
    "#obs = env.reset()\n",
    "done = [False for _ in range(1)] #env.num_envs\n",
    "state=None\n",
    "\n",
    "while True:\n",
    "    obs = env.reset()\n",
    "    #env._seed()\n",
    "    for i in range(80):\n",
    "        action, _states = model.predict(obs,state=state,mask=done)\n",
    "        #actionlist.append(action)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "    print(rewards)\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "while True:\n",
    "    obs = env.reset()\n",
    "    env._seed()\n",
    "    actionlist=[]\n",
    "    #print(\"reset\")\n",
    "    for i in range(80):\n",
    "        action, _states = model.predict(obs)\n",
    "        actionlist.append(action)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "    print(rewards)       \n",
    "\"\"\"       \n",
    "        \n",
    "        \n",
    "    #print(\"actionlist\",actionlist)\n",
    "    #env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"UR5-RL_savedpolicy-9-13-2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
