{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor env in gym.envs.registry.env_specs:\\n     if 'MainEnvRL-v0' in env:\\n        print('Remove {} from registry'.format(env))\\n        del gym.registry.env_specs[env]\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To register MainEnvRL with local copy of Gym\n",
    "\"\"\"\n",
    "from gym.envs.registration import register\n",
    " \n",
    "register(\n",
    "    id='MainEnvRL-v2',\n",
    "    #entry_point='balance_bot.envs:BalancebotEnv',\n",
    "    entry_point='MainEnv_RL.envs:MainEnvRL',\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "#import gym\n",
    "#for env in gym.envs.registry.env_specs:\n",
    "#    print(env)\n",
    "    \n",
    "    #if 'MainEnvRL-v1' == env:\n",
    "    #     print('Remove {} from registry'.format(env))\n",
    "         #del gym.envs.registry.env_specs[env]\n",
    "            \n",
    "            \n",
    "#import MainEnv_RL\n",
    "\n",
    "#env = gym.make('MainEnvRL-v2')\n",
    "#env.reset()\n",
    "\"\"\"\n",
    "for env in gym.envs.registry.env_specs:\n",
    "     if 'MainEnvRL-v0' in env:\n",
    "        print('Remove {} from registry'.format(env))\n",
    "        del gym.registry.env_specs[env]\n",
    "\"\"\"                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep: 20   Total Steps taken: 570\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done status: True\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0030520535 |\n",
      "| clipfrac           | 0.016666668  |\n",
      "| explained_variance | 4.77e-07     |\n",
      "| fps                | 0            |\n",
      "| n_updates          | 19           |\n",
      "| policy_entropy     | 0.12909731   |\n",
      "| policy_loss        | -0.00542566  |\n",
      "| serial_timesteps   | 570          |\n",
      "| time_elapsed       | 770          |\n",
      "| total_timesteps    | 570          |\n",
      "| value_loss         | 117.79695    |\n",
      "-------------------------------------\n",
      "Ep: 20  tStep: 1 Z difference 0.005198982748388925  Reward: -1.994801017251611\n",
      "done status: False\n",
      "Ep: 20  tStep: 2 Z difference 0.0009954157050695578  Reward: -1.9990045842949304\n",
      "done status: False\n",
      "Ep: 20  tStep: 3 Z difference 0.0011247742805626793  Reward: -1.9988752257194373\n",
      "done status: False\n",
      "Ep: 20  tStep: 4 Z difference 0.001236826379969358  Reward: -1.9987631736200306\n",
      "done status: False\n",
      "Ep: 20  tStep: 5 Z difference 0.00022278421334887  Reward: -1.9997772157866511\n",
      "done status: False\n",
      "Ep: 20  tStep: 6 Z difference 0.0006462062172589711  Reward: -1.999353793782741\n",
      "done status: False\n",
      "Ep: 20  tStep: 7 Z difference 0.0014641572099178823  Reward: -1.9985358427900821\n",
      "done status: False\n",
      "Ep: 20  tStep: 8 Z difference 0.0041315545029938505  Reward: -1.9958684454970061\n",
      "done status: False\n",
      "Ep: 20  tStep: 9 Z difference 0.004359765323251441  Reward: -1.9956402346767486\n",
      "done status: False\n",
      "Ep: 20  tStep: 10 Z difference 0.005176103000342547  Reward: -1.9948238969996575\n",
      "done status: False\n",
      "Ep: 20  tStep: 11 Z difference 0.005100570498779433  Reward: -1.9948994295012206\n",
      "done status: False\n",
      "Ep: 20  tStep: 12 Z difference 0.003072339500486798  Reward: -1.9969276604995132\n",
      "done status: False\n",
      "Ep: 20  tStep: 13 Z difference 0.0057221369873730055  Reward: -1.994277863012627\n",
      "done status: False\n",
      "Ep: 20  tStep: 14 Z difference 0.004555269837006826  Reward: -1.9954447301629932\n",
      "done status: False\n",
      "Ep: 20  tStep: 15 Z difference 0.008638864868133922  Reward: -1.991361135131866\n",
      "done status: False\n",
      "Ep: 20  tStep: 16 Z difference 0.005266448672115676  Reward: -2\n",
      "done status: False\n",
      "Ep: 20  tStep: 17 Z difference 0.007025109305605071  Reward: -2\n",
      "done status: False\n",
      "Ep: 20  tStep: 18 Z difference 0.004831733459234044  Reward: -2\n",
      "done status: False\n",
      "Ep: 20  tStep: 19 Z difference 0.0077836609523740385  Reward: -2\n",
      "done status: False\n",
      "Ep: 20  tStep: 20 Z difference 0.004513470297306643  Reward: -2\n",
      "done status: False\n",
      "Ep: 20  tStep: 21 Z difference 0.008421067266538351  Reward: -2\n",
      "done status: False\n",
      "Ep: 20  tStep: 22 Z difference 0.001970298302918394  Reward: -2\n",
      "done status: False\n",
      "Ep: 20  tStep: 23 Z difference 0.00702422931529556  Reward: -2\n",
      "done status: False\n",
      "Ep: 20  tStep: 24 Z difference 0.005765549842640549  Reward: -2\n",
      "done status: False\n",
      "Ep: 20  tStep: 25 Z difference 0.009879064544290106  Reward: -2\n",
      "done status: False\n",
      "Ep: 20  tStep: 26 Z difference 0.008236122636496646  Reward: -2\n",
      "done status: False\n",
      "Ep: 20  tStep: 27 Z difference 0.012932924248278077  Reward: -2\n",
      "done status: False\n",
      "Ep: 20  tStep: 28 Z difference 0.008548372531309578  Reward: -2\n",
      "done status: False\n",
      "Ep: 20  tStep: 29 Z difference 0.012499969016015466  Reward: -2\n",
      "done status: False\n",
      "Ep: 20  tStep: 30 Z difference 0.009906050913780717  Reward: -2\n",
      "   Actionlist: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "done status: True\n",
      "---------------------------------------\n",
      "| approxkl           | 6.850929e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 6.56e-07       |\n",
      "| fps                | 0              |\n",
      "| n_updates          | 20             |\n",
      "| policy_entropy     | 0.06789262     |\n",
      "| policy_loss        | -1.7007192e-06 |\n",
      "| serial_timesteps   | 600            |\n",
      "| time_elapsed       | 811            |\n",
      "| total_timesteps    | 600            |\n",
      "| value_loss         | 120.62861      |\n",
      "---------------------------------------\n",
      "Ep: 21  tStep: 1 Z difference 0.0024504796817899077  Reward: -1.99754952031821\n",
      "done status: False\n",
      "Ep: 21  tStep: 2 Z difference -0.0013551850765942675  Reward: -2.0013551850765943\n",
      "done status: False\n",
      "Ep: 21  tStep: 3 Z difference 0.0032449642661958045  Reward: -1.9967550357338042\n",
      "done status: False\n",
      "Ep: 21  tStep: 4 Z difference 0.00010178554579631793  Reward: -1.9998982144542037\n",
      "done status: False\n",
      "Ep: 21  tStep: 5 Z difference 0.0025924514517190467  Reward: -1.997407548548281\n",
      "done status: False\n",
      "Ep: 21  tStep: 6 Z difference -0.0021687361177056275  Reward: -2.0021687361177056\n",
      "done status: False\n",
      "Ep: 21  tStep: 7 Z difference 0.0014827836714683684  Reward: -1.9985172163285316\n",
      "done status: False\n",
      "Ep: 21  tStep: 8 Z difference -0.002841782039403995  Reward: -2.002841782039404\n",
      "done status: False\n",
      "Ep: 21  tStep: 9 Z difference 0.0015866225279865809  Reward: -1.9984133774720134\n",
      "done status: False\n",
      "Ep: 21  tStep: 10 Z difference -0.00036064936183377583  Reward: -2.0003606493618338\n",
      "done status: False\n",
      "Ep: 21  tStep: 11 Z difference 0.004384111721813522  Reward: -1.9956158882781865\n",
      "done status: False\n",
      "Ep: 21  tStep: 12 Z difference 0.0009905757583679176  Reward: -1.999009424241632\n",
      "done status: False\n",
      "Ep: 21  tStep: 13 Z difference 0.00499321168102318  Reward: -1.9950067883189768\n",
      "done status: False\n",
      "Ep: 21  tStep: 14 Z difference -0.00033527630791052587  Reward: -2.0003352763079105\n",
      "done status: False\n",
      "Ep: 21  tStep: 15 Z difference 0.002469839468598245  Reward: -1.9975301605314018\n",
      "done status: False\n",
      "Ep: 21  tStep: 16 Z difference 0.001006855579093191  Reward: -2\n",
      "done status: False\n",
      "Ep: 21  tStep: 17 Z difference 0.004951412141322997  Reward: -2\n",
      "done status: False\n",
      "Ep: 21  tStep: 18 Z difference 0.002305427945777705  Reward: -2\n",
      "done status: False\n",
      "Ep: 21  tStep: 19 Z difference 0.0041095547452569825  Reward: -2\n",
      "done status: False\n",
      "Ep: 21  tStep: 20 Z difference 0.0007120588254183602  Reward: -2\n",
      "done status: False\n",
      "Ep: 21  tStep: 21 Z difference 0.005765256512537675  Reward: -2\n",
      "done status: False\n",
      "Ep: 21  tStep: 22 Z difference 0.002550651912018864  Reward: -2\n",
      "done status: False\n",
      "Ep: 21  tStep: 23 Z difference 0.0056807774428278  Reward: -2\n",
      "done status: False\n",
      "Ep: 21  tStep: 24 Z difference 0.0008582838818429472  Reward: -2\n",
      "done status: False\n",
      "Ep: 21  tStep: 25 Z difference 0.005325114692747768  Reward: -2\n",
      "done status: False\n",
      "Ep: 21  tStep: 26 Z difference 0.0005950201142579381  Reward: -2\n",
      "done status: False\n",
      "Ep: 21  tStep: 27 Z difference 0.005877601942047672  Reward: -2\n",
      "done status: False\n",
      "Ep: 21  tStep: 28 Z difference 0.0035868405014278792  Reward: -2\n",
      "done status: False\n",
      "Ep: 21  tStep: 29 Z difference 0.005097490532696369  Reward: -2\n",
      "done status: False\n",
      "Ep: 21  tStep: 30 Z difference 0.0005379674091936515  Reward: -2\n",
      "   Actionlist: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "done status: True\n",
      "closing SnS socket\n",
      "socket DC Closed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2d6938391fee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m#model.learn(total_timesteps=timesteps,b_log_name=\"first_run\", reset_num_timesteps=False)#50000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#50000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mtoday\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_rollout_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0;31m# true_reward is the reward without discount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 \u001b[0mrollout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m                 \u001b[0;31m# Unpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneglogpacs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep_infos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrollout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/stable_baselines/common/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callback)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m                 \u001b[0mclipped_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/stable_baselines/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/stable_baselines/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;31m# save final observation where user can get it, then reset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_infos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'terminal_observation'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         return (self._obs_from_buf(), np.copy(self.buf_rews), np.copy(self.buf_dones),\n",
      "\u001b[0;32m~/ScheragaThesis/UR5-RL/UR5_RL/envs/ur5_env_0.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m#if self.totalstepstaken>=410:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;31m#    print(\"reset\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresetEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#you *have* to compute and return the observation from reset()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisodeinitialpose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentpose\u001b[0m \u001b[0;31m#contains just initial xyz poses IN INCHES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ScheragaThesis/UR5-RL/UR5_RL/envs/ur5_env_0.py\u001b[0m in \u001b[0;36mresetEnvironment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock_DC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#receive the \"done\" command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock_DC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#48 bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://github.com/ZhizhenQin/BalancingBot/blob/master/balance-bot/balance_bot/balancebot_task.py\n",
    "\n",
    "\n",
    "#%load_ext tensorboard\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "import gym\n",
    "from stable_baselines import DQN, PPO2\n",
    "from stable_baselines import results_plotter\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines.results_plotter import load_results, ts2xy\n",
    "from stable_baselines.common.noise import AdaptiveParamNoiseSpec\n",
    "from stable_baselines.common.callbacks import BaseCallback\n",
    "from stable_baselines.deepq.policies import MlpPolicy\n",
    "from stable_baselines.common.policies import FeedForwardPolicy, register_policy,LstmPolicy\n",
    "from stable_baselines.common.tf_layers import conv, linear, conv_to_fc, lstm\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "from datetime import date\n",
    "import csv\n",
    "#import balance_bot\n",
    "import socket\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import UR5_RL\n",
    "\n",
    "HOST_SnS = '192.168.0.103'\n",
    "PORT_SnS= 65499\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    # Create a TCP/IP socket\n",
    "    sock_SnS = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    #sock_SnS.setblocking(False)\n",
    "    # Connect the socket to the port where the server is listening\n",
    "    server_address_SnS = (HOST_SnS, PORT_SnS)\n",
    "    print('connecting to {} port {}'.format(*server_address_SnS))\n",
    "    sock_SnS.connect(server_address_SnS)\n",
    "\n",
    "\n",
    "    #def callback(lcl, glb):\n",
    "         #stop training if reward exceeds 199\n",
    "    #    is_solved = lcl['t'] > 1000 and sum(lcl['episode_rewards'][-101:-1]) / 100 >= 1\n",
    "    #    return is_solved\n",
    "\n",
    "    #https://stable-baselines.readthedocs.io/en/master/guide/custom_policy.html\n",
    "    #Layers of 20 and 15\n",
    "\n",
    "    #Do this only after restarting the notebook!! \n",
    "    #register_policy('ScottLSTMPolicy', ScottLSTMPolicy)    \n",
    "    #print(\"lstm registered\")\n",
    "\n",
    "    #try:\n",
    "    \n",
    "    #code stopped at ep 36 at 10steps per ep, 80 ep\n",
    "    StepsPerEpisode=30 #was 10\n",
    "    TotalEpisodes=700  #was 80\n",
    "    env= gym.make(\"ur5-rl-v0\",StepsPerEpisode=StepsPerEpisode,TotalEpisodes=TotalEpisodes,\n",
    "                 continuousactionspace=False)\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "\n",
    "    timesteps=(StepsPerEpisode*TotalEpisodes)\n",
    "    print(\"Total timesteps:\",timesteps)\n",
    "    \n",
    "    class ScottLSTMPolicy(LstmPolicy):\n",
    "        def __init__(self, sess, ob_space, ac_space, n_env=1, n_steps=StepsPerEpisode,\n",
    "                     n_batch=StepsPerEpisode, n_lstm=StepsPerEpisode, reuse=False,  **_kwargs):\n",
    "            super().__init__(sess, ob_space, ac_space, n_env, n_steps, n_batch, n_lstm, reuse,\n",
    "                             net_arch=[7,'lstm',dict(vf=[20, 15],pi=[20,15])],\n",
    "                             layer_norm=True, feature_extraction=\"mlp\", **_kwargs)\n",
    "            \n",
    "    #model = DQN(\"LnMlpPolicy\", env, learning_rate=1e-3, prioritized_replay=True,gamma=1 , buffer_size=50000,param_noise=False,\n",
    "    # exploration_initial_eps=0.1, exploration_final_eps=0.1,learning_starts=1, verbose=1)\n",
    "\n",
    "\n",
    "    #model = PPO2(\"MlpPolicy\", env,verboThe new research shows that \"we must expect extreme event records to be broken - not just by small marse=0)\n",
    "    #model = PPO2(\"MlpLstmPolicy\", env,nminibatches=1, n_steps=80, #exploration_initial_eps=1, exploration_final_eps=0.1,\n",
    "    #             verbose=0,tensorboard_log=\"./ScottPPOLstm/\") #n_lstm=2, n_batch=80, nminibatches=10,\n",
    "\n",
    "    model = PPO2(ScottLSTMPolicy, env,nminibatches=1, n_steps=StepsPerEpisode,learning_rate=0.1,\n",
    "                 verbose=2)\n",
    "    \n",
    "    # DEFAULT learning_rate=0.00025  #n_lstm=2, n_batch=80, nminibatches=10,\n",
    "    ##exploration_initial_eps=1, exploration_final_eps=0.1,\n",
    "\n",
    "    #model.learn(total_timesteps=timesteps,b_log_name=\"first_run\", reset_num_timesteps=False)#50000\n",
    "    model.learn(total_timesteps=timesteps,reset_num_timesteps=False)#50000\n",
    "    \n",
    "    today = date.today()\n",
    "    todaydate = today.strftime(\"%m_%d_%Y\")\n",
    "    RLmodelfilename=\"UR5-RL_savedpolicy_\"+todaydate\n",
    "    model.save(RLmodelfilename)# save trained model\n",
    "    \n",
    "    del model\n",
    "    print(\"training complete\")\n",
    "    \n",
    "\n",
    "finally:\n",
    "    endmsg='end'\n",
    "    data1=endmsg.encode('ascii')    \n",
    "    sock_SnS.sendall(data1)\n",
    "    sock_SnS.sendall(data1)\n",
    "    print('closing SnS socket')\n",
    "    sock_SnS.close()\n",
    "    \n",
    "    HOST2 = '192.168.0.103'\n",
    "    PORT2= PORT_SnS-10 #65481\n",
    "    sock_DC = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    server_address_DC = (HOST2, PORT2)\n",
    "    sock_DC.close()\n",
    "    print(\"socket DC Closed\")\n",
    "      \n",
    "    #gitkraken\n",
    "    \n",
    "    #check_env(env)\n",
    "    #https://stable-baselines.readthedocs.io/en/master/modules/dqn.html\n",
    "    #model.learn(total_timesteps=25000)\n",
    "    #del model # remove to demonstrate saving and loading\n",
    "    #model = DQN.load(\"deepq_cartpole\")\n",
    "\n",
    "    \n",
    "    #Starting at 11:02AM\n",
    "    #80 episodes in 45 min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved!\n"
     ]
    }
   ],
   "source": [
    "model.save(\"UR5-RL_savedpolicy-8-5to6-2021\")\n",
    "print(\"saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST2 = '192.168.0.103'learning_rate=0.00025\n",
    "PORT2= 65485\n",
    "sock_DC = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "server_address_DC = (HOST2, PORT2)\n",
    "sock_DC.close()\n",
    "print(\"socket DC Closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 9] Bad file descriptor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5c92c6e2c5c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mendmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'end'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msock_SnS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'closing SnS socket'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msock_SnS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 9] Bad file descriptor"
     ]
    }
   ],
   "source": [
    "endmsg='end'\n",
    "data1=endmsg.encode('ascii')    \n",
    "sock_SnS.sendall(data1)\n",
    "\n",
    "\n",
    "#print('closing SnS socket')\n",
    "#sock_SnS.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "/home/scott/.local/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/stable_baselines/common/policies.py:346: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/stable_baselines/common/policies.py:442: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/stable_baselines/common/tf_layers.py:121: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/stable_baselines/common/distributions.py:326: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/stable_baselines/common/distributions.py:327: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "#import tensorflow.contrib.layers as layers\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#from tensorflow.keras import layers\n",
    "#from keras.utils import to_categorical\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense, Dropout, Embedding, LSTM, GlobalMaxPooling1D, SpatialDropout1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "import gym\n",
    "from stable_baselines import DQN,PPO2\n",
    "from stable_baselines import results_plotter\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines.results_plotter import load_results, ts2xy\n",
    "from stable_baselines.common.noise import AdaptiveParamNoiseSpec\n",
    "from stable_baselines.common.callbacks import BaseCallback\n",
    "from stable_baselines.deepq.policies import MlpPolicy\n",
    "from stable_baselines.common.policies import FeedForwardPolicy, register_policy,LstmPolicy\n",
    "from stable_baselines.common.tf_layers import conv, linear, conv_to_fc, lstm\n",
    "#from stable_baselines.common import get_vec_normalize_env\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "#import balance_bot\n",
    "import MainEnv_RL\n",
    "\n",
    "env= gym.make(\"UR5-RL-env\", render=True)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "#env=get_vec_normalize_env(env) \n",
    "#model = DQN.load(\"MainScott_RL\")\n",
    "model = PPO2.load(\"UR5-RL_savedpolicy\")\n",
    "#env=model.get_env()\n",
    "#obs = env.reset()\n",
    "done = [False for _ in range(1)] #env.num_envs\n",
    "state=None\n",
    "\n",
    "while True:\n",
    "    obs = env.reset()\n",
    "    #env._seed()\n",
    "    for i in range(80):\n",
    "        action, _states = model.predict(obs,state=state,mask=done)\n",
    "        #actionlist.append(action)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "    print(rewards)\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "while True:\n",
    "    obs = env.reset()\n",
    "    env._seed()\n",
    "    actionlist=[]\n",
    "    #print(\"reset\")\n",
    "    for i in range(80):\n",
    "        action, _states = model.predict(obs)\n",
    "        actionlist.append(action)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "    print(rewards)       \n",
    "\"\"\"       \n",
    "        \n",
    "        \n",
    "    #print(\"actionlist\",actionlist)\n",
    "    #env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"UR5-RL_savedpolicy-9-13-2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
