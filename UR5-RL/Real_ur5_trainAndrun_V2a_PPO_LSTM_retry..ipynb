{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor env in gym.envs.registry.env_specs:\\n     if 'MainEnvRL-v0' in env:\\n        print('Remove {} from registry'.format(env))\\n        del gym.registry.env_specs[env]\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To register MainEnvRL with local copy of Gym\n",
    "\"\"\"\n",
    "from gym.envs.registration import register\n",
    " \n",
    "register(\n",
    "    id='MainEnvRL-v2',\n",
    "    #entry_point='balance_bot.envs:BalancebotEnv',\n",
    "    entry_point='MainEnv_RL.envs:MainEnvRL',\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "#import gym\n",
    "#for env in gym.envs.registry.env_specs:\n",
    "#    print(env)\n",
    "    \n",
    "    #if 'MainEnvRL-v1' == env:\n",
    "    #     print('Remove {} from registry'.format(env))\n",
    "         #del gym.envs.registry.env_specs[env]\n",
    "            \n",
    "            \n",
    "#import MainEnv_RL\n",
    "\n",
    "#env = gym.make('MainEnvRL-v2')\n",
    "#env.reset()\n",
    "\"\"\"\n",
    "for env in gym.envs.registry.env_specs:\n",
    "     if 'MainEnvRL-v0' in env:\n",
    "        print('Remove {} from registry'.format(env))\n",
    "        del gym.registry.env_specs[env]\n",
    "\"\"\"                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep: 400   Total Steps taken: 10999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/ScheragaThesis/UR5-RL/UR5_RL/envs/ur5_env_0.py:756: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  self.fig, (self.ax1) = plt.subplots(1,figsize=(8,8))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep: 400  tStep: 1  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [-0.18056294141551132, -0.12628787209046477, 0.8792592940177304, 0.17443853781685625, -0.0841364742749211]\n",
      "Ep: 400  tStep: 2  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [-0.19721669836208977, -0.13630757186414577, 0.878290937425124, 0.18264797884137196, -0.09029720439583244]\n",
      "Ep: 400  tStep: 3  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [-0.1670022190938879, -0.11326882932672333, 0.8807169525037399, 0.16779402265816468, -0.081848498677499]\n",
      "Ep: 400  tStep: 4  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [-0.17783232085457668, -0.10649398334938676, 0.8847717010851472, 0.16054288252620474, -0.07642483052465798]\n",
      "Ep: 400  tStep: 5  Reward: 0.11  Button Pressed? 0  GRU output: 0 FT Observation: [-0.13552485043715334, -0.1336073362625143, 0.8773731144274517, 0.17744725974544107, -0.06680422604878222]\n",
      "Ep: 400  tStep: 6  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [-0.1781818491821131, -0.1432340872248753, 0.8780993940942279, 0.18011674352658424, -0.0813805727817859]\n",
      "Ep: 400  tStep: 7  Reward: 0.16  Button Pressed? 0  GRU output: 0 FT Observation: [-0.1614419038830457, -0.13292325288171547, 0.8837570202650715, 0.17474108220377982, -0.07343691187622459]\n",
      "Ep: 400  tStep: 8  Reward: 0.16  Button Pressed? 0  GRU output: 0 FT Observation: [-0.04530115841244742, -0.12717100739465947, 0.8835929657496595, 0.18241528783693073, 0.002280144579829946]\n",
      "Ep: 400  tStep: 9  Reward: 0.16  Button Pressed? 0  GRU output: 0 FT Observation: [-0.08431962635463197, -0.15256239629851653, 0.8935771518910633, 0.19524663489747995, -0.020295371310383947]\n",
      "Ep: 400  tStep: 10  Reward: 0.21  Button Pressed? 0  GRU output: 0.6 FT Observation: [-0.12261139108698604, -0.14010737944807794, 0.877076279872437, 0.18768854847255212, -0.03669697779074499]\n",
      "Ep: 400  tStep: 11  Reward: 0.26  Button Pressed? 0  GRU output: 0.67 FT Observation: [-0.14284501712058673, -0.14479888086593962, 0.8795676012583633, 0.19084755282852828, -0.0523479123878724]\n",
      "Ep: 400  tStep: 12  Reward: 0.26  Button Pressed? 0  GRU output: 0.62 FT Observation: [-0.14099967500035848, -0.16756400304003916, 0.8784409004188685, 0.20743322684602528, -0.05096208277635461]\n",
      "Ep: 400  tStep: 13  Reward: 0.26  Button Pressed? 0  GRU output: 0.73 FT Observation: [-0.12596106117942718, -0.13533162215361183, 0.8793728947907078, 0.18581043544224096, -0.049029028247804196]\n",
      "Ep: 400  tStep: 14  Reward: 0.31  Button Pressed? 0  GRU output: 0.79 FT Observation: [-0.1517141757883943, -0.1284832486320946, 0.880822882547853, 0.1818565376691259, -0.05969486357548637]\n",
      "Ep: 400  tStep: 15  Reward: 0.3  Button Pressed? 0  GRU output: 0.87 FT Observation: [-0.1393098120457258, -0.1652467365606245, 0.8729738308301791, 0.20130122738533784, -0.05390991597153316]\n",
      "Ep: 400  tStep: 16  Reward: 0.31  Button Pressed? 0  GRU output: 0.75 FT Observation: [-0.12492104488453037, -0.17887290660523725, 0.8776957250433219, 0.21303864915532733, -0.05184006053009771]\n",
      "Ep: 400  tStep: 17  Reward: 0.31  Button Pressed? 0  GRU output: 0.74 FT Observation: [-0.038456542995429, -0.1573526400517301, 0.8782112707050769, 0.20652008712957848, 0.003279883226927849]\n",
      "Ep: 400  tStep: 18  Reward: 0.31  Button Pressed? 0  GRU output: 0.59 FT Observation: [-0.0559315203559968, -0.18128104308817683, 0.8787072590230669, 0.21722344097861535, -0.007161654319212896]\n",
      "Ep: 400  tStep: 19  Reward: 0.36  Button Pressed? 0  GRU output: 0.86 FT Observation: [-0.08565104344158947, -0.1740069186710943, 0.8708435022231946, 0.21423530971916982, -0.02583064076756514]\n",
      "Ep: 400  tStep: 20  Reward: 0.36  Button Pressed? 0  GRU output: 0.78 FT Observation: [-0.08966779568393657, -0.13355273792263622, 0.8770173128757879, 0.19335301602302435, -0.020556585986805986]\n",
      "Ep: 400  tStep: 21  Reward: 0.36  Button Pressed? 0  GRU output: 0.51 FT Observation: [-0.09021660595980341, -0.12510422630554419, 0.880777586625018, 0.1815717442039848, -0.020712089900294606]\n",
      "Ep: 400  tStep: 22  Reward: 0.36  Button Pressed? 0  GRU output: 0.58 FT Observation: [-0.08599513185160867, -0.1262490071880985, 0.8793571768854822, 0.18330776701131368, -0.018852730935804973]\n",
      "Ep: 400  tStep: 23  Reward: 0.36  Button Pressed? 0  GRU output: 0.37 FT Observation: [-0.0363514039326045, -0.12804973082518878, 0.8792307117118983, 0.18121920165637673, 0.006376994862682395]\n",
      "Ep: 400  tStep: 24  Reward: 0.36  Button Pressed? 0  GRU output: 0.52 FT Observation: [-0.04477477280658693, -0.14787595225746486, 0.8783360752726033, 0.1935002643460937, 0.007773154187154185]\n",
      "Ep: 400  tStep: 25  Reward: 0.36  Button Pressed? 0  GRU output: 0.34 FT Observation: [-0.04059065861288502, -0.16684483956720975, 0.8794287540584544, 0.2032423059356241, 0.009333435265927115]\n",
      "Ep: 400  tStep: 26  Reward: 0.41  Button Pressed? 0  GRU output: 0.39 FT Observation: [-0.0792970344534939, -0.15669695199028266, 0.8758379403499483, 0.20132381329718974, -0.01173718020420822]\n",
      "Ep: 400  tStep: 27  Reward: 0.41  Button Pressed? 0  GRU output: 0.4 FT Observation: [-0.07715726088575448, -0.17133554319931565, 0.874469424957121, 0.21254627392036785, -0.00535322620912404]\n",
      "Ep: 400  tStep: 28  Reward: 1  Button Pressed? 1  GRU output: 0.76 FT Observation: [-0.0945947693154463, -0.16739075560914163, 0.8450282794204131, 0.21072905752400994, -0.02627577005537962]\n",
      "   Actionlist: [4, 4, 2, 2, 3, 4, 3, 0, 3, 4, 4, 3, 2, 4, 3, 3, 0, 3, 4, 2, 2, 2, 0, 3, 3, 4, 3, 4]\n",
      "Ep: 401  tStep: 1  Reward: 0.01  Button Pressed? 0  GRU output: 0 FT Observation: [0.030178612878157818, -0.13107948736245167, 0.8599230604485473, 0.1796424202304321, 0.07038726415505603]\n",
      "Ep: 401  tStep: 2  Reward: -0.0  Button Pressed? 0  GRU output: 0 FT Observation: [0.03737923492127915, -0.14511424002388928, 0.8731314564045736, 0.18922225531348835, 0.07091044511014877]\n",
      "Ep: 401  tStep: 3  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [0.05200601380428682, -0.12352642858265472, 0.8583631002672893, 0.174814242412469, 0.09141891260392976]\n",
      "Ep: 401  tStep: 4  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [0.04619115181172373, -0.11727555855667737, 0.8608936315729989, 0.17496979328217166, 0.09148727185848071]\n",
      "Ep: 401  tStep: 5  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [-0.0021248165199762026, -0.12767771368118652, 0.8688767082755551, 0.17332184455821276, 0.06373439803983194]\n",
      "Ep: 401  tStep: 6  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [0.014944410038874034, -0.12332088634878724, 0.8609209490722791, 0.17143735450831543, 0.06268919775717108]\n",
      "Ep: 401  tStep: 7  Reward: 0.2  Button Pressed? 0  GRU output: 0 FT Observation: [0.005880033008416774, -0.10996422930292393, 0.8557900382370922, 0.16914612755438974, 0.06420921794237655]\n",
      "Ep: 401  tStep: 8  Reward: 0.25  Button Pressed? 0  GRU output: 0 FT Observation: [0.017552613377801674, -0.1258287306152599, 0.8691617898463826, 0.1686272446559074, 0.06702195146406531]\n",
      "Ep: 401  tStep: 9  Reward: 0.3  Button Pressed? 0  GRU output: 0 FT Observation: [0.003770075421458685, -0.11991541523252702, 0.8589338516081579, 0.16660567004146531, 0.0691997332669283]\n",
      "Ep: 401  tStep: 10  Reward: 0.35  Button Pressed? 0  GRU output: 0.25 FT Observation: [0.013025631757571432, -0.11912053845065773, 0.8607233560997372, 0.16630691681207854, 0.0703469853187293]\n",
      "Ep: 401  tStep: 11  Reward: 0.35  Button Pressed? 0  GRU output: 0.15 FT Observation: [0.08199566960762361, -0.13139446605944471, 0.8610710025112014, 0.1735379091166631, 0.1054520522688791]\n",
      "Ep: 401  tStep: 12  Reward: 0.35  Button Pressed? 0  GRU output: 0.13 FT Observation: [0.0548498037615166, -0.09353749475177875, 0.8633329232500082, 0.1536059852662479, 0.09416321908731051]\n",
      "Ep: 401  tStep: 13  Reward: 0.35  Button Pressed? 0  GRU output: 0.09 FT Observation: [0.05169745689961003, -0.13019145605723315, 0.8706471872980526, 0.17040009439540404, 0.09252338380130887]\n",
      "Ep: 401  tStep: 14  Reward: 0.35  Button Pressed? 0  GRU output: 0.05 FT Observation: [0.050306727405362794, -0.10366977799182286, 0.8614786272145518, 0.15830024149977895, 0.09136201810799216]\n",
      "Ep: 401  tStep: 15  Reward: 0.35  Button Pressed? 0  GRU output: 0.36 FT Observation: [0.10005652281431643, -0.12028918119890697, 0.8623864417607008, 0.16435162608510567, 0.125153701663004]\n",
      "Ep: 401  tStep: 16  Reward: 0.35  Button Pressed? 0  GRU output: 0.46 FT Observation: [0.12354976595708789, -0.11180475241867227, 0.8649304816852035, 0.1641542443431412, 0.15056796408853756]\n",
      "Ep: 401  tStep: 17  Reward: 0.35  Button Pressed? 0  GRU output: 0.2 FT Observation: [0.0755970443020344, -0.1444368013130095, 0.8621881999866017, 0.17921807324744954, 0.12082865669712017]\n",
      "Ep: 401  tStep: 18  Reward: 0.35  Button Pressed? 0  GRU output: 0.17 FT Observation: [0.09932796087515405, -0.13303859835166565, 0.8609592563736326, 0.17364272023756144, 0.13159533298996662]\n",
      "Ep: 401  tStep: 19  Reward: 0.35  Button Pressed? 0  GRU output: 0.08 FT Observation: [0.07919723813098312, -0.09739871775010156, 0.868563021583896, 0.15629410546859268, 0.12401696805540263]\n",
      "Ep: 401  tStep: 20  Reward: 0.35  Button Pressed? 0  GRU output: 0.15 FT Observation: [0.08076235636382934, -0.09432713313530416, 0.8724429681553383, 0.14629786092385322, 0.11746940533602235]\n",
      "Ep: 401  tStep: 21  Reward: 0.4  Button Pressed? 0  GRU output: 0.37 FT Observation: [0.06830360025951143, -0.07917581035903443, 0.8660996990916638, 0.14342373343406534, 0.11449234272148123]\n",
      "Ep: 401  tStep: 22  Reward: 1  Button Pressed? 1  GRU output: 0.77 FT Observation: [0.06873176891771116, -0.08263817696440634, 0.8559685941293473, 0.13959146918424614, 0.11213368860173856]\n",
      "   Actionlist: [2, 3, 4, 4, 1, 4, 4, 4, 4, 4, 0, 2, 3, 2, 0, 0, 3, 0, 2, 2, 4, 4]\n",
      "Ep: 402  tStep: 1  Reward: 0.0  Button Pressed? 0  GRU output: 0 FT Observation: [-0.007855894993326507, -0.14751460240374148, 0.8639421379305323, 0.18938305744206363, 0.06386145669899168]\n",
      "Ep: 402  tStep: 2  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [-0.0017866913061133083, -0.16053340170053598, 0.8593079084698809, 0.19621385629608423, 0.06056896569323156]\n",
      "Ep: 402  tStep: 3  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [-0.018199696472225302, -0.16221935487854433, 0.8651829251765719, 0.1930990202509908, 0.051227587765877214]\n",
      "Ep: 402  tStep: 4  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [-0.023786230123206242, -0.15800984644883465, 0.8621561703750396, 0.19292666643299805, 0.04971206257413674]\n",
      "Ep: 402  tStep: 5  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [-0.012245243429876762, -0.14509912262089997, 0.8692619721401866, 0.18686772309845678, 0.0544990844142228]\n",
      "Ep: 402  tStep: 6  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [-0.0008010033257408455, -0.15119630396125638, 0.8650404507991041, 0.18595286454718263, 0.060639911363300936]\n",
      "Ep: 402  tStep: 7  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [-0.0074489150318894914, -0.14894044026682296, 0.8677774041767237, 0.18348799059876186, 0.0559574772023288]\n",
      "Ep: 402  tStep: 8  Reward: 0.2  Button Pressed? 0  GRU output: 0 FT Observation: [-0.008640044386238221, -0.1445103928812791, 0.8687623537927627, 0.18313785747610933, 0.05769893628943534]\n",
      "Ep: 402  tStep: 9  Reward: 0.25  Button Pressed? 0  GRU output: 0 FT Observation: [-0.014657476193111085, -0.13235774196036354, 0.8570975288017699, 0.18008387700882444, 0.05393230853507558]\n",
      "Ep: 402  tStep: 10  Reward: 0.25  Button Pressed? 0  GRU output: 0.12 FT Observation: [-6.0476838531720034e-05, -0.1294195590118975, 0.8666845269818564, 0.17330691755047534, 0.05832700596326945]\n",
      "Ep: 402  tStep: 11  Reward: 0.25  Button Pressed? 0  GRU output: 0.23 FT Observation: [-0.007333820985418127, -0.11454913990915805, 0.8638289490497837, 0.1642589513814967, 0.058006067151321394]\n",
      "Ep: 402  tStep: 12  Reward: 0.3  Button Pressed? 0  GRU output: 0.4 FT Observation: [-0.0072908140222800455, -0.11168149920631176, 0.8624346484293597, 0.1612601604985806, 0.0548156611420334]\n",
      "Ep: 402  tStep: 13  Reward: 0.35  Button Pressed? 0  GRU output: 0.41 FT Observation: [-0.015753450597459806, -0.1179578076692509, 0.8684575364322791, 0.16112564854028988, 0.056314910257495354]\n",
      "Ep: 402  tStep: 14  Reward: 0.35  Button Pressed? 0  GRU output: 0.09 FT Observation: [-0.005380171088567254, -0.14439513689157124, 0.8651902170134751, 0.17891561232294273, 0.05896548376656097]\n",
      "Ep: 402  tStep: 15  Reward: 0.35  Button Pressed? 0  GRU output: 0.31 FT Observation: [-0.05375675252927803, -0.14112532527745414, 0.8630911577896665, 0.1724939779018857, 0.028342797186320157]\n",
      "Ep: 402  tStep: 16  Reward: 0.35  Button Pressed? 0  GRU output: 0.31 FT Observation: [-0.03445922837419102, -0.10945182329379488, 0.8607082571532341, 0.15814851075398106, 0.03843086503344839]\n",
      "Ep: 402  tStep: 17  Reward: 0.35  Button Pressed? 0  GRU output: 0.57 FT Observation: [-0.09632515365968197, -0.11251495462393546, 0.8658218889872042, 0.15757156943466644, 0.009071247693225759]\n",
      "Ep: 402  tStep: 18  Reward: 0.4  Button Pressed? 0  GRU output: 0.48 FT Observation: [-0.07188458540175546, -0.11180760666518486, 0.8682391349576792, 0.15451088871503926, 0.012024344097783857]\n",
      "Ep: 402  tStep: 19  Reward: 0.4  Button Pressed? 0  GRU output: 0.45 FT Observation: [-0.05124287834124841, -0.13089786242335355, 0.8643098729493284, 0.17182107051401418, 0.026965542884630045]\n",
      "Ep: 402  tStep: 20  Reward: 0.4  Button Pressed? 0  GRU output: 0.52 FT Observation: [-0.04564993452694044, -0.11010819614988243, 0.8625792128237744, 0.15603593952145967, 0.02420310225256861]\n",
      "Ep: 402  tStep: 21  Reward: 0.4  Button Pressed? 0  GRU output: 0.21 FT Observation: [-0.035407550989251524, -0.14547133516993016, 0.8653367956464444, 0.17500430057285143, 0.03325946941745728]\n",
      "Ep: 402  tStep: 22  Reward: 0.4  Button Pressed? 0  GRU output: 0.1 FT Observation: [-0.028842786078503102, -0.16116209089133315, 0.8669121510127185, 0.18445019283765518, 0.03748940181020388]\n",
      "Ep: 402  tStep: 23  Reward: 0.4  Button Pressed? 0  GRU output: 0.13 FT Observation: [-0.03495288726184098, -0.12884964954792333, 0.8675875972302773, 0.16877418564090108, 0.03732671016026945]\n",
      "Ep: 402  tStep: 24  Reward: 0.4  Button Pressed? 0  GRU output: 0.06 FT Observation: [-0.028775097806228223, -0.15287142250931207, 0.8688748545568208, 0.18315016996227618, 0.042315674432966244]\n",
      "Ep: 402  tStep: 25  Reward: 1  Button Pressed? 1  GRU output: 0.41 FT Observation: [-0.0897555429707041, -0.1471127542440428, 0.8437918677654084, 0.1776697003415666, 0.009613666608966343]\n",
      "   Actionlist: [3, 4, 1, 4, 2, 2, 4, 4, 4, 2, 2, 4, 4, 3, 1, 2, 1, 4, 3, 2, 3, 3, 2, 3, 4]\n",
      "Ep: 403  tStep: 1  Reward: 0.0  Button Pressed? 0  GRU output: 0 FT Observation: [0.04042005069872312, -0.14821256671134675, 0.8624392880225351, 0.19024329327833844, 0.08630136719572379]\n",
      "Ep: 403  tStep: 2  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [0.08304015012340882, -0.16205578438174273, 0.8619102727515626, 0.19604362340538484, 0.11139180999963005]\n",
      "Ep: 403  tStep: 3  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [0.05151567855361705, -0.14707880779498372, 0.8717874272102912, 0.1910523921828966, 0.09746429736473772]\n",
      "Ep: 403  tStep: 4  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [0.037191282500563805, -0.16800279362534776, 0.8579190236109631, 0.199599735066331, 0.09391238728757378]\n",
      "Ep: 403  tStep: 5  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [0.04551205537504632, -0.1598156134300578, 0.8581527285522428, 0.1966962484441035, 0.08843404023728896]\n",
      "Ep: 403  tStep: 6  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [0.026313720457487033, -0.1695906611972905, 0.8644115638849947, 0.2036475542629037, 0.08442198610555263]\n",
      "Ep: 403  tStep: 7  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [0.03379411397000043, -0.15799946788088615, 0.8638354003983904, 0.19560408577161947, 0.0852613905819175]\n",
      "Ep: 403  tStep: 8  Reward: 0.2  Button Pressed? 0  GRU output: 0 FT Observation: [0.026306231031967053, -0.1535288674619265, 0.8612649876581933, 0.19160789642597664, 0.08335142240360027]\n",
      "Ep: 403  tStep: 9  Reward: 0.2  Button Pressed? 0  GRU output: 0 FT Observation: [-0.0007071565723381079, -0.15276632898432607, 0.864446316426043, 0.19077025190206331, 0.06220978185007242]\n",
      "Ep: 403  tStep: 10  Reward: 0.25  Button Pressed? 0  GRU output: 0.15 FT Observation: [0.014398366053728795, -0.15517154807370637, 0.855387382824035, 0.19253464542588872, 0.06186365672051242]\n",
      "Ep: 403  tStep: 11  Reward: 0.25  Button Pressed? 0  GRU output: 0.27 FT Observation: [0.00375802911112455, -0.1763571001978046, 0.8647945873981271, 0.20363831841006985, 0.06606121505920104]\n",
      "Ep: 403  tStep: 12  Reward: 0.3  Button Pressed? 0  GRU output: 0.15 FT Observation: [0.0074975635928540285, -0.1686655401233529, 0.8598844842688564, 0.1993546088944087, 0.0636649861434051]\n",
      "Ep: 403  tStep: 13  Reward: 0.3  Button Pressed? 0  GRU output: 0.24 FT Observation: [0.012891511626837326, -0.1837539487953227, 0.856771682122623, 0.21114224558188854, 0.06390080849275726]\n",
      "Ep: 403  tStep: 14  Reward: 0.35  Button Pressed? 0  GRU output: 0.23 FT Observation: [0.012247243880507241, -0.1796185918376969, 0.8630435471628775, 0.21103532924426927, 0.0680361572914907]\n",
      "Ep: 403  tStep: 15  Reward: 0.35  Button Pressed? 0  GRU output: 0.06 FT Observation: [0.0024332674743561267, -0.15477496076463493, 0.8578206104981709, 0.1958507643444911, 0.06610700099352385]\n",
      "Ep: 403  tStep: 16  Reward: 0.35  Button Pressed? 0  GRU output: 0.07 FT Observation: [0.007502305805519471, -0.14817330468421985, 0.8635371667949945, 0.18790005352827732, 0.0687248648524792]\n",
      "Ep: 403  tStep: 17  Reward: 0.35  Button Pressed? 0  GRU output: 0.05 FT Observation: [0.01322014968995977, -0.17502932548850558, 0.8604592618333435, 0.2021356041101623, 0.06529778388050156]\n",
      "Ep: 403  tStep: 18  Reward: 0.35  Button Pressed? 0  GRU output: 0.13 FT Observation: [-0.0015009539151553675, -0.1859498606835822, 0.8621277494038488, 0.210747334811342, 0.06370549159013561]\n",
      "Ep: 403  tStep: 19  Reward: 0.35  Button Pressed? 0  GRU output: 0.08 FT Observation: [0.0027645192052636602, -0.1827406211199648, 0.8609668010088818, 0.20799787464232522, 0.06005000793202875]\n",
      "Ep: 403  tStep: 20  Reward: 0.35  Button Pressed? 0  GRU output: -0.01 FT Observation: [0.008426862849061356, -0.15614984036426582, 0.8597195941413447, 0.1943532345335226, 0.06164947865518733]\n",
      "Ep: 403  tStep: 21  Reward: 0.4  Button Pressed? 0  GRU output: 0.07 FT Observation: [-0.0040017297847539934, -0.152318817090229, 0.8539270655757263, 0.19503097390436186, 0.06318455480904217]\n",
      "Ep: 403  tStep: 22  Reward: 0.4  Button Pressed? 0  GRU output: 0.06 FT Observation: [0.007233078945783733, -0.1528169883517554, 0.8587819128761711, 0.1955646227772132, 0.06992154455418387]\n",
      "Ep: 403  tStep: 23  Reward: 1  Button Pressed? 1  GRU output: -0.03 FT Observation: [0.05325069541278271, -0.16276534108386154, 0.7962158611091126, 0.19869449973169484, 0.0875889867822206]\n",
      "   Actionlist: [3, 4, 4, 3, 4, 3, 2, 4, 1, 4, 3, 4, 3, 4, 2, 2, 3, 3, 1, 2, 4, 0, 4]\n",
      "Ep: 404  tStep: 1  Reward: 0.0  Button Pressed? 0  GRU output: 0 FT Observation: [0.030919390103048006, -0.13043743625656445, 0.8712507287844278, 0.18089873076974872, 0.06822676787481607]\n",
      "Ep: 404  tStep: 2  Reward: 0.0  Button Pressed? 0  GRU output: 0 FT Observation: [0.07642434783020136, -0.13301093643702466, 0.8591195451323621, 0.18446160926886224, 0.09402634374520202]\n",
      "Ep: 404  tStep: 3  Reward: 0.0  Button Pressed? 0  GRU output: 0 FT Observation: [0.09589607062656924, -0.1359249695210254, 0.8550306576722897, 0.1836176702058685, 0.10270078133672333]\n",
      "Ep: 404  tStep: 4  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [0.08901895470033527, -0.1244840430219426, 0.8688908641681152, 0.17683475705421992, 0.10745581721798869]\n",
      "Ep: 404  tStep: 5  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [0.06538320874832082, -0.13484627342615108, 0.8954129967028348, 0.18298649556054958, 0.09638220411087484]\n",
      "Ep: 404  tStep: 6  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [0.05586690583471188, -0.12330264597351981, 0.8657825388162836, 0.17875108531580852, 0.09908475712893727]\n",
      "Ep: 404  tStep: 7  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [0.05704129985413253, -0.13205184874205467, 0.8693153551656325, 0.18208008119653973, 0.09380856383709446]\n",
      "Ep: 404  tStep: 8  Reward: 0.16  Button Pressed? 0  GRU output: 0 FT Observation: [0.09981354437422496, -0.12905030209547164, 0.8693070545798092, 0.18110529313206514, 0.11553831520733637]\n",
      "Ep: 404  tStep: 9  Reward: 0.16  Button Pressed? 0  GRU output: 0 FT Observation: [0.023211334952270457, -0.14070705116763105, 0.8717393494871224, 0.18023264950290807, 0.07076816833295974]\n",
      "Ep: 404  tStep: 10  Reward: 0.15  Button Pressed? 0  GRU output: 0.04 FT Observation: [0.03382639372104013, -0.13296959805606723, 0.8676729685150981, 0.18086822525646884, 0.07744250827599797]\n",
      "Ep: 404  tStep: 11  Reward: 0.21  Button Pressed? 0  GRU output: 0.03 FT Observation: [0.03224534546921176, -0.1375576216801493, 0.8680802170765098, 0.1805173049482145, 0.0800801405284215]\n",
      "Ep: 404  tStep: 12  Reward: 0.26  Button Pressed? 0  GRU output: 0.06 FT Observation: [0.042869220937965746, -0.13668631662434416, 0.8613838367978008, 0.18265534599524513, 0.08071504236471538]\n",
      "Ep: 404  tStep: 13  Reward: 0.31  Button Pressed? 0  GRU output: 0.13 FT Observation: [0.035866077984739064, -0.14094008481911313, 0.8671119313733671, 0.18286087735123835, 0.08243598349127934]\n",
      "Ep: 404  tStep: 14  Reward: 0.36  Button Pressed? 0  GRU output: 0.07 FT Observation: [0.03001283438976765, -0.12911228407919817, 0.8631139198260829, 0.17952763191405796, 0.07512614856253785]\n",
      "Ep: 404  tStep: 15  Reward: 0.36  Button Pressed? 0  GRU output: 0.01 FT Observation: [0.0254330697622438, -0.1234170066784317, 0.8662522540323507, 0.1729196578287573, 0.07903362265744662]\n",
      "Ep: 404  tStep: 16  Reward: 0.41  Button Pressed? 0  GRU output: 0.19 FT Observation: [0.039359025584095875, -0.12551391873171547, 0.8602140064419259, 0.17343908470581426, 0.08194576919970942]\n",
      "Ep: 404  tStep: 17  Reward: 0.41  Button Pressed? 0  GRU output: 0.18 FT Observation: [0.03610830966260625, -0.1404363615289107, 0.8629580825810039, 0.1832120334715044, 0.08018045376048599]\n",
      "Ep: 404  tStep: 18  Reward: 0.41  Button Pressed? 0  GRU output: -0.05 FT Observation: [0.026684109069932127, -0.16662286226197776, 0.8630725855650005, 0.1973972581186112, 0.07959919904029422]\n",
      "Ep: 404  tStep: 19  Reward: 0.41  Button Pressed? 0  GRU output: 0.01 FT Observation: [0.036164499431872166, -0.13910153610102627, 0.8630650655780991, 0.1802170128191516, 0.07937778841277598]\n",
      "Ep: 404  tStep: 20  Reward: 1  Button Pressed? 1  GRU output: 0.02 FT Observation: [0.12551313466449332, -0.15009361339188887, 0.7484931263001169, 0.18988765550246156, 0.12247531554800961]\n",
      "   Actionlist: [2, 0, 0, 4, 3, 4, 4, 0, 1, 3, 4, 4, 4, 4, 2, 4, 3, 3, 2, 4]\n",
      "Ep: 405  tStep: 1  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [-0.048353715254352725, -0.12259712436768755, 0.8800086722421703, 0.17468471856096057, 0.022323998278345636]\n",
      "Ep: 405  tStep: 2  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [-0.05466283129588234, -0.1239321609873616, 0.8738157328418801, 0.17496088096894136, 0.022848213932555206]\n",
      "Ep: 405  tStep: 3  Reward: 0.16  Button Pressed? 0  GRU output: 0 FT Observation: [-0.04314341894477092, -0.11935858738091876, 0.8691179288240711, 0.1750276631761336, 0.02351711999734607]\n",
      "Ep: 405  tStep: 4  Reward: 0.2  Button Pressed? 0  GRU output: 0 FT Observation: [-0.04746390173210879, -0.12173638661933728, 0.8663198793214275, 0.17357085909683945, 0.028543011797669937]\n",
      "Ep: 405  tStep: 5  Reward: 0.2  Button Pressed? 0  GRU output: 0 FT Observation: [-0.06296416723060827, -0.12441894052165636, 0.8735137877269081, 0.1747239110389458, 0.015616638674190053]\n",
      "Ep: 405  tStep: 6  Reward: 0.2  Button Pressed? 0  GRU output: 0 FT Observation: [-0.04872180907193335, -0.12274639486493832, 0.8720863460785027, 0.1729162810375715, 0.02206640405201199]\n",
      "Ep: 405  tStep: 7  Reward: 0.25  Button Pressed? 0  GRU output: 0 FT Observation: [-0.054901479060154745, -0.12939377607271396, 0.8729643683090083, 0.17545560493449597, 0.019655359733449895]\n",
      "Ep: 405  tStep: 8  Reward: 0.26  Button Pressed? 0  GRU output: 0 FT Observation: [-0.05033521883708891, -0.14223706692352078, 0.8724070467529603, 0.1835218503192797, 0.023788839827034947]\n",
      "Ep: 405  tStep: 9  Reward: 0.3  Button Pressed? 0  GRU output: 0 FT Observation: [-0.049136147639230465, -0.13043305104498537, 0.8971901450386695, 0.1816508816718323, 0.023502638196992498]\n",
      "Ep: 405  tStep: 10  Reward: 0.3  Button Pressed? 0  GRU output: 0.25 FT Observation: [-0.036863192244766196, -0.15016785888290907, 0.8977554681410789, 0.1910021556633692, 0.023585302482491022]\n",
      "Ep: 405  tStep: 11  Reward: 0.3  Button Pressed? 0  GRU output: 0.36 FT Observation: [-0.06100192684276806, -0.11950475595490684, 0.8729493845578837, 0.17497628273054278, 0.027104135415253472]\n",
      "Ep: 405  tStep: 12  Reward: 0.3  Button Pressed? 0  GRU output: 0.1 FT Observation: [-0.014641810538857825, -0.12982926161175956, 0.8702085583340466, 0.17909646433329263, 0.04126077044028498]\n",
      "Ep: 405  tStep: 13  Reward: 0.3  Button Pressed? 0  GRU output: 0.41 FT Observation: [-0.07182700294819533, -0.13556400767082255, 0.8682825453837444, 0.178232819302776, 0.023873247882914006]\n",
      "Ep: 405  tStep: 14  Reward: 0.3  Button Pressed? 0  GRU output: 0.3 FT Observation: [-0.04948849949108958, -0.1482653744816329, 0.870995516937279, 0.1869307401687479, 0.027892872529959867]\n",
      "Ep: 405  tStep: 15  Reward: 0.3  Button Pressed? 0  GRU output: 0.22 FT Observation: [-0.019635742032875436, -0.14215985562620537, 0.871878401207208, 0.18839999144009445, 0.044006815377672925]\n",
      "Ep: 405  tStep: 16  Reward: 0.3  Button Pressed? 0  GRU output: 0.32 FT Observation: [-0.024211464877995414, -0.16004337219823572, 0.8745962779857017, 0.19791479088976582, 0.040584934483144375]\n",
      "Ep: 405  tStep: 17  Reward: 0.35  Button Pressed? 0  GRU output: 0.29 FT Observation: [-0.026171176085747372, -0.14279370182581963, 0.8630231519789857, 0.19168539864415246, 0.04232038473954236]\n",
      "Ep: 405  tStep: 18  Reward: 0.35  Button Pressed? 0  GRU output: 0.51 FT Observation: [-0.02605128531841905, -0.17274090177350587, 0.867926536052618, 0.20462653502505623, 0.03609754874795157]\n",
      "Ep: 405  tStep: 19  Reward: 0.35  Button Pressed? 0  GRU output: 0.2 FT Observation: [-0.029416070532378713, -0.14418391002022946, 0.8734247750051534, 0.1888886879463021, 0.03611926613210881]\n",
      "Ep: 405  tStep: 20  Reward: 0.35  Button Pressed? 0  GRU output: 0.0 FT Observation: [-0.0074088678635529925, -0.15712696373282686, 0.88716806155294, 0.19413433323481755, 0.05128028631433712]\n",
      "Ep: 405  tStep: 21  Reward: 0.35  Button Pressed? 0  GRU output: 0.04 FT Observation: [-0.014234492626633122, -0.12208227105968039, 0.8710364380839006, 0.1806684007659516, 0.04574876490019886]\n",
      "Ep: 405  tStep: 22  Reward: 0.35  Button Pressed? 0  GRU output: -0.03 FT Observation: [-0.015811425509999144, -0.1457317114926503, 0.8718492900822734, 0.19073004560119355, 0.0419510137685557]\n",
      "Ep: 405  tStep: 23  Reward: 0.35  Button Pressed? 0  GRU output: 0.05 FT Observation: [-0.040992743738720194, -0.1555602420019354, 0.8716420117349017, 0.1902737580423206, 0.03377007515650332]\n",
      "Ep: 405  tStep: 24  Reward: 0.35  Button Pressed? 0  GRU output: 0.36 FT Observation: [-0.026954736790190337, -0.17161960948743682, 0.8690535343019317, 0.20242667585148633, 0.036821067255522255]\n",
      "Ep: 405  tStep: 25  Reward: 0.35  Button Pressed? 0  GRU output: 0.62 FT Observation: [-0.041373210915784164, -0.17191759338465928, 0.8688881084420668, 0.21250200349076342, 0.03630478628818068]\n",
      "Ep: 405  tStep: 26  Reward: 0.35  Button Pressed? 0  GRU output: 0.43 FT Observation: [-0.03304162293474444, -0.14778835888403175, 0.8693572011345678, 0.19586000117923552, 0.03614839985675555]\n",
      "Ep: 405  tStep: 27  Reward: 0.35  Button Pressed? 0  GRU output: 0.33 FT Observation: [-0.026306590786031037, -0.1514376154889322, 0.8699019345144712, 0.19619261167436308, 0.04249933651663573]\n",
      "Ep: 405  tStep: 28  Reward: 0.36  Button Pressed? 0  GRU output: 0.48 FT Observation: [-0.027286969668545935, -0.1778413532889227, 0.8690903984526945, 0.2123363453224063, 0.038700761347160384]\n",
      "Ep: 405  tStep: 29  Reward: 0.35  Button Pressed? 0  GRU output: 0.44 FT Observation: [-0.03565510539202432, -0.20128759915489602, 0.872371763355756, 0.22626163517147235, 0.03872672385524667]\n",
      "Ep: 405  tStep: 30  Reward: 0.35  Button Pressed? 0  GRU output: 0.27 FT Observation: [0.009408244682300948, -0.19102555855667747, 0.8703703460162635, 0.22537166265806174, 0.05888743409292263]\n",
      "   Actionlist: [4, 4, 4, 4, 1, 3, 4, 3, 4, 3, 2, 0, 1, 3, 0, 3, 4, 3, 2, 0, 2, 3, 1, 3, 3, 2, 0, 3, 3, 0]\n",
      "Ep: 406  tStep: 1  Reward: 0.0  Button Pressed? 0  GRU output: 0 FT Observation: [-0.022920100410193656, -0.10666375067637501, 0.8557699524816353, 0.15627760936742252, 0.03156441828032763]\n",
      "Ep: 406  tStep: 2  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [-0.17291827656610415, -0.07555761929459415, 0.877172402725918, 0.12270249372661124, -0.07087969387898319]\n",
      "Ep: 406  tStep: 3  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [-0.153581909873714, -0.03954335423640909, 0.8813421389063625, 0.1067993566960439, -0.05408497350532293]\n",
      "Ep: 406  tStep: 4  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [-0.16344806697164205, -0.04102266221213369, 0.8748908587446638, 0.10009589890585913, -0.06255981451386872]\n",
      "Ep: 406  tStep: 5  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [-0.16042517348758178, -0.015832126523106727, 0.8753722862038471, 0.08534821949881888, -0.05751575666662556]\n",
      "Ep: 406  tStep: 6  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [-0.017947906782968648, -0.032024230504121065, 0.8808606772246794, 0.1004013202913796, 0.023881748763517896]\n",
      "Ep: 406  tStep: 7  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [-0.07825321348682646, -0.036032838709532555, 0.876732050414605, 0.09625039064338625, -0.0023369819247567314]\n",
      "Ep: 406  tStep: 8  Reward: 0.2  Button Pressed? 0  GRU output: 0 FT Observation: [-0.11300960961974504, -0.022681116956188907, 0.8788594904796494, 0.09125837192844943, -0.016064697283588503]\n",
      "Ep: 406  tStep: 9  Reward: 0.2  Button Pressed? 0  GRU output: 0 FT Observation: [-0.2369607793502735, -0.029152987613075276, 0.8759231234110207, 0.08584938676293774, -0.10046209915078386]\n",
      "Ep: 406  tStep: 10  Reward: 0.2  Button Pressed? 0  GRU output: 1.3 FT Observation: [-0.22720956912669965, -0.035667304311511994, 0.8760589215491694, 0.08233674625621767, -0.12574345224854933]\n",
      "Ep: 406  tStep: 11  Reward: 0.25  Button Pressed? 0  GRU output: 1.13 FT Observation: [-0.2404331909884614, -0.021338223440632742, 0.8891922849292058, 0.0772710056796233, -0.13048182927467233]\n",
      "Ep: 406  tStep: 12  Reward: 0.3  Button Pressed? 0  GRU output: 1.03 FT Observation: [-0.2476679542373642, -0.0064766080886595745, 0.8761295616775067, 0.07248511753173581, -0.13298277877890996]\n",
      "Ep: 406  tStep: 13  Reward: 0.3  Button Pressed? 0  GRU output: 1.03 FT Observation: [-0.3001436007404914, -0.023381964978928527, 0.8693939609881887, 0.06934950720018684, -0.1824452083954463]\n",
      "Ep: 406  tStep: 14  Reward: 0.3  Button Pressed? 0  GRU output: 0.96 FT Observation: [-0.23583102076879825, -0.06670385326085737, 0.8849015787308454, 0.09637527398452983, -0.15704574675265293]\n",
      "Ep: 406  tStep: 15  Reward: 0.3  Button Pressed? 0  GRU output: 0.3 FT Observation: [-0.0852121652864537, -0.06166407342794722, 0.8789182765859429, 0.11144919128570985, -0.043206249332795155]\n",
      "Ep: 406  tStep: 16  Reward: 0.3  Button Pressed? 0  GRU output: 0.56 FT Observation: [-0.10056801678224347, -0.08951715522835091, 0.8736361054594555, 0.1336450803190452, -0.05184745028872162]\n",
      "Ep: 406  tStep: 17  Reward: 0.35  Button Pressed? 0  GRU output: 0.84 FT Observation: [-0.13555755535208724, -0.07350752376012881, 0.8735642577657712, 0.1230618495076714, -0.07498670906722316]\n",
      "Ep: 406  tStep: 18  Reward: 0.4  Button Pressed? 0  GRU output: 0.89 FT Observation: [-0.1893638776307669, -0.06294243908134234, 0.8700654162104238, 0.11751396717030782, -0.0952039296928795]\n",
      "Ep: 406  tStep: 19  Reward: 1  Button Pressed? 1  GRU output: 0.86 FT Observation: [-0.19916122358767407, -0.0618342617352472, 0.8616848141086291, 0.11509522240860548, -0.10794768008363298]\n",
      "   Actionlist: [2, 4, 2, 4, 2, 0, 4, 4, 1, 1, 4, 4, 1, 3, 0, 3, 4, 4, 4]\n",
      "Ep: 407  tStep: 1  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [-0.006793873741498313, -0.12597173201403722, 0.8891476783452934, 0.1813690624758253, 0.046909948507736665]\n",
      "Ep: 407  tStep: 2  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [0.0006681505104606522, -0.13356149396230033, 0.8935983307294575, 0.17963518035674442, 0.04634330819610355]\n",
      "Ep: 407  tStep: 3  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [0.022257858587698243, -0.12446963356751062, 0.8885209014112556, 0.1772176320533323, 0.05804588545682754]\n",
      "Ep: 407  tStep: 4  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [-0.030700654181150977, -0.12584357859084983, 0.8954131466299764, 0.17509098120208, 0.0078422404557279]\n",
      "Ep: 407  tStep: 5  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [-0.03109465029135916, -0.1284160443876028, 0.8914566280302467, 0.17694460488648445, 0.018599262215005297]\n",
      "Ep: 407  tStep: 6  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [-0.02538985021715834, -0.10960680579224003, 0.8927262273617593, 0.16367099891465076, 0.021890623491479078]\n",
      "Ep: 407  tStep: 7  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [0.016022568440812623, -0.10951060477470254, 0.8946123466552529, 0.16612730667339237, 0.04654181625168485]\n",
      "Ep: 407  tStep: 8  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [9.607613843742868e-05, -0.1380537894262095, 0.8938504071437754, 0.17830511739379706, 0.03377254195362678]\n",
      "Ep: 407  tStep: 9  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [-0.00980671046421644, -0.12546155509565793, 0.8916957161911021, 0.17851146128096396, 0.030287776339757988]\n",
      "Ep: 407  tStep: 10  Reward: 0.15  Button Pressed? 0  GRU output: 0.27 FT Observation: [-0.019499711390027152, -0.10993928200965897, 0.8998728239762077, 0.16485922290103772, 0.03117784884232777]\n",
      "Ep: 407  tStep: 11  Reward: 0.15  Button Pressed? 0  GRU output: 0.32 FT Observation: [-0.019452185697809155, -0.11281790328229935, 0.8943381070982634, 0.16228173458671868, 0.028021268256956944]\n",
      "Ep: 407  tStep: 12  Reward: 0.15  Button Pressed? 0  GRU output: 0.25 FT Observation: [-0.011473707232491193, -0.11242979591997104, 0.8930234546606994, 0.16596860141529635, 0.04235372371531976]\n",
      "Ep: 407  tStep: 13  Reward: 0.16  Button Pressed? 0  GRU output: 0.37 FT Observation: [-0.001907612278262194, -0.09472085076191827, 0.8942220080828069, 0.15393644537675866, 0.03780769838471576]\n",
      "Ep: 407  tStep: 14  Reward: 0.15  Button Pressed? 0  GRU output: 0.51 FT Observation: [-0.008617783240806642, -0.11165350401559082, 0.8911495348735323, 0.16257205025673893, 0.038948570788784]\n",
      "Ep: 407  tStep: 15  Reward: 0.21  Button Pressed? 0  GRU output: 0.6 FT Observation: [-0.0026517308552947982, -0.10320665755103964, 0.888337224366365, 0.15876887020433994, 0.035988044752803594]\n",
      "Ep: 407  tStep: 16  Reward: 0.25  Button Pressed? 0  GRU output: 0.47 FT Observation: [-0.0031612625283261586, -0.11455561598961805, 0.8965814049916234, 0.15981859960229627, 0.03874918021526641]\n",
      "Ep: 407  tStep: 17  Reward: 0.26  Button Pressed? 0  GRU output: 0.47 FT Observation: [-0.02029858889629743, -0.0910539101773955, 0.897789641751507, 0.15520363462838938, 0.03469380030086411]\n",
      "Ep: 407  tStep: 18  Reward: 0.25  Button Pressed? 0  GRU output: 0.34 FT Observation: [-0.01834535326170239, -0.1106783508348882, 0.8976155078951078, 0.16174311920912232, 0.0356689640132577]\n",
      "Ep: 407  tStep: 19  Reward: 0.25  Button Pressed? 0  GRU output: 0.54 FT Observation: [-0.01163924315942888, -0.08364458933651253, 0.8933030818169294, 0.15149299770355418, 0.033338662111314754]\n",
      "Ep: 407  tStep: 20  Reward: 0.26  Button Pressed? 0  GRU output: 0.49 FT Observation: [-0.01482873548016228, -0.11039787129902179, 0.8973890299105756, 0.16228548941355636, 0.029837569915622808]\n",
      "Ep: 407  tStep: 21  Reward: 0.3  Button Pressed? 0  GRU output: 0.57 FT Observation: [-0.010387239056749986, -0.09992440596871499, 0.8948118442728683, 0.1579885083917394, 0.030805575131622742]\n",
      "Ep: 407  tStep: 22  Reward: 0.35  Button Pressed? 0  GRU output: 0.59 FT Observation: [-0.019757349808237845, -0.10063523964444565, 0.8933564102493401, 0.15774682676284724, 0.03755024238408278]\n",
      "Ep: 407  tStep: 23  Reward: 0.4  Button Pressed? 0  GRU output: 0.58 FT Observation: [-0.0010016970362324296, -0.10557299349557359, 0.8909465367830891, 0.15834286821073107, 0.036882737183606684]\n",
      "Ep: 407  tStep: 24  Reward: 0.4  Button Pressed? 0  GRU output: 0.56 FT Observation: [-0.020373728438358052, -0.08894740047464123, 0.8953413836777202, 0.15230776174238048, 0.03587123074462828]\n",
      "Ep: 407  tStep: 25  Reward: 0.4  Button Pressed? 0  GRU output: 0.44 FT Observation: [0.05670990362328654, -0.09911316287559868, 0.8874722555750358, 0.15363379494347051, 0.07193905631506436]\n",
      "Ep: 407  tStep: 26  Reward: 0.41  Button Pressed? 0  GRU output: 0.38 FT Observation: [0.02963396702812582, -0.07584125898933292, 0.8901272501399489, 0.1421175917816362, 0.057115859081237064]\n",
      "Ep: 407  tStep: 27  Reward: 1  Button Pressed? 1  GRU output: 0.82 FT Observation: [0.09890736476746631, -0.11037034339644669, 0.7729806872265146, 0.16247564232832956, 0.08682973161459961]\n",
      "   Actionlist: [4, 0, 0, 1, 4, 2, 0, 3, 4, 2, 2, 0, 2, 3, 4, 4, 2, 3, 2, 3, 4, 4, 4, 2, 0, 2, 4]\n",
      "Ep: 408  tStep: 1  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [-0.11202266250014759, -0.1443248773824679, 0.896775746419282, 0.19489639713995932, -0.04360437124956462]\n",
      "Ep: 408  tStep: 2  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [-0.09348136319143785, -0.1525008307344815, 0.9035926630272049, 0.19356254891094005, -0.03739574060692563]\n",
      "Ep: 408  tStep: 3  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [-0.09423585467732376, -0.14206500665710198, 0.8943911943435332, 0.19240087873788303, -0.03364973905114221]\n",
      "Ep: 408  tStep: 4  Reward: 0.2  Button Pressed? 0  GRU output: 0 FT Observation: [-0.08466707246925098, -0.13358572444888062, 0.8921944064569265, 0.18810451042839516, -0.03237660591682556]\n",
      "Ep: 408  tStep: 5  Reward: 0.25  Button Pressed? 0  GRU output: 0 FT Observation: [-0.09563452397102368, -0.1303554261345139, 0.8946440920978442, 0.19112888499678649, -0.033489843813464204]\n",
      "Ep: 408  tStep: 6  Reward: 0.25  Button Pressed? 0  GRU output: 0 FT Observation: [-0.0776584091989243, -0.10961464865544501, 0.8990157100633842, 0.17544277627010385, -0.028624235346055515]\n",
      "Ep: 408  tStep: 7  Reward: 0.3  Button Pressed? 0  GRU output: 0 FT Observation: [-0.08390098164020188, -0.11212640523228012, 0.8965281124113553, 0.1766705359122951, -0.030454694506315216]\n",
      "Ep: 408  tStep: 8  Reward: 0.3  Button Pressed? 0  GRU output: 0 FT Observation: [-0.08599835873654882, -0.09810208042856916, 0.8969793637740056, 0.16464610112920686, -0.024594956165440385]\n",
      "Ep: 408  tStep: 9  Reward: 0.3  Button Pressed? 0  GRU output: 0 FT Observation: [-0.12806845688138213, -0.11701890790971492, 0.896684737385044, 0.17021178550908322, -0.041258936291561854]\n",
      "Ep: 408  tStep: 10  Reward: 0.3  Button Pressed? 0  GRU output: 0.81 FT Observation: [-0.09154761968614344, -0.08863045843072015, 0.8935465243834626, 0.15632842128666957, -0.03164181935644661]\n",
      "Ep: 408  tStep: 11  Reward: 0.34  Button Pressed? 0  GRU output: 0.76 FT Observation: [-0.09310605248929515, -0.09096528259566361, 0.8915155265818964, 0.15857024732714464, -0.032661180736696216]\n",
      "Ep: 408  tStep: 12  Reward: 0.39  Button Pressed? 0  GRU output: 0.85 FT Observation: [-0.09373977562596869, -0.09605392421007253, 0.8915586013015357, 0.15895668420762554, -0.030733878523851565]\n",
      "Ep: 408  tStep: 13  Reward: 0.39  Button Pressed? 0  GRU output: 1.05 FT Observation: [-0.09587027189950525, -0.11956228993082452, 0.8932462268374055, 0.17130756848662765, -0.030615419098198537]\n",
      "Ep: 408  tStep: 14  Reward: 0.4  Button Pressed? 0  GRU output: 0.9 FT Observation: [-0.0860685870905501, -0.10213025299232803, 0.8932538731216273, 0.15876433181269656, -0.027933149372646682]\n",
      "Ep: 408  tStep: 15  Reward: 0.4  Button Pressed? 0  GRU output: 0.62 FT Observation: [-0.08472968057807273, -0.08609985316206736, 0.89429261724793, 0.15471385949318583, -0.02518039517239301]\n",
      "Ep: 408  tStep: 16  Reward: 0.4  Button Pressed? 0  GRU output: 0.62 FT Observation: [-0.06116823133520677, -0.10507634056970427, 0.8984535321716627, 0.1551520607463741, -0.02005618768413253]\n",
      "Ep: 408  tStep: 17  Reward: 0.39  Button Pressed? 0  GRU output: 0.59 FT Observation: [-0.07613376057289922, -0.08457803178794265, 0.8911882584467794, 0.1548563897349382, -0.02192242603542749]\n",
      "Ep: 408  tStep: 18  Reward: 0.4  Button Pressed? 0  GRU output: 0.62 FT Observation: [-0.06760477662695707, -0.09241052765110946, 0.8972576839566753, 0.15754550755863916, -0.014795806615014229]\n",
      "Ep: 408  tStep: 19  Reward: 0.4  Button Pressed? 0  GRU output: 0.71 FT Observation: [-0.07911447561833318, -0.09898399769639576, 0.8913256601534862, 0.16552167293906028, -0.014755359648387811]\n",
      "Ep: 408  tStep: 20  Reward: 0.4  Button Pressed? 0  GRU output: 0.52 FT Observation: [-0.055750117094496954, -0.08412468089692382, 0.8932667505593765, 0.15626404328803178, -0.012327552805407538]\n",
      "Ep: 408  tStep: 21  Reward: 0.4  Button Pressed? 0  GRU output: 0.61 FT Observation: [-0.07888996727895048, -0.11287071526238857, 0.8993294489036143, 0.16797445563808777, -0.015643491674772414]\n",
      "Ep: 408  tStep: 22  Reward: 0.4  Button Pressed? 0  GRU output: 0.45 FT Observation: [-0.07300620045941231, -0.12435940267945544, 0.8980962883860824, 0.1772508064001228, -0.015855944577022996]\n",
      "Ep: 408  tStep: 23  Reward: 0.4  Button Pressed? 0  GRU output: 0.5 FT Observation: [-0.0635559517646982, -0.1325767621018502, 0.8917708753190441, 0.18463192549923968, -0.014811936491032074]\n",
      "Ep: 408  tStep: 24  Reward: 1  Button Pressed? 1  GRU output: 0.37 FT Observation: [-0.08009975478726894, -0.13288381456908316, 0.8644658395473082, 0.18091984798854566, -0.020676544629676386]\n",
      "   Actionlist: [4, 4, 4, 4, 4, 2, 4, 2, 1, 2, 4, 4, 3, 2, 2, 2, 3, 0, 3, 2, 3, 3, 3, 4]\n",
      "Ep: 409  tStep: 1  Reward: 0.0  Button Pressed? 0  GRU output: 0 FT Observation: [-0.0666445712261372, -0.10071539710230837, 0.9016587202348261, 0.16033765531707678, -0.014480173543430674]\n",
      "Ep: 409  tStep: 2  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [-0.14513409952663758, -0.09873020269921351, 0.9000701215759843, 0.15650653597523156, -0.06430397830579526]\n",
      "Ep: 409  tStep: 3  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [-0.06710971142796485, -0.09732297777897525, 0.9291209073548892, 0.1639036999875132, -0.017880547050539985]\n",
      "Ep: 409  tStep: 4  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [-0.091666153199502, -0.09489208029385543, 0.9014259681253463, 0.1583295377899283, -0.02977038159224954]\n",
      "Ep: 409  tStep: 5  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [-0.09657905281595192, -0.08810031511779592, 0.8989934882535702, 0.15571617831085072, -0.03090606521616157]\n",
      "Ep: 409  tStep: 6  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [-0.09037344783018786, -0.09447290739106717, 0.8983023925757851, 0.15651296945468784, -0.030943152234982008]\n",
      "Ep: 409  tStep: 7  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [-0.1851278280321499, -0.09593676538935625, 0.9053632895323798, 0.15452777365287962, -0.08017456417436508]\n",
      "Ep: 409  tStep: 8  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [-0.14858623411756655, -0.10304830159703093, 0.9036470213938925, 0.1554039405006682, -0.06653459023735264]\n",
      "Ep: 409  tStep: 9  Reward: 0.19  Button Pressed? 0  GRU output: 0 FT Observation: [-0.16209371283767748, -0.09241092056606692, 0.9055963251997141, 0.15407619877481404, -0.07319084886316807]\n",
      "Ep: 409  tStep: 10  Reward: 0.25  Button Pressed? 0  GRU output: 0.81 FT Observation: [-0.1643117383652154, -0.09720342217701827, 0.8993505267041522, 0.15342919222960116, -0.07568588656050645]\n",
      "Ep: 409  tStep: 11  Reward: 0.3  Button Pressed? 0  GRU output: 0.84 FT Observation: [-0.17140486752917794, -0.08223480485597978, 0.8939557374793221, 0.15169078202893993, -0.07606188173238904]\n",
      "Ep: 409  tStep: 12  Reward: 0.3  Button Pressed? 0  GRU output: 0.73 FT Observation: [-0.1448862398779922, -0.08989425255226335, 0.8979524039601443, 0.15222906355686994, -0.0710289244722011]\n",
      "Ep: 409  tStep: 13  Reward: 0.3  Button Pressed? 0  GRU output: 0.72 FT Observation: [-0.07128837480251116, -0.0912082303334838, 0.8994700512288658, 0.155228667461915, -0.016536812481313]\n",
      "Ep: 409  tStep: 14  Reward: 0.3  Button Pressed? 0  GRU output: 0.75 FT Observation: [-0.07150680002771614, -0.10043818156712447, 0.9023925223329679, 0.1579603903945308, -0.018036199822475618]\n",
      "Ep: 409  tStep: 15  Reward: 0.3  Button Pressed? 0  GRU output: 0.89 FT Observation: [-0.08468567066421007, -0.1157868767526814, 0.9014699847785492, 0.16709266538723955, -0.023431170193265016]\n",
      "Ep: 409  tStep: 16  Reward: 0.35  Button Pressed? 0  GRU output: 0.69 FT Observation: [-0.10089155560404584, -0.10270308651538318, 0.8941679626075452, 0.16282870798890792, -0.031093999005625594]\n",
      "Ep: 409  tStep: 17  Reward: 0.35  Button Pressed? 0  GRU output: 0.65 FT Observation: [-0.08656284556830729, -0.12689274817911977, 0.8938222892861536, 0.17401288587444208, -0.028949150805090307]\n",
      "Ep: 409  tStep: 18  Reward: 0.35  Button Pressed? 0  GRU output: 0.55 FT Observation: [-0.09737480700284595, -0.134960710258336, 0.8988693942103236, 0.18151345577055134, -0.02808688825026251]\n",
      "Ep: 409  tStep: 19  Reward: 0.35  Button Pressed? 0  GRU output: 0.5 FT Observation: [-0.07625453982374997, -0.12749536570840325, 0.896330479105153, 0.17937023210634906, -0.017458044246684845]\n",
      "Ep: 409  tStep: 20  Reward: 0.35  Button Pressed? 0  GRU output: 0.62 FT Observation: [-0.06961569282985713, -0.14397118024917543, 0.8943506423110155, 0.19011525603975676, -0.015049025466277843]\n",
      "Ep: 409  tStep: 21  Reward: 0.35  Button Pressed? 0  GRU output: 0.65 FT Observation: [-0.08083887496313591, -0.11544353783995565, 0.8992819513332979, 0.17599325460283644, -0.015345764147825847]\n",
      "Ep: 409  tStep: 22  Reward: 0.35  Button Pressed? 0  GRU output: 0.43 FT Observation: [-0.04822698370898404, -0.11642021637265398, 0.8987151094037582, 0.17455968155077928, -0.004489613295526107]\n",
      "Ep: 409  tStep: 23  Reward: 0.4  Button Pressed? 0  GRU output: 0.47 FT Observation: [-0.06167046981220781, -0.1152018979476368, 0.8994746533402558, 0.1750610250678839, -0.01094091510517703]\n",
      "Ep: 409  tStep: 24  Reward: 0.39  Button Pressed? 0  GRU output: 0.51 FT Observation: [-0.06470186657415089, -0.13385617597061217, 0.8947035708023463, 0.18557754952467342, -0.014640696113135787]\n",
      "Ep: 409  tStep: 25  Reward: 0.4  Button Pressed? 0  GRU output: 0.51 FT Observation: [-0.043864180761721716, -0.12740950080996616, 0.8962639440471387, 0.18402236228068913, 0.0019341922323961036]\n",
      "Ep: 409  tStep: 26  Reward: 0.39  Button Pressed? 0  GRU output: 0.52 FT Observation: [-0.03335070073332691, -0.12587872623706464, 0.8933614979942974, 0.18167560330100896, 0.005099651160861862]\n",
      "Ep: 409  tStep: 27  Reward: 0.4  Button Pressed? 0  GRU output: 0.35 FT Observation: [-0.05357779123475992, -0.14125924472764262, 0.8984449732874487, 0.19353138502647949, 0.002838576411380078]\n",
      "Ep: 409  tStep: 28  Reward: 0.39  Button Pressed? 0  GRU output: 0.48 FT Observation: [0.0035126986425673135, -0.1412580737007425, 0.8909946992476858, 0.19416416368443334, 0.028877140531305523]\n",
      "Ep: 409  tStep: 29  Reward: 0.4  Button Pressed? 0  GRU output: 0.4 FT Observation: [-0.015642809870238472, -0.13830598224248913, 0.8970735897232167, 0.19277990317385618, 0.029768536810780066]\n",
      "Ep: 409  tStep: 30  Reward: 0.4  Button Pressed? 0  GRU output: 0.27 FT Observation: [-0.01958490224261078, -0.12293020118368436, 0.8963493536285663, 0.1777680686548564, 0.02012029782747482]\n",
      "   Actionlist: [0, 4, 0, 4, 4, 2, 1, 3, 4, 4, 4, 2, 0, 3, 3, 4, 3, 3, 0, 3, 2, 0, 4, 3, 0, 0, 3, 0, 0, 2]\n",
      "Ep: 410  tStep: 1  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [0.0544979610502343, -0.11987147751740612, 0.8615249246547669, 0.17547848541958322, 0.06559299277568686]\n",
      "Ep: 410  tStep: 2  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [0.03830121645277007, -0.10110561497926529, 0.8595321194684389, 0.1679942804168153, 0.06577800388903321]\n",
      "Ep: 410  tStep: 3  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [0.028130751023020872, -0.10588241963766509, 0.8620055135608546, 0.1665969241621128, 0.058864557739427115]\n",
      "Ep: 410  tStep: 4  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [0.053563012701324464, -0.11417862952385438, 0.8629915725562591, 0.17359760438277205, 0.07871331076218402]\n",
      "Ep: 410  tStep: 5  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [0.0655244469675198, -0.12731324085518503, 0.858814562668688, 0.18698058588778332, 0.07591977042731313]\n",
      "Ep: 410  tStep: 6  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [0.07751015373141512, -0.14654259254269864, 0.8560184000887516, 0.19666142399624054, 0.07783701804951204]\n",
      "Ep: 410  tStep: 7  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [0.06073361129186039, -0.14044156484556192, 0.8589105873361875, 0.1924403741353451, 0.07843506616439]\n",
      "Ep: 410  tStep: 8  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [0.03483478845131027, -0.14490103454508307, 0.8619302226355474, 0.19136445815869196, 0.059232421518636835]\n",
      "Ep: 410  tStep: 9  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [0.0007406409544115089, -0.14171352598515008, 0.8643006948008338, 0.19047389600785558, 0.04484066457641056]\n",
      "Ep: 410  tStep: 10  Reward: 0.2  Button Pressed? 0  GRU output: -0.02 FT Observation: [0.00822111622921251, -0.1276359833061661, 0.8572262711975223, 0.18770263987421232, 0.045324765537313016]\n",
      "Ep: 410  tStep: 11  Reward: 0.2  Button Pressed? 0  GRU output: 0.12 FT Observation: [0.05471673035839841, -0.13650462678411457, 0.8624962503547815, 0.19234768863071738, 0.07581993159848022]\n",
      "Ep: 410  tStep: 12  Reward: 0.2  Button Pressed? 0  GRU output: 0.08 FT Observation: [0.06530077396617262, -0.11169398548235365, 0.8575940455314519, 0.17994085360238077, 0.07555767690656845]\n",
      "Ep: 410  tStep: 13  Reward: 0.25  Button Pressed? 0  GRU output: 0.05 FT Observation: [0.052917941299845284, -0.11072766306532045, 0.8571982122107482, 0.1774044032673654, 0.07690717176606077]\n",
      "Ep: 410  tStep: 14  Reward: 0.25  Button Pressed? 0  GRU output: 0.13 FT Observation: [0.04761484786022452, -0.09468230019151802, 0.8598447075055011, 0.16518941200417192, 0.0719756309684263]\n",
      "Ep: 410  tStep: 15  Reward: 0.26  Button Pressed? 0  GRU output: 0.14 FT Observation: [0.05672922552094972, -0.12333397883647779, 0.862224640837636, 0.18218721291015227, 0.07476904678387064]\n",
      "Ep: 410  tStep: 16  Reward: 0.25  Button Pressed? 0  GRU output: 0.03 FT Observation: [0.05395656899856216, -0.14523712558011082, 0.8584996243094722, 0.19507360945251095, 0.07593117869946209]\n",
      "Ep: 410  tStep: 17  Reward: 0.3  Button Pressed? 0  GRU output: 0.07 FT Observation: [0.041257321049716245, -0.13606932086333523, 0.8614375766131768, 0.19147007837407637, 0.07024475744473002]\n",
      "Ep: 410  tStep: 18  Reward: 0.3  Button Pressed? 0  GRU output: 0.08 FT Observation: [0.039336595463270285, -0.15215927256847384, 0.8577342500201439, 0.1959660004121826, 0.07245736614329457]\n",
      "Ep: 410  tStep: 19  Reward: 0.3  Button Pressed? 0  GRU output: 0.08 FT Observation: [0.04251107759075379, -0.14460264650676147, 0.8560825611645537, 0.19656568867671798, 0.07223583354031748]\n",
      "Ep: 410  tStep: 20  Reward: 0.3  Button Pressed? 0  GRU output: 0.11 FT Observation: [0.046343936228599336, -0.14395576184526337, 0.8588104471075395, 0.19579971283901298, 0.07156701718932279]\n",
      "Ep: 410  tStep: 21  Reward: 0.35  Button Pressed? 0  GRU output: 0.28 FT Observation: [0.042840660008294895, -0.1375778424169658, 0.8531812627876851, 0.1940312149281107, 0.06677214306615231]\n",
      "Ep: 410  tStep: 22  Reward: 0.35  Button Pressed? 0  GRU output: 0.1 FT Observation: [0.04149647710287496, -0.1499413097314931, 0.8609132877138612, 0.19694535037278982, 0.0690829278978593]\n",
      "Ep: 410  tStep: 23  Reward: 0.35  Button Pressed? 0  GRU output: 0.09 FT Observation: [-0.01241631738907667, -0.1469737942562569, 0.8614675684582158, 0.19323850656931296, 0.040637994544975964]\n",
      "Ep: 410  tStep: 24  Reward: 0.4  Button Pressed? 0  GRU output: 0.11 FT Observation: [-0.002260743597260473, -0.1427679371291164, 0.8554786440455031, 0.19403970060110542, 0.042859329405455115]\n",
      "Ep: 410  tStep: 25  Reward: 0.4  Button Pressed? 0  GRU output: 0.0 FT Observation: [0.02148484521832139, -0.1313372360663937, 0.8582072355219874, 0.18679190043867688, 0.05301168549442492]\n",
      "Ep: 410  tStep: 26  Reward: 0.4  Button Pressed? 0  GRU output: 0.08 FT Observation: [0.02777917863830104, -0.16698278078264173, 0.8568380330309961, 0.20107550966197074, 0.057576997297581256]\n",
      "Ep: 410  tStep: 27  Reward: 0.4  Button Pressed? 0  GRU output: 0.09 FT Observation: [0.02298706099811154, -0.15004468425354012, 0.8570195316508158, 0.20101189951756604, 0.05922817506561473]\n",
      "Ep: 410  tStep: 28  Reward: 0.4  Button Pressed? 0  GRU output: 0.12 FT Observation: [0.046132622959687675, -0.15542223763945673, 0.8562515115344784, 0.2030018340208175, 0.07713071944058347]\n",
      "Ep: 410  tStep: 29  Reward: 1  Button Pressed? 1  GRU output: 0.05 FT Observation: [0.05442874092743866, -0.14078467853382104, 0.8333051339935695, 0.1995751205267995, 0.0758640435398199]\n",
      "   Actionlist: [4, 2, 4, 0, 3, 3, 4, 1, 1, 4, 0, 2, 4, 2, 3, 3, 4, 3, 3, 2, 4, 3, 1, 4, 2, 3, 3, 0, 4]\n",
      "Ep: 411  tStep: 1  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [0.1269683507561139, -0.1334611055939302, 0.8554978163861462, 0.1916084099653168, 0.12170926605555321]\n",
      "Ep: 411  tStep: 2  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [0.14634765355099288, -0.1419459772805346, 0.8493906784963874, 0.19473285891698477, 0.13356525124966656]\n",
      "Ep: 411  tStep: 3  Reward: 0.06  Button Pressed? 0  GRU output: 0 FT Observation: [0.1332442495057089, -0.12352330771527809, 0.8567033304202489, 0.18381817356495378, 0.12494482136348384]\n",
      "Ep: 411  tStep: 4  Reward: 0.06  Button Pressed? 0  GRU output: 0 FT Observation: [0.17087418667782317, -0.13151849738374766, 0.8537005541835159, 0.1870984279466954, 0.15121037866611764]\n",
      "Ep: 411  tStep: 5  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [0.07498833361176138, -0.13234685793100243, 0.8551454537882928, 0.18416786145243558, 0.09363473704367964]\n",
      "Ep: 411  tStep: 6  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [0.10603592425594055, -0.12777216763043098, 0.851986224505191, 0.1823972313644573, 0.10880652686873704]\n",
      "Ep: 411  tStep: 7  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [0.11171602121772795, -0.13201387706343504, 0.8585936489977921, 0.1822309768118735, 0.10914647171455583]\n",
      "Ep: 411  tStep: 8  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [0.09309719490816759, -0.10456347148223244, 0.8594352643705947, 0.16937291752433303, 0.1068586210519018]\n",
      "Ep: 411  tStep: 9  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [0.10999717625764482, -0.13755533189807112, 0.8554303365426932, 0.18621285095690898, 0.10637862167285417]\n",
      "Ep: 411  tStep: 10  Reward: 0.16  Button Pressed? 0  GRU output: 0.01 FT Observation: [0.0933011809134292, -0.11773569003724838, 0.8620710948703947, 0.17367958411412254, 0.10289803207006387]\n",
      "Ep: 411  tStep: 11  Reward: 0.2  Button Pressed? 0  GRU output: 0.06 FT Observation: [0.10337147118873613, -0.10897079014075339, 0.8539554820653992, 0.17056487375360962, 0.10777527010365229]\n",
      "Ep: 411  tStep: 12  Reward: 0.2  Button Pressed? 0  GRU output: 0.18 FT Observation: [0.09505391906702232, -0.08778656691117204, 0.8516367019674034, 0.15246183139966552, 0.10814477132578015]\n",
      "Ep: 411  tStep: 13  Reward: 0.2  Button Pressed? 0  GRU output: 0.49 FT Observation: [0.08796365430852604, -0.1245482607619407, 0.8541652680256961, 0.17439273707929526, 0.10705583191244394]\n",
      "Ep: 411  tStep: 14  Reward: 0.2  Button Pressed? 0  GRU output: 0.33 FT Observation: [0.17344184954928066, -0.12041069856911601, 0.8515945072548994, 0.17743275348647458, 0.15532242845969368]\n",
      "Ep: 411  tStep: 15  Reward: 0.2  Button Pressed? 0  GRU output: 0.27 FT Observation: [0.14141954069827967, -0.1427865830487507, 0.8570264270770973, 0.1906861507524642, 0.1354627179766139]\n",
      "Ep: 411  tStep: 16  Reward: 0.2  Button Pressed? 0  GRU output: 0.28 FT Observation: [0.12038270375718008, -0.15108187168969145, 0.8522189847628849, 0.19641866815695064, 0.12584648887580818]\n",
      "Ep: 411  tStep: 17  Reward: 0.2  Button Pressed? 0  GRU output: 0.1 FT Observation: [0.1154859767211649, -0.11867043612437667, 0.8549678960522795, 0.1816318442014453, 0.12217498299823881]\n",
      "Ep: 411  tStep: 18  Reward: 0.2  Button Pressed? 0  GRU output: -0.05 FT Observation: [0.049812704675534114, -0.13451433887006636, 0.8559217133788468, 0.18268350201081196, 0.0810019150207264]\n",
      "Ep: 411  tStep: 19  Reward: 0.21  Button Pressed? 0  GRU output: 0.04 FT Observation: [0.09156224150852865, -0.14872158663550294, 0.8548834703677186, 0.1958564751376104, 0.09207386584749155]\n",
      "Ep: 411  tStep: 20  Reward: 0.2  Button Pressed? 0  GRU output: 0.57 FT Observation: [0.13674454753469711, -0.151088607374677, 0.8493796156659443, 0.19683306592891503, 0.1319683084619223]\n",
      "Ep: 411  tStep: 21  Reward: 0.2  Button Pressed? 0  GRU output: 0.37 FT Observation: [0.1502727611708763, -0.13757611850258988, 0.8551389124019191, 0.19310357337129602, 0.14420482369418175]\n",
      "Ep: 411  tStep: 22  Reward: 0.2  Button Pressed? 0  GRU output: 0.39 FT Observation: [0.18901115512320543, -0.13786766420758034, 0.8516308156974526, 0.19384908913399612, 0.16230750476240696]\n",
      "Ep: 411  tStep: 23  Reward: 0.2  Button Pressed? 0  GRU output: 0.28 FT Observation: [0.09910026925738458, -0.13713005583321547, 0.8594125622490159, 0.1879317520631596, 0.10768626338503262]\n",
      "Ep: 411  tStep: 24  Reward: 0.25  Button Pressed? 0  GRU output: 0.18 FT Observation: [0.12079416429196299, -0.1378598195902907, 0.8522334185095499, 0.1882442132580453, 0.11805495067043714]\n",
      "Ep: 411  tStep: 25  Reward: 0.3  Button Pressed? 0  GRU output: 0.16 FT Observation: [0.11582378578751684, -0.13059665118581731, 0.8552249432846808, 0.18503952452093597, 0.11747457550887264]\n",
      "Ep: 411  tStep: 26  Reward: 0.3  Button Pressed? 0  GRU output: 0.18 FT Observation: [0.11224048268442655, -0.12400010299984954, 0.8554691664501359, 0.17514217901226492, 0.11868558416520392]\n",
      "Ep: 411  tStep: 27  Reward: 0.3  Button Pressed? 0  GRU output: 0.11 FT Observation: [0.11706344378480837, -0.0935607777695453, 0.8611578116502736, 0.16175191320210303, 0.11841578620439464]\n",
      "Ep: 411  tStep: 28  Reward: 0.3  Button Pressed? 0  GRU output: 0.14 FT Observation: [0.11918079268254145, -0.12809376010352747, 0.8555855958756791, 0.17882439992996857, 0.11928341563787748]\n",
      "Ep: 411  tStep: 29  Reward: 0.3  Button Pressed? 0  GRU output: 0.07 FT Observation: [0.1141479150856568, -0.1487935700589822, 0.860565905202685, 0.19368766987449337, 0.11911924603621848]\n",
      "Ep: 411  tStep: 30  Reward: 0.3  Button Pressed? 0  GRU output: 0.22 FT Observation: [0.15671597826527295, -0.14146465575597955, 0.8509480320129907, 0.19047027570279518, 0.15118584892058484]\n",
      "   Actionlist: [4, 0, 2, 0, 1, 4, 4, 2, 3, 2, 4, 2, 3, 0, 3, 3, 2, 1, 3, 0, 0, 0, 1, 4, 4, 2, 2, 3, 3, 0]\n",
      "Ep: 412  tStep: 1  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [-0.09519886179918968, -0.17094415219055703, 0.860108094578516, 0.21484397461209181, -0.040675570670122396]\n",
      "Ep: 412  tStep: 2  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [-0.06335451129198222, -0.18261388359389208, 0.8622884961516994, 0.22357739744436755, -0.017886139875052498]\n",
      "Ep: 412  tStep: 3  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [-0.024903342804240447, -0.20501437507437315, 0.8564636684214073, 0.23538038139740003, -0.008950225775733234]\n",
      "Ep: 412  tStep: 4  Reward: 0.1  Button Pressed? 0  GRU output: 0 FT Observation: [-0.060293102319768144, -0.18571380299019513, 0.8654203409164591, 0.2284019689494987, -0.02075855500128232]\n",
      "Ep: 412  tStep: 5  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [-0.07265262762406233, -0.1894282077015822, 0.8528401043917917, 0.22738334255753423, -0.02463515857890375]\n",
      "Ep: 412  tStep: 6  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [-0.051691840511822185, -0.20976725963146825, 0.8492231846197542, 0.24002882167375295, -0.01593122442027073]\n",
      "Ep: 412  tStep: 7  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [-0.10783359896265221, -0.20485177002575272, 0.8530972546991029, 0.23690758651608057, -0.06758455266122754]\n",
      "Ep: 412  tStep: 8  Reward: 0.15  Button Pressed? 0  GRU output: 0 FT Observation: [-0.10051776022962844, -0.16471475496700638, 0.8641232165099091, 0.2161527733151023, -0.057669250991078225]\n",
      "Ep: 412  tStep: 9  Reward: 0.2  Button Pressed? 0  GRU output: 0 FT Observation: [-0.10874441994192197, -0.1575765819317495, 0.8586247062218402, 0.21508389665685934, -0.06609308671599978]\n",
      "Ep: 412  tStep: 10  Reward: 0.25  Button Pressed? 0  GRU output: 0.91 FT Observation: [-0.1304930466516423, -0.16936405591516634, 0.8610680739411589, 0.21656539972001254, -0.07327703790403906]\n",
      "Ep: 412  tStep: 11  Reward: 0.25  Button Pressed? 0  GRU output: 0.77 FT Observation: [-0.12021718418269944, -0.14595969759019645, 0.8580830752745001, 0.1969957351608458, -0.06286519761809473]\n",
      "Ep: 412  tStep: 12  Reward: 0.25  Button Pressed? 0  GRU output: 0.75 FT Observation: [-0.11617086669725218, -0.1399334689731897, 0.8568961403910453, 0.1928783475852316, -0.060055919738927765]\n",
      "Ep: 412  tStep: 13  Reward: 0.3  Button Pressed? 0  GRU output: 0.87 FT Observation: [-0.1356421084588295, -0.1442976118909538, 0.8615909845700396, 0.1966956642071871, -0.07549899478017219]\n",
      "Ep: 412  tStep: 14  Reward: 0.3  Button Pressed? 0  GRU output: 0.6 FT Observation: [-0.20553059298415022, -0.14502872488992768, 0.8668310298364332, 0.19394440026806015, -0.13577383213105332]\n",
      "Ep: 412  tStep: 15  Reward: 0.3  Button Pressed? 0  GRU output: 0.9 FT Observation: [-0.16628519653887797, -0.15114525729194028, 0.8656563832748398, 0.19544861885528864, -0.11333967328548034]\n",
      "Ep: 412  tStep: 16  Reward: 0.3  Button Pressed? 0  GRU output: 0.35 FT Observation: [-0.13175613226966465, -0.19168996091057477, 0.8593647378843827, 0.2238417828144057, -0.0975333730005652]\n",
      "Ep: 412  tStep: 17  Reward: 0.35  Button Pressed? 0  GRU output: 0.97 FT Observation: [-0.18934002484614176, -0.18157054844192377, 0.866741623555932, 0.21948788827973065, -0.12058437998542892]\n",
      "Ep: 412  tStep: 18  Reward: 0.35  Button Pressed? 0  GRU output: 0.17 FT Observation: [-0.13863639604396105, -0.21260192775304287, 0.8653302061856067, 0.24176048418350682, -0.10323796894132298]\n",
      "Ep: 412  tStep: 19  Reward: 0.35  Button Pressed? 0  GRU output: 0.44 FT Observation: [0.023164030018228088, -0.20045327230802734, 0.8478664173221857, 0.24309971230171135, 0.005673463259821432]\n",
      "Ep: 412  tStep: 20  Reward: 0.35  Button Pressed? 0  GRU output: 0.61 FT Observation: [-0.1991344491639815, -0.20522505607457753, 0.8499935184215186, 0.23997260138990817, -0.11885215676750904]\n",
      "Ep: 412  tStep: 21  Reward: 0.35  Button Pressed? 0  GRU output: 0.36 FT Observation: [-0.2508208388566482, -0.19533778898895127, 0.8598858222438257, 0.2362423890916845, -0.1864775285414807]\n",
      "Ep: 412  tStep: 22  Reward: 0.35  Button Pressed? 0  GRU output: 0.54 FT Observation: [-0.21841255750123623, -0.15605620171355827, 0.852596865530614, 0.20749663668063012, -0.16509439539440474]\n",
      "Ep: 412  tStep: 23  Reward: 0.4  Button Pressed? 0  GRU output: 0.58 FT Observation: [-0.2997444045488087, -0.15510357799586427, 0.8546989210564959, 0.2084073903538719, -0.21182282697502197]\n",
      "Ep: 412  tStep: 24  Reward: 0.4  Button Pressed? 0  GRU output: 0.93 FT Observation: [-0.2499042727139884, -0.20945128303572835, 0.8596913900272365, 0.23840619446508993, -0.1916783874972514]\n",
      "Ep: 412  tStep: 25  Reward: 0.4  Button Pressed? 0  GRU output: 0.17 FT Observation: [-0.2563100317791477, -0.22852938667097755, 0.8599473457745144, 0.258807472652135, -0.19361735383270096]\n",
      "Ep: 412  tStep: 26  Reward: 0.4  Button Pressed? 0  GRU output: 0.64 FT Observation: [-0.26313452277184346, -0.17470235288702685, 0.855447690201923, 0.22894222019046118, -0.1943571590492964]\n",
      "Ep: 412  tStep: 27  Reward: 0.4  Button Pressed? 0  GRU output: 0.55 FT Observation: [-0.2370229186886479, -0.2362045649982375, 0.8451027671355038, 0.2595807705985558, -0.18493767296819918]\n",
      "Ep: 412  tStep: 28  Reward: 0.4  Button Pressed? 0  GRU output: 0.76 FT Observation: [-0.369284625336637, -0.22130388828641934, 0.8434986901289345, 0.2595899534282071, -0.29463680027492034]\n",
      "Ep: 412  tStep: 29  Reward: 0.4  Button Pressed? 0  GRU output: 0.9 FT Observation: [-0.09438836859729871, -0.209321048566534, 0.8285098903708621, 0.26145318020007857, -0.1288290752020116]\n",
      "Ep: 412  tStep: 30  Reward: 0.45  Button Pressed? 0  GRU output: 0.5 FT Observation: [-0.2152224982953107, -0.2039637766087622, 0.8387860693983926, 0.25876065514595714, -0.18223276612594186]\n",
      "   Actionlist: [4, 3, 3, 4, 4, 3, 1, 2, 4, 4, 2, 2, 4, 1, 3, 3, 4, 3, 0, 1, 1, 2, 4, 3, 3, 2, 3, 1, 0, 4]\n",
      "Ep: 413  tStep: 1  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [0.03643570630166604, -0.130929000407509, 0.8692864583387314, 0.18469461878444982, 0.0643870333447174]\n",
      "Ep: 413  tStep: 2  Reward: 0.05  Button Pressed? 0  GRU output: 0 FT Observation: [0.029731392244304322, -0.1236763929957857, 0.8704335085284132, 0.17910824137123504, 0.05576610637764867]\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/ZhizhenQin/BalancingBot/blob/master/balance-bot/balance_bot/balancebot_task.py\n",
    "\n",
    "\n",
    "#%load_ext tensorboard\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import gym\n",
    "from stable_baselines import DQN, PPO2\n",
    "from stable_baselines import results_plotter\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines.results_plotter import load_results, ts2xy\n",
    "from stable_baselines.common.noise import AdaptiveParamNoiseSpec\n",
    "from stable_baselines.common.callbacks import BaseCallback\n",
    "from stable_baselines.deepq.policies import MlpPolicy\n",
    "from stable_baselines.common.policies import FeedForwardPolicy, register_policy,LstmPolicy\n",
    "from stable_baselines.common.tf_layers import conv, linear, conv_to_fc, lstm\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "from datetime import date\n",
    "import csv\n",
    "#import balance_bot\n",
    "import socket\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import UR5_RL\n",
    "\n",
    "class GRUNet(nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "            super(GRUNet, self).__init__()\n",
    "            self.hidden_dim = hidden_dim\n",
    "            self.n_layers = n_layers\n",
    "\n",
    "            self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "            self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "            self.relu = nn.ReLU()\n",
    "\n",
    "        def forward(self, x, h):\n",
    "            out, h = self.gru(x, h)\n",
    "            out = self.fc(self.relu(out[:,-1]))\n",
    "            return out, h\n",
    "\n",
    "        def init_hidden(self, batch_size):\n",
    "            weight = next(self.parameters()).data\n",
    "            hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "            return hidden\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "#HOST_SnS = '192.168.0.103'\n",
    "HOST_SnS = '128.138.224.117'\n",
    "PORT_SnS= 65491\n",
    "\n",
    "\n",
    "try:\n",
    "    # Create a TCP/IP socket\n",
    "    sock_SnS = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    #sock_SnS.setblocking(False)\n",
    "    # Connect the socket to the port where the server is listening\n",
    "    server_address_SnS = (HOST_SnS, PORT_SnS)\n",
    "    print('connecting to {} port {}'.format(*server_address_SnS))\n",
    "    sock_SnS.connect(server_address_SnS)\n",
    "\n",
    "\n",
    "    #def callback(lcl, glb):\n",
    "         #stop training if reward exceeds 199\n",
    "    #    is_solved = lcl['t'] > 1000 and sum(lcl['episode_rewards'][-101:-1]) / 100 >= 1\n",
    "    #    return is_solved\n",
    "\n",
    "    #https://stable-baselines.readthedocs.io/en/master/guide/custom_policy.html\n",
    "    #Layers of 20 and 15\n",
    "\n",
    "    #Do this only after restarting the notebook!! \n",
    "    #register_policy('ScottLSTMPolicy', ScottLSTMPolicy)    \n",
    "    #print(\"lstm registered\")\n",
    "\n",
    "    #try:\n",
    "    \n",
    "    #code stopped at ep 36 at 10steps per ep, 80 ep\n",
    "    StepsPerEpisode=30 #was 10\n",
    "    TotalEpisodes=500  #was 80\n",
    "    env= gym.make(\"ur5-rl-v0\",StepsPerEpisode=StepsPerEpisode,TotalEpisodes=TotalEpisodes,\n",
    "                 continuousactionspace=False,actualbutton=True,GRUrewards=False)\n",
    "    \n",
    "    \n",
    "    env = DummyVecEnv([lambda: env])\n",
    "\n",
    "    timesteps=(StepsPerEpisode*TotalEpisodes)\n",
    "    print(\"Total timesteps:\",timesteps)\n",
    "    \n",
    "    \n",
    "    class ScottLSTMPolicy(LstmPolicy):\n",
    "        def __init__(self, sess, ob_space, ac_space, n_env=1, n_steps=StepsPerEpisode,\n",
    "                     n_batch=StepsPerEpisode, n_lstm=StepsPerEpisode, reuse=False,  **_kwargs):\n",
    "            super().__init__(sess, ob_space, ac_space, n_env, n_steps, n_batch, n_lstm, reuse,\n",
    "                             net_arch=[7,'lstm',dict(vf=[20, 15],pi=[20,15])],\n",
    "                             layer_norm=True, feature_extraction=\"mlp\", **_kwargs)\n",
    "    \"\"\"   \"\"\"\n",
    "    \n",
    "\n",
    "    #model = PPO2(\"MlpPolicy\", env,verbose=0)\n",
    "    #model = PPO2(\"MlpLstmPolicy\", env,nminibatches=1, n_steps=80, #exploration_initial_eps=1, exploration_final_eps=0.1,\n",
    "    #             verbose=0,tensorboard_log=\"./ScottPPOLstm/\") #n_lstm=2, n_batch=80, nminibatches=10,\n",
    "\n",
    "    #model = PPO2(ScottLSTMPolicy, env,nminibatches=1, n_steps=StepsPerEpisode,learning_rate=0.1, verbose=0)\n",
    "    \n",
    "    \n",
    "    model = PPO2(ScottLSTMPolicy, env,nminibatches=1, n_steps=StepsPerEpisode,learning_rate=0.0001, verbose=0) #exploration_initial_eps and  exploration_final_eps ARE NOT VALID ARGUMENTS!!!\n",
    "     \n",
    "    \n",
    "    \n",
    "    #model = DQN(MlpPolicy, env, learning_rate=0.1,exploration_final_eps=0.02, exploration_initial_eps=1.0,  verbose=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # DEFAULT learning_rate=0.00025  #n_lstm=2, n_batch=80, nminibatches=10,\n",
    "    ##exploration_initial_eps=1, exploration_final_eps=0.1,\n",
    "\n",
    "    #model.learn(total_timesteps=timesteps,b_log_name=\"first_run\", reset_num_timesteps=False)#50000\n",
    "    model.learn(total_timesteps=timesteps,reset_num_timesteps=False)#50000\n",
    "    \n",
    "    today = date.today()\n",
    "    todaydate = today.strftime(\"%m_%d_%Y\")\n",
    "    RLmodelfilename=\"UR5-RL_model_PPO_LSTM_lr0.0001_squarepeg\"+todaydate\n",
    "    model.save(RLmodelfilename)# save trained model\n",
    "    print(\"model saved\")\n",
    "    #del model\n",
    "    print(\"training complete\")\n",
    "    \n",
    "\n",
    "finally:\n",
    "    endmsg='end'\n",
    "    data1=endmsg.encode('ascii')    \n",
    "    sock_SnS.sendall(data1)\n",
    "    sock_SnS.sendall(data1)\n",
    "    print('closing SnS socket')\n",
    "    sock_SnS.close()\n",
    "    \n",
    "\n",
    "    HOST2 = HOST_SnS\n",
    "    PORT2= PORT_SnS-10 #65481\n",
    "    sock_DC = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    server_address_DC = (HOST2, PORT2)\n",
    "    sock_DC.close()\n",
    "    print(\"socket DC Closed\")\n",
    "    \n",
    "    #if error, save model, just in case!\n",
    "    today = date.today()\n",
    "    todaydate = today.strftime(\"%m_%d_%Y\")\n",
    "    RLmodelfilename=\"UR5-RL_model_PPO_LSTM_lr0.0001_squarepeg_backupfile\"+todaydate\n",
    "    model.save(RLmodelfilename)# save trained model\n",
    "    print(\"model saved\")  \n",
    "    #gitkraken\n",
    "    \n",
    "    #check_env(env)\n",
    "    #https://stable-baselines.readthedocs.io/en/master/modules/dqn.html\n",
    "    #model.learn(total_timesteps=25000)\n",
    "    #del model # remove to demonstrate saving and loading\n",
    "    #model = DQN.load(\"deepq_cartpole\")\n",
    "\n",
    "    \n",
    "    #started 10-23-2021 run at ~5:16pm  500episodes on paper. probably 650-700 in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if arduino error, run this in terminal:\n",
    "#sudo chmod a+rw /dev/ttyACM0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "training complete\n"
     ]
    }
   ],
   "source": [
    "today = date.today()\n",
    "todaydate = today.strftime(\"%m_%d_%Y\")\n",
    "RLmodelfilename=\"UR5-RL_DQN_savedpolicy_cylinder_withbutton_train_noposeobs_GRUrewards_10-4_13-2021GRU_lookahead\"+todaydate\n",
    "model.save(RLmodelfilename)# save trained model\n",
    "print(\"model saved\")\n",
    "del model\n",
    "print(\"training complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved!\n"
     ]
    }
   ],
   "source": [
    "model.save(\"UR5-RL_savedpolicy-10-15-2021\")  #10-4 and 6 were good policies\n",
    "print(\"saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST2 = '192.168.0.103'learning_rate=0.00025\n",
    "PORT2= 65485\n",
    "sock_DC = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "server_address_DC = (HOST2, PORT2)\n",
    "sock_DC.close()\n",
    "print(\"socket DC Closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 9] Bad file descriptor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5c92c6e2c5c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mendmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'end'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msock_SnS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'closing SnS socket'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msock_SnS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 9] Bad file descriptor"
     ]
    }
   ],
   "source": [
    "endmsg='end'\n",
    "data1=endmsg.encode('ascii')    \n",
    "sock_SnS.sendall(data1)\n",
    "\n",
    "\n",
    "#print('closing SnS socket')\n",
    "#sock_SnS.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting to 128.138.224.89 port 65490\n",
      "GRU model loaded\n",
      "TotalEpisodes: 380    StepsPerEpisode: 30\n",
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4974/915785649.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;31m#model = DQN.load(\"UR5-RL_savedpolicy-10-6-2021\")  #seems to only go to the side (action 1).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m#model = DQN.load(\"UR5-RL_DQN_savedpolicy_10_14_2021\")  #seems to only go down (action 4).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UR5-RL_DQN_savedpolicy_cylinder_withbutton_train_noposeobs_10_21_2021\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#seems to only go down (action 4).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/stable_baselines/common/base_class.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, load_path, env, custom_objects, **kwargs)\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/stable_baselines/deepq/dqn.py\u001b[0m in \u001b[0;36msetup_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                     \u001b[0mfull_tensorboard_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_tensorboard_log\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mdouble_q\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble_q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 )\n\u001b[1;32m    143\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py\u001b[0m in \u001b[0;36mbuild_train\u001b[0;34m(q_func, ob_space, ac_space, optimizer, sess, grad_norm_clipping, gamma, double_q, scope, reuse, param_noise, param_noise_filter_func, full_tensorboard_log)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mact_t_ph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"action\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mrew_t_ph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"reward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0mdone_mask_ph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0mimportance_weights_ph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   2617\u001b[0m                        \"eager execution.\")\n\u001b[1;32m   2618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2619\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   6667\u001b[0m   \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6668\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 6669\u001b[0;31m         \"Placeholder\", dtype=dtype, shape=shape, name=name)\n\u001b[0m\u001b[1;32m   6670\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6671\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    792\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    793\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m       \u001b[0;31m# Conditionally invoke tfdbg v2's op callback(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mis_in_graph_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIS_IN_GRAPH_MODE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_PRINT_DEPRECATION_WARNINGS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0minvalid_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0mnamed_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcallargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeprecated_positions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m           if (spec.position < len(args) and\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "#import tensorflow.contrib.layers as layers\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#from tensorflow.keras import layers\n",
    "#from keras.utils import to_categorical\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense, Dropout, Embedding, LSTM, GlobalMaxPooling1D, SpatialDropout1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import gym\n",
    "from stable_baselines import DQN,PPO2\n",
    "from stable_baselines import results_plotter\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines.results_plotter import load_results, ts2xy\n",
    "from stable_baselines.common.noise import AdaptiveParamNoiseSpec\n",
    "from stable_baselines.common.callbacks import BaseCallback\n",
    "from stable_baselines.deepq.policies import MlpPolicy\n",
    "from stable_baselines.common.policies import FeedForwardPolicy, register_policy,LstmPolicy\n",
    "from stable_baselines.common.tf_layers import conv, linear, conv_to_fc, lstm\n",
    "#from stable_baselines.common import get_vec_normalize_env\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "#import balance_bot\n",
    "\n",
    "import socket\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import UR5_RL\n",
    "\n",
    "#env= gym.make(\"UR5-RL-env\", render=True)\n",
    "#HOST_SnS = '192.168.0.103'\n",
    "HOST_SnS = '128.138.224.89'\n",
    "PORT_SnS= 65490\n",
    "\n",
    "class GRUNet(nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "            super(GRUNet, self).__init__()\n",
    "            self.hidden_dim = hidden_dim\n",
    "            self.n_layers = n_layers\n",
    "\n",
    "            self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "            self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "            self.relu = nn.ReLU()\n",
    "\n",
    "        def forward(self, x, h):\n",
    "            out, h = self.gru(x, h)\n",
    "            out = self.fc(self.relu(out[:,-1]))\n",
    "            return out, h\n",
    "\n",
    "        def init_hidden(self, batch_size):\n",
    "            weight = next(self.parameters()).data\n",
    "            hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "            return hidden\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "#try:\n",
    "\n",
    "# Create a TCP/IP socket\n",
    "sock_SnS = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "#sock_SnS.setblocking(False)\n",
    "# Connect the socket to the port where the server is listening\n",
    "server_address_SnS = (HOST_SnS, PORT_SnS)\n",
    "print('connecting to {} port {}'.format(*server_address_SnS))\n",
    "sock_SnS.connect(server_address_SnS)\n",
    "\n",
    "\n",
    "StepsPerEpisode=30 #was 10\n",
    "TotalEpisodes=380  #was 80\n",
    "env= gym.make(\"ur5-rl-v0\",StepsPerEpisode=StepsPerEpisode,TotalEpisodes=TotalEpisodes,\n",
    "                 continuousactionspace=False,actualbutton=True)\n",
    "\n",
    "\n",
    "env = DummyVecEnv([lambda: env])  #no clue what this line does\n",
    "\n",
    "#model = DQN.load(\"UR5-RL_savedpolicy-10-4-2021\")  #seems to only go down (action 4). \n",
    "#model = DQN.load(\"UR5-RL_savedpolicy-10-6-2021\")  #seems to only go to the side (action 1).\n",
    "#model = DQN.load(\"UR5-RL_DQN_savedpolicy_10_14_2021\")  #seems to only go down (action 4). \n",
    "model = DQN.load(\"UR5-RL_DQN_savedpolicy_cylinder_withbutton_train_noposeobs_10_21_2021\")  #seems to only go down (action 4).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#model = DQN(MlpPolicy, env, learning_rate=0.1,exploration_final_eps=0.02, exploration_initial_eps=1.0,  verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "#env=model.get_env()\n",
    "#obs = env.reset()\n",
    "done = [False for _ in range(1)] #env.num_envs\n",
    "state=None\n",
    "\n",
    "while True:\n",
    "    obs = env.reset()\n",
    "    #env._seed()\n",
    "    for i in range(500000):\n",
    "        action, _states = model.predict(obs,state=state,mask=done)\n",
    "        #actionlist.append(action)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        print(obs)\n",
    "    #print(rewards)\n",
    "        \n",
    "        \n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "while True:\n",
    "    obs = env.reset()\n",
    "    env._seed()\n",
    "    actionlist=[]\n",
    "    #print(\"reset\")\n",
    "    for i in range(80):\n",
    "        action, _states = model.predict(obs)\n",
    "        actionlist.append(action)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "    print(rewards)       \n",
    "\"\"\"       \n",
    "        \n",
    "        \n",
    "#print(\"actionlist\",actionlist)\n",
    "#env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.5522386]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
