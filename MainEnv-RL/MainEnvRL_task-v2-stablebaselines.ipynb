{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To register MainEnvRL with local copy of Gym\n",
    "\"\"\"\n",
    "from gym.envs.registration import register\n",
    " \n",
    "register(\n",
    "    id='MainEnvRL-v2',\n",
    "    #entry_point='balance_bot.envs:BalancebotEnv',\n",
    "    entry_point='MainEnv_RL.envs:MainEnvRL',\n",
    ")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gym\n",
    "#for env in gym.envs.registry.env_specs:\n",
    "#    print(env)\n",
    "    \n",
    "    #if 'MainEnvRL-v1' == env:\n",
    "    #     print('Remove {} from registry'.format(env))\n",
    "         #del gym.envs.registry.env_specs[env]\n",
    "            \n",
    "            \n",
    "#import MainEnv_RL\n",
    "\n",
    "#env = gym.make('MainEnvRL-v2')\n",
    "#env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/.local/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/scott/.local/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import PPO2\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "# Optional: PPO2 requires a vectorized environment to run\n",
    "# the env is now wrapped automatically when passing it to the constructor\n",
    "# env = DummyVecEnv([lambda: env])\n",
    "\n",
    "model = PPO2(MlpPolicy, env, verbose=0)\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "obs = env.reset()\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/scott/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "/home/scott/.local/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world frame pose ((0.6806935694380881, 0.10099857271809896, 0.8667025767190513), (0.009668371718622306, 0.9994763447134758, 0.02105514059078755, 0.022588492672197622))\n",
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/scott/.local/lib/python3.6/site-packages/stable_baselines/deepq/build_graph.py:149: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "joint config [0.41453651980542044, 0.3210231703974388, -1.2891777962967765, 0.7363832411683133, -1.5526441139077183, -1.1473571156276352, -0.3169822917392441]\n",
      "world frame pose ((0.6988955720533278, 0.08850633850952169, 0.8749730486630475), (-0.0598978986124916, 0.9982045089513355, 3.284389646085461e-06, 6.343789709983838e-06))\n",
      "joint config [0.41554439299905765, 0.31762858044840103, -1.2809997365555248, 0.7359092105754017, -1.5615444816450397, -1.1442779659576479, -0.31441782846788735]\n",
      "world frame pose ((0.699067233252741, 0.08853995617064336, 0.8749402529139259), (-0.05988672063098835, 0.9982051796305226, -3.2704975564956666e-06, -6.337667047870422e-06))\n",
      "joint config [0.42089093433635133, 0.30192843406950015, -1.2441141072683024, 0.7368081075719781, -1.6007751170326694, -1.1306329657956293, -0.30465739008492976]\n",
      "world frame pose ((0.6990665814941099, 0.08853995657487126, 0.8749404488594271), (-0.05988678072672801, 0.9982051760244757, -3.2731515304806887e-06, -6.43589093704544e-06))\n",
      "joint config [0.43381887527288715, 0.259188437095807, -1.1474445623863159, 0.7430506328121828, -1.7050360956198947, -1.095735098055409, -0.27802649481990344]\n",
      "world frame pose ((0.6988995950010656, 0.08850669605081651, 0.8749720089144551), (-0.05989753746331285, 0.9982045306209689, 3.2263661122744468e-06, 6.572134991805753e-06))\n",
      "joint config [0.44978966721777675, 0.1850285856856449, -0.991356254991918, 0.7631057692212866, -1.8789447838930522, -1.0414654127006533, -0.229828920942509]\n",
      "world frame pose ((0.69889810019318, 0.08850615662873663, 0.8749719528511712), (-0.05989739588437711, 0.9982045391117109, 3.362029792286503e-06, 7.1933181455402515e-06))\n",
      "joint config [0.4565623995927447, 0.13188996712733828, -0.888047201544431, 0.7844894735278569, -1.997582405742776, -1.0063629070202909, -0.19469091835440402]\n",
      "world frame pose ((0.6989003683100686, 0.08850660709522255, 0.8749712812655267), (-0.059897047080390474, 0.9982045600413371, 3.306863735008658e-06, 7.266014702148049e-06))\n",
      "joint config [0.4597169935551494, 0.06551576740169736, -0.7677420178132368, 0.8185120189062014, -2.1393115682287904, -0.9655931227776134, -0.15004344559312344]\n",
      "world frame pose ((0.6989007531404441, 0.08850681958355579, 0.8749708676110968), (-0.05989673871904815, 0.9982045785427562, 3.3242693581736474e-06, 7.486640949266875e-06))\n",
      "joint config [0.45657576480236023, -0.00695981992495825, -0.6457065781774435, 0.864168897551915, -2.287070760002739, -0.923652124645326, -0.09973837557353221]\n",
      "world frame pose ((0.698900564703133, 0.08850708524126566, 0.874970503809976), (-0.05989642776090409, 0.9982045971997965, 3.36091914793224e-06, 7.705787221548577e-06))\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/ZhizhenQin/BalancingBot/blob/master/balance-bot/balance_bot/balancebot_task.py\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "#import tensorflow.contrib.layers as layers\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, GlobalMaxPooling1D, SpatialDropout1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "import gym\n",
    "from stable_baselines import DQN\n",
    "from stable_baselines import results_plotter\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines.results_plotter import load_results, ts2xy\n",
    "from stable_baselines.common.noise import AdaptiveParamNoiseSpec\n",
    "from stable_baselines.common.callbacks import BaseCallback\n",
    "from stable_baselines.deepq.policies import MlpPolicy\n",
    "from stable_baselines.common.policies import FeedForwardPolicy, register_policy,LstmPolicy\n",
    "from stable_baselines.common.tf_layers import conv, linear, conv_to_fc, lstm\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "#import balance_bot\n",
    "\n",
    "\"\"\"\n",
    "for env in gym.envs.registry.env_specs:\n",
    "     if 'MainEnvRL-v0' in env:\n",
    "        print('Remove {} from registry'.format(env))\n",
    "        del gym.registry.env_specs[env]\n",
    "\"\"\"                \n",
    "import MainEnv_RL\n",
    "\n",
    "def callback(lcl, glb):\n",
    "    # stop training if reward exceeds 199\n",
    "    is_solved = lcl['t'] > 100 and sum(lcl['episode_rewards'][-101:-1]) / 100 >= 199\n",
    "    \n",
    "    return is_solved\n",
    "\n",
    "#https://stable-baselines.readthedocs.io/en/master/guide/custom_policy.html\n",
    "class ScottCustomLSTMPolicy(LstmPolicy):\n",
    "    def __init__(self, sess, ob_space, ac_space, n_env, n_steps, n_batch, n_lstm=64, reuse=False, **_kwargs):\n",
    "        super().__init__(sess, ob_space, ac_space, n_env, n_steps, n_batch, n_lstm, reuse,\n",
    "                         net_arch=[8, 'lstm', dict(vf=[5, 10], pi=[10])],\n",
    "                         layer_norm=True, feature_extraction=\"mlp\", **_kwargs)\n",
    "        \n",
    "\n",
    "        \n",
    "def main():\n",
    "    #env = gym.make(\"MainEnvRL-v2\") # <-- this we need to create\n",
    "    #env = gym.make(\"CartPole-v0\")\n",
    "    #policy_kwargs= dict(act_fun=tf.nn.tanh, net_arch=[32, 32])\n",
    "    \n",
    "    \n",
    "    env= gym.make(\"MainEnvRL-v2\")\n",
    "    \n",
    "    model = DQN(\"MlpPolicy\", env, learning_rate=1e-3, prioritized_replay=True,gamma=1 , buffer_size=50000,param_noise=False,\n",
    "                exploration_initial_eps=0.1, exploration_final_eps=0.1,learning_starts=1, verbose=1)\n",
    "    \n",
    "    model.learn(total_timesteps=50000)\n",
    "    \"\"\"\n",
    "    register_policy('ScottCustomLSTMPolicy', ScottCustomLSTMPolicy)\n",
    "    \n",
    "    model = DQN(policy='ScottCustomLSTMPolicy', env= gym.make(\"MainEnvRL-v2\"), learning_rate=1e-3, prioritized_replay=True,gamma=1 , buffer_size=50000,param_noise=False,\n",
    "                exploration_initial_eps=0.1, exploration_final_eps=0.1,learning_starts=1, verbose=1)\n",
    "    env = model.get_env()\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #check_env(env)\n",
    "    #https://stable-baselines.readthedocs.io/en/master/modules/dqn.html\n",
    "    #model.learn(total_timesteps=25000)\n",
    "    #del model # remove to demonstrate saving and loading\n",
    "    #model = DQN.load(\"deepq_cartpole\")\n",
    "    \"\"\"\n",
    "    \n",
    "    act = deepq.learn(\n",
    "        env, network= model,  lr=1e-3, \n",
    "        total_timesteps=50000, buffer_size=50000, exploration_fraction=0.1,prioritized_replay=True,param_noise=True,\n",
    "        exploration_final_eps=0.02, print_freq=100, callback=callback\n",
    "    )\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    #default\n",
    "    act = deepq.learn(\n",
    "        env, network= 'mlp',  lr=1e-3,\n",
    "        total_timesteps=50000, buffer_size=50000, exploration_fraction=0.1,prioritized_replay=True,param_noise=False\n",
    "        exploration_final_eps=0.02, print_freq=100, callback=callback\n",
    "    )\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    #rescale rewards to be between -1 and +1\n",
    "    obs = env.reset()\n",
    "    while True:\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, done, info = env.step(action)\n",
    "        #obs = env.reset()\n",
    "        #env.render()\n",
    "        if done:\n",
    "            #print(\"Done!\")\n",
    "            #break\n",
    "            obs = env.reset()\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    # save trained model\n",
    "    #act.save(\"balance.pkl\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
