{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To register MainEnvRL with local copy of Gym\n",
    "\"\"\"\n",
    "from gym.envs.registration import register\n",
    " \n",
    "register(\n",
    "    id='MainEnvRL-v2',\n",
    "    #entry_point='balance_bot.envs:BalancebotEnv',\n",
    "    entry_point='MainEnv_RL.envs:MainEnvRL',\n",
    ")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gym\n",
    "#for env in gym.envs.registry.env_specs:\n",
    "#    print(env)\n",
    "    \n",
    "    #if 'MainEnvRL-v1' == env:\n",
    "    #     print('Remove {} from registry'.format(env))\n",
    "         #del gym.envs.registry.env_specs[env]\n",
    "            \n",
    "            \n",
    "#import MainEnv_RL\n",
    "\n",
    "#env = gym.make('MainEnvRL-v2')\n",
    "#env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/.local/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/scott/.local/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import PPO2\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "# Optional: PPO2 requires a vectorized environment to run\n",
    "# the env is now wrapped automatically when passing it to the constructor\n",
    "# env = DummyVecEnv([lambda: env])\n",
    "\n",
    "model = PPO2(MlpPolicy, env, verbose=0)\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "obs = env.reset()\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep: 0 Reward: -0.39370100000000036 Target: (0.7, 0.08, 0.87)  Final Position:  [0.71, 0.08, 0.87]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://github.com/ZhizhenQin/BalancingBot/blob/master/balance-bot/balance_bot/balancebot_task.py\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "#import tensorflow.contrib.layers as layers\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, GlobalMaxPooling1D, SpatialDropout1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "import gym\n",
    "from stable_baselines import DQN\n",
    "from stable_baselines import results_plotter\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines.results_plotter import load_results, ts2xy\n",
    "from stable_baselines.common.noise import AdaptiveParamNoiseSpec\n",
    "from stable_baselines.common.callbacks import BaseCallback\n",
    "from stable_baselines.deepq.policies import MlpPolicy\n",
    "from stable_baselines.common.policies import FeedForwardPolicy, register_policy,LstmPolicy\n",
    "from stable_baselines.common.tf_layers import conv, linear, conv_to_fc, lstm\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "#import balance_bot\n",
    "\n",
    "\"\"\"\n",
    "for env in gym.envs.registry.env_specs:\n",
    "     if 'MainEnvRL-v0' in env:\n",
    "        print('Remove {} from registry'.format(env))\n",
    "        del gym.registry.env_specs[env]\n",
    "\"\"\"                \n",
    "import MainEnv_RL\n",
    "\n",
    "def callback(lcl, glb):\n",
    "    # stop training if reward exceeds 199\n",
    "    is_solved = lcl['t'] > 100 and sum(lcl['episode_rewards'][-101:-1]) / 100 >= 199\n",
    "    \n",
    "    return is_solved\n",
    "\n",
    "#https://stable-baselines.readthedocs.io/en/master/guide/custom_policy.html\n",
    "class ScottCustomLSTMPolicy(LstmPolicy):\n",
    "    def __init__(self, sess, ob_space, ac_space, n_env, n_steps, n_batch, n_lstm=64, reuse=False, **_kwargs):\n",
    "        super().__init__(sess, ob_space, ac_space, n_env, n_steps, n_batch, n_lstm, reuse,\n",
    "                         net_arch=[8, 'lstm', dict(vf=[5, 10], pi=[10])],\n",
    "                         layer_norm=True, feature_extraction=\"mlp\", **_kwargs)\n",
    "        \n",
    "\n",
    "        \n",
    "def main():\n",
    "    #env = gym.make(\"MainEnvRL-v2\") # <-- this we need to create\n",
    "    #env = gym.make(\"CartPole-v0\")\n",
    "    #policy_kwargs= dict(act_fun=tf.nn.tanh, net_arch=[32, 32])\n",
    "    \n",
    "    \n",
    "    env= gym.make(\"MainEnvRL-v2\")\n",
    "    \n",
    "    model = DQN(\"MlpPolicy\", env, learning_rate=1e-3, prioritized_replay=True,gamma=1 , buffer_size=50000,param_noise=False,\n",
    "                exploration_initial_eps=0.1, exploration_final_eps=0.1,learning_starts=1, verbose=1)\n",
    "    \n",
    "    model.learn(total_timesteps=50000)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    register_policy('ScottCustomLSTMPolicy', ScottCustomLSTMPolicy)\n",
    "    \n",
    "    model = DQN(policy='ScottCustomLSTMPolicy', env= gym.make(\"MainEnvRL-v2\"), learning_rate=1e-3, prioritized_replay=True,gamma=1 , buffer_size=50000,param_noise=False,\n",
    "                exploration_initial_eps=0.1, exploration_final_eps=0.1,learning_starts=1, verbose=1)\n",
    "    env = model.get_env()\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #check_env(env)\n",
    "    #https://stable-baselines.readthedocs.io/en/master/modules/dqn.html\n",
    "    #model.learn(total_timesteps=25000)\n",
    "    #del model # remove to demonstrate saving and loading\n",
    "    #model = DQN.load(\"deepq_cartpole\")\n",
    "    \"\"\"\n",
    "    \n",
    "    act = deepq.learn(\n",
    "        env, network= model,  lr=1e-3, \n",
    "        total_timesteps=50000, buffer_size=50000, exploration_fraction=0.1,prioritized_replay=True,param_noise=True,\n",
    "        exploration_final_eps=0.02, print_freq=100, callback=callback\n",
    "    )\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    #default\n",
    "    act = deepq.learn(\n",
    "        env, network= 'mlp',  lr=1e-3,\n",
    "        total_timesteps=50000, buffer_size=50000, exploration_fraction=0.1,prioritized_replay=True,param_noise=False\n",
    "        exploration_final_eps=0.02, print_freq=100, callback=callback\n",
    "    )\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    #rescale rewards to be between -1 and +1\n",
    "    obs = env.reset()\n",
    "    while True:\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, done, info = env.step(action)\n",
    "        #obs = env.reset()\n",
    "        #env.render()\n",
    "        if done:\n",
    "            #print(\"Done!\")\n",
    "            #break\n",
    "            obs = env.reset()\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    # save trained model\n",
    "    #act.save(\"balance.pkl\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
