{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "A drawback of the ANN architectures that we have considered so far is that they do not consider the spatial information that might be hidden in a dataset. For example, how to interpret the value of a certain pixel usually depends on what can be seen nearby. For example, a blue pixel surrounded by white ones might be an eye, whereas a blue pixel surround by blue ones might be an ocean. In addition to color, neighboring pixels also encode structure. When looking at the MNIST data we might for example be looking for crosses (such as the center of an eight), T-shaped junctions (such as in the letter four) or half-circles (like in the letter three), whose number might then serve as features for our neural network.\n",
    "\n",
    "One way to extract such features in image processing is by <i>convolving</i> an image with a <i>kernel</i>. This is illustrated for a 3x3 and a 7x7 kernel in the image below.\n",
    "\n",
    "<center>\n",
    "<img src=\"figs/convolution.svg\" width=\"50%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During a convolution, the kernel is swept across the input image, summing over a piece-wise multiplication of each element of the kernel with the underlying image pixels. As all multiplications are summed, such an operation yields only one pixel. As the kernel has to start somewhat inside the image (unless its borders are padded with appropriate values), we are loosing half the width of the kernel on each side. In the example above, a 3x3 kernel turns a 28x28 input image into a 26x26 output image and a 7x7 kernel turns it into a 22x22 pixel image. Mathematically, the convolution is defined as\n",
    "\n",
    "$$x(n_1,n_2)*h(n_1,n_2)=\\sum_{k_1=-\\infty}^{\\infty} \\sum_{k_2=-\\infty}^{\\infty} h(k_1,k_2)x(n_1-k_1,n_2-k_2)$$\n",
    "\n",
    "where bounds (here, infinity) need to be chosen so that the kernel starts at the upper left corner of the image and ends at the lower right corner. It is also possible to artificially grow the input image by adding pixels around it, which is known as <i>padding</i>. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what kind of features even simple convolution kernels can extract, consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAD8CAYAAADub8g7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHFhJREFUeJzt3XtsXPWVB/DvmfGMn0n8SOw4zpOQAGF5LeZRHi1SoKWIKqxAtEjtRitUdrewgoqVyNKuVlWlXbrS0pXaqlK2ZJNqEWxb6Caq0m1Jmi5CpBBDKeQBCSQNeTi283b8npmzf3g6d87F9kw8M3fu+Pf9SJbvb37Xc3+Oz5zcOfP73SuqCiIil0TKPQAioqAx8RGRc5j4iMg5THxE5BwmPiJyDhMfETmHiY+InMPER0TOKSjxicjdIvKBiHwoIuuKNSiicmNsz2wy3ZUbIhIFsB/AXQCOAtgF4CFV3TvZz8SlWmtQP63jUXH148xJVZ1X7nGE0cXGNuM6PPKN66oCjnEjgA9V9SAAiMiLANYAmDTx1aAeN8nqAg5JxbJNf3a43GMIsYuKbcZ1eOQb14W81e0AcCSrfTT9mCEij4hIl4h0jWGkgMMRBSZnbDOuK1vJP9xQ1fWq2qmqnTFUl/pwRIFgXFe2QhLfMQCLstoL048RVTrG9gxXSOLbBWCFiCwTkTiALwHYUpxhEZUVY3uGm/aHG6qaEJHHAPwKQBTABlXdU7SREZUJY3vmK+RTXajqVgBbizQWotBgbM9sXLlBRM5h4iMi5zDxEZFzCqrxERFNJFJTk9mWJQtNn8Zs2pGRUdNOHfrY7p9IFHl0POMjIgcx8RGRc5j4iMg5rPGFyMADN5n2d/71h6b97Qf/0rS1a3fJx0SFM/WuhqkvX6VDw6adGhgoyZhKLdLUmNnu+5S9SlTfzUnTXvwL+7N1x06YNmt8RERFwMRHRM5h4iMi54S2xje05kbbbomadvOGnUEOJxC9nfb/oW//8QtlGgkVU3a960LnYtOXrBbTnvOWrW+lDlVmjS81z/udT16fMn31rfZ3urBgtu2Px+yTDRZ3bADP+IjIQUx8ROQcJj4ick5oa3zHP21zct3ys3aHDQEOppQiXu1SFw+ZrtWt75v2drklkCFRcSUXevPYum+xtepEnb29a8NhW+/CoZINq7gi9vcaXjArsx1rtXHdPue8afcPzjJtHR0r8uA+iWd8ROQcJj4icg4THxE5J7Q1vm/d+1PT/s6+z5ZpJKUVXb4ks/3+Z2zh8to3v2zaC3a9F8iYqLhGWry1ui3X9pq+U2cbTDtZZ1+SlXJmUtXRbtonLvfm4v3tn71i+p4/ZOfozjpha3o6aq/PVwqV8u9KRFQ0THxE5JzQvtWNSfEvRRNGVT+afD3O0EezJ+2j8JJY3LSHm72pHktmnzF9I2P+l2BdqYZVUsn5TaZd97mezPbl1d2m79Qp+/Z+bq9dwpYqwWWo/HjGR0TOYeIjIucw8RGRc0JV40vddm1m+/aa18o4kuAsrT81ad+ibclJ+yi8Is2Npt2/yDu/uH7OYdN38GxLIGMqOt8StcGOWtO+YZ633LI5esH0xf9YY9qR0z2mbS9iVRo84yMi5zDxEZFzciY+EdkgIr0isjvrsWYReUVEDqS/N031HERhxNh2Vz41vo0Avg/gx1mPrQOwXVWfEZF16fZThQ7m8L1enaA1WpnzmXKpWmovPf5A85ZJ9609ZOd8seJXdBtRitiea3PlwEpvCdY1NR+bvp/o9aYtY0FUuApX1WZvGXl+sU0l9za+k9nuS9rLTtX22efS8/3FHVwecp7xqeqrAE77Hl4DYFN6exOA+4o8LqKSY2y7a7qf6rap6p+mY58A0DbZjiLyCIBHAKCmQmelk1Pyim3GdWUr+MMNVVUAOkX/elXtVNXOGKoLPRxRYKaKbcZ1ZZvuGV+PiLSrareItAPozfkT+Qzm0snf6w+/3zhpXyU58u/1pn1rtVfTee78QrvzWXuJbgpEwbGdmG3nqTW3en/HuNhK7SfWrV6wa7cDq/iJvc1lpMGOS+bbmt7Z61pNe/H9B037phrvd/6nnttNX8Nx+2+QGhq+uLEWwXTP+LYAWJveXgtgc3GGQ1R2jG0H5DOd5QUAOwFcJiJHReRhAM8AuEtEDgC4M90mqiiMbXflfKurqg9N0rW6yGMhChRj212hWqs7ldaucM5vis61ay177l9p2s0PHjXt/1v5nO8ZvHrQD39gZ0609rxe+AApcFpl30jFq7ya1rDGTF+0x34wIkO+26j6ZF/rT2rsz0Ya59hxNNj1s6kGW3scneM919gsmwoG59nfoX+ZHcfVtx0w7R8v2+obqbeWd3PXdabn8oO2lp9KlP52kn5cskZEzmHiIyLnVMxb3aFmm6PrJ9lvIqnb7am2Ru1H90futG8ZRhfYU+9I3Hur8uvbv2f6YvapcCJpn+sfD/6FaZ9O2bfsdRHvudvesG8BJp0cSeGm6mt6QbKg6pzpq77UTlnqu83Ol65dNde0E7Xe62Cgzb4mRn0zvoZ9cRyd5WtHvfayeSdMn//1NSth36K31thLTdVF7OX23xkZyWw3fGh/Vo7YY/n/vYLAMz4icg4THxE5h4mPiJwTqhrfyLBXC0j5Klz/+fR3TXvLY9ciX0+1/Mi0I7CFuSG1d24/nrRLar7fd0dm+85tT5i+xt/b2kb7r+1ltOWwnc7St89OMWjLqrPorvf8Q6cKFDtlb5fY83FzZvudS+yyxG9eaaeB/E+brUf3DdmlY63V3pK2Zb7bFtRFbRyfGLG3Jz0zai+m8PF57/JZB47ZJWjim2ZTf8yeI/1q8Xz7XPdvM+2PxhZ44zphX8upc+VfiskzPiJyDhMfETmHiY+InBOqGt+lX/59ZvvKf3nM9C264di0n3dHr11G1vdLW2dp2WPnN8X/d5fvGbz+leia8lj+y8Mfe+oW076heqdpv3ihY8rnowrUZy/qfMlPvVrbt4YfMH0tK2ydLhqx8zwTSXsbx+GE95LNrtEBQN8R26772L68Zx22z11zxovW5WdsfbCqz3fLx0Y7s2//X9l2f8qO8/X+Syc8DgBoIoFy4xkfETmHiY+InMPER0TOCVWNL9uyf9iZe6dpasfHuXcqkrpP903Z/80d92e2V+LNUg+HApA8aet21W95Na3LjtpLuI+12lsvJqvzPxepH7K1sxbf/DjpseNInbf9mrWe1s9fq9ZPXWParcvscyd9c2O3Hrwys724d2jS45QLz/iIyDlMfETkHCY+InJOaGt8rliymVfdm+mSZ7OuwXfWXo8v8oHdt5AzkVLenCFVY+fp1cd969sT9rL3yQPeGuOqk92mr/yz+HjGR0QOYuIjIucw8RGRc1jjI6KCDaR8t7rMLuSNBn/7yFx4xkdEzmHiIyLn8K1uwKJi/685s9K73P78XwY9GqLiqI/Y5W9js7OmacXCl2Z4xkdEzmHiIyLn5Ex8IrJIRHaIyF4R2SMij6cfbxaRV0TkQPp7U67nIgoTxra78jnjSwB4UlVXAbgZwKMisgrAOgDbVXUFgO3pNuWQ1JT5QgTeFwWNsV0kC6rOma9UbdL7mlVrvsIg58tNVbtV9e30dj+AfQA6AKwBsCm92yYA95VqkESlwNh210V93CIiSwFcB+ANAG2q+qfVxycAtE3yM48AeAQAalA30S5EZXexsc24rmx5v8ESkQYALwF4QlXNpVxVVQFMeJkRVV2vqp2q2hlD9US7EJXVdGKbcV3Z8jrjE5EYxgPjeVV9Of1wj4i0q2q3iLQD6C3VIGeywRsGyz0EpzG2i6MxYi821dA6kNnW6ph/97LL51NdAfAcgH2q+mxW1xYAa9PbawFsLv7wiEqHse2ufM74bgXwFQDvicg76ceeBvAMgJ+IyMMADgN4sDRDJCoZxrajciY+VX0N8N1CybO6uMMhCg5j213hW0Q3w/nX6hJVgsiwveHk+dG4aY/5Pv6JV3k1v1Tc7jvZ/zRB4quQiJzDxEdEzmHiIyLnsMZXYiPb5pl28tpS3gSQqDSq+sy8bvS/1m7aX69/wLTPHmjObLedPmX6bLWwPHjGR0TOYeIjIufwrW6Jzf/u66Z9z3f/3LQvwTsgCjvtOWnai39h1ycP7lxg2isueEvWcPJsycY1XTzjIyLnMPERkXOY+IjIOazxEVFOqf5++8C775tm1Ld/9gq2MExf8eMZHxE5h4mPiJzDxEdEzpHxWwoEdDCRPoxf2HEugJM5di8Hl8a1RFXn5d6NcmFcT1vZ4jrQxJc5qEiXqnYGfuAcOC4qRFj/ThzXJ/GtLhE5h4mPiJxTrsS3vkzHzYXjokKE9e/EcfmUpcZHRFROfKtLRM5h4iMi5wSa+ETkbhH5QEQ+FJF1QR57grFsEJFeEdmd9ViziLwiIgfS35sCHtMiEdkhIntFZI+IPB6GcVFuYYntMMZ1egyhiu3AEp+IRAH8AMDnAawC8JCIrArq+BPYCOBu32PrAGxX1RUAtqfbQUoAeFJVVwG4GcCj6X+jco+LphCy2N6I8MU1ELLYDvKM70YAH6rqQVUdBfAigDUBHt9Q1VcBnPY9vAbApvT2JgD3BTymblV9O73dD2AfgI5yj4tyCk1shzGugfDFdpCJrwPAkaz20fRjYdKmqt3p7RMA2so1EBFZCuA6AG8gROOiCYU9tkMVP2GIbX64MQkdn+dTlrk+ItIA4CUAT6iqua9fOcdFla/c8ROW2A4y8R0DsCirvTD9WJj0iEg7AKS/9wY9ABGJYTwwnlfVl8MyLppS2GM7FPETptgOMvHtArBCRJaJSBzAlwBsCfD4+dgCYG16ey2AzUEeXEQEwHMA9qnqs2EZF+UU9tgue/yELrZVNbAvAPcA2A/gIwDfCPLYE4zlBQDdAMYwXpN5GEALxj9ZOgBgG4DmgMd0G8ZP9d8F8E76655yj4tfef3tQhHbYYzr9LhCFdtcskZEzuGHG0TknIISX1hmqxMVG2N7Zpv2W930bPX9AO7CeC1hF4CHVHVv8YZHFDzG9sxXyH11M7PVAUBE/jRbfdLgiNbXa6ypuYBDUrGMHDt6UnnPjclcVGzHpVprUB/g8Ggy/TiTV1wXkvgmmq1+01Q/EGtqxsK/+3oBh6Ri+Wjdk4fLPYYQu6jYrkE9bpLVJR8U5bZNf5ZXXJf8ww0ReUREukSkKzkwUOrDEQUiO67HMFLu4dBFKiTx5TVbXVXXq2qnqnZG6/l2gCpCztjOjusYqgMdHBWukMQX9tnqRNPF2J7hpl3jU9WEiDwG4FcAogA2qOqeoo2MqEwY2zNfIR9uQFW3AthapLEQhQZje2bjyg0icg4THxE5h4mPiJzDxEdEzinoww0qXHREMts1fbYvkrDrqJPVYtpD82y/8q9JlBee8RGRc5j4iMg5THxE5JxQVYUio14NKzo89b6puG0nayrzEvpVg972wEL7O+xf+0PTvvJ7XzPtSMLW/JJVlflvQDNP1RJvqfPHX1xk+sYabJzW9to4bn/hfdNOnvLfH71wPOMjIucw8RGRc5j4iMg5oarxxbKuUzqwMGk7G8dMc9bbNaY9ZJsVI37Oq3cMdNjax6f+cL9p1/XY/oF2WxuhcKpa2JHZHl3eOuW+sePnTDt54GBJxlRqydbGvPetPpMq4UgmxjM+InIOEx8ROYeJj4icE6oaX22vV8MavHrU9F2x8IRp9/5mqWkPtZVsWEUlvtJl7SmvvnF6dsL0LZ9zyrR3N9hfkmtzK0NiYUtmu+f62in3bamJmna8Qmt8Y7O9ibbDc21tOjHLvggSR+zvHASe8RGRc5j4iMg5THxE5JxQVYmqz3n1roevft30/df+G0y7cdi/LrUy5rRVn7HjrBr0fuevXv+a6fuPrttNu+O4rY0MzeP/W5Xg3PK6zPbA4qnnrLVU6L3cIrNmmfbJq7x7Dafah+zOQzbtzD5s5+iWYm2uH185ROQcJj4ick5Z3+pG7Bkuak57U1gODc01fcMDvutQVaiaU/Yt+rm/7s9s+3/nqt6YaQ+1mCans1SKrOqGVkZF5qIN3nGFafdf511X7pblh0zfzjcuN+3Y+UEEjWd8ROQcJj4icg4THxE5p6xVoqpBW/C40OF9BF5fNWL6NFmZOVp8sxfqeuyytO5hr3Z5bsxeW2vuu/7LUPn/DXip+TCKzptn2oNtkaw+W89KnJ8Ztetk3L6WIzEv8D86Z4vTNb02jqsO95q2fYWURmVmEyKiAuRMfCKyQUR6RWR31mPNIvKKiBxIf28q7TCJio+x7a58zvg2Arjb99g6ANtVdQWA7ek2UaXZCMa2k3LW+FT1VRFZ6nt4DYA70tubAPwWwFMXe/D4WVujOnWVVyfo99W7IHbfZKwyJkTFz9lxSsr+HvW1Xi1zTszeU7N7yHc5nzpQEZUqtlNL55v24AKv3rWy3daz9g10oBJF6mwwDrXYc6h5Td781KjvtVvlW8GWujCAoE23xtemqt3p7RMAKuRqeEQ5MbYdUPCHG6qqmOLjRRF5RES6RKQrORB8ZiearqliOzuuxzAy0S4UYtNNfD0i0g4A6e+9k+2oqutVtVNVO6P19dM8HFFg8ort7LiOoXqiXSjEpjuPbwuAtQCeSX/fPJ0niflOAMfmejN4RlJ2aPFjdr5TYuoreJeMf15edNjW8OJnbX/LHns2cGiNXX/bHvcWLB/st/Odxursc6dinLcXgIJje3SOjdVkg3c5sZRvsW70vL3sevVp+6II6198+PZVpn36Bjv77u+XvJnZXr//NtNXfcb+VjpqbzMRhHyms7wAYCeAy0TkqIg8jPGguEtEDgC4M90mqiiMbXfl86nuQ5N0rS7yWIgCxdh2F1duEJFzyns9vqSvgpH06h+1UXuxvsb9dteROf55fPa5sq/1FxnzX+7d/mTUN68oNmifK37BK+zFLtgiX2TMtntusIXug1+xzz276ZxpJ1Pe/z2nX15ox1Xnq4UEfxc+KrJj5+aYdvyMPfeI9toicRDrVgFAYrYuKZddYtrHVzeb9qzP29u9/miFLYVuPXtNZnt4d6Pp63jzpGknR4L/VJxnfETkHCY+InJOaC9e3jfcYNo1Z+wdxhrft+9PR+bZJW5Vg97+55bZt5/xfvv2tO86m//Hmu2xEPXecn73jhdMV0zsm5GzSTtX8Zu/ud+0BwbsOJc0nclsn+qz01nOrrDvbTUS1skNlK+amI2X/rivnFE99WWqzCWvWu3bz7NX2espnFtm43pwiT32ZSuPZba/MP9d03dP/W9M+43hRVOOa8x3H4Q959oz2/47C6L31JTPFQSe8RGRc5j4iMg5THxE5Jyy1viGG23erZ17IbO9vKHP9O1+wi71Sqj92fm1x0z7zLB32Zy/WdBlj6v2uRqjdn7LQMrWBH/Re3Vm++s77JzX+oP2uea+a6fhrNz6pmkfeuEa026p9pYoDR+3H+ufvLpM6/KoIJ+YppXyalxfXf6a6br+yj+a9vtfbDft42N2Kshl1d68rivjdhnx8pitiw+m7FKw34/al/vzp27JbP/bm581fc+9ca9pz3vrgmn3ds4ybXzutGkms5bmxc/7Lil3yu5bDjzjIyLnMPERkXOY+IjIOWWt8Y3a1Tto+m9vDtzPP32D6atdYGsM6ru8T2+/rW+MjXlz4J49a9ecR3baA9ectjWIxgP2EvAjzV4dr3WOnVs3YkswGJhv/0n7nr7FtC9fcNC0uwdne8/VZOdwaWhnWdJUojveNu3LLlyV2f7ewftMX/Km86a9qMl3XTOfbbgis/1Rz1zTF/vAXg5+wWu2Zlyz19bBE93esrMVeGvK40auvty0Bxbb18xn5h8x7dePLs1sVw2Gb/4pz/iIyDlMfETkHCY+InJOWatIY7Pte/8zK7362Zz37b41O+28oeho/nWDRI2tB4422J8dbLP9/Uvs/LlUfKpj2b6mvbZ3eJVdUxzx7f/hW4sz2822ZEMzhO56L7O9YFfxnnc5jl7U/oVc4mqow77+xubZ+aoDCVufHjru1dwXHLY18zDgGR8ROYeJj4icw8RHRM4J1UyxRFbtLWGn5WFgof9S8/52IYo3z8hfe0yN2Hl/2WtzAaC1y9t/YL7//6HwzX8imsh7vXaNce1xL+7jh+ya4qAupz8VnvERkXOY+IjIOUx8ROScUNX4XOC/bWYq6y+QioGIAsAzPiJyDhMfETmHb3UDNpKy/+QXFnn/90TDt7KHKC8t9fb2DcdneZd+0zm+uWn26lhlwTM+InJOzsQnIotEZIeI7BWRPSLyePrxZhF5RUQOpL835XouojBhbLsrnzO+BIAnVXUVgJsBPCoiqwCsA7BdVVcA2J5uE1USxrajctb4VLUbQHd6u19E9gHoALAGwB3p3TYB+C2Ap0oyyhmkb9jWO7LrelVDXKIWJMZ2QKSYy0uL46JqfCKyFMB1AN4A0JYOHAA4AaCtqCMjChBj2y15Jz4RaQDwEoAnVNXcIUVVFZOsqBeRR0SkS0S6kgMDE+1CVFbTie3suB7DiL+bQi6vxCciMYwHxvOq+nL64R4RaU/3twPonehnVXW9qnaqame0vn6iXYjKZrqxnR3XMVQHN2Aqipw1PhERAM8B2Keqz2Z1bQGwFsAz6e+bSzLCGcZ/ie7zV3hL2Ob+jtMqg8TYLp4Vc/pM+3Bza2Z7pM3Wtav2BDKkKeXzSrsVwFcAvCci76QfexrjQfETEXkYwGEAD5ZmiEQlw9h2VD6f6r6Gya/6uXqSx4lCj7HtLq7cICLnsKhUZMlqewIRqU6adixi25LIWqv7iVtmhm/+E9FEIpIq9xAuCs/4iMg5THxE5BwmPiJyDmt8RTbS6KvL9dnJrf98689N+7GRhzLbA3vm+56Na3cpHOo+NgtaEOtpNu0/tHcEOZyC8YyPiJzDxEdEzuFb3SIbnWPbjfvsW9+v/e5x007Uev2j9mb0RKGR3POBaS97eur950zdXXY84yMi5zDxEZFzmPiIyDms8RVZos5OQelfZvv7p1yGxukrREHgGR8ROYeJj4icw8RHRM6R8XupBHQwkT6MX9F2LoCTgR04fy6Na4mqzivyczqJcT1tZYvrQBNf5qAiXaraGfiBc+C4qBBh/TtxXJ/Et7pE5BwmPiJyTrkS3/oyHTcXjosKEda/E8flU5YaHxFROfGtLhE5J9DEJyJ3i8gHIvKhiKwL8tgTjGWDiPSKyO6sx5pF5BUROZD+3hTwmBaJyA4R2Ssie0Tk8TCMi3ILS2yHMa7TYwhVbAeW+EQkCuAHAD4PYBWAh0RkVVDHn8BGAHf7HlsHYLuqrgCwPd0OUgLAk6q6CsDNAB5N/xuVe1w0hZDF9kaEL66BkMV2kGd8NwL4UFUPquoogBcBrAnw+IaqvgrgtO/hNQA2pbc3Abgv4DF1q+rb6e1+APsAdJR7XJRTaGI7jHENhC+2g0x8HQCOZLWPph8LkzZV7U5vnwDQVq6BiMhSANcBeAMhGhdNKOyxHar4CUNs88ONSej4x91l+chbRBoAvATgCVU1t7cq57io8pU7fsIS20EmvmMAFmW1F6YfC5MeEWkHgPT33qAHICIxjAfG86r6cljGRVMKe2yHIn7CFNtBJr5dAFaIyDIRiQP4EoAtAR4/H1sArE1vrwWwOciDi4gAeA7APlV9NizjopzCHttlj5/QxbaqBvYF4B4A+wF8BOAbQR57grG8AKAbwBjGazIPA2jB+CdLBwBsA9Ac8Jhuw/ip/rsA3kl/3VPucfErr79dKGI7jHGdHleoYpsrN4jIOfxwg4icw8RHRM5h4iMi5zDxEZFzmPiIyDlMfETkHCY+InIOEx8ROef/AY/wDuw/XGFVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "\n",
    "K=np.array([[[0,0,0],[0,1,0],[0,0,0]],\n",
    "            [[1,1,1],[1,4,1],[1,1,1]],\n",
    "            [[-1,-1,-1],[-1,8,-1],[-1,-1,-1]],\n",
    "            [[0,0,0],[1,1,1],[0,0,0]]])\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "for I in range(2):\n",
    "    for J in range(2):\n",
    "        plt.subplot(2,2,I*2+J+1)\n",
    "        plt.imshow(signal.convolve2d(X_train[2,:,:],K[I*2+J,:,:],mode='valid'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have defined four different kernels (in the <code>K</code> array). The first one simply returns the value of the pixel itself, resulting in the original image, the second one implements a low-pass filter (also called a Gaussian Kernel), the third one emphasizes edges and the last one smooths the image only along one axis.\n",
    "\n",
    "In this example, we used the <code>convolve2d</code> function from SciPy's signal processing toolbox. It is also possible to use keras' convolutional neural network implementation in which the kernel values are loaded as weights of the neural network, which is described in <a href=\"https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/\">this article</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From convolutions to 2D neural networks\n",
    "\n",
    "To look at how one individual pixel in the output above gets computed, we assume that the input pixel is labeled $x_{i,j}$ with $i$ the row and $j$ the column of this pixel. We also assume the entries of the convolution kernel to be indexed in a similar way. The first pixel of the output is then calculated by\n",
    "\n",
    "$$ o_{0,0}=x_{0,0}w_{0,0}+x_{0,1}w_{0,1}+x_{0,2}w_{0,2}+x_{1,0}w_{1,0}+x_{1,1}w_{1,1}+x_{1,2}w_{1,2}+x_{2,0}w_{2,0}+x_{2,1}w_{2,1}+x_{2,2}w_{2,2} $$\n",
    "\n",
    "This pixel is therefore simply computing the dot-product of the value of 9 pixels with the kernel weights. Adding a bias value and an activation function such as Relu is therefore identical to adding a hidden layer with 9 neurons. \n",
    "\n",
    "Performing the convolution by moving the convolution kernel with a width of (2r+1) across an entire XxY image is therefore akin to creating (X-2r)(Y-2r) \"convolutional\" neurons, and the resulting structure is called a <i>feature map</i>. Note, that the \"weights\" in the feature map - the entries of the kernel matrix - are identical for each neuron in the feature map. We can now repeat this step with additional kernels, resulting in multiple feature maps, which then form a <i>convolutional layer</i>.\n",
    "\n",
    "As this structure is very similar to the conventional neural network structure, except for a large number of weights being identical, the parameters of each kernel can also be trained using back-propagation. A detailed derivation of how this can be implemented can be found in the article <a href=\"https://towardsdatascience.com/backpropagation-in-a-convolutional-layer-24c8d64d8509\">Backpropagation in a convolutional layer</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding and striding\n",
    "\n",
    "A convolution of kernel width $2r+1$ needs to reduce the input by $r$ on each side. If this is not desired, <i>padding</i> can be used to surround the input image with up to $r$ pixels, resulting in the output image having the same dimension than the input image. Instead of moving the convolution kernel pixel by pixel, skipping pixels will further reduce the size of the output image. The amount by which the convolution kernel is moved is known as <i>stride</i>. This is illustrated below for strides of one and three.\n",
    "\n",
    "<center>\n",
    "    <img src=\"figs/stride.svg\" width=\"75%\">\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a 2D input, the stride is usually provided as a tuple, expressing the stride along each axes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling\n",
    "\n",
    "The feature maps that result from convolution each identify specific features that are defined by their kernels. Training finds these kernels by itself and some might fire on edges, others on intersections of lines, and yet again others on very specific patterns in the dataset. Activation functions further amplify this effect, making a clear distinction between whether a feature is present or not. In most practical applications, such features are rather sparse, however, and whether they exist in a larger area or not, might the most salient information. This can be achieved by a <i>pooling layer</i>.\n",
    "\n",
    "A pooling operation applies a window to select the maximum (<i>MaxPooling</i>) or the average, among many other possible non-linear functions, from a window of a given size. The figure below shows the result of a MaxPooling layer with pool size of 3x3 and stride lengts of 1x1 and 3x3. Usually, the stride length is the same as the width of the window.\n",
    "\n",
    "<center>\n",
    "    <img src=\"figs/pooling.svg\" width=\"75%\">\n",
    "</center>\n",
    "\n",
    "Although the $max()$ function is not differentiable, MaxPooling can still be used in backpropagation by selectively passing the gradient to only that neuron which has shown the maximum activation and set the gradient of all other neurons in a pool to zero. In case an average pooling function has been used, the gradient is divided among all neurons in the pool to equal parts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flattening\n",
    "\n",
    "The first step in previous neural network models has been to flatten a 2D input image into a one-dimensional vector. This has been the precondition to apply a dense layer and has been accomplished during preprocessing. Convolutional neural networks require multi-dimensional (2D images with multiple color channels) inputs, however. Turning a multi-dimensional tensor into a vector is known as <i>flattening</i> and results into simple reordering. For example, an RGB image of dimensioniality (28x28x3) might be turned into 20 convolutional filters, or 2352 individual neurons. A flattening layer arranges them again in a single vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A sample CNN\n",
    "\n",
    "The figure below shows a typical CNN that combines multiple convolutional and pooling layers. The network takes a 28x28 image as an input and trains 20 different 5x5 convolution kernels to create 20 feature maps of 28x28 each. This layer is followed by a maxpooling layer that downsamples each feature map by a factor two. These feature maps are then convolved with 50 5x5 convolution kernels to create 50 14x14 feature maps. These will again be downsampled by a maxpooling operation. The resulting 50 feature maps are then flattened and fed into a hidden layer of 500 neurons, and finally into a SoftMax-activated output layer with 10 neurons. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"figs/cnn.svg\" width=\"75%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Networks beyond 2D image data\n",
    "\n",
    "Convolution kernels emphasize areas of similarity. This can be readily understood when considering a simple kernel like [[0,9,0],[0,9,0],[0,9,0]] which emphasizes vertical lines, but ignores horizontal ones. Training a convolutional network therefore automatically finds regularities in the training set, as well as in the resulting feature map, often generating hierarchical representations by itself. A common example is a convolutional neural network for face detection in which early layers detect low-level, which then get recombined into noses, ears, mouth and eyes in deeper layers.\n",
    "\n",
    "Convolutional neural networks are not limited to 2D image data, but can also be applied to 1D time series. Here, the will find distinct patterns, for example peaks in an electro-cardiogram, which can then be used in their plurality to classify complex signals. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
