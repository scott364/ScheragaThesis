{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll be using a GRU model for a time series prediction task and we will compare the performance of the GRU model against an LSTM model as well. The dataset that we will be using is the Hourly Energy Consumption dataset which can be found on [Kaggle](https://www.kaggle.com/robikscube/hourly-energy-consumption). The dataset contains power consumption data across different regions around the United States recorded on an hourly basis.\n",
    "\n",
    "You can run the code implementation in this article on FloydHub using their GPUs on the cloud by clicking the following link and using the main.ipynb notebook.\n",
    "\n",
    "[![Run on FloydHub](https://static.floydhub.com/button/button-small.svg)](https://floydhub.com/run?template=https://github.com/gabrielloye/https://github.com/gabrielloye/GRU_Prediction)\n",
    "\n",
    "This will speed up the training process significantly. Alternatively, the link to the GitHub repository can be found [here]().\n",
    "\n",
    "The goal of this implementation is to create a model that can accurately predict the energy usage in the next hour given historical usage data. We will be using both the GRU and LSTM model to train on a set of historical data and evaluate both models on an unseen test set. To do so, weâ€™ll start with feature selection, data-preprocessing, followed by defining, training and eventually evaluating the models.\n",
    "\n",
    "We will be using the PyTorch library to implement both types of models along with other common Python libraries used in data analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.python-engineer.com/posts/pytorch-rnn-lstm-gru/\n",
    "\n",
    "#https://blog.floydhub.com/gru-with-pytorch/\n",
    "\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import MinMaxScaler,QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Local ###\n",
    "#from data_processing import *\n",
    "\n",
    "\n",
    "\n",
    "# Define data root directory\n",
    "\n",
    "#data_dir = \"./data/\"\n",
    "#print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of **12** *.csv* files containing hourly energy trend data (*'est_hourly.paruqet'* and *'pjm_hourly_est.csv'* are not used). In our next step, we will be reading these files and pre-processing these data in this order:\n",
    "- Getting the time data of each individual time step and generalizing them\n",
    "    - Hour of the day *i.e. 0-23*\n",
    "    - Day of the week *i.e. 1-7*\n",
    "    - Month *i.e. 1-12*\n",
    "    - Day of the year *i.e. 1-365*\n",
    "    \n",
    "    \n",
    "- Scale the data to values between 0 and 1\n",
    "    - Algorithms tend to perform better or converge faster when features are on a relatively similar scale and/or close to normally distributed\n",
    "    - Scaling preserves the shape of the original distribution and doesn't reduce the importance of outliers.\n",
    "    \n",
    "    \n",
    "- Group the data into sequences to be used as inputs to the model and store their corresponding labels\n",
    "    - The **sequence length** or **lookback period** is the number of data points in history that the model will use to make the prediction\n",
    "    - The label will be the next data point in time after the last one in the input sequence\n",
    "    \n",
    "\n",
    "- The inputs and labels will then be split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(device)\n",
    "\n",
    "\n",
    "def get_torch_device( v=0 ):\n",
    "    # torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "    is_cuda = torch.cuda.is_available()\n",
    "    # If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "    if is_cuda:\n",
    "        device = torch.device(\"cuda\")\n",
    "        if v:  print( \"CUDA Available!\" )\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        if v:  print( \"NO CUDA\" )\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contatenated data size:\n",
      "(175656, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#choppeddata_testset=pd.read_csv('choppeddata_10_04_2021_3Xcopiedsuccess.csv')#.head()\n",
    "#choppeddata2=pd.read_csv('choppeddata_10_06_2021_3Xcopiedsuccess.csv')#.head()\n",
    "#choppeddata3=pd.read_csv('choppeddata_10_13_2021_3Xcopiedsuccess.csv')#.head()\n",
    "\n",
    "\n",
    "#choppeddata1=pd.read_csv('choppeddata_10_04_2021_3Xcopiedsuccess.csv')#.head()\n",
    "\n",
    "#choppeddata2=pd.read_csv('choppeddata_10_06_2021_3Xcopiedsuccess.csv')#.head()\n",
    "#choppeddata3=pd.read_csv('choppeddata_10_13_2021_3Xcopiedsuccess.csv')#.head()\n",
    "\n",
    "#choppeddata1=pd.read_csv('choppeddata_10_04_2021_randomselector_even.csv')#.head()\n",
    "#choppeddata2=pd.read_csv('choppeddata_10_06_2021_randomselector_even.csv')#.head()\n",
    "#choppeddata3=pd.read_csv('choppeddata_10_13_2021_randomselector_even.csv')#.head()\n",
    "\n",
    "\n",
    "\n",
    "#choppeddata_testset1=pd.read_csv('choppeddata_10_23_2021_3Xcopiedsuccess_fromGRUlookahead.csv')#.head()\n",
    "#choppeddata_testset2=pd.read_csv('choppeddata_10_23_2021_3Xcopiedsuccess_fromGRUlookahead_pos2rewardifbuttonpress.csv')#.head()\n",
    "\n",
    "\n",
    "choppeddata1=pd.read_csv('choppeddata_10_04_2021_V10-retroactiveVals.csv')\n",
    "choppeddata2=pd.read_csv('choppeddata_10_06_2021_V10-retroactiveVals.csv')\n",
    "choppeddata3=pd.read_csv('choppeddata_10_13_2021_V10-retroactiveVals.csv')\n",
    "\n",
    "\n",
    "choppeddata_testset =pd.read_csv('forcetorquebuttonresults_cylinder_withbutton_test_noposeobs_10_21_2021.csv')\n",
    "\n",
    "\n",
    "#print(choppeddata1.shape)\n",
    "#print(choppeddata2.shape)\n",
    "#print(choppeddata3.shape)\n",
    "\n",
    "#frames = [choppeddata1,choppeddata2,choppeddata3]\n",
    "frames = [choppeddata1,choppeddata2,choppeddata3]\n",
    "choppeddata = pd.concat(frames)\n",
    "\n",
    "#frames2 = [choppeddata_testset1,choppeddata_testset2]\n",
    "#choppeddata_testset = pd.concat(frames2)\n",
    "\n",
    "\n",
    "\n",
    "print(\"contatenated data size:\")\n",
    "print(choppeddata.shape)\n",
    "\n",
    "#print(\"contatenated data testset size:\")\n",
    "#print(choppeddata_testset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175656, 10)\n",
      "total runs: 29276\n",
      "(29276, 5, 10)\n",
      "(29276, 10)\n"
     ]
    }
   ],
   "source": [
    "print(choppeddata.shape)\n",
    "runqty=int(choppeddata.shape[0]/6)\n",
    "print(\"total runs:\",runqty)\n",
    "choppedheaders=[]\n",
    "lookback=10 #save only the last 11 timesteps\n",
    "for i in range(lookback):  \n",
    "    label=str(i)\n",
    "    choppedheaders.append(\"header\"+label)\n",
    "\n",
    "#put chopped data in np.arrays\n",
    "State=np.zeros((runqty,5,lookback)) #96 runs,with 5 sets of data (x,y,z,roll,pitch) each, and each run is 11 timesteps long\n",
    "Labels=np.zeros((runqty,lookback)) #96 runs, each run is 11 timesteps long\n",
    "runcounter=0\n",
    "\n",
    "for i in range(0,choppeddata.shape[0],6):\n",
    "            State[runcounter][0][:]=(choppeddata[choppedheaders[:]].iloc[i]).tolist()\n",
    "            State[runcounter][1][:]=(choppeddata[choppedheaders[:]].iloc[i+1]).tolist()\n",
    "            State[runcounter][2][:]=(choppeddata[choppedheaders[:]].iloc[i+2]).tolist()\n",
    "            State[runcounter][3][:]=(choppeddata[choppedheaders[:]].iloc[i+3]).tolist()\n",
    "            State[runcounter][4][:]=(choppeddata[choppedheaders[:]].iloc[i+4]).tolist()\n",
    "            Labels[runcounter][:]=(choppeddata[choppedheaders[:]].iloc[i+5]).tolist()  #labels   \n",
    "            runcounter+=1\n",
    "#print(State[0])\n",
    "#print(Labels)\n",
    "#print(Labels[:,9]) #just getting finals labels\n",
    "\n",
    "print(State.shape)\n",
    "print(Labels.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 30)\n",
      "total runs: 500\n",
      "(500, 5, 10)\n",
      "(500, 10)\n"
     ]
    }
   ],
   "source": [
    "#make test set with data outside of training set, because of duplication of successful runs. \n",
    "\n",
    "\n",
    "print(choppeddata_testset.shape)\n",
    "runqty_testset=int(choppeddata_testset.shape[0]/6)\n",
    "print(\"total runs:\",runqty_testset)\n",
    "\n",
    "#put chopped data in np.arrays\n",
    "State_testset=np.zeros((runqty_testset,5,lookback)) #96 runs,with 5 sets of data (x,y,z,roll,pitch) each, and each run is 11 timesteps long\n",
    "Labels_testset=np.zeros((runqty_testset,lookback)) #96 runs, each run is 11 timesteps long\n",
    "runcounter=0\n",
    "\n",
    "for i in range(0,choppeddata_testset.shape[0],6):\n",
    "            State_testset[runcounter][0][:]=(choppeddata_testset[choppedheaders[:]].iloc[i]).tolist()\n",
    "            State_testset[runcounter][1][:]=(choppeddata_testset[choppedheaders[:]].iloc[i+1]).tolist()\n",
    "            State_testset[runcounter][2][:]=(choppeddata_testset[choppedheaders[:]].iloc[i+2]).tolist()\n",
    "            State_testset[runcounter][3][:]=(choppeddata_testset[choppedheaders[:]].iloc[i+3]).tolist()\n",
    "            State_testset[runcounter][4][:]=(choppeddata_testset[choppedheaders[:]].iloc[i+4]).tolist()\n",
    "            Labels_testset[runcounter][:]=(choppeddata_testset[choppedheaders[:]].iloc[i+5]).tolist()  #labels   \n",
    "            runcounter+=1\n",
    "\n",
    "print(State_testset.shape)\n",
    "print(Labels_testset.shape)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of 980,185 sequences of training data\n",
    "\n",
    "To improve the speed of our training, we can process the data in batches so that the model does not need to update its weights as frequently. The Torch *Dataset* and *DataLoader* classes are useful for splitting our data into batches and shuffling them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f67d6586390>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check if we have any GPUs to speed up our training time by many folds. If youâ€™re using FloydHub with GPU to run this code, the training time will be significantly reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden\n",
    "def train(train_loader, learn_rate, hidden_dim=128, EPOCHS=400, model_type=\"GRU\"):\n",
    "    #got  109 / 180 on training set, 29 / 60 on test set from 128 hidden dim, 50 epoch, batch size of 4, lr =0.001\n",
    "    #Got training data= 146 / 180, success vs test data= 38 / 60 with same as above but 100 epoch\n",
    "    #Got training data= 172 / 180, success vs test data= 46 / 60 with same as above but 200 epoch\n",
    "    #Got training data= 165 / 180, success vs test data= 52 / 60 with same as above but 200 epoch\n",
    "    \n",
    "    losslist=[]\n",
    "    # Setting common hyperparameters\n",
    "    input_dim = next(iter(train_loader))[0].shape[2]  #  = 11\n",
    "    #print(input_dim)\n",
    "    #print(\"input_dim\",input_dim)\n",
    "    output_dim = 1\n",
    "    n_layers = 2\n",
    "    # Instantiating the models\n",
    "    if model_type == \"GRU\":\n",
    "        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    else:\n",
    "        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Defining loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    \n",
    "    model.train()\n",
    "    print(\"Starting Training of {} model\".format(model_type))\n",
    "    epoch_times = []\n",
    "    # Start training loop\n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        start_time = time.clock()\n",
    "        h = model.init_hidden(batch_size)\n",
    "        avg_loss = 0.\n",
    "        counter = 0\n",
    "        for x, label in train_loader:\n",
    "            #print(\"x\",x)\n",
    "            #print(\"label\",label)\n",
    "            counter += 1\n",
    "            if model_type == \"GRU\":\n",
    "                h = h.data\n",
    "            else:\n",
    "                h = tuple([e.data for e in h])\n",
    "            model.zero_grad()\n",
    "            \n",
    "            out, h = model(x.to(device).float(), h)\n",
    "            #print(\"out\",out)\n",
    "            loss = criterion(out, label.to(device).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "            \n",
    "            if counter%20000 == 0:\n",
    "                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter, len(train_loader), avg_loss/counter))\n",
    "        current_time = time.clock()\n",
    "        if epoch%40 == 0:\n",
    "            print(\"Epoch {}/{} Done, Total Loss: {}   Time Elapsed: {} seconds\".format(epoch, EPOCHS, avg_loss/len(train_loader),str(current_time-start_time)))\n",
    "        \n",
    "            #print(\"Total\".format())\n",
    "        losslist.append(avg_loss/len(train_loader))\n",
    "        epoch_times.append(current_time-start_time)\n",
    "    print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n",
    "    plt.plot(losslist)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.show()\n",
    "    return model,losslist\n",
    "\n",
    "def train_existing_model(model,train_loader, learn_rate, hidden_dim=128, EPOCHS=400, model_type=\"GRU\"):\n",
    "    #got  109 / 180 on training set, 29 / 60 on test set from 128 hidden dim, 50 epoch, batch size of 4, lr =0.001\n",
    "    #Got training data= 146 / 180, success vs test data= 38 / 60 with same as above but 100 epoch\n",
    "    #Got training data= 172 / 180, success vs test data= 46 / 60 with same as above but 200 epoch\n",
    "    #Got training data= 165 / 180, success vs test data= 52 / 60 with same as above but 200 epoch\n",
    "    \n",
    "    losslist=[]\n",
    "    # Setting common hyperparameters\n",
    "    input_dim = next(iter(train_loader))[0].shape[2]  #  = 11\n",
    "    #print(input_dim)\n",
    "    #print(\"input_dim\",input_dim)\n",
    "    output_dim = 1\n",
    "    n_layers = 2\n",
    "    # Instantiating the models\n",
    "    \"\"\"\n",
    "    if model_type == \"GRU\":\n",
    "        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    else:\n",
    "        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    \"\"\"    \n",
    "        \n",
    "    model.to(device)\n",
    "    \n",
    "    # Defining loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    \n",
    "    model.train()\n",
    "    print(\"Starting Training of {} model\".format(model_type))\n",
    "    epoch_times = []\n",
    "    # Start training loop\n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        start_time = time.clock()\n",
    "        h = model.init_hidden(batch_size)\n",
    "        avg_loss = 0.\n",
    "        counter = 0\n",
    "        for x, label in train_loader:\n",
    "            #print(\"x\",x)\n",
    "            #print(\"label\",label)\n",
    "            counter += 1\n",
    "            if model_type == \"GRU\":\n",
    "                h = h.data\n",
    "            else:\n",
    "                h = tuple([e.data for e in h])\n",
    "            model.zero_grad()\n",
    "            \n",
    "            out, h = model(x.to(device).float(), h)\n",
    "            #print(\"out\",out)\n",
    "            loss = criterion(out, label.to(device).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "            \n",
    "            if counter%20000 == 0:\n",
    "                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter, len(train_loader), avg_loss/counter))\n",
    "        current_time = time.clock()\n",
    "        if epoch%40 == 0:\n",
    "            print(\"Epoch {}/{} Done, Total Loss: {}   Time Elapsed: {} seconds\".format(epoch, EPOCHS, avg_loss/len(train_loader),str(current_time-start_time)))\n",
    "        \n",
    "            #print(\"Total\".format())\n",
    "        losslist.append(avg_loss/len(train_loader))\n",
    "        epoch_times.append(current_time-start_time)\n",
    "    print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n",
    "    plt.plot(losslist)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.show()\n",
    "    return model,losslist\n",
    "\n",
    "\n",
    "def evaluate(model, test_x, test_y):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []\n",
    "    start_time = time.clock()\n",
    "    #for i in test_x.keys():\n",
    "    for i in range( len( test_x ) ):    \n",
    "        inp = torch.from_numpy(np.array(test_x[i])) # should be 5x1\n",
    "        labs = torch.from_numpy(np.array(test_y[i])) #should be 1x1\n",
    "        h = model.init_hidden(inp.shape[0])\n",
    "        #print(\"inp\",inp)\n",
    "        #print(\"labs\",labs)\n",
    "        #print(\"h\",h)\n",
    "        out, h = model(inp.to(device).float(), h)\n",
    "        #outputs.append(label_scalers[i].inverse_transform(out.cpu().detach().numpy()).reshape(-1))\n",
    "        #targets.append(label_scalers[i].inverse_transform(labs.numpy()).reshape(-1))\n",
    "        outputs.append( out.cpu().detach().numpy().reshape(-1) )\n",
    "        targets.append( labs.numpy().reshape(-1) )\n",
    "        \n",
    "    print(\"Evaluation Time: {}\".format(str(time.clock()-start_time)))\n",
    "    sMAPE = 0\n",
    "    for i in range(len(outputs)):\n",
    "        sMAPE += np.mean(abs(outputs[i]-targets[i])/(targets[i]+outputs[i])/2)/len(outputs)\n",
    "    print(\"sMAPE: {}%\".format(sMAPE*100))\n",
    "    return outputs, targets, sMAPE\n",
    "                               \n",
    "def evaluate2(model, test_x, test_y):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []  #labels\n",
    "    #start_time = time.clock()\n",
    "    #for i in test_x.keys():\n",
    "    #for i in range( len( test_x ) ):    \n",
    "    inp = torch.from_numpy(np.array(test_x)) # should be 5x1\n",
    "    labs = torch.from_numpy(np.array(test_y)) #should be 1x1\n",
    "    h = model.init_hidden(inp.shape[0])\n",
    "    #print(\"inp\",inp)\n",
    "    #print(\"labs\",labs)\n",
    "    #print(\"h\",h)\n",
    "    out, h = model(inp.to(device).float(), h)\n",
    "    #outputs.append(label_scalers[i].inverse_transform(out.cpu().detach().numpy()).reshape(-1))\n",
    "    #targets.append(label_scalers[i].inverse_transform(labs.numpy()).reshape(-1))\n",
    "    outputs.append( out.cpu().detach().numpy().reshape(-1) )\n",
    "    targets.append( labs.numpy().reshape(-1) )\n",
    "        \n",
    "    #print(\"Evaluation Time: {}\".format(str(time.clock()-start_time)))\n",
    "    sMAPE = 0\n",
    "    #for i in range(len(outputs)):\n",
    "    #    sMAPE += np.mean(abs(outputs[i]-targets[i])/(targets[i]+outputs[i])/2)/len(outputs)\n",
    "    #print(\"sMAPE: {}%\".format(sMAPE*100))\n",
    "    return outputs, targets#, sMAPE                               \n",
    "\n",
    "def evaluatefull_maxdiff(gru_model, train_x, train_y, test_x, test_y,maxdifference=0.2, verbose=False):\n",
    "\n",
    "    #m = nn.ReLU()\n",
    "    #m = nn.Sigmoid()\n",
    "    #output = m(input)\n",
    "    print(\"Vs Training Set\")\n",
    "    gru_outputs, targets = evaluate2(gru_model, train_x, train_y)\n",
    "    #print(test_y)\n",
    "    #print(gru_outputs)\n",
    "    #print(gru_outputs[0][5])\n",
    "\n",
    "\n",
    "    testy=test_y.reshape(-1)\n",
    "    trainy=train_y.reshape(-1)\n",
    "\n",
    "\n",
    "    #print(\"Train size:\",trainy.size)\n",
    "    print(gru_outputs[0][4])\n",
    "    train_successcounter=0\n",
    "    for i in range(int(trainy.size)):\n",
    "        #print(testy[i],gru_outputs[0][i],m(torch.tensor(gru_outputs[0][i])))\n",
    "        #print(train[i],gru_outputs[0][i],m(torch.tensor(gru_outputs[0][i])))\n",
    "\n",
    "\n",
    "        #print(trainy[i],gru_outputs[0][i], m(torch.tensor(gru_outputs[0][i])))\n",
    "\n",
    "\n",
    "        if abs(trainy[i]-gru_outputs[0][i])<maxdifference :\n",
    "            train_successcounter+=1\n",
    "        #print(testy[i])\n",
    "        #print\n",
    "        #output = m(input)\n",
    "\n",
    "\n",
    "\n",
    "    test_successcounter=0\n",
    "    print(\"Vs Test Set\")\n",
    "    gru_outputs, targets = evaluate2(gru_model, test_x, test_y)\n",
    "    #print(\"test size: \",testy.size)\n",
    "\n",
    "    for i in range(int(testy.size)):\n",
    "\n",
    "\n",
    "        #, m(torch.tensor(gru_outputs[0][i])))\n",
    "\n",
    "\n",
    "        if abs(testy[i]-gru_outputs[0][i])<maxdifference :\n",
    "            test_successcounter+=1\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"OK\" )\n",
    "        else:\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"X\" )\n",
    "            #print(testy[i])\n",
    "        #print\n",
    "        #output = m(input)\n",
    "    print(\"\")\n",
    "    print(\" vs training data=\" ,train_successcounter,\"/\",trainy.size, \" vs test data=\" ,\n",
    "          test_successcounter,\"/\",testy.size,int(100*test_successcounter/testy.size),\"%\", \"at max difference\",maxdifference )\n",
    "    return ( train_successcounter ,test_successcounter)\n",
    "\n",
    "\n",
    "def evaluatefull_cutoff(gru_model, train_x, train_y, test_x, test_y,cutoff=0.5, verbose=False):\n",
    "\n",
    "    #m = nn.ReLU()\n",
    "    #m = nn.Sigmoid()\n",
    "    #output = m(input)\n",
    "    \n",
    "    #gru_outputs, targets, gru_sMAPE = evaluate2(gru_model, train_x, train_y)\n",
    "    gru_outputs, targets= evaluate2(gru_model, train_x, train_y)\n",
    "    #print(test_y)\n",
    "    #print(gru_outputs)\n",
    "    #print(gru_outputs[0][5])\n",
    "\n",
    "\n",
    "    testy=test_y.reshape(-1)\n",
    "    trainy=train_y.reshape(-1)\n",
    "    #print(\"Vs Training Set\")\n",
    "    #print(gru_outputs[0][4])\n",
    "    traincounter_falsenegative=0\n",
    "    traincounter_falsepositive=0\n",
    "    \n",
    "    traincounter_truenegative=0\n",
    "    traincounter_truepositive=0\n",
    "    for i in range(int(trainy.size)):\n",
    "        \n",
    "        if trainy[i]==1  and gru_outputs[0][i]>= cutoff:\n",
    "            traincounter_truepositive+=1\n",
    "            if verbose==True:\n",
    "                print(trainy[i],gru_outputs[0][i], \"OK-truepositive\" )\n",
    "        elif trainy[i]==1  and gru_outputs[0][i]< cutoff:\n",
    "            traincounter_falsenegative+=1\n",
    "            if verbose==True:\n",
    "                print(trainy[i],gru_outputs[0][i], \"X-falsenegative\" )       \n",
    "                \n",
    "        elif trainy[i]==0 and gru_outputs[0][i]<= cutoff :\n",
    "            traincounter_truenegative+=1\n",
    "            if verbose==True:\n",
    "                print(trainy[i],gru_outputs[0][i], \"OK-truenegative\" )           \n",
    "        elif trainy[i]==0 and gru_outputs[0][i]> cutoff:\n",
    "            traincounter_falsepositive+=1\n",
    "            if verbose==True:\n",
    "                print(trainy[i],gru_outputs[0][i], \"X-falsepositive\" )     \n",
    "                \n",
    "           \n",
    "    #print(\"TRAINING SET: Fails for button not pressed:\",  train_failzerocounter,\"Fails for button pressed:\", train_failonecounter )        \n",
    "    test_successcounter=0\n",
    "    test_failzerocounter=0\n",
    "    test_failonecounter=0\n",
    "    \n",
    "    #gru_outputs, targets, gru_sMAPE = evaluate2(gru_model, test_x, test_y)\n",
    "    gru_outputs, targets = evaluate2(gru_model, test_x, test_y)\n",
    "    #print(\"Vs Test Set\")\n",
    "    #print(gru_outputs[0][4])\n",
    "    #print(\"test size: \",testy.size)\n",
    "\n",
    "\n",
    "    testcounter_falsenegative=0\n",
    "    testcounter_falsepositive=0\n",
    "    \n",
    "    testcounter_truenegative=0\n",
    "    testcounter_truepositive=0\n",
    "    for i in range(int(testy.size)):\n",
    "        \n",
    "        if testy[i]==1  and gru_outputs[0][i]>= cutoff:\n",
    "            testcounter_truepositive+=1\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"OK-truepositive\" )\n",
    "        elif testy[i]==1  and gru_outputs[0][i]< cutoff:\n",
    "            testcounter_falsenegative+=1\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"X-falsenegative\" )       \n",
    "                \n",
    "        elif testy[i]==0 and gru_outputs[0][i]<= cutoff :\n",
    "            testcounter_truenegative+=1\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"OK-truenegative\" )           \n",
    "        elif testy[i]==0 and gru_outputs[0][i]> cutoff:\n",
    "            testcounter_falsepositive+=1\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"X-falsepositive\" )   \n",
    "    \n",
    "    print(\" vs training data=\" ,traincounter_truepositive+traincounter_truenegative,\"/\",trainy.size, \" vs test data=\" ,\n",
    "          testcounter_truepositive+testcounter_truenegative,\"/\",testy.size,round((100*(testcounter_truepositive+testcounter_truenegative)/testy.size),2),\"%\", \"at cutoff\",cutoff )\n",
    "    \n",
    "    \n",
    "    print(\"TEST SET: True Positives\",testcounter_truepositive,\"True Negatives\", testcounter_truenegative,\" False Positives\",testcounter_falsepositive,\"False Negatives\", testcounter_falsenegative)\n",
    "    print(\"\")\n",
    "    return ( traincounter_truepositive+traincounter_truenegative, testcounter_truepositive+testcounter_truenegative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (29276, 5, 10)\n",
      "x.shape (500, 5, 10)\n",
      "Starting Training of GRU model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:72: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/500 Done, Total Loss: 0.0627169204352979   Time Elapsed: 0.6177840000000288 seconds\n",
      "Epoch 80/500 Done, Total Loss: 0.051702361243466534   Time Elapsed: 0.62667399999998 seconds\n",
      "Epoch 120/500 Done, Total Loss: 0.04368826783703346   Time Elapsed: 0.5846409999999196 seconds\n",
      "Epoch 160/500 Done, Total Loss: 0.037558578126328554   Time Elapsed: 0.6031540000000177 seconds\n",
      "Epoch 200/500 Done, Total Loss: 0.032028076108218284   Time Elapsed: 0.6331000000000131 seconds\n",
      "Epoch 240/500 Done, Total Loss: 0.02746845901894726   Time Elapsed: 0.5930380000000923 seconds\n",
      "Epoch 280/500 Done, Total Loss: 0.024860471364502843   Time Elapsed: 0.6069370000000163 seconds\n",
      "Epoch 320/500 Done, Total Loss: 0.022341395908019   Time Elapsed: 0.6233969999999545 seconds\n",
      "Epoch 360/500 Done, Total Loss: 0.019766272486824738   Time Elapsed: 0.6030789999999797 seconds\n",
      "Epoch 400/500 Done, Total Loss: 0.0184025194193645   Time Elapsed: 0.592773999999963 seconds\n",
      "Epoch 440/500 Done, Total Loss: 0.017713299703277778   Time Elapsed: 0.5855009999999083 seconds\n",
      "Epoch 480/500 Done, Total Loss: 0.016190022315928025   Time Elapsed: 0.59556699999996 seconds\n",
      "Total Training Time: 299.6047310000005 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vs Training Set\n",
      "0.1337676\n",
      "Vs Test Set\n",
      "\n",
      " vs training data= 29164 / 29275  vs test data= 191 / 498 38 % at max difference 0.4\n",
      "10_25_2021\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type GRUNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntrain2 ,test2=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.1)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.2)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.3)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.7)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.8)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.9)\\n\\ngru_model3, losslist3 =train_existing_model(gru_model2,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\ntrain2 ,test2=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.7)\\n\\n\\ngru_model4, losslist4 =train_existing_model(gru_model3,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\n\\ntrain2 ,test2=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.7)\\n\\ngru_model5, losslist5 =train_existing_model(gru_model4,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\ntrain2 ,test2=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.7)\\n\\ngru_model6, losslist6 =train_existing_model(gru_model5,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\ntrain2 ,test2=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.7)\\n\\ngru_model7, losslist7 =train_existing_model(gru_model6,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\ntrain2 ,test2=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.7)\\n\\ngru_model8, losslist8 =train_existing_model(gru_model7,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\ntrain2 ,test2=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.7)\\n\\nfulllosslist=losslist1+losslist2+losslist3+losslist4+losslist5+losslist6+losslist7+losslist8\\nplt.plot(fulllosslist)\\nplt.title(\"Loss\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0005\n",
    "batch_size = 64*2\n",
    "#a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels.\n",
    "\n",
    "#X=State[:,:,0:9]\n",
    "X=State[:,:,:]\n",
    "y=Labels[:,lookback-1]\n",
    "print(\"x.shape\",X.shape)\n",
    "y=y.reshape(runqty,1)\n",
    "\n",
    "\n",
    "X_testset=State_testset[:,:,:]\n",
    "y_testset=Labels_testset[:,lookback-1]\n",
    "print(\"x.shape\",X_testset.shape)\n",
    "\n",
    "y_testset=y_testset.reshape(runqty_testset,1)\n",
    "\n",
    "\n",
    "random_seed=int(time.time())\n",
    "#print(int(time.time()))\n",
    "train_x_trainset, test_x_trainset, train_y_trainset,test_y_trainset = train_test_split(X, y, test_size= float(.00001),#.25 #0.33, \n",
    "                                                   random_state=random_seed)\n",
    "\n",
    "train_x_testset, test_x_testset, train_y_testset,test_y_testset = train_test_split(X_testset, y_testset, test_size=.995,#.25 #0.33, \n",
    "                                                   random_state=random_seed)\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x_trainset), torch.from_numpy(train_y_trainset))\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "test_data   = TensorDataset( torch.from_numpy( test_x_testset ), torch.from_numpy( test_y_testset) )\n",
    "test_loader = DataLoader( test_data, shuffle = True, batch_size = batch_size, drop_last = True )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gru_model1, losslist1 =train(train_loader, lr , hidden_dim=128, EPOCHS=500 ,model_type=\"GRU\") #1500  #had low total loss with batch size 32\n",
    "train2 ,test2=evaluatefull_maxdiff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,maxdifference=0.4)\n",
    "\n",
    "import time\n",
    "from datetime import date\n",
    "\n",
    "today = date.today()    \n",
    "todaydate = today.strftime(\"%m_%d_%Y\")\n",
    "print(todaydate)\n",
    "torch.save(gru_model1,\"currentmodel_V10A_retroactiveVals_3datasets\"+todaydate+\".pt\")\n",
    "\n",
    "\n",
    "print(\"model saved\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.1)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.2)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.3)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.7)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.8)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.9)\n",
    "\"\"\"\n",
    "\n",
    "#gru_model2, losslist2 =train_existing_model(gru_model1,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "#train2 ,test2=evaluatefull_maxdiff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,maxdifference=0.4)\n",
    "\n",
    "\"\"\"\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.1)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.2)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.3)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.7)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.8)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.9)\n",
    "\n",
    "gru_model3, losslist3 =train_existing_model(gru_model2,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "\n",
    "\n",
    "gru_model4, losslist4 =train_existing_model(gru_model3,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "\n",
    "gru_model5, losslist5 =train_existing_model(gru_model4,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "\n",
    "gru_model6, losslist6 =train_existing_model(gru_model5,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "\n",
    "gru_model7, losslist7 =train_existing_model(gru_model6,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "\n",
    "gru_model8, losslist8 =train_existing_model(gru_model7,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "\n",
    "fulllosslist=losslist1+losslist2+losslist3+losslist4+losslist5+losslist6+losslist7+losslist8\n",
    "plt.plot(fulllosslist)\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vs Training Set\n",
      "-0.03258577\n",
      "Vs Test Set\n",
      "\n",
      " vs training data= 18254 / 18301  vs test data= 8757 / 10920 80 % at max difference 0.4\n",
      "Vs Training Set\n",
      "-0.03258577\n",
      "Vs Test Set\n",
      "\n",
      " vs training data= 18254 / 18301  vs test data= 8757 / 10920 80 % at max difference 0.4\n"
     ]
    }
   ],
   "source": [
    "train2 ,test2=evaluatefull_maxdiff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,maxdifference=0.4)\n",
    "\n",
    "\n",
    "\n",
    "train2 ,test2=evaluatefull_maxdiff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,maxdifference=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ngru_model3, losslist3 =train_existing_model(gru_model2,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\ntrain2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.1)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.2)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.3)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.7)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.8)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.9)\\n\\n\\nprint(\"\")\\nprint(\"\")\\n\\n\\ngru_model4, losslist4 =train_existing_model(gru_model3,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\ntrain2 ,test2=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.1)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.2)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.3)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.7)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.8)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.9)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "gru_model3, losslist3 =train_existing_model(gru_model2,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.1)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.2)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.3)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.7)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.8)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.9)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "gru_model4, losslist4 =train_existing_model(gru_model3,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.1)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.2)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.3)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.7)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.8)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.9)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_episode(model, data, verbose=False):\n",
    "\n",
    "   \n",
    "    model.eval()\n",
    "    inp = torch.from_numpy(np.array(data)) # should be 5x1\n",
    "    h = model.init_hidden(inp.shape[0])\n",
    "    #print(\"inp\",inp)\n",
    "    #print(\"labs\",labs)\n",
    "    #print(\"h\",h)\n",
    "    out, h = model(inp.to(device).float(), h)\n",
    "    #print(\"model output\",out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "gru_model3=torch.load('currentmodel_9steplookhead10_23_2021.pt',map_location=torch.device('cpu'))\n",
    "gru_model3.eval()\n",
    "print(\"loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x_trainset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8751/1960168386.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluatefull_cutoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_testset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_testset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluatefull_cutoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_testset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_testset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluatefull_cutoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_testset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_testset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluatefull_cutoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_testset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_testset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluatefull_cutoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_testset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_testset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_x_trainset' is not defined"
     ]
    }
   ],
   "source": [
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.1)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.2)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.3)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.7)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.8)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " vs training data= 12561 / 12569  vs test data= 4039 / 4042 99.93 % at cutoff 0.5\n",
      "TEST SET: True Positives 2021 True Negatives 2018\n",
      "TEST SET: False Positives 3 False Negatives 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:184: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index= 44\n",
      "(1, 5, 10)\n",
      "prediction 0.2498023509979248   actual [0.]\n"
     ]
    }
   ],
   "source": [
    "randomindex=random.randint(0,225)\n",
    "print(\"index=\",randomindex)\n",
    "\n",
    "exampledata=np.expand_dims(test_x[207, 0:5, 0:10], axis=0)\n",
    "\n",
    "print(exampledata.shape)\n",
    "prediction=evaluate_episode(gru_model3, exampledata)\n",
    "\n",
    "print(\"prediction\",float(prediction), \"  actual\",test_y[randomindex])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## simlulate a buffer of 10 timesteps entering the classifier over a 1 episode, and classifying them. Filling empty data with zeroes or ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index= 188\n",
      "final partial data\n",
      "[[[1.         0.64779416 0.68590197 0.69517914 0.69903447 0.71459429\n",
      "   0.71267351 0.71409191 0.71673093 0.72399386]\n",
      "  [1.         0.52154944 0.52310862 0.53282553 0.52718083 0.53709991\n",
      "   0.52978522 0.54277099 0.53688102 0.54443726]\n",
      "  [1.         0.8726286  0.96482141 0.95083008 0.94447182 0.93691809\n",
      "   0.95239155 0.9493714  0.95276295 0.95638539]\n",
      "  [1.         0.50752062 0.50852903 0.49810241 0.50102952 0.4947311\n",
      "   0.50046923 0.49000781 0.49422322 0.48543027]\n",
      "  [1.         0.62007232 0.67079484 0.67376652 0.67304434 0.68618886\n",
      "   0.68665851 0.69233506 0.69529406 0.70288601]]]\n",
      "\n",
      "full data\n",
      "[[[0.64779416 0.68590197 0.69517914 0.69903447 0.71459429 0.71267351\n",
      "   0.71409191 0.71673093 0.72399386 0.7219988 ]\n",
      "  [0.52154944 0.52310862 0.53282553 0.52718083 0.53709991 0.52978522\n",
      "   0.54277099 0.53688102 0.54443726 0.53999553]\n",
      "  [0.8726286  0.96482141 0.95083008 0.94447182 0.93691809 0.95239155\n",
      "   0.9493714  0.95276295 0.95638539 0.94038139]\n",
      "  [0.50752062 0.50852903 0.49810241 0.50102952 0.4947311  0.50046923\n",
      "   0.49000781 0.49422322 0.48543027 0.49026894]\n",
      "  [0.62007232 0.67079484 0.67376652 0.67304434 0.68618886 0.68665851\n",
      "   0.69233506 0.69529406 0.70288601 0.70206539]]]\n",
      "predictions: [-0.15575464069843292, 0.23807184398174286, 0.38706398010253906, 0.21107828617095947, 0.10108674317598343, 0.1720225214958191, 0.42928677797317505, 0.3034760355949402, 0.030546963214874268]\n",
      "\n",
      "\n",
      "prediction from 10 timesteps 0.4351702332496643 actual [0.]\n"
     ]
    }
   ],
   "source": [
    "outputlist=[]\n",
    "\n",
    "randomindex=random.randint(0,225)\n",
    "print(\"index=\",randomindex)\n",
    "exampledata=np.expand_dims(test_x[randomindex, 0:5, 0:10], axis=0)\n",
    "\n",
    "\n",
    "#print(temparray.shape)\n",
    "#temparray=np.expand_dims(temparray, axis=1)\n",
    "\n",
    "#print(temparray.shape)\n",
    "#print(temparray)\n",
    "\n",
    "#temparray2=test_x[randomindex, 0:5, 0]\n",
    "#temparray2=np.expand_dims(temparray2, axis=1)\n",
    "\n",
    "for i in range(9):\n",
    "    if i!=10:\n",
    "        temparray=np.ones((5,1)) #test_x[randomindex, 0:5, 0]   #zeroes or \"ones\" here seems to work equally well. \n",
    "    \n",
    "    for j in range(8-i):\n",
    "        #temparray2=test_x[randomindex, 0:5, 0]\n",
    "        #temparray2=np.expand_dims(temparray2, axis=1)\n",
    "        temparray=np.append(temparray,np.ones((5,1)),axis=1)       #zeroes or \"ones\" here seems to work equally well. \n",
    "        #temparray=np.append(temparray,temparray2,axis=1)\n",
    "        #temparray=np.append(np.zeros((5,1)),temparray,axis=1)   \n",
    "    \n",
    "    for j in range(i+1):\n",
    "\n",
    "        temparray2=test_x[randomindex, 0:5, j]\n",
    "        temparray2=np.expand_dims(temparray2, axis=1)\n",
    "        temparray=np.append(temparray,temparray2,axis=1)\n",
    "        #temparray=np.append(np.zeros((5,1)),temparray,axis=1)\n",
    "\n",
    "    \n",
    "    #print(temparray)\n",
    "    temparray=np.expand_dims(temparray, axis=0)\n",
    "    outputpartial=evaluate_episode(gru_model3, temparray)\n",
    "    \n",
    "    \n",
    "    outputlist.append(float(outputpartial))\n",
    "\n",
    "print(\"final partial data\")\n",
    "print(temparray)   \n",
    "print(\"\")\n",
    "print(\"full data\")\n",
    "print(exampledata)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"prediction from\",x,\" timesteps\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "print(\"predictions:\",outputlist)\n",
    "\n",
    "\n",
    "#print(\"full data\")\n",
    "#print(exampledata)\n",
    "print(\"\")\n",
    "#print(\"evaluating all 10 timesteps\")\n",
    "\n",
    "outputfull=evaluate_episode(gru_model3, exampledata)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "#print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "#print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "print(\"prediction from 10 timesteps\",float(outputfull),\"actual\",test_y[randomindex])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classifying progression of 10 actual forces and torques in a sucessful sequence longer than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 30)\n",
      "['header0', 'header1', 'header2', 'header3', 'header4', 'header5', 'header6', 'header7', 'header8', 'header9', 'header10', 'header11', 'header12', 'header13', 'header14', 'header15', 'header16', 'header17', 'header18', 'header19', 'header20', 'header21', 'header22', 'header23', 'header24', 'header25', 'header26', 'header27', 'header28', 'header29']\n"
     ]
    }
   ],
   "source": [
    "#originaldata=pd.read_csv('forcetorquebuttonresults_renormalized_10_06_2021_newrange.csv')#.head()\n",
    "originaldata=pd.read_csv('forcetorquebuttonresults_cylinder_withbutton_test_noposeobs_10_21_2021.csv')#.head()\n",
    "\n",
    "print(originaldata.shape)\n",
    "headers=[]\n",
    "lookback=30 #save only the last 11 timesteps\n",
    "for i in range(lookback):  \n",
    "    label=str(i)\n",
    "    headers.append(\"header\"+label)\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header0</th>\n",
       "      <th>header1</th>\n",
       "      <th>header2</th>\n",
       "      <th>header3</th>\n",
       "      <th>header4</th>\n",
       "      <th>header5</th>\n",
       "      <th>header6</th>\n",
       "      <th>header7</th>\n",
       "      <th>header8</th>\n",
       "      <th>header9</th>\n",
       "      <th>...</th>\n",
       "      <th>header20</th>\n",
       "      <th>header21</th>\n",
       "      <th>header22</th>\n",
       "      <th>header23</th>\n",
       "      <th>header24</th>\n",
       "      <th>header25</th>\n",
       "      <th>header26</th>\n",
       "      <th>header27</th>\n",
       "      <th>header28</th>\n",
       "      <th>header29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4039</th>\n",
       "      <td>-0.146118</td>\n",
       "      <td>-0.150491</td>\n",
       "      <td>-0.161489</td>\n",
       "      <td>-0.145119</td>\n",
       "      <td>-0.144571</td>\n",
       "      <td>-0.139811</td>\n",
       "      <td>-0.140801</td>\n",
       "      <td>-0.155982</td>\n",
       "      <td>-0.166506</td>\n",
       "      <td>-0.181792</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4040</th>\n",
       "      <td>0.855510</td>\n",
       "      <td>0.854350</td>\n",
       "      <td>0.856338</td>\n",
       "      <td>0.850147</td>\n",
       "      <td>0.851591</td>\n",
       "      <td>0.854438</td>\n",
       "      <td>0.850040</td>\n",
       "      <td>0.839254</td>\n",
       "      <td>0.842253</td>\n",
       "      <td>0.845896</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4041</th>\n",
       "      <td>0.186981</td>\n",
       "      <td>0.186524</td>\n",
       "      <td>0.187637</td>\n",
       "      <td>0.185199</td>\n",
       "      <td>0.188515</td>\n",
       "      <td>0.183551</td>\n",
       "      <td>0.182902</td>\n",
       "      <td>0.192211</td>\n",
       "      <td>0.219140</td>\n",
       "      <td>0.220496</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4042</th>\n",
       "      <td>0.077426</td>\n",
       "      <td>0.079701</td>\n",
       "      <td>0.079563</td>\n",
       "      <td>0.080320</td>\n",
       "      <td>0.082692</td>\n",
       "      <td>0.082281</td>\n",
       "      <td>0.082844</td>\n",
       "      <td>0.103996</td>\n",
       "      <td>0.197891</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4043</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       header0   header1   header2   header3   header4   header5   header6  \\\n",
       "4039 -0.146118 -0.150491 -0.161489 -0.145119 -0.144571 -0.139811 -0.140801   \n",
       "4040  0.855510  0.854350  0.856338  0.850147  0.851591  0.854438  0.850040   \n",
       "4041  0.186981  0.186524  0.187637  0.185199  0.188515  0.183551  0.182902   \n",
       "4042  0.077426  0.079701  0.079563  0.080320  0.082692  0.082281  0.082844   \n",
       "4043  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       header7   header8   header9  ...  header20  header21  header22  \\\n",
       "4039 -0.155982 -0.166506 -0.181792  ...       NaN       NaN       NaN   \n",
       "4040  0.839254  0.842253  0.845896  ...       NaN       NaN       NaN   \n",
       "4041  0.192211  0.219140  0.220496  ...       NaN       NaN       NaN   \n",
       "4042  0.103996  0.197891  0.189500  ...       NaN       NaN       NaN   \n",
       "4043  0.000000  0.000000  0.000000  ...       NaN       NaN       NaN   \n",
       "\n",
       "      header23  header24  header25  header26  header27  header28  header29  \n",
       "4039       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "4040       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "4041       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "4042       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "4043       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originaldata.iloc[4039:4044]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0731408   0.03829234  0.0469334   0.00194419 -0.01112242 -0.02011151\n",
      "  -0.03633799 -0.03225345 -0.0420291   0.00937499]\n",
      " [-0.11749066 -0.23484093 -0.26258131 -0.25717197 -0.26656799 -0.25038209\n",
      "  -0.26268438 -0.26090061 -0.26164099 -0.21694467]\n",
      " [ 0.86082529  0.77558722  0.85436662  0.84721256  0.85877484  0.84311893\n",
      "   0.864341    0.85094293  0.84540413  0.70251442]\n",
      " [ 0.176776    0.27154119  0.30495647  0.30333233  0.30492832  0.29572228\n",
      "   0.30752579  0.3070787   0.3079597   0.27827674]\n",
      " [ 0.07638625  0.02011034 -0.00378486 -0.02415284 -0.03190367 -0.04353291\n",
      "  -0.05766036 -0.05307872 -0.05883769 -0.04239337]]\n",
      "(1, 5, 10)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_episode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3678/3011891858.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelstest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0moutputfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate_episode' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(originaldata[headers[0:30]].iloc[4039:4044])\n",
    "#print(originaldata[headers[0:30]].iloc[4039:4044].to_numpy()\n",
    "classifytest=originaldata[headers[19:29]].iloc[4038:4043].to_numpy()\n",
    "labelstest=originaldata[headers[19:29]].iloc[4043].to_numpy()\n",
    "print(classifytest)\n",
    "classifytest=np.expand_dims(classifytest, axis=0)\n",
    "print(classifytest.shape)\n",
    "print(labelstest)\n",
    "\n",
    "outputfull=evaluate_episode(gru_model3, classifytest)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "#print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "#print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "print(\"prediction from 10 timesteps\",float(outputfull),\"actual\",labelstest[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction from timestep 0 - 10  : 0.6744205951690674 actual 0.0 X\n",
      "prediction from timestep 1 - 11  : 0.7874221801757812 actual 0.0 X\n",
      "prediction from timestep 2 - 12  : 0.9713693857192993 actual 0.0 X\n",
      "prediction from timestep 3 - 13  : 0.8565201759338379 actual 0.0 X\n",
      "prediction from timestep 4 - 14  : 0.881328284740448 actual 0.0 X\n",
      "prediction from timestep 5 - 15  : 0.906579852104187 actual 0.0 X\n",
      "prediction from timestep 6 - 16  : 0.9099953770637512 actual 1.0 OK\n",
      "prediction from timestep 7 - 17  : nan actual nan OK\n",
      "prediction from timestep 8 - 18  : nan actual nan OK\n",
      "prediction from timestep 9 - 19  : nan actual nan OK\n",
      "prediction from timestep 10 - 20  : nan actual nan OK\n",
      "prediction from timestep 11 - 21  : nan actual nan OK\n",
      "prediction from timestep 12 - 22  : nan actual nan OK\n",
      "prediction from timestep 13 - 23  : nan actual nan OK\n",
      "prediction from timestep 14 - 24  : nan actual nan OK\n",
      "prediction from timestep 15 - 25  : nan actual nan OK\n",
      "prediction from timestep 16 - 26  : nan actual nan OK\n",
      "prediction from timestep 17 - 27  : nan actual nan OK\n",
      "prediction from timestep 18 - 28  : nan actual nan OK\n",
      "prediction from timestep 19 - 29  : nan actual nan OK\n",
      "okcounter 14\n"
     ]
    }
   ],
   "source": [
    "\n",
    "okcounter=0\n",
    "for i in range(20):\n",
    "    classifytest=originaldata[headers[i:10+i]].iloc[1320:1325].to_numpy()\n",
    "    labelstest=originaldata[headers[i:10+i]].iloc[1325].to_numpy()\n",
    "    #print(classifytest)\n",
    "    classifytest=np.expand_dims(classifytest, axis=0)\n",
    "    #print(classifytest.shape)\n",
    "    #print(labelstest)\n",
    "\n",
    "    outputfull=evaluate_episode(gru_model1, classifytest)\n",
    "\n",
    "    #print(\"\")\n",
    "\n",
    "    #print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "    #print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "    \n",
    "    if abs(float(outputfull)-labelstest[9])>0.3:\n",
    "        result=\"X\"\n",
    "    else:\n",
    "        result=\"OK\"\n",
    "        okcounter+=1\n",
    "    print(\"prediction from timestep\",i,\"-\",i+10,\" :\",float(outputfull),\"actual\",labelstest[9], result)\n",
    "print(\"okcounter\",okcounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header0</th>\n",
       "      <th>header1</th>\n",
       "      <th>header2</th>\n",
       "      <th>header3</th>\n",
       "      <th>header4</th>\n",
       "      <th>header5</th>\n",
       "      <th>header6</th>\n",
       "      <th>header7</th>\n",
       "      <th>header8</th>\n",
       "      <th>header9</th>\n",
       "      <th>...</th>\n",
       "      <th>header20</th>\n",
       "      <th>header21</th>\n",
       "      <th>header22</th>\n",
       "      <th>header23</th>\n",
       "      <th>header24</th>\n",
       "      <th>header25</th>\n",
       "      <th>header26</th>\n",
       "      <th>header27</th>\n",
       "      <th>header28</th>\n",
       "      <th>header29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4890</th>\n",
       "      <td>0.519653</td>\n",
       "      <td>0.629009</td>\n",
       "      <td>0.666283</td>\n",
       "      <td>0.757858</td>\n",
       "      <td>0.748447</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.751999</td>\n",
       "      <td>0.743304</td>\n",
       "      <td>0.741959</td>\n",
       "      <td>0.748569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785070</td>\n",
       "      <td>0.768524</td>\n",
       "      <td>0.756693</td>\n",
       "      <td>0.763045</td>\n",
       "      <td>0.771942</td>\n",
       "      <td>0.774374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4891</th>\n",
       "      <td>0.372140</td>\n",
       "      <td>0.333817</td>\n",
       "      <td>0.319136</td>\n",
       "      <td>0.330614</td>\n",
       "      <td>0.324397</td>\n",
       "      <td>0.318553</td>\n",
       "      <td>0.308498</td>\n",
       "      <td>0.310825</td>\n",
       "      <td>0.340429</td>\n",
       "      <td>0.380643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510981</td>\n",
       "      <td>0.545773</td>\n",
       "      <td>0.534438</td>\n",
       "      <td>0.555681</td>\n",
       "      <td>0.578675</td>\n",
       "      <td>0.561716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4892</th>\n",
       "      <td>0.932075</td>\n",
       "      <td>0.880805</td>\n",
       "      <td>0.871212</td>\n",
       "      <td>0.782250</td>\n",
       "      <td>0.917737</td>\n",
       "      <td>0.913229</td>\n",
       "      <td>0.930457</td>\n",
       "      <td>0.932578</td>\n",
       "      <td>0.922336</td>\n",
       "      <td>0.936276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951116</td>\n",
       "      <td>0.928739</td>\n",
       "      <td>0.959949</td>\n",
       "      <td>0.949016</td>\n",
       "      <td>0.937812</td>\n",
       "      <td>0.899633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>0.641091</td>\n",
       "      <td>0.669016</td>\n",
       "      <td>0.684142</td>\n",
       "      <td>0.675920</td>\n",
       "      <td>0.699291</td>\n",
       "      <td>0.686433</td>\n",
       "      <td>0.692765</td>\n",
       "      <td>0.690845</td>\n",
       "      <td>0.670727</td>\n",
       "      <td>0.643720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498684</td>\n",
       "      <td>0.474195</td>\n",
       "      <td>0.481877</td>\n",
       "      <td>0.466092</td>\n",
       "      <td>0.447252</td>\n",
       "      <td>0.446521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>0.550714</td>\n",
       "      <td>0.634439</td>\n",
       "      <td>0.686677</td>\n",
       "      <td>0.743846</td>\n",
       "      <td>0.772609</td>\n",
       "      <td>0.768783</td>\n",
       "      <td>0.769648</td>\n",
       "      <td>0.771199</td>\n",
       "      <td>0.775574</td>\n",
       "      <td>0.782100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835276</td>\n",
       "      <td>0.823710</td>\n",
       "      <td>0.817117</td>\n",
       "      <td>0.822949</td>\n",
       "      <td>0.825044</td>\n",
       "      <td>0.824857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       header0   header1   header2   header3   header4   header5   header6  \\\n",
       "4890  0.519653  0.629009  0.666283  0.757858  0.748447  0.748698  0.751999   \n",
       "4891  0.372140  0.333817  0.319136  0.330614  0.324397  0.318553  0.308498   \n",
       "4892  0.932075  0.880805  0.871212  0.782250  0.917737  0.913229  0.930457   \n",
       "4893  0.641091  0.669016  0.684142  0.675920  0.699291  0.686433  0.692765   \n",
       "4894  0.550714  0.634439  0.686677  0.743846  0.772609  0.768783  0.769648   \n",
       "4895  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       header7   header8   header9  ...  header20  header21  header22  \\\n",
       "4890  0.743304  0.741959  0.748569  ...  0.785070  0.768524  0.756693   \n",
       "4891  0.310825  0.340429  0.380643  ...  0.510981  0.545773  0.534438   \n",
       "4892  0.932578  0.922336  0.936276  ...  0.951116  0.928739  0.959949   \n",
       "4893  0.690845  0.670727  0.643720  ...  0.498684  0.474195  0.481877   \n",
       "4894  0.771199  0.775574  0.782100  ...  0.835276  0.823710  0.817117   \n",
       "4895  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "      header23  header24  header25  header26  header27  header28  header29  \n",
       "4890  0.763045  0.771942  0.774374       NaN       NaN       NaN       NaN  \n",
       "4891  0.555681  0.578675  0.561716       NaN       NaN       NaN       NaN  \n",
       "4892  0.949016  0.937812  0.899633       NaN       NaN       NaN       NaN  \n",
       "4893  0.466092  0.447252  0.446521       NaN       NaN       NaN       NaN  \n",
       "4894  0.822949  0.825044  0.824857       NaN       NaN       NaN       NaN  \n",
       "4895  0.000000  0.000000  1.000000       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[6 rows x 30 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originaldata.iloc[4890:4896]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction from timestep 0 - 10  : 0.6850756406784058 actual 0.0 X\n",
      "prediction from timestep 1 - 11  : 0.7771387100219727 actual 0.0 X\n",
      "prediction from timestep 2 - 12  : 0.8105878829956055 actual 0.0 X\n",
      "prediction from timestep 3 - 13  : 0.6370461583137512 actual 0.0 X\n",
      "prediction from timestep 4 - 14  : 0.9027876257896423 actual 0.0 X\n",
      "prediction from timestep 5 - 15  : 0.9541449546813965 actual 0.0 X\n",
      "prediction from timestep 6 - 16  : 0.6878060698509216 actual 0.0 X\n",
      "prediction from timestep 7 - 17  : 0.6639975309371948 actual 0.0 X\n",
      "prediction from timestep 8 - 18  : 0.652870774269104 actual 0.0 X\n",
      "prediction from timestep 9 - 19  : 0.7242254614830017 actual 0.0 X\n",
      "prediction from timestep 10 - 20  : 0.7337037324905396 actual 0.0 X\n",
      "prediction from timestep 11 - 21  : 0.874970555305481 actual 1.0 OK\n",
      "prediction from timestep 12 - 22  : nan actual nan OK\n",
      "prediction from timestep 13 - 23  : nan actual nan OK\n",
      "prediction from timestep 14 - 24  : nan actual nan OK\n",
      "prediction from timestep 15 - 25  : nan actual nan OK\n",
      "prediction from timestep 16 - 26  : nan actual nan OK\n",
      "prediction from timestep 17 - 27  : nan actual nan OK\n",
      "prediction from timestep 18 - 28  : nan actual nan OK\n",
      "prediction from timestep 19 - 29  : nan actual nan OK\n",
      "okcounter 9\n"
     ]
    }
   ],
   "source": [
    "okcounter=0\n",
    "for i in range(20):\n",
    "    classifytest=originaldata[headers[i:10+i]].iloc[1386:1391].to_numpy()\n",
    "    labelstest=originaldata[headers[i:10+i]].iloc[1391].to_numpy()\n",
    "    #print(classifytest)\n",
    "    classifytest=np.expand_dims(classifytest, axis=0)\n",
    "    #print(classifytest.shape)\n",
    "    #print(labelstest)\n",
    "\n",
    "    outputfull=evaluate_episode(gru_model1, classifytest)\n",
    "\n",
    "    #print(\"\")\n",
    "\n",
    "    #print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "    #print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "    \n",
    "    if abs(float(outputfull)-labelstest[9])>0.3:\n",
    "        result=\"X\"\n",
    "    else:\n",
    "        result=\"OK\"\n",
    "        okcounter+=1\n",
    "    print(\"prediction from timestep\",i,\"-\",i+10,\" :\",float(outputfull),\"actual\",labelstest[9], result)\n",
    "print(\"okcounter\",okcounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction from timestep 0 - 10  : 0.040196746587753296 actual 0.0 OK\n",
      "prediction from timestep 1 - 11  : 0.08223167061805725 actual 0.0 OK\n",
      "prediction from timestep 2 - 12  : 0.4337526857852936 actual 0.0 X\n",
      "prediction from timestep 3 - 13  : -0.08302059769630432 actual 0.0 OK\n",
      "prediction from timestep 4 - 14  : 0.3114229738712311 actual 0.0 X\n",
      "prediction from timestep 5 - 15  : 0.5656418204307556 actual 0.0 X\n",
      "prediction from timestep 6 - 16  : 0.6966806650161743 actual 0.0 X\n",
      "prediction from timestep 7 - 17  : 0.7677610516548157 actual 0.0 X\n",
      "prediction from timestep 8 - 18  : 0.7471033334732056 actual 0.0 X\n",
      "prediction from timestep 9 - 19  : 0.8336632251739502 actual 1.0 OK\n",
      "prediction from timestep 10 - 20  : nan actual nan OK\n",
      "prediction from timestep 11 - 21  : nan actual nan OK\n",
      "prediction from timestep 12 - 22  : nan actual nan OK\n",
      "prediction from timestep 13 - 23  : nan actual nan OK\n",
      "prediction from timestep 14 - 24  : nan actual nan OK\n",
      "prediction from timestep 15 - 25  : nan actual nan OK\n",
      "prediction from timestep 16 - 26  : nan actual nan OK\n",
      "prediction from timestep 17 - 27  : nan actual nan OK\n",
      "prediction from timestep 18 - 28  : nan actual nan OK\n",
      "prediction from timestep 19 - 29  : nan actual nan OK\n",
      "okcounter 14\n"
     ]
    }
   ],
   "source": [
    "okcounter=0\n",
    "for i in range(20):\n",
    "    classifytest=originaldata[headers[i:10+i]].iloc[1506:1511].to_numpy()\n",
    "    labelstest=originaldata[headers[i:10+i]].iloc[1511].to_numpy()\n",
    "    #print(classifytest)\n",
    "    classifytest=np.expand_dims(classifytest, axis=0)\n",
    "    #print(classifytest.shape)\n",
    "    #print(labelstest)\n",
    "\n",
    "    outputfull=evaluate_episode(gru_model1, classifytest)\n",
    "\n",
    "    #print(\"\")\n",
    "\n",
    "    #print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "    #print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "    \n",
    "    if abs(float(outputfull)-labelstest[9])>0.3:\n",
    "        result=\"X\"\n",
    "    else:\n",
    "        result=\"OK\"\n",
    "        okcounter+=1\n",
    "    print(\"prediction from timestep\",i,\"-\",i+10,\" :\",float(outputfull),\"actual\",labelstest[9], result)\n",
    "print(\"okcounter\",okcounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_episode(model, data, verbose=False):\n",
    "\n",
    "   \n",
    "    model.eval()\n",
    "    inp = torch.from_numpy(np.array(data)) # should be 5x1\n",
    "    h = model.init_hidden(inp.shape[0])\n",
    "    #print(\"inp\",inp)\n",
    "    #print(\"labs\",labs)\n",
    "    #print(\"h\",h)\n",
    "    out, h = model(inp.to(device).float(), h)\n",
    "    #print(\"model output\",out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8454625996709277"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(278+13082)/(278+13082+2410+32)  #evaluation on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15802"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(278+13082+2410+32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate2(model, test_x, test_y):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []  #labels\n",
    "    #start_time = time.clock()\n",
    "    #for i in test_x.keys():\n",
    "    #for i in range( len( test_x ) ):    \n",
    "    inp = torch.from_numpy(np.array(test_x)) # should be 5x1\n",
    "    labs = torch.from_numpy(np.array(test_y)) #should be 1x1\n",
    "    h = model.init_hidden(inp.shape[0])\n",
    "    #print(\"inp\",inp)\n",
    "    #print(\"labs\",labs)\n",
    "    #print(\"h\",h)\n",
    "    out, h = model(inp.to(device).float(), h)\n",
    "    #outputs.append(label_scalers[i].inverse_transform(out.cpu().detach().numpy()).reshape(-1))\n",
    "    #targets.append(label_scalers[i].inverse_transform(labs.numpy()).reshape(-1))\n",
    "    outputs.append( out.cpu().detach().numpy().reshape(-1) )\n",
    "    targets.append( labs.numpy().reshape(-1) )\n",
    "\n",
    "    #print(\"Evaluation Time: {}\".format(str(time.clock()-start_time)))\n",
    "    sMAPE = 0\n",
    "    #for i in range(len(outputs)):\n",
    "    #    sMAPE += np.mean(abs(outputs[i]-targets[i])/(targets[i]+outputs[i])/2)/len(outputs)\n",
    "    #print(\"sMAPE: {}%\".format(sMAPE*100))\n",
    "    return outputs, targets#, sMAPE       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluatedataset(model,dataset,cutofflist=[0.2,0.3,0.4,0.5,0.6,0.7,0.75,0.8,0.9,1.0]):\n",
    "    headers=[]\n",
    "    counter_truepositive=[0] * len(cutofflist)\n",
    "    counter_falsenegative=[0] * len(cutofflist)\n",
    "    counter_truenegative=[0] * len(cutofflist)\n",
    "    counter_falsepositive=[0] * len(cutofflist)\n",
    "    \n",
    "    for i in range(30):  \n",
    "        label=str(i)\n",
    "        headers.append(\"header\"+label)\n",
    "\n",
    "    choppedheaders=[]\n",
    "    GRUoutputlist=[]\n",
    "    lookback=10 #save only the last 11 timesteps\n",
    "    for i in range(10):  \n",
    "        label=str(i)\n",
    "        choppedheaders.append(\"header\"+label)\n",
    "    #print(\"headers\",headers)    #header0 to header29\n",
    "    #print(\"choppedheaders\",choppedheaders)\n",
    "    for i in range(0,int((dataset.shape[0])-1),6):\n",
    "    #for i in range(0,12,6):    \n",
    "        #print(\"\")\n",
    "       \n",
    "        for h in range(10,len(headers)+1):\n",
    "            successflag=False\n",
    "            #print(headers[h-10:h])\n",
    "            if dataset[headers[h-1]].iloc[i+5]==0 or dataset[headers[h-1]].iloc[i+5]==1: #if label is 0 or 1  (ignores n/a values)\n",
    "\n",
    "                classifytest=dataset[headers[h-10:h]].iloc[i:i+5].to_numpy()\n",
    "                \n",
    "                labelstest=dataset[headers[h-1]].iloc[i+5]\n",
    "                \"\"\"\n",
    "                try:\n",
    "                    labelstest=dataset[headers[h-1]].iloc[i+5]\n",
    "                except IndexError:\n",
    "                    print(\"IndexError. headers[h-1]:\",headers[h-1],\"i+5:\",i+5, \"h=\",h, \"i=\",i)\n",
    "                    print(\"classifytest\",classifytest)\n",
    "                    print(\"labelstest\",labelstest)\n",
    "                \"\"\"  \n",
    "                    \n",
    "                #print(classifytest)\n",
    "                #print(labelstest)\n",
    "               \n",
    "                #print(classifytest)\n",
    "                classifytest=np.expand_dims(classifytest, axis=0)\n",
    "                #print(classifytest.shape)\n",
    "                #print(labelstest)\n",
    "\n",
    "                outputfull=evaluate2(gru_model3, classifytest,labelstest)\n",
    "                GRUoutputlist.append(outputfull[0][0])\n",
    "                #print(\"GRU output\",float(outputfull[0]))\n",
    "                #print(\"GRU output\",outputfull[0][0])\n",
    "\n",
    "                cutoff=0.5\n",
    "                for k in range(len(cutofflist)):\n",
    "                    if labelstest==1  and outputfull[0][0]>= cutofflist[k]:\n",
    "                        counter_truepositive[k]+=1\n",
    "                    elif labelstest==1  and outputfull[0][0]< cutofflist[k]:\n",
    "                        counter_falsenegative[k]+=1\n",
    "                    elif labelstest==0 and outputfull[0][0]<= cutofflist[k]:\n",
    "                        counter_truenegative[k]+=1\n",
    "                    elif labelstest==0 and outputfull[0][0]> cutofflist[k]:\n",
    "                        counter_falsepositive[k]+=1\n",
    "       \n",
    "    for k in range(len(cutofflist)):\n",
    "        totalevalqty=counter_truepositive[k]+counter_falsenegative[k]+counter_truenegative[k]+counter_falsepositive[k]\n",
    "        print(\"At cuttoff of\",cutofflist[k],\" truepositive\",counter_truepositive[k],\"truenegative\",counter_truenegative[k],\"falsepositive\",counter_falsepositive[k],\"falsenegative\",counter_falsenegative[k],\n",
    "             \"Accuracy\",100*(counter_truepositive[k]+counter_truenegative[k])/totalevalqty,\"%\")\n",
    "   \n",
    "    GRUoutputlist.sort()\n",
    "    plt.plot(GRUoutputlist)\n",
    "    plt.show()\n",
    "         \n",
    "\n",
    "def evaluatedatasetlookahead(model,dataset,cutofflist=[0.2,0.3,0.4,0.5,0.6,0.7,0.75,0.8,0.9,1.0]):\n",
    "    headers=[]\n",
    "    counter_truepositive=[0] * len(cutofflist)\n",
    "    counter_falsenegative=[0] * len(cutofflist)\n",
    "    counter_truenegative=[0] * len(cutofflist)\n",
    "    counter_falsepositive=[0] * len(cutofflist)\n",
    "    \n",
    "    for i in range(30):  \n",
    "        label=str(i)\n",
    "        headers.append(\"header\"+label)\n",
    "\n",
    "    choppedheaders=[]\n",
    "    GRUoutputlist=[]\n",
    "    lookback=10 #save only the last 11 timesteps\n",
    "    for i in range(10):  \n",
    "        label=str(i)\n",
    "        choppedheaders.append(\"header\"+label)\n",
    "    #print(\"headers\",headers)    #header0 to header29\n",
    "    #print(\"choppedheaders\",choppedheaders)\n",
    "    for i in range(0,int((dataset.shape[0])-1),6):\n",
    "    #for i in range(0,12,6):    \n",
    "        #print(\"\")\n",
    "       \n",
    "        for h in range(10,len(headers)+1):\n",
    "            successflag=False\n",
    "            #print(headers[h-10:h])\n",
    "            if dataset[headers[h-1]].iloc[i+5]==0 or dataset[headers[h-1]].iloc[i+5]==1: #if label is 0 or 1  (ignores n/a values)\n",
    "\n",
    "                classifytest=dataset[headers[h-10:h-1]].iloc[i:i+5].to_numpy()\n",
    "                labelstest=dataset[headers[h-1]].iloc[i+5]\n",
    "                #print(classifytest)\n",
    "                #print(labelstest)\n",
    "               \n",
    "                #print(classifytest)\n",
    "                classifytest=np.expand_dims(classifytest, axis=0)\n",
    "                #print(classifytest.shape)\n",
    "                #print(labelstest)\n",
    "\n",
    "                outputfull=evaluate2(gru_model3, classifytest,labelstest)\n",
    "                GRUoutputlist.append(outputfull[0][0])\n",
    "                #print(\"GRU output\",float(outputfull[0]))\n",
    "                #print(\"GRU output\",outputfull[0][0])\n",
    "\n",
    "               \n",
    "                for k in range(len(cutofflist)):\n",
    "                    if labelstest==1  and outputfull[0][0]>= cutofflist[k]:\n",
    "                        counter_truepositive[k]+=1\n",
    "                    elif labelstest==1  and outputfull[0][0]< cutofflist[k]:\n",
    "                        counter_falsenegative[k]+=1\n",
    "                    elif labelstest==0 and outputfull[0][0]<= cutofflist[k]:\n",
    "                        counter_truenegative[k]+=1\n",
    "                    elif labelstest==0 and outputfull[0][0]> cutofflist[k]:\n",
    "                        counter_falsepositive[k]+=1\n",
    "       \n",
    "    for k in range(len(cutofflist)):\n",
    "        totalevalqty=counter_truepositive[k]+counter_falsenegative[k]+counter_truenegative[k]+counter_falsepositive[k]\n",
    "        print(\"At cuttoff of\",cutofflist[k],\" truepositive\",counter_truepositive[k],\"truenegative\",counter_truenegative[k],\"falsepositive\",counter_falsepositive[k],\"falsenegative\",counter_falsenegative[k],\n",
    "             \"Accuracy\",100*(counter_truepositive[k]+counter_truenegative[k])/totalevalqty,\"%\")\n",
    "   \n",
    "\n",
    "    #GRUoutputlist.sort()\n",
    "    #GRUoutputlist.sort()\n",
    "    plt.plot(sorted(GRUoutputlist))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n",
      "loaded\n",
      "loaded\n",
      "loaded\n",
      "loaded\n"
     ]
    }
   ],
   "source": [
    "gru_model1=torch.load('currentmodel_3datasets_1steplookhead_model1_10_24_2021.pt',map_location=torch.device('cpu'))\n",
    "gru_model1.eval()\n",
    "print(\"loaded\")\n",
    "gru_model2=torch.load('currentmodel_3datasets_1steplookhead_model2_10_24_2021.pt',map_location=torch.device('cpu'))\n",
    "gru_model2.eval()\n",
    "print(\"loaded\")\n",
    "gru_model3=torch.load('currentmodel_3datasets_1steplookhead_model3_10_24_2021.pt',map_location=torch.device('cpu'))\n",
    "gru_model3.eval()\n",
    "print(\"loaded\")\n",
    "gru_model4=torch.load('currentmodel_3datasets_1steplookhead_model4_10_24_2021.pt',map_location=torch.device('cpu'))\n",
    "gru_model4.eval()\n",
    "print(\"loaded\")\n",
    "gru_model_old=torch.load('currentmodel_9steplookhead10_23_2021.pt',map_location=torch.device('cpu'))\n",
    "gru_model_old.eval()\n",
    "print(\"loaded\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test sets-model1\n",
      "At cuttoff of 0.2  truepositive 25 truenegative 7578 falsepositive 2218 falsenegative 1 Accuracy 77.40785990633272 %\n",
      "At cuttoff of 0.3  truepositive 24 truenegative 8190 falsepositive 1606 falsenegative 2 Accuracy 83.62858888210141 %\n",
      "At cuttoff of 0.4  truepositive 24 truenegative 8611 falsepositive 1185 falsenegative 2 Accuracy 87.91488495214824 %\n",
      "At cuttoff of 0.5  truepositive 21 truenegative 8940 falsepositive 856 falsenegative 5 Accuracy 91.23396456933415 %\n",
      "At cuttoff of 0.6  truepositive 20 truenegative 9181 falsepositive 615 falsenegative 6 Accuracy 93.67745876603543 %\n",
      "At cuttoff of 0.7  truepositive 19 truenegative 9393 falsepositive 403 falsenegative 7 Accuracy 95.82569741396864 %\n",
      "At cuttoff of 0.75  truepositive 17 truenegative 9486 falsepositive 310 falsenegative 9 Accuracy 96.7521889635512 %\n",
      "At cuttoff of 0.8  truepositive 16 truenegative 9551 falsepositive 245 falsenegative 10 Accuracy 97.40378741600489 %\n",
      "At cuttoff of 0.9  truepositive 14 truenegative 9652 falsepositive 144 falsenegative 12 Accuracy 98.41172877214417 %\n",
      "At cuttoff of 1.0  truepositive 5 truenegative 9738 falsepositive 58 falsenegative 21 Accuracy 99.1956831602525 %\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD4CAYAAAD2FnFTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAj30lEQVR4nO3deXwc9X3/8dfHuu/TluXbxgaMMRgQxgTCaY7QFNOGw4EGEyDk0YakTfprC83vl4P01wehbUj4lTS4QAJJuAnEoQlgjpxgsIyNL3wI28KSbUnWad3X5/fHjswiJFu21tqV9v18PPahme/M7H5mx573znxnd8zdERER6W9ctAsQEZHYpIAQEZEBKSBERGRACggRERmQAkJERAaUGO0CjkZhYaHPmDEj2mWIiIwqa9as2e/u44c6/6gMiBkzZlBaWhrtMkRERhUzKz+S+XWKSUREBqSAEBGRASkgRERkQAoIEREZkAJCREQGFJGAMLOHzazazDYOMv0GM1tvZhvM7A0zOzVs2q6gfZ2Z6dIkEZEYEakjiJ8Alx9i+k7gfHefD3wHWN5v+oXuvsDdSyJUj4iIDFNEAsLdfw/UHWL6G+5eH4yuAqZE4nVFROLFln1NfO/lrexv7hix14xGH8QtwG/Cxh142czWmNltgy1kZreZWamZldbU1BzzIkVEYsnWfQe477UyGtu6Ruw1R/Sb1GZ2IaGAODes+Vx3rzSzCcBKM9sSHJF8hLsvJzg1VVJSorsciUhc6ezuBSA5YeQ+14/YK5nZKcCDwBJ3r+1rd/fK4G818BywcKRqEhEZLbp7Q5+LExNsxF5zRALCzKYBvwA+5+7bwtozzCyrbxi4FBjwSigRkXjW3RM6gkgcN3JHEBE5xWRmjwMXAIVmVgF8E0gCcPcfAd8ACoAfmhlAd3DFUhHwXNCWCDzm7i9GoiYRkbGksyd0BJE0gkcQEQkId//sYabfCtw6QPsO4NSPLyEiIuHaOrsBSEtOGLHX1DepRURGgZbOHpISjJREBYSIiIRp6egmI2Vkb+GjgBARGQWaO7rJSFZAiIhIPy0d3WTqCEJERPpr6eghI2Xk+h9AASEiMio0qw9CREQGUtXUrj4IERH5uOaObnp9ZH+GTgEhIhLj3J3Wzh6Om5A5oq+rgBARiXHNHd309Dr56ckj+roKCBGRGNfQGroHRE560oi+rgJCRCTG1bZ0AlCYqSMIEREJU3MgdJvR8ZmpI/q6CggRkRh3MCCyUkb0dRUQIiIxri8gCnSKSUREwtU0t5OXnkTSCN6PGhQQIiIxr+ZAx4ifXgIFhIhIzBvVAWFmD5tZtZltHGS6mdl9ZlZmZuvN7PSwacvMbHvwWBaJekRExpKa5g7GZ47SgAB+Alx+iOmfAuYEj9uA/wIws3zgm8BZwELgm2aWF6GaRERGva6eXvY2tFOUPbKXuEKEAsLdfw/UHWKWJcCjHrIKyDWzYuAyYKW717l7PbCSQweNiEhcWbWjlu5eZ/6UnBF/7ZHqg5gM7A4brwjaBmv/GDO7zcxKzay0pqbmmBUqIhJL3ilvwAzOP378iL/2qOmkdvfl7l7i7iXjx4/8GyUiEg2b9jQyszCDrNSR/R0mGLmAqASmho1PCdoGaxcRiXu9vU5peT0LpuRG5fVHKiBWADcGVzMtAhrdfS/wEnCpmeUFndOXBm0iInFv054m6lo6OS8Kp5cAInL/OjN7HLgAKDSzCkJXJiUBuPuPgF8DVwBlQCvw+WBanZl9B1gdPNVd7n6ozm4RkbixcvM+zOCc2YVRef2IBIS7f/Yw0x340iDTHgYejkQdIiJjydNrKjhvzviofEkORlEntYhIPKluamdvY3tUrl7qo4AQEYlBGyobATixOCtqNSggRERi0JOrd5OfkcyCqblRq0EBISISY5rau3jlvSquOWMK6ckR6So+KgoIEZEYs2ZXPb1O1C5v7aOAEBGJMX/Yvp/kxHGcMT26v12qgBARiTF/LKth4Yx8UpMSolqHAkJEJIbUHOhgW1Vz1L4cF04BISISQ9aUh35MYuHM/ChXooAQEYkppbvqSUkcx/zJI3//h/4UECIiMeS322o4dUouyYnR3z1HvwIREQFgd10rZdXNXDx3QrRLARQQIiIx4ydv7CIpwfj0qZOiXQqggBARiQm9vc5vNuzl/OPHMzk3LdrlAAoIEZGYsGpHLXsa2/nzGDl6AAWEiEhMeHpNBVmpiVw2b2K0SzlIASEiEmV7Gtp4Yf0e/uK0yVH/9nS4iASEmV1uZlvNrMzM7hhg+r1mti54bDOzhrBpPWHTVkSiHhGR0eRnq8rp6nFuPmdmtEv5iGH/jqyZJQD3A5cAFcBqM1vh7pv75nH3r4bN/2XgtLCnaHP3BcOtQ0RkNGrv6uGxtz/g4hMnMKMwI9rlfEQkjiAWAmXuvsPdO4EngCWHmP+zwOMReF0RkVFvfUUjDa1dXFMyNdqlfEwkAmIysDtsvCJo+xgzmw7MBF4La041s1IzW2VmVw32ImZ2WzBfaU1NTQTKFhGJvsff/oDkhHF8YnZBtEv5mJHupF4KPOPuPWFt0929BLge+L6ZHTfQgu6+3N1L3L1k/Pjo3kRDRCQSyqqbeW5tJTefO5Ps1KRol/MxkQiISiD82GhK0DaQpfQ7veTulcHfHcBv+Wj/hIjImHX/62UkJRi3nBtbndN9IhEQq4E5ZjbTzJIJhcDHrkYysxOBPODNsLY8M0sJhguBc4DN/ZcVERlr3vmgnufWVrLs7BmMz0qJdjkDGvZVTO7ebWa3Ay8BCcDD7r7JzO4CSt29LyyWAk+4u4ctPhd4wMx6CYXV3eFXP4mIjEU9vc63VmyiMDOFv108J9rlDGrYAQHg7r8Gft2v7Rv9xr81wHJvAPMjUYOIyGjxs1XlrK9o5AdLF5AVg30PffRNahGREdTR3cO/v7yVc2cXcmUM/e7SQBQQIiIj6MWN+zjQ3s2tn5yJmUW7nENSQIiIjKBH3tjFzMIMzpsT+5frKyBEREbIS5v28c4HDdz0iRmMGxfbRw+ggBARGRGrd9Xx5cfWMm9SNksXxt7PagxEASEicoxVNbXzhUdLmZiTyk9vOYuUxNj5Se9DichlriIiMrj//fxG2rt6ePqLZ5OfkRztcoZMRxAiIsfQ77bVsHJzFV+6YDZzirKiXc4RUUCIiBwju+ta+crjazmhKIsvnDcr2uUcMQWEiMgx8s/PbaCn11l+4xkxdSvRoVJAiIgcA7/bVsMftu/nKxfPZnpBbN0pbqgUECIiEdbY2sU/PvMus8ZncOPZM6JdzlFTQIiIRNi9r2yj5kAH9y09bVSeWuqjgBARiaA336/l52+Vc+Wpkzh5ck60yxkWBYSISIQ0tXfxlSfWMjUvnW9feXK0yxk2fVFORCQCunp6uePZ9dQ2d/DwsjPJSY/d+zwMlQJCRGSYunt6+dLP3+HlzVX88xUnMn/K6D611EcBISIyTPe9VsbLm6v4xqdP4uZzZ0a7nIiJSB+EmV1uZlvNrMzM7hhg+k1mVmNm64LHrWHTlpnZ9uCxLBL1iIiMlC37mvjh62VctWDSmAoHiMARhJklAPcDlwAVwGozW+Hum/vN+qS7395v2Xzgm0AJ4MCaYNn64dYlInKstXf18PdPvUtmaiLf/PN50S4n4iJxBLEQKHP3He7eCTwBLBnispcBK929LgiFlcDlEahJROSYe+B3O9i0p4nvLDmZvFH0K61DFYmAmAzsDhuvCNr6+4yZrTezZ8ys724ZQ10WM7vNzErNrLSmpiYCZYuIHL3Xt1Rz7yvbuGL+RD59SnG0yzkmRup7EL8CZrj7KYSOEh450idw9+XuXuLuJePHx/69XEVk7Nrb2MbXnlrH3OJsvnftAsxi//ahRyMSAVEJhN8/b0rQdpC717p7RzD6IHDGUJcVEYklbZ09fP7Hq+no7uX+60f3T2kcTiQCYjUwx8xmmlkysBRYET6DmYUff10JvBcMvwRcamZ5ZpYHXBq0iYjEnN5e545frGfLvgN8/7oFzBqfGe2SjqlhX8Xk7t1mdjuhHXsC8LC7bzKzu4BSd18BfMXMrgS6gTrgpmDZOjP7DqGQAbjL3euGW5OIyLFw7yvb+OW6PfzDZSdw6byJ0S7nmDN3j3YNR6ykpMRLS0ujXYaIxIneXue+17bz/Ve2c80ZU7jn6lNGZb+Dma1x95Khzq9vUouIHEJHdw//5/mNPFVawZ/NL+Zf/3L+qAyHo6GAEBEZRF1LJ19+/B3+VFbLVy6azVcvOT5uwgEUECIiA6pr6eSaH73BrtpW7rn6FK4tmXr4hcYYBYSISD/bqw7wt0+sY3d9Gw8tK+GCEyZEu6SoUECIiIR5d3cDN/34bcyM/7rh9LgNB1BAiIgctLuulS/+dA0J44xn//oTTC/IiHZJUaVbjoqIEAqHpctX0drZzY9vWhj34QA6ghARYdOeRm75SSltXT089oVFnDx5bNwRbrh0BCEice3J1R/wlz98A4AnblM4hNMRhIjEpd5e519//R4P/nEn584u5N7rFjA+KyXaZcUUBYSIxJ3qA+3c+ewGXt1SzecWTed/f3ouKYlj91dZj5YCQkTihrvzq/V7ufPZ9XT29PLtK+dx49nT4+rb0UdCASEicaGzu5evP7eBp9dUcMqUHP7jmlOZU5QV7bJimgJCRMa8ivpW/v6pd3lrZx1fvmg2f7f4eBLG6ajhcBQQIjJm9fY6D/1xJ99buQ3Hueczp3DtmfH3m0pHSwEhImNSWXUzf//0u7y7u4HFcyfwrSvnMSUvPdpljSoKCBEZc954fz+3P7YWd+eeq0/hmjOmqCP6KEQkIMzscuAHhG45+qC7391v+teAWwndcrQGuNndy4NpPcCGYNYP3P3KSNQkIvFnTXk9D/9xJ/+zYS/T8tP57xtLOGGiOqKP1rADwswSgPuBS4AKYLWZrXD3zWGzrQVK3L3VzP4auAe4LpjW5u4LhluHiMSvrp5e7v7NFh76406yUhL50oXHcfuFc0hL1ncbhiMSRxALgTJ33wFgZk8AS4CDAeHur4fNvwr4qwi8rojEOXfnxY37+I+V2yirbua6kql888qTSE/W2fNIiMS7OBnYHTZeAZx1iPlvAX4TNp5qZqWETj/d7e7PD7SQmd0G3AYwbdq04dQrIqNcb6/z8uZ9/PcfdrKmvJ5Z4zN48MYSFp9UFO3SxpQRjVkz+yugBDg/rHm6u1ea2SzgNTPb4O7v91/W3ZcDywFKSkp8RAoWkZjS1dPL82sreeD3OyirbqY4J5W7/3I+15RM1fcajoFIBEQlEH5h8ZSg7SPMbDHwdeB8d+/oa3f3yuDvDjP7LXAa8LGAEJH4tmpHLf/07HrKa1s5cWIW/++zp3HF/GIFwzEUiYBYDcwxs5mEgmEpcH34DGZ2GvAAcLm7V4e15wGt7t5hZoXAOYQ6sEVEcHfWlNez/Pc7eHlz1cErkxbPnaDLVkfAsAPC3bvN7HbgJUKXuT7s7pvM7C6g1N1XAP8GZAJPBxu173LWucADZtZL6N4Ud/e7+klE4lB7Vw8r1u3h529/wLu7G8hNT+IrF83mi+cfR0aKOqBHirmPvtP5JSUlXlpaGu0yRCTC2rt6eG5tJT/63fuU17Yye0ImN549nc+cPkXBEAFmtsbdS4Y6v95xEYmq9q4e3t3dwK/W72HFuj00tXdz8uRsHlpWwkUn6lRSNCkgRGTEdXb38rttNTy3toJX3qums7uXlMRxfOrkiVx75lTOnlWgYIgBCggRGRHuzjsf1PPC+r08v7aS+tYuCjKSuX7hND5xXAGLjisgOzUp2mVKGAWEiBxTLR3dPLe2kkff3MW2qmaSEozL5k3kM6dP4dw5hSQljIt2iTIIBYSIRFxlQxt/2r6fP5Tt57X3qmjp7GFucTb3XH0Ki+cWkZ+RHO0SZQgUECISEe/tbeKF9Xt4ceM+3q9pAWB8VgpXzC/mujOncsb0PPUrjDIKCBE5Kh3dPayvaOTN92t5fl0lO2paGGdw9nEFXH/WdD45p5A5EzIVCqOYAkJEhsTd2Vp1gNe2VPP7bTWs/aCBju5eAM6Ynsd3rprJFSdPpCAzJcqVSqQoIERkUJUNbby2pZrVO+t454N6KurbADipOJsbzprOwpn5LJqVT266+hTGIgWEiBxU1dTOys1VvFNez9u76g4GwsTsVOZPyeFvLpjNxXMnUJSdGuVKZSQoIETikLtT2dDGxspGtuw7wKY9Tby3t+lgIBRmpnDmjDxuPmcmn5xTyGz1JcQlBYTIGOfuVDV18N6+UAhs2XuA9RUN7KptBcAMZhRkcNq0PD63aDoXnjhBncsCKCBExpTunl527m9h054mNu358OigrqXz4DyTc9OYW5zNTZ+YwalTczlxYrbu3SwDUkCIjELuTm1LJ2XVzWzdd4At+w6wJThCaO8KXVmUnDiO44syWTx3AvMm5TC3OJsTJmaRk6afs5ChUUCIxKj2rh72NLSxp6GdyoZWPqhrpby2lV21LZTvb+VAR/fBeXPSkjhhYhY3nDWdeZOymVuczewJmfoZCxkWBYRIFPT0OtUH2g8GwL7GdvY1hcYrG9rY09DG/ubOjyyTMM6YkpfG9IIMzpiWx/SCDI6bkMkJRVkUZaeoz0AiTgEhEkHuTlN7N7XNHexraqfmQAdVTe3sa+xgX1MbexvbqWpsp/pAB929H71ZV3pyApNy05iUm8a8SdlMDoYn5aYxOTeNiTmpOiKQEaWAEDmErp5e6ls6qWvtpK65k9qWTupbO6lt7qQurL2+NZjW0vmxHT9AWlICxbmpFOeksui4AiZmpx7c8U/KTWNidirZaYk6CpCYEpGAMLPLgR8Quif1g+5+d7/pKcCjwBlALXCdu+8Kpt0J3AL0AF9x95ciUZNIf+5OS2cP9S2hnXldSwd1LV39/nYefNS2dHKgvXvQ58tJS6IgI5n8jGSm5qezYGoueRnJB9smZqcyITuVCdkpus+BjErDDggzSwDuBy4BKoDVZrbC3TeHzXYLUO/us81sKfBd4DozOwlYCswDJgGvmNnx7t4z3Lpk7OvpdRpaP9yZ1/f7Wxf2ab/vE35n8NtB/SUlGPkZyeRnpFCQkczkvHQKMpLJS08mPzOZ/PTQTr8gM9SWl55Eok73yBgXiSOIhUCZu+8AMLMngCVAeEAsAb4VDD8D/KeFjqWXAE+4ewew08zKgud7MwJ1ySjS1dNLY1sXDa1dNLZ10tAaGq5v/XBHH/7pvq6lk4a2LvzjZ3MAyEpNDHb4yRTnpDJvUvZHdvR9j4KMFPIykshM0ekdkf4iERCTgd1h4xXAWYPN4+7dZtYIFATtq/otO3mgFzGz24DbAKZNmxaBsuVY6O11GttCO/b61k7qW7qoa+2ksbWLhr4df1vXwfH6li4a27po7hj8VE7iOCMv48Od+4kTs8nPSP7I6ZzwR156MsmJ+nQvMlyjppPa3ZcDywFKSkoG+dwokdR3zn7/gQ72N4ceNc2d1BzooKG1k6a2Lprau2lo7Tz4af9Qn+oTxxm56UlkpyWRm5bEhKxUjp+QRU56ErlpyeSmJ5GbnkROWhK56cnkpiWRn5lMlj7di0RFJAKiEpgaNj4laBtongozSwRyCHVWD2VZibC+b+H2XYNfcyB0OWZNc+eHQRCEQt+3csOZhTpoc9KSyE5NIjstkeLcNPLSk8hPTyY3+KSfm5508BN9TnqSdvQio0wkAmI1MMfMZhLauS8Fru83zwpgGaG+hauB19zdzWwF8JiZfY9QJ/Uc4O0I1BTX2rt62Nv40S9d9YVBX1tHv85aMyjISKYwM4XxWSnMKMigMDM03tdWmJlCYVboVI86aEXGvmEHRNCncDvwEqHLXB92901mdhdQ6u4rgIeAnwad0HWEQoRgvqcIdWh3A1/SFUyH1vdFrL2NbextaGdPYxu769rYXd9KRX0blfVt7G/u+NhyE7JSmJSbxtxJ2Sw+qYhJOakHv4Q1ITuFgowUEsbp072IfMh8sBPGMaykpMRLS0ujXcYx19TexfaqA2yrCv0g2/bqA2zd1/yxAEhKMCbnpjE1P/3gF6/C/xblpJCSqF/rFIl3ZrbG3UuGOv+o6aQey9ydXbWtbNrTyPqK0E80b686wN7G9oPzpCcnMGdCJhecMJ7jizKZlJtGcU4qxTlpFGWn6tO/iEScAiIKenud7dXNvL2zllU763invP5gGCQnjmPOhEzOmpnP8ROzOKEoi+OLspicm8Y4hYCIjCAFxAhwd96vaeZPZbX8YXsNa8rrqW/tAkL3+i2ZkceiWQUsmJrL8UVZuoZfRGKCAuIYKq9t4Werynl5cxXlwe0dZxSkc/HcIs6amc9ZMwuYmp+mSz9FJCYpICKssbWLFzftZcW7e3jz/VoSxhnnzC7kC5+cxXlzxjOtID3aJYqIDIkCIkJ217Vy92+2sHJzFZ09vcwoSOf2C2dzw6LpFGWnRrs8EZEjpoAYpi37mnj4jzt5Yf1eDLhh0TT+4rTJzJ+co1NHIjKqKSCO0u66Vu57dTtPr6kgLSmBPz+1mL+5YDYzCjOiXZqISEQoII6Qu/Pom+V898UtdPc4t5w7ky9fNJvc9ORolyYiElEKiCPwQW0rdz63nj+V1XLO7AL+5ar5zNQRg4iMUQqIIXB3Vry7hzue3cA4g7uWzOOGs6br28siMqYpIA7jnQ/q+favNvPu7gZOmZLDA587g+KctGiXJSJyzCkgBtHT6zz2Vjl3vbCZ/Ixk/vUv5nNtyRT9zLWIxA0FxACqmtr58uNreXtnHefOLuQ/rz9NndAiEncUEP28sD7U19Drzr9dfQpXnzFF32cQkbikgAjz+pZqvvrkOk6alMO9157KrPGZ0S5JRCRqFBCBN8r288WfreGEiVk8evNCctKSol2SiEhUqccV2NvYxlefWsfE7FR+evNZCgcREYYZEGaWb2YrzWx78DdvgHkWmNmbZrbJzNab2XVh035iZjvNbF3wWDCceo6Gu/ONX26ivqWLH95wOnkZ6owWEYHhH0HcAbzq7nOAV4Px/lqBG919HnA58H0zyw2b/g/uviB4rBtmPUdsTXk9KzdX8cXzZ3Hy5JyRfnkRkZg13IBYAjwSDD8CXNV/Bnff5u7bg+E9QDUwfpivGzH//YcdZKUk8oXzZkW7FBGRmDLcgChy973B8D6g6FAzm9lCIBl4P6z5/wannu41s5RDLHubmZWaWWlNTc0wyw7Ztb+FlzZVsewTM8hOVb+DiEi4wwaEmb1iZhsHeCwJn8/dHfBDPE8x8FPg8+7eGzTfCZwInAnkA/802PLuvtzdS9y9ZPz4yByAPLF6NwnjjBsWTYvI84mIjCWHvczV3RcPNs3Mqsys2N33BgFQPch82cD/AF9391Vhz9139NFhZj8G/tcRVT8M3T29PPtOBReeMF6/rSQiMoDhnmJaASwLhpcBv+w/g5klA88Bj7r7M/2mFQd/jVD/xcZh1jNkL27aR82BDpaeqaMHEZGBDDcg7gYuMbPtwOJgHDMrMbMHg3muBc4Dbhrgctafm9kGYANQCPzLMOsZsidX72ZqfhoXnjhhpF5SRGRUGdY3qd29Frh4gPZS4NZg+GfAzwZZ/qLhvP7R6u11NlQ28qmTJ+qeDiIig4jLb1K/uqWahtYuFs0qiHYpIiIxKy4D4qVN+8hITuDP5hdHuxQRkZgVlwGxbncDp0/P081/REQOIe72kG2dPbxf08yCqbnRLkVEJKbFXUCU17XgDnOKsqJdiohITIu7gNi1vxWAmQUZUa5ERCS2xV1AlNe2ADCtID3KlYiIxLa4C4hdta3kZyTrpkAiIocRdwFRXtvCDB09iIgcVtwFRFl1MzMLM6NdhohIzIurgHB36lo6Kcoe9LYTIiISiKuAaOnsobvXyU1X/4OIyOHEVUDUt3QCkJuWHOVKRERiX1wFRGtnDwAZKcP6EVsRkbgQVwHR2R2602lyYlyttojIUYmrPWVHd+gIIkUBISJyWHG1p9QRhIjI0A1rT2lm+Wa20sy2B3/zBpmvJ+x2oyvC2mea2VtmVmZmTwb3rz5mOoKA0BGEiMjhDXdPeQfwqrvPAV4NxgfS5u4LgseVYe3fBe5199lAPXDLMOs5pA4dQYiIDNlw95RLgEeC4UeAq4a6oJkZcBHwzNEsfzQ+7INIOJYvIyIyJgw3IIrcfW8wvA8oGmS+VDMrNbNVZnZV0FYANLh7dzBeAUwe7IXM7LbgOUpramqOqthOnWISERmyw34hwMxeASYOMOnr4SPu7mbmgzzNdHevNLNZwGtmtgFoPJJC3X05sBygpKRksNc5JPVBiIgM3WEDwt0XDzbNzKrMrNjd95pZMVA9yHNUBn93mNlvgdOAZ4FcM0sMjiKmAJVHsQ5D9uERhE4xiYgcznA/Sq8AlgXDy4Bf9p/BzPLMLCUYLgTOATa7uwOvA1cfavlIUie1iMjQDXdPeTdwiZltBxYH45hZiZk9GMwzFyg1s3cJBcLd7r45mPZPwNfMrIxQn8RDw6znkPQ9CBGRoRvWjxK5ey1w8QDtpcCtwfAbwPxBlt8BLBxODUeis6eHxHFGwjgbqZcUERm14uqjdEdXrzqoRUSGKK72lp09vTq9JCIyRHG1twwdQegKJhGRoYirgNARhIjI0MXV3rKju0d9ECIiQxRXe8vObh1BiIgMVVzde/O0aXnM6eg+/IwiIhJfAfGlC2dHuwQRkVFD51tERGRACggRERmQAkJERAakgBARkQEpIEREZEAKCBERGZACQkREBqSAEBGRAVnozp+ji5nVAOVHuXghsD+C5YwWWu/4ovWOL0Nd7+nuPn6oTzoqA2I4zKzU3UuiXcdI03rHF613fDlW661TTCIiMiAFhIiIDCgeA2J5tAuIEq13fNF6x5djst5x1wchIiJDE49HECIiMgQKCBERGVBcBYSZXW5mW82szMzuiHY9w2FmU83sdTPbbGabzOxvg/Z8M1tpZtuDv3lBu5nZfcG6rzez08Oea1kw/3YzWxatdToSZpZgZmvN7IVgfKaZvRWs35Nmlhy0pwTjZcH0GWHPcWfQvtXMLovSqgyZmeWa2TNmtsXM3jOzs+Nhe5vZV4N/4xvN7HEzSx2L29vMHjazajPbGNYWse1rZmeY2YZgmfvMzA5blLvHxQNIAN4HZgHJwLvASdGuaxjrUwycHgxnAduAk4B7gDuC9juA7wbDVwC/AQxYBLwVtOcDO4K/ecFwXrTXbwjr/zXgMeCFYPwpYGkw/CPgr4PhvwF+FAwvBZ4Mhk8K/g2kADODfxsJ0V6vw6zzI8CtwXAykDvWtzcwGdgJpIVt55vG4vYGzgNOBzaGtUVs+wJvB/NasOynDltTtN+UEXzzzwZeChu/E7gz2nVFcP1+CVwCbAWKg7ZiYGsw/ADw2bD5twbTPws8ENb+kfli8QFMAV4FLgJeCP7B7wcS+29r4CXg7GA4MZjP+m//8Pli8QHkBDtK69c+prd3EBC7gx1eYrC9Lxur2xuY0S8gIrJ9g2lbwto/Mt9gj3g6xdT3D61PRdA26gWH0acBbwFF7r43mLQPKAqGB1v/0fi+fB/4R6A3GC8AGty9OxgPX4eD6xdMbwzmH23rPROoAX4cnFp70MwyGOPb290rgX8HPgD2Etp+axj727tPpLbv5GC4f/shxVNAjElmlgk8C/yduzeFT/PQR4UxdR2zmX0aqHb3NdGuZYQlEjr98F/ufhrQQuiUw0FjdHvnAUsIBeQkIAO4PKpFRUk0tm88BUQlMDVsfErQNmqZWRKhcPi5u/8iaK4ys+JgejFQHbQPtv6j7X05B7jSzHYBTxA6zfQDINfMEoN5wtfh4PoF03OAWkbfelcAFe7+VjD+DKHAGOvbezGw091r3L0L+AWhfwNjfXv3idT2rQyG+7cfUjwFxGpgTnD1QzKhDqwVUa7pqAVXIDwEvOfu3wubtALou3JhGaG+ib72G4OrHxYBjcGh60vApWaWF3xauzRoi0nufqe7T3H3GYS24WvufgPwOnB1MFv/9e57P64O5vegfWlw1ctMYA6hTryY5O77gN1mdkLQdDGwmTG+vQmdWlpkZunBv/m+9R7T2ztMRLZvMK3JzBYF7+ONYc81uGh3yoxwB9AVhK72eR/4erTrGea6nEvocHM9sC54XEHofOurwHbgFSA/mN+A+4N13wCUhD3XzUBZ8Ph8tNftCN6DC/jwKqZZhP7DlwFPAylBe2owXhZMnxW2/NeD92MrQ7iiI9oPYAFQGmzz5wldpTLmtzfwbWALsBH4KaErkcbc9gYeJ9TP0kXoiPGWSG5foCR4D98H/pN+FzwM9NBPbYiIyIDi6RSTiIgcAQWEiIgMSAEhIiIDUkCIiMiAFBAiIjIgBYSIiAxIASEiIgP6/wDF/fYvhKO4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At cuttoff of 0.2  truepositive 45 truenegative 7659 falsepositive 2614 falsenegative 7 Accuracy 74.61501210653753 %\n",
      "At cuttoff of 0.3  truepositive 42 truenegative 8418 falsepositive 1855 falsenegative 10 Accuracy 81.93704600484261 %\n",
      "At cuttoff of 0.4  truepositive 40 truenegative 8891 falsepositive 1382 falsenegative 12 Accuracy 86.49878934624698 %\n",
      "At cuttoff of 0.5  truepositive 38 truenegative 9259 falsepositive 1014 falsenegative 14 Accuracy 90.04358353510897 %\n",
      "At cuttoff of 0.6  truepositive 37 truenegative 9558 falsepositive 715 falsenegative 15 Accuracy 92.92978208232445 %\n",
      "At cuttoff of 0.7  truepositive 31 truenegative 9792 falsepositive 481 falsenegative 21 Accuracy 95.13801452784503 %\n",
      "At cuttoff of 0.75  truepositive 30 truenegative 9877 falsepositive 396 falsenegative 22 Accuracy 95.95157384987894 %\n",
      "At cuttoff of 0.8  truepositive 26 truenegative 9957 falsepositive 316 falsenegative 26 Accuracy 96.68765133171912 %\n",
      "At cuttoff of 0.9  truepositive 15 truenegative 10101 falsepositive 172 falsenegative 37 Accuracy 97.97578692493947 %\n",
      "At cuttoff of 1.0  truepositive 9 truenegative 10192 falsepositive 81 falsenegative 43 Accuracy 98.79903147699758 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test sets-model_old\n",
      "At cuttoff of 0.2  truepositive 25 truenegative 7578 falsepositive 2218 falsenegative 1 Accuracy 77.40785990633272 %\n",
      "At cuttoff of 0.3  truepositive 24 truenegative 8190 falsepositive 1606 falsenegative 2 Accuracy 83.62858888210141 %\n",
      "At cuttoff of 0.4  truepositive 24 truenegative 8611 falsepositive 1185 falsenegative 2 Accuracy 87.91488495214824 %\n",
      "At cuttoff of 0.5  truepositive 21 truenegative 8940 falsepositive 856 falsenegative 5 Accuracy 91.23396456933415 %\n",
      "At cuttoff of 0.6  truepositive 20 truenegative 9181 falsepositive 615 falsenegative 6 Accuracy 93.67745876603543 %\n",
      "At cuttoff of 0.7  truepositive 19 truenegative 9393 falsepositive 403 falsenegative 7 Accuracy 95.82569741396864 %\n",
      "At cuttoff of 0.75  truepositive 17 truenegative 9486 falsepositive 310 falsenegative 9 Accuracy 96.7521889635512 %\n",
      "At cuttoff of 0.8  truepositive 16 truenegative 9551 falsepositive 245 falsenegative 10 Accuracy 97.40378741600489 %\n",
      "At cuttoff of 0.9  truepositive 14 truenegative 9652 falsepositive 144 falsenegative 12 Accuracy 98.41172877214417 %\n",
      "At cuttoff of 1.0  truepositive 5 truenegative 9738 falsepositive 58 falsenegative 21 Accuracy 99.1956831602525 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At cuttoff of 0.2  truepositive 45 truenegative 7659 falsepositive 2614 falsenegative 7 Accuracy 74.61501210653753 %\n",
      "At cuttoff of 0.3  truepositive 42 truenegative 8418 falsepositive 1855 falsenegative 10 Accuracy 81.93704600484261 %\n",
      "At cuttoff of 0.4  truepositive 40 truenegative 8891 falsepositive 1382 falsenegative 12 Accuracy 86.49878934624698 %\n",
      "At cuttoff of 0.5  truepositive 38 truenegative 9259 falsepositive 1014 falsenegative 14 Accuracy 90.04358353510897 %\n",
      "At cuttoff of 0.6  truepositive 37 truenegative 9558 falsepositive 715 falsenegative 15 Accuracy 92.92978208232445 %\n",
      "At cuttoff of 0.7  truepositive 31 truenegative 9792 falsepositive 481 falsenegative 21 Accuracy 95.13801452784503 %\n",
      "At cuttoff of 0.75  truepositive 30 truenegative 9877 falsepositive 396 falsenegative 22 Accuracy 95.95157384987894 %\n",
      "At cuttoff of 0.8  truepositive 26 truenegative 9957 falsepositive 316 falsenegative 26 Accuracy 96.68765133171912 %\n",
      "At cuttoff of 0.9  truepositive 15 truenegative 10101 falsepositive 172 falsenegative 37 Accuracy 97.97578692493947 %\n",
      "At cuttoff of 1.0  truepositive 9 truenegative 10192 falsepositive 81 falsenegative 43 Accuracy 98.79903147699758 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nprint(\"test sets-model2\")\\nevaluatedatasetlookahead(gru_model2,originaldata1)\\nevaluatedatasetlookahead(gru_model2,originaldata2)\\nprint(\"\")\\n\\nprint(\"test sets-model3\")\\nevaluatedatasetlookahead(gru_model3,originaldata1)\\nevaluatedatasetlookahead(gru_model3,originaldata2)\\nprint(\"\")\\n\\nprint(\"test sets-model4\")\\nevaluatedatasetlookahead(gru_model4,originaldata1)\\nevaluatedatasetlookahead(gru_model4,originaldata2)\\nprint(\"\")\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "#device = torch.device(\"cuda\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Training sets\")\n",
    "originaldata=pd.read_csv('forcetorquebuttonresults_renormalized_10_04_2021_newrange.csv')#.head()\n",
    "evaluatedatasetlookahead(gru_model1,originaldata)\n",
    "print(\"\")\n",
    "\n",
    "originaldata=pd.read_csv('forcetorquebuttonresults_renormalized_10_06_2021_newrange.csv')#.head()\n",
    "evaluatedatasetlookahead(gru_model1,originaldata)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "originaldata=pd.read_csv('forcetorquebuttonresults_10_13_2021.csv')\n",
    "evaluatedatasetlookahead(gru_model1,originaldata)\n",
    "\n",
    "print(\"\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"test sets-model1\")\n",
    "originaldata1=pd.read_csv('forcetorquebuttonresults_cylinder_withbutton_train_noposeobs_GRUrewards_10-4_13-2021GRU_lookahead10_23_2021.csv')#.head()\n",
    "evaluatedatasetlookahead(gru_model1,originaldata1)\n",
    "originaldata2=pd.read_csv('forcetorquebuttonresults_cylinder_withbutton_train_noposeobs_GRUrewards_10-4_13-2021GRU_lookahead_pos2rewardifbuttonpress10_23_2021.csv')#.head()\n",
    "evaluatedatasetlookahead(gru_model1,originaldata2)\n",
    "print(\"\")\n",
    "\n",
    "print(\"test sets-model_old\")\n",
    "originaldata1=pd.read_csv('forcetorquebuttonresults_cylinder_withbutton_train_noposeobs_GRUrewards_10-4_13-2021GRU_lookahead10_23_2021.csv')#.head()\n",
    "evaluatedatasetlookahead(gru_model_old,originaldata1)\n",
    "originaldata2=pd.read_csv('forcetorquebuttonresults_cylinder_withbutton_train_noposeobs_GRUrewards_10-4_13-2021GRU_lookahead_pos2rewardifbuttonpress10_23_2021.csv')#.head()\n",
    "evaluatedatasetlookahead(gru_model_old,originaldata2)\n",
    "print(\"\")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\"test sets-model2\")\n",
    "evaluatedatasetlookahead(gru_model2,originaldata1)\n",
    "evaluatedatasetlookahead(gru_model2,originaldata2)\n",
    "print(\"\")\n",
    "\n",
    "print(\"test sets-model3\")\n",
    "evaluatedatasetlookahead(gru_model3,originaldata1)\n",
    "evaluatedatasetlookahead(gru_model3,originaldata2)\n",
    "print(\"\")\n",
    "\n",
    "print(\"test sets-model4\")\n",
    "evaluatedatasetlookahead(gru_model4,originaldata1)\n",
    "evaluatedatasetlookahead(gru_model4,originaldata2)\n",
    "print(\"\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5454, 30)\n"
     ]
    }
   ],
   "source": [
    "originaldata=pd.read_csv('forcetorquebuttonresults_cylindernobutton_10_19_2021.csv')\n",
    "print(originaldata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8742799265683358"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " (310+13501)/(310+13501+1986)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22696/705497413.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mclassifytest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginaldata1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#print(classifytest)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mlabelstest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginaldata1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelstest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#print(classifytest)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1498\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "row=897\n",
    "\n",
    "headers=[]\n",
    "for i in range(30):  \n",
    "    label=str(i)\n",
    "    headers.append(\"header\"+label)\n",
    "\n",
    "choppedheaders=[]\n",
    "lookback=10 #save only the last 11 timesteps\n",
    "for i in range(10):  \n",
    "    label=str(i)\n",
    "    choppedheaders.append(\"header\"+label)\n",
    "\n",
    "okcounter=0\n",
    "for i in range(20):\n",
    "    classifytest=originaldata1[headers[i:10+i]].iloc[row*6:(row*6)+5].to_numpy()\n",
    "    #print(classifytest)\n",
    "    labelstest=originaldata1[headers[i:10+i]].iloc[(row*6)+5].to_numpy()\n",
    "    print(labelstest)\n",
    "    #print(classifytest)\n",
    "    classifytest=np.expand_dims(classifytest, axis=0)\n",
    "    #print(classifytest.shape)\n",
    "    #print(labelstest)\n",
    "\n",
    "    outputfull=evaluate_episode(gru_model3, classifytest)\n",
    "\n",
    "    #print(\"\")\n",
    "\n",
    "    #print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "    #print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "    \n",
    "    if abs(float(outputfull)-labelstest[9])>0.3:\n",
    "        result=\"X\"\n",
    "    else:\n",
    "        result=\"OK\"\n",
    "        okcounter+=1\n",
    "    print(\"prediction from timestep\",i,\"-\",i+10,\" :\",float(outputfull),\"actual\",labelstest[9], result)\n",
    "print(\"okcounter\",okcounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
