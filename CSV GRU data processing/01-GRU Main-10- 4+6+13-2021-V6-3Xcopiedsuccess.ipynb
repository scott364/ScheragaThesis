{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll be using a GRU model for a time series prediction task and we will compare the performance of the GRU model against an LSTM model as well. The dataset that we will be using is the Hourly Energy Consumption dataset which can be found on [Kaggle](https://www.kaggle.com/robikscube/hourly-energy-consumption). The dataset contains power consumption data across different regions around the United States recorded on an hourly basis.\n",
    "\n",
    "You can run the code implementation in this article on FloydHub using their GPUs on the cloud by clicking the following link and using the main.ipynb notebook.\n",
    "\n",
    "[![Run on FloydHub](https://static.floydhub.com/button/button-small.svg)](https://floydhub.com/run?template=https://github.com/gabrielloye/https://github.com/gabrielloye/GRU_Prediction)\n",
    "\n",
    "This will speed up the training process significantly. Alternatively, the link to the GitHub repository can be found [here]().\n",
    "\n",
    "The goal of this implementation is to create a model that can accurately predict the energy usage in the next hour given historical usage data. We will be using both the GRU and LSTM model to train on a set of historical data and evaluate both models on an unseen test set. To do so, weâ€™ll start with feature selection, data-preprocessing, followed by defining, training and eventually evaluating the models.\n",
    "\n",
    "We will be using the PyTorch library to implement both types of models along with other common Python libraries used in data analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.python-engineer.com/posts/pytorch-rnn-lstm-gru/\n",
    "\n",
    "#https://blog.floydhub.com/gru-with-pytorch/\n",
    "\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import MinMaxScaler,QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Local ###\n",
    "#from data_processing import *\n",
    "\n",
    "\n",
    "\n",
    "# Define data root directory\n",
    "\n",
    "#data_dir = \"./data/\"\n",
    "#print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of **12** *.csv* files containing hourly energy trend data (*'est_hourly.paruqet'* and *'pjm_hourly_est.csv'* are not used). In our next step, we will be reading these files and pre-processing these data in this order:\n",
    "- Getting the time data of each individual time step and generalizing them\n",
    "    - Hour of the day *i.e. 0-23*\n",
    "    - Day of the week *i.e. 1-7*\n",
    "    - Month *i.e. 1-12*\n",
    "    - Day of the year *i.e. 1-365*\n",
    "    \n",
    "    \n",
    "- Scale the data to values between 0 and 1\n",
    "    - Algorithms tend to perform better or converge faster when features are on a relatively similar scale and/or close to normally distributed\n",
    "    - Scaling preserves the shape of the original distribution and doesn't reduce the importance of outliers.\n",
    "    \n",
    "    \n",
    "- Group the data into sequences to be used as inputs to the model and store their corresponding labels\n",
    "    - The **sequence length** or **lookback period** is the number of data points in history that the model will use to make the prediction\n",
    "    - The label will be the next data point in time after the last one in the input sequence\n",
    "    \n",
    "\n",
    "- The inputs and labels will then be split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(device)\n",
    "\n",
    "\n",
    "def get_torch_device( v=0 ):\n",
    "    # torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "    is_cuda = torch.cuda.is_available()\n",
    "    # If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "    if is_cuda:\n",
    "        device = torch.device(\"cuda\")\n",
    "        if v:  print( \"CUDA Available!\" )\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        if v:  print( \"NO CUDA\" )\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24264, 10)\n",
      "(44100, 10)\n",
      "contatenated data size:\n",
      "(68364, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#choppeddata_testset=pd.read_csv('choppeddata_10_04_2021_3Xcopiedsuccess.csv')#.head()\n",
    "#choppeddata2=pd.read_csv('choppeddata_10_06_2021_3Xcopiedsuccess.csv')#.head()\n",
    "#choppeddata3=pd.read_csv('choppeddata_10_13_2021_3Xcopiedsuccess.csv')#.head()\n",
    "\n",
    "\n",
    "choppeddata2=pd.read_csv('choppeddata_10_04_2021_3Xcopiedsuccess.csv')#.head()\n",
    "choppeddata_testset=pd.read_csv('choppeddata_10_06_2021_randomselector_even.csv')#.head()\n",
    "\n",
    "choppeddata3=pd.read_csv('choppeddata_10_13_2021_3Xcopiedsuccess.csv')#.head()\n",
    "\n",
    "#choppeddata1=pd.read_csv('choppeddata_10_04_2021_randomselector_even.csv')#.head()\n",
    "#choppeddata2=pd.read_csv('choppeddata_10_06_2021_randomselector_even.csv')#.head()\n",
    "#choppeddata3=pd.read_csv('choppeddata_10_13_2021_randomselector_even.csv')#.head()\n",
    "\n",
    "\n",
    "#print(choppeddata1.shape)\n",
    "print(choppeddata2.shape)\n",
    "print(choppeddata3.shape)\n",
    "#frames = [choppeddata1, choppeddata2,choppeddata3]\n",
    "frames = [choppeddata2,choppeddata3]\n",
    "choppeddata = pd.concat(frames)\n",
    "print(\"contatenated data size:\")\n",
    "print(choppeddata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68364, 10)\n",
      "total runs: 11394\n"
     ]
    }
   ],
   "source": [
    "print(choppeddata.shape)\n",
    "runqty=int(choppeddata.shape[0]/6)\n",
    "print(\"total runs:\",runqty)\n",
    "choppedheaders=[]\n",
    "lookback=10 #save only the last 11 timesteps\n",
    "for i in range(lookback):  \n",
    "    label=str(i)\n",
    "    choppedheaders.append(\"header\"+label)\n",
    "\n",
    "#put chopped data in np.arrays\n",
    "State=np.zeros((runqty,5,lookback)) #96 runs,with 5 sets of data (x,y,z,roll,pitch) each, and each run is 11 timesteps long\n",
    "Labels=np.zeros((runqty,lookback)) #96 runs, each run is 11 timesteps long\n",
    "runcounter=0\n",
    "\n",
    "for i in range(0,choppeddata.shape[0],6):\n",
    "            State[runcounter][0][:]=(choppeddata[choppedheaders[:]].iloc[i]).tolist()\n",
    "            State[runcounter][1][:]=(choppeddata[choppedheaders[:]].iloc[i+1]).tolist()\n",
    "            State[runcounter][2][:]=(choppeddata[choppedheaders[:]].iloc[i+2]).tolist()\n",
    "            State[runcounter][3][:]=(choppeddata[choppedheaders[:]].iloc[i+3]).tolist()\n",
    "            State[runcounter][4][:]=(choppeddata[choppedheaders[:]].iloc[i+4]).tolist()\n",
    "            Labels[runcounter][:]=(choppeddata[choppedheaders[:]].iloc[i+5]).tolist()  #labels   \n",
    "            runcounter+=1\n",
    "#print(State[0])\n",
    "#print(Labels)\n",
    "#print(Labels[:,9]) #just getting finals labels\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10440, 10)\n",
      "total runs: 1740\n"
     ]
    }
   ],
   "source": [
    "#make test set with data outside of training set, because of duplication of successful runs. \n",
    "\n",
    "\n",
    "print(choppeddata_testset.shape)\n",
    "runqty_testset=int(choppeddata_testset.shape[0]/6)\n",
    "print(\"total runs:\",runqty_testset)\n",
    "\n",
    "#put chopped data in np.arrays\n",
    "State_testset=np.zeros((runqty_testset,5,lookback)) #96 runs,with 5 sets of data (x,y,z,roll,pitch) each, and each run is 11 timesteps long\n",
    "Labels_testset=np.zeros((runqty_testset,lookback)) #96 runs, each run is 11 timesteps long\n",
    "runcounter=0\n",
    "\n",
    "for i in range(0,choppeddata_testset.shape[0],6):\n",
    "            State_testset[runcounter][0][:]=(choppeddata_testset[choppedheaders[:]].iloc[i]).tolist()\n",
    "            State_testset[runcounter][1][:]=(choppeddata_testset[choppedheaders[:]].iloc[i+1]).tolist()\n",
    "            State_testset[runcounter][2][:]=(choppeddata_testset[choppedheaders[:]].iloc[i+2]).tolist()\n",
    "            State_testset[runcounter][3][:]=(choppeddata_testset[choppedheaders[:]].iloc[i+3]).tolist()\n",
    "            State_testset[runcounter][4][:]=(choppeddata_testset[choppedheaders[:]].iloc[i+4]).tolist()\n",
    "            Labels_testset[runcounter][:]=(choppeddata_testset[choppedheaders[:]].iloc[i+5]).tolist()  #labels   \n",
    "            runcounter+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (11394, 5, 10)\n",
      "Test set X size (11393, 5, 10)\n",
      "Train set Y size (11393, 1)\n",
      "Test set X size (1, 5, 10)\n",
      "Test set Y size (1, 1)\n"
     ]
    }
   ],
   "source": [
    "#X= range(0,575,6)\n",
    "#y= range(0,575,6)\n",
    "\n",
    "X=State\n",
    "y=Labels[:,lookback-1]\n",
    "print(\"x.shape\",X.shape)\n",
    "\n",
    "y=y.reshape(runqty,1)\n",
    "\n",
    "random_seed=int(time.time())\n",
    "#print(int(time.time()))\n",
    "train_x, test_x, train_y,test_y = train_test_split(X, y, test_size= float(.00001),#.25 #0.33, \n",
    "                                                   random_state=random_seed)\n",
    "#print(\"Train\")\n",
    "#print(train_x[0])\n",
    "#print(train_y[0])\n",
    "print(\"Test set X size\", train_x.shape)\n",
    "print(\"Train set Y size\", train_y.shape)\n",
    "#print(test_x[0])\n",
    "#print(test_y[0])\n",
    "print(\"Test set X size\", test_x.shape)\n",
    "print(\"Test set Y size\", test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (11394, 5, 10)\n",
      "Test set X size (1, 5, 10)\n",
      "Train set Y size (1, 1)\n",
      "Test set X size (1739, 5, 10)\n",
      "Test set Y size (1739, 1)\n"
     ]
    }
   ],
   "source": [
    "#X= range(0,575,6)\n",
    "#y= range(0,575,6)\n",
    "\n",
    "X_testset=State_testset\n",
    "y_testset=Labels_testset[:,lookback-1]\n",
    "print(\"x.shape\",X.shape)\n",
    "\n",
    "y_testset=y_testset.reshape(runqty_testset,1)\n",
    "\n",
    "random_seed=int(time.time())\n",
    "#print(int(time.time()))\n",
    "train_x_testset, test_x_testset, train_y_testset,test_y_testset = train_test_split(X_testset, y_testset, test_size=.999,#.25 #0.33, \n",
    "                                                   random_state=random_seed)\n",
    "#print(\"Train\")\n",
    "#print(train_x[0])\n",
    "#print(train_y[0])\n",
    "print(\"Test set X size\", train_x_testset.shape)\n",
    "print(\"Train set Y size\", train_y_testset.shape)\n",
    "#print(test_x[0])\n",
    "#print(test_y[0])\n",
    "print(\"Test set X size\", test_x_testset.shape)\n",
    "print(\"Test set Y size\", test_y_testset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of 980,185 sequences of training data\n",
    "\n",
    "To improve the speed of our training, we can process the data in batches so that the model does not need to update its weights as frequently. The Torch *Dataset* and *DataLoader* classes are useful for splitting our data into batches and shuffling them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f67d6586390>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check if we have any GPUs to speed up our training time by many folds. If youâ€™re using FloydHub with GPU to run this code, the training time will be significantly reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden\n",
    "def train(train_loader, learn_rate, hidden_dim=128, EPOCHS=400, model_type=\"GRU\"):\n",
    "    #got  109 / 180 on training set, 29 / 60 on test set from 128 hidden dim, 50 epoch, batch size of 4, lr =0.001\n",
    "    #Got training data= 146 / 180, success vs test data= 38 / 60 with same as above but 100 epoch\n",
    "    #Got training data= 172 / 180, success vs test data= 46 / 60 with same as above but 200 epoch\n",
    "    #Got training data= 165 / 180, success vs test data= 52 / 60 with same as above but 200 epoch\n",
    "    \n",
    "    losslist=[]\n",
    "    # Setting common hyperparameters\n",
    "    input_dim = next(iter(train_loader))[0].shape[2]  #  = 11\n",
    "    #print(input_dim)\n",
    "    #print(\"input_dim\",input_dim)\n",
    "    output_dim = 1\n",
    "    n_layers = 2\n",
    "    # Instantiating the models\n",
    "    if model_type == \"GRU\":\n",
    "        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    else:\n",
    "        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Defining loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    \n",
    "    model.train()\n",
    "    print(\"Starting Training of {} model\".format(model_type))\n",
    "    epoch_times = []\n",
    "    # Start training loop\n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        start_time = time.clock()\n",
    "        h = model.init_hidden(batch_size)\n",
    "        avg_loss = 0.\n",
    "        counter = 0\n",
    "        for x, label in train_loader:\n",
    "            #print(\"x\",x)\n",
    "            #print(\"label\",label)\n",
    "            counter += 1\n",
    "            if model_type == \"GRU\":\n",
    "                h = h.data\n",
    "            else:\n",
    "                h = tuple([e.data for e in h])\n",
    "            model.zero_grad()\n",
    "            \n",
    "            out, h = model(x.to(device).float(), h)\n",
    "            #print(\"out\",out)\n",
    "            loss = criterion(out, label.to(device).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "            \n",
    "            if counter%20000 == 0:\n",
    "                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter, len(train_loader), avg_loss/counter))\n",
    "        current_time = time.clock()\n",
    "        if epoch%40 == 0:\n",
    "            print(\"Epoch {}/{} Done, Total Loss: {}   Time Elapsed: {} seconds\".format(epoch, EPOCHS, avg_loss/len(train_loader),str(current_time-start_time)))\n",
    "        \n",
    "            #print(\"Total\".format())\n",
    "        losslist.append(avg_loss/len(train_loader))\n",
    "        epoch_times.append(current_time-start_time)\n",
    "    print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n",
    "    plt.plot(losslist)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.show()\n",
    "    return model,losslist\n",
    "\n",
    "def train_existing_model(model,train_loader, learn_rate, hidden_dim=128, EPOCHS=400, model_type=\"GRU\"):\n",
    "    #got  109 / 180 on training set, 29 / 60 on test set from 128 hidden dim, 50 epoch, batch size of 4, lr =0.001\n",
    "    #Got training data= 146 / 180, success vs test data= 38 / 60 with same as above but 100 epoch\n",
    "    #Got training data= 172 / 180, success vs test data= 46 / 60 with same as above but 200 epoch\n",
    "    #Got training data= 165 / 180, success vs test data= 52 / 60 with same as above but 200 epoch\n",
    "    \n",
    "    losslist=[]\n",
    "    # Setting common hyperparameters\n",
    "    input_dim = next(iter(train_loader))[0].shape[2]  #  = 11\n",
    "    #print(input_dim)\n",
    "    #print(\"input_dim\",input_dim)\n",
    "    output_dim = 1\n",
    "    n_layers = 2\n",
    "    # Instantiating the models\n",
    "    \"\"\"\n",
    "    if model_type == \"GRU\":\n",
    "        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    else:\n",
    "        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    \"\"\"    \n",
    "        \n",
    "    model.to(device)\n",
    "    \n",
    "    # Defining loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    \n",
    "    model.train()\n",
    "    print(\"Starting Training of {} model\".format(model_type))\n",
    "    epoch_times = []\n",
    "    # Start training loop\n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        start_time = time.clock()\n",
    "        h = model.init_hidden(batch_size)\n",
    "        avg_loss = 0.\n",
    "        counter = 0\n",
    "        for x, label in train_loader:\n",
    "            #print(\"x\",x)\n",
    "            #print(\"label\",label)\n",
    "            counter += 1\n",
    "            if model_type == \"GRU\":\n",
    "                h = h.data\n",
    "            else:\n",
    "                h = tuple([e.data for e in h])\n",
    "            model.zero_grad()\n",
    "            \n",
    "            out, h = model(x.to(device).float(), h)\n",
    "            #print(\"out\",out)\n",
    "            loss = criterion(out, label.to(device).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "            \n",
    "            if counter%20000 == 0:\n",
    "                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter, len(train_loader), avg_loss/counter))\n",
    "        current_time = time.clock()\n",
    "        if epoch%40 == 0:\n",
    "            print(\"Epoch {}/{} Done, Total Loss: {}   Time Elapsed: {} seconds\".format(epoch, EPOCHS, avg_loss/len(train_loader),str(current_time-start_time)))\n",
    "        \n",
    "            #print(\"Total\".format())\n",
    "        losslist.append(avg_loss/len(train_loader))\n",
    "        epoch_times.append(current_time-start_time)\n",
    "    print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n",
    "    plt.plot(losslist)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.show()\n",
    "    return model,losslist\n",
    "\n",
    "\n",
    "def evaluate(model, test_x, test_y):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []\n",
    "    start_time = time.clock()\n",
    "    #for i in test_x.keys():\n",
    "    for i in range( len( test_x ) ):    \n",
    "        inp = torch.from_numpy(np.array(test_x[i])) # should be 5x1\n",
    "        labs = torch.from_numpy(np.array(test_y[i])) #should be 1x1\n",
    "        h = model.init_hidden(inp.shape[0])\n",
    "        #print(\"inp\",inp)\n",
    "        #print(\"labs\",labs)\n",
    "        #print(\"h\",h)\n",
    "        out, h = model(inp.to(device).float(), h)\n",
    "        #outputs.append(label_scalers[i].inverse_transform(out.cpu().detach().numpy()).reshape(-1))\n",
    "        #targets.append(label_scalers[i].inverse_transform(labs.numpy()).reshape(-1))\n",
    "        outputs.append( out.cpu().detach().numpy().reshape(-1) )\n",
    "        targets.append( labs.numpy().reshape(-1) )\n",
    "        \n",
    "    print(\"Evaluation Time: {}\".format(str(time.clock()-start_time)))\n",
    "    sMAPE = 0\n",
    "    for i in range(len(outputs)):\n",
    "        sMAPE += np.mean(abs(outputs[i]-targets[i])/(targets[i]+outputs[i])/2)/len(outputs)\n",
    "    print(\"sMAPE: {}%\".format(sMAPE*100))\n",
    "    return outputs, targets, sMAPE\n",
    "                               \n",
    "def evaluate2(model, test_x, test_y):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []  #labels\n",
    "    #start_time = time.clock()\n",
    "    #for i in test_x.keys():\n",
    "    #for i in range( len( test_x ) ):    \n",
    "    inp = torch.from_numpy(np.array(test_x)) # should be 5x1\n",
    "    labs = torch.from_numpy(np.array(test_y)) #should be 1x1\n",
    "    h = model.init_hidden(inp.shape[0])\n",
    "    #print(\"inp\",inp)\n",
    "    #print(\"labs\",labs)\n",
    "    #print(\"h\",h)\n",
    "    out, h = model(inp.to(device).float(), h)\n",
    "    #outputs.append(label_scalers[i].inverse_transform(out.cpu().detach().numpy()).reshape(-1))\n",
    "    #targets.append(label_scalers[i].inverse_transform(labs.numpy()).reshape(-1))\n",
    "    outputs.append( out.cpu().detach().numpy().reshape(-1) )\n",
    "    targets.append( labs.numpy().reshape(-1) )\n",
    "        \n",
    "    #print(\"Evaluation Time: {}\".format(str(time.clock()-start_time)))\n",
    "    sMAPE = 0\n",
    "    #for i in range(len(outputs)):\n",
    "    #    sMAPE += np.mean(abs(outputs[i]-targets[i])/(targets[i]+outputs[i])/2)/len(outputs)\n",
    "    #print(\"sMAPE: {}%\".format(sMAPE*100))\n",
    "    return outputs, targets#, sMAPE                               \n",
    "\n",
    "def evaluatefull_maxdiff(model, train_x, train_y, test_x, test_y,maxdifference=0.2, verbose=False):\n",
    "\n",
    "    #m = nn.ReLU()\n",
    "    #m = nn.Sigmoid()\n",
    "    #output = m(input)\n",
    "    print(\"Vs Training Set\")\n",
    "    gru_outputs, targets, gru_sMAPE = evaluate2(gru_model, train_x, train_y)\n",
    "    #print(test_y)\n",
    "    #print(gru_outputs)\n",
    "    #print(gru_outputs[0][5])\n",
    "\n",
    "\n",
    "    testy=test_y.reshape(-1)\n",
    "    trainy=train_y.reshape(-1)\n",
    "\n",
    "\n",
    "    #print(\"Train size:\",trainy.size)\n",
    "    print(gru_outputs[0][4])\n",
    "    train_successcounter=0\n",
    "    for i in range(int(trainy.size)):\n",
    "        #print(testy[i],gru_outputs[0][i],m(torch.tensor(gru_outputs[0][i])))\n",
    "        #print(train[i],gru_outputs[0][i],m(torch.tensor(gru_outputs[0][i])))\n",
    "\n",
    "\n",
    "        #print(trainy[i],gru_outputs[0][i], m(torch.tensor(gru_outputs[0][i])))\n",
    "\n",
    "\n",
    "        if abs(trainy[i]-gru_outputs[0][i])<maxdifference :\n",
    "            train_successcounter+=1\n",
    "        #print(testy[i])\n",
    "        #print\n",
    "        #output = m(input)\n",
    "\n",
    "\n",
    "\n",
    "    test_successcounter=0\n",
    "    print(\"Vs Test Set\")\n",
    "    gru_outputs, targets, gru_sMAPE = evaluate2(gru_model, test_x, test_y)\n",
    "    #print(\"test size: \",testy.size)\n",
    "\n",
    "    for i in range(int(testy.size)):\n",
    "\n",
    "\n",
    "        #, m(torch.tensor(gru_outputs[0][i])))\n",
    "\n",
    "\n",
    "        if abs(testy[i]-gru_outputs[0][i])<maxdifference :\n",
    "            test_successcounter+=1\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"OK\" )\n",
    "        else:\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"X\" )\n",
    "            #print(testy[i])\n",
    "        #print\n",
    "        #output = m(input)\n",
    "    print(\"\")\n",
    "    print(\" vs training data=\" ,train_successcounter,\"/\",trainy.size, \" vs test data=\" ,\n",
    "          test_successcounter,\"/\",testy.size,int(100*test_successcounter/testy.size),\"%\", \"at max difference\",maxdifference )\n",
    "    return ( train_successcounter ,test_successcounter)\n",
    "\n",
    "\n",
    "def evaluatefull_cutoff(gru_model, train_x, train_y, test_x, test_y,cutoff=0.5, verbose=False):\n",
    "\n",
    "    #m = nn.ReLU()\n",
    "    #m = nn.Sigmoid()\n",
    "    #output = m(input)\n",
    "    \n",
    "    #gru_outputs, targets, gru_sMAPE = evaluate2(gru_model, train_x, train_y)\n",
    "    gru_outputs, targets= evaluate2(gru_model, train_x, train_y)\n",
    "    #print(test_y)\n",
    "    #print(gru_outputs)\n",
    "    #print(gru_outputs[0][5])\n",
    "\n",
    "\n",
    "    testy=test_y.reshape(-1)\n",
    "    trainy=train_y.reshape(-1)\n",
    "    #print(\"Vs Training Set\")\n",
    "    #print(gru_outputs[0][4])\n",
    "    traincounter_falsenegative=0\n",
    "    traincounter_falsepositive=0\n",
    "    \n",
    "    traincounter_truenegative=0\n",
    "    traincounter_truepositive=0\n",
    "    for i in range(int(trainy.size)):\n",
    "        \n",
    "        if trainy[i]==1  and gru_outputs[0][i]>= cutoff:\n",
    "            traincounter_truepositive+=1\n",
    "            if verbose==True:\n",
    "                print(trainy[i],gru_outputs[0][i], \"OK-truepositive\" )\n",
    "        elif trainy[i]==1  and gru_outputs[0][i]< cutoff:\n",
    "            traincounter_falsenegative+=1\n",
    "            if verbose==True:\n",
    "                print(trainy[i],gru_outputs[0][i], \"X-falsenegative\" )       \n",
    "                \n",
    "        elif trainy[i]==0 and gru_outputs[0][i]<= cutoff :\n",
    "            traincounter_truenegative+=1\n",
    "            if verbose==True:\n",
    "                print(trainy[i],gru_outputs[0][i], \"OK-truenegative\" )           \n",
    "        elif trainy[i]==0 and gru_outputs[0][i]> cutoff:\n",
    "            traincounter_falsepositive+=1\n",
    "            if verbose==True:\n",
    "                print(trainy[i],gru_outputs[0][i], \"X-falsepositive\" )     \n",
    "                \n",
    "           \n",
    "    #print(\"TRAINING SET: Fails for button not pressed:\",  train_failzerocounter,\"Fails for button pressed:\", train_failonecounter )        \n",
    "    test_successcounter=0\n",
    "    test_failzerocounter=0\n",
    "    test_failonecounter=0\n",
    "    \n",
    "    #gru_outputs, targets, gru_sMAPE = evaluate2(gru_model, test_x, test_y)\n",
    "    gru_outputs, targets = evaluate2(gru_model, test_x, test_y)\n",
    "    #print(\"Vs Test Set\")\n",
    "    #print(gru_outputs[0][4])\n",
    "    #print(\"test size: \",testy.size)\n",
    "\n",
    "\n",
    "    testcounter_falsenegative=0\n",
    "    testcounter_falsepositive=0\n",
    "    \n",
    "    testcounter_truenegative=0\n",
    "    testcounter_truepositive=0\n",
    "    for i in range(int(testy.size)):\n",
    "        \n",
    "        if testy[i]==1  and gru_outputs[0][i]>= cutoff:\n",
    "            testcounter_truepositive+=1\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"OK-truepositive\" )\n",
    "        elif testy[i]==1  and gru_outputs[0][i]< cutoff:\n",
    "            testcounter_falsenegative+=1\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"X-falsenegative\" )       \n",
    "                \n",
    "        elif testy[i]==0 and gru_outputs[0][i]<= cutoff :\n",
    "            testcounter_truenegative+=1\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"OK-truenegative\" )           \n",
    "        elif testy[i]==0 and gru_outputs[0][i]> cutoff:\n",
    "            testcounter_falsepositive+=1\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"X-falsepositive\" )   \n",
    "    \n",
    "    print(\" vs training data=\" ,traincounter_truepositive+traincounter_truenegative,\"/\",trainy.size, \" vs test data=\" ,\n",
    "          testcounter_truepositive+testcounter_truenegative,\"/\",testy.size,round((100*(testcounter_truepositive+testcounter_truenegative)/testy.size),2),\"%\", \"at cutoff\",cutoff )\n",
    "    \n",
    "    \n",
    "    print(\"TEST SET: True Positives\",testcounter_truepositive,\"True Negatives\", testcounter_truenegative,\" False Positives\",testcounter_falsepositive,\"False Negatives\", testcounter_falsenegative)\n",
    "    print(\"\")\n",
    "    return ( traincounter_truepositive+traincounter_truenegative, testcounter_truepositive+testcounter_truenegative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (11394, 5, 10)\n",
      "x.shape (11394, 5, 10)\n",
      "Starting Training of GRU model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:72: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/400 Done, Total Loss: 0.04757167681465658   Time Elapsed: 0.4348930000000024 seconds\n",
      "Epoch 80/400 Done, Total Loss: 0.04139339252573888   Time Elapsed: 0.40247599999999295 seconds\n",
      "Epoch 120/400 Done, Total Loss: 0.03333015230306414   Time Elapsed: 0.4327820000000031 seconds\n",
      "Epoch 160/400 Done, Total Loss: 0.02691493244067337   Time Elapsed: 0.4314870000000042 seconds\n",
      "Epoch 200/400 Done, Total Loss: 0.020927986438815178   Time Elapsed: 0.4071969999999965 seconds\n",
      "Epoch 240/400 Done, Total Loss: 0.01681384632070915   Time Elapsed: 0.42408799999998337 seconds\n",
      "Epoch 280/400 Done, Total Loss: 0.01144087054567893   Time Elapsed: 0.41415399999999636 seconds\n",
      "Epoch 320/400 Done, Total Loss: 0.009354425008209903   Time Elapsed: 0.4013389999999788 seconds\n",
      "Epoch 360/400 Done, Total Loss: 0.007149711423265758   Time Elapsed: 0.40598499999998694 seconds\n",
      "Epoch 400/400 Done, Total Loss: 0.00664320055544481   Time Elapsed: 0.39974300000000085 seconds\n",
      "Total Training Time: 167.67633899999993 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " vs training data= 11378 / 11393  vs test data= 1605 / 1739 92.29 % at cutoff 0.4\n",
      "TEST SET: True Positives 772 True Negatives 833  False Positives 37 False Negatives 97\n",
      "\n",
      " vs training data= 11388 / 11393  vs test data= 1597 / 1739 91.83 % at cutoff 0.5\n",
      "TEST SET: True Positives 761 True Negatives 836  False Positives 34 False Negatives 108\n",
      "\n",
      " vs training data= 11388 / 11393  vs test data= 1596 / 1739 91.78 % at cutoff 0.6\n",
      "TEST SET: True Positives 747 True Negatives 849  False Positives 21 False Negatives 122\n",
      "\n",
      " vs training data= 11386 / 11393  vs test data= 1583 / 1739 91.03 % at cutoff 0.7\n",
      "TEST SET: True Positives 727 True Negatives 856  False Positives 14 False Negatives 142\n",
      "\n",
      " vs training data= 11359 / 11393  vs test data= 1557 / 1739 89.53 % at cutoff 0.8\n",
      "TEST SET: True Positives 698 True Negatives 859  False Positives 11 False Negatives 171\n",
      "\n",
      " vs training data= 11215 / 11393  vs test data= 1518 / 1739 87.29 % at cutoff 0.9\n",
      "TEST SET: True Positives 653 True Negatives 865  False Positives 5 False Negatives 216\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:184: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ngru_model2, losslist2 =train_existing_model(gru_model1,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\n\\ntrain2 ,test2=evaluatefull_cutoff(gru_model2, train_x, train_y, test_x, test_y,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model2, train_x, train_y, test_x, test_y,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model2, train_x, train_y, test_x, test_y,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model2, train_x, train_y, test_x, test_y,cutoff=.7)\\n\\ngru_model3, losslist3 =train_existing_model(gru_model2,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\ntrain2 ,test2=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.7)\\n\\n\\ngru_model4, losslist4 =train_existing_model(gru_model3,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\n\\ntrain2 ,test2=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.7)\\n\\ngru_model5, losslist5 =train_existing_model(gru_model4,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\ntrain2 ,test2=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.7)\\n\\ngru_model6, losslist6 =train_existing_model(gru_model5,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\ntrain2 ,test2=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.7)\\n\\ngru_model7, losslist7 =train_existing_model(gru_model6,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\ntrain2 ,test2=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.7)\\n\\ngru_model8, losslist8 =train_existing_model(gru_model7,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\ntrain2 ,test2=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.7)\\n\\nfulllosslist=losslist1+losslist2+losslist3+losslist4+losslist5+losslist6+losslist7+losslist8\\nplt.plot(fulllosslist)\\nplt.title(\"Loss\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0005\n",
    "batch_size = 64\n",
    "#a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels.\n",
    "\n",
    "X=State\n",
    "y=Labels[:,lookback-1]\n",
    "print(\"x.shape\",X.shape)\n",
    "y=y.reshape(runqty,1)\n",
    "\n",
    "\n",
    "X_testset=State_testset\n",
    "y_testset=Labels_testset[:,lookback-1]\n",
    "print(\"x.shape\",X.shape)\n",
    "\n",
    "y_testset=y_testset.reshape(runqty_testset,1)\n",
    "\n",
    "\n",
    "random_seed=int(time.time())\n",
    "#print(int(time.time()))\n",
    "train_x_trainset, test_x_trainset, train_y_trainset,test_y_trainset = train_test_split(X, y, test_size= float(.00001),#.25 #0.33, \n",
    "                                                   random_state=random_seed)\n",
    "\n",
    "train_x_testset, test_x_testset, train_y_testset,test_y_testset = train_test_split(X_testset, y_testset, test_size=.999,#.25 #0.33, \n",
    "                                                   random_state=random_seed)\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x_trainset), torch.from_numpy(train_y_trainset))\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "test_data   = TensorDataset( torch.from_numpy( test_x_testset ), torch.from_numpy( test_y_testset) )\n",
    "test_loader = DataLoader( test_data, shuffle = True, batch_size = batch_size, drop_last = True )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gru_model1, losslist1 =train(train_loader, lr , hidden_dim=128, EPOCHS=400 ,model_type=\"GRU\") #1500  #had low total loss with batch size 32\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.7)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.8)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.9)\n",
    "\n",
    "\"\"\"\n",
    "gru_model2, losslist2 =train_existing_model(gru_model1,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model2, train_x, train_y, test_x, test_y,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model2, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model2, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model2, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "\n",
    "gru_model3, losslist3 =train_existing_model(gru_model2,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "\n",
    "\n",
    "gru_model4, losslist4 =train_existing_model(gru_model3,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "\n",
    "gru_model5, losslist5 =train_existing_model(gru_model4,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "\n",
    "gru_model6, losslist6 =train_existing_model(gru_model5,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "\n",
    "gru_model7, losslist7 =train_existing_model(gru_model6,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "\n",
    "gru_model8, losslist8 =train_existing_model(gru_model7,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "\n",
    "fulllosslist=losslist1+losslist2+losslist3+losslist4+losslist5+losslist6+losslist7+losslist8\n",
    "plt.plot(fulllosslist)\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:184: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " vs training data= 11111 / 11393  vs test data= 1525 / 1739 87.69 % at cutoff 0.1\n",
      "TEST SET: True Positives 815 True Negatives 710  False Positives 160 False Negatives 54\n",
      "\n",
      " vs training data= 11318 / 11393  vs test data= 1586 / 1739 91.2 % at cutoff 0.2\n",
      "TEST SET: True Positives 801 True Negatives 785  False Positives 85 False Negatives 68\n",
      "\n",
      " vs training data= 11358 / 11393  vs test data= 1608 / 1739 92.47 % at cutoff 0.3\n",
      "TEST SET: True Positives 786 True Negatives 822  False Positives 48 False Negatives 83\n",
      "\n",
      " vs training data= 11378 / 11393  vs test data= 1605 / 1739 92.29 % at cutoff 0.4\n",
      "TEST SET: True Positives 772 True Negatives 833  False Positives 37 False Negatives 97\n",
      "\n",
      " vs training data= 11388 / 11393  vs test data= 1597 / 1739 91.83 % at cutoff 0.5\n",
      "TEST SET: True Positives 761 True Negatives 836  False Positives 34 False Negatives 108\n",
      "\n",
      " vs training data= 11388 / 11393  vs test data= 1596 / 1739 91.78 % at cutoff 0.6\n",
      "TEST SET: True Positives 747 True Negatives 849  False Positives 21 False Negatives 122\n",
      "\n",
      " vs training data= 11386 / 11393  vs test data= 1583 / 1739 91.03 % at cutoff 0.7\n",
      "TEST SET: True Positives 727 True Negatives 856  False Positives 14 False Negatives 142\n",
      "\n",
      " vs training data= 11359 / 11393  vs test data= 1557 / 1739 89.53 % at cutoff 0.8\n",
      "TEST SET: True Positives 698 True Negatives 859  False Positives 11 False Negatives 171\n",
      "\n",
      " vs training data= 11215 / 11393  vs test data= 1518 / 1739 87.29 % at cutoff 0.9\n",
      "TEST SET: True Positives 653 True Negatives 865  False Positives 5 False Negatives 216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train2 ,test2=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.1)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.2)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.3)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.7)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.8)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_episode(model, data, verbose=False):\n",
    "\n",
    "   \n",
    "    model.eval()\n",
    "    inp = torch.from_numpy(np.array(data)) # should be 5x1\n",
    "    h = model.init_hidden(inp.shape[0])\n",
    "    #print(\"inp\",inp)\n",
    "    #print(\"labs\",labs)\n",
    "    #print(\"h\",h)\n",
    "    out, h = model(inp.to(device).float(), h)\n",
    "    #print(\"model output\",out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_20_2021\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type GRUNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import date\n",
    "\n",
    "today = date.today()    \n",
    "todaydate = today.strftime(\"%m_%d_%Y\")\n",
    "print(todaydate)\n",
    "torch.save(gru_model1,\"currentmodel_3Xcopiedsuccess\"+todaydate+\".pt\")\n",
    "\n",
    "\n",
    "print(\"model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "gru_model3=torch.load('currentmodel_3Xcopiedsuccess10_20_2021.pt',map_location=torch.device('cpu'))\n",
    "gru_model3.eval()\n",
    "print(\"loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x_trainset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8751/1960168386.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluatefull_cutoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_testset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_testset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluatefull_cutoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_testset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_testset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluatefull_cutoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_testset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_testset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluatefull_cutoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_testset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_testset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluatefull_cutoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_testset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_testset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_x_trainset' is not defined"
     ]
    }
   ],
   "source": [
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.1)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.2)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.3)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.7)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.8)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " vs training data= 12561 / 12569  vs test data= 4039 / 4042 99.93 % at cutoff 0.5\n",
      "TEST SET: True Positives 2021 True Negatives 2018\n",
      "TEST SET: False Positives 3 False Negatives 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:184: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index= 44\n",
      "(1, 5, 10)\n",
      "prediction 0.2498023509979248   actual [0.]\n"
     ]
    }
   ],
   "source": [
    "randomindex=random.randint(0,225)\n",
    "print(\"index=\",randomindex)\n",
    "\n",
    "exampledata=np.expand_dims(test_x[207, 0:5, 0:10], axis=0)\n",
    "\n",
    "print(exampledata.shape)\n",
    "prediction=evaluate_episode(gru_model3, exampledata)\n",
    "\n",
    "print(\"prediction\",float(prediction), \"  actual\",test_y[randomindex])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## simlulate a buffer of 10 timesteps entering the classifier over a 1 episode, and classifying them. Filling empty data with zeroes or ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index= 188\n",
      "final partial data\n",
      "[[[1.         0.64779416 0.68590197 0.69517914 0.69903447 0.71459429\n",
      "   0.71267351 0.71409191 0.71673093 0.72399386]\n",
      "  [1.         0.52154944 0.52310862 0.53282553 0.52718083 0.53709991\n",
      "   0.52978522 0.54277099 0.53688102 0.54443726]\n",
      "  [1.         0.8726286  0.96482141 0.95083008 0.94447182 0.93691809\n",
      "   0.95239155 0.9493714  0.95276295 0.95638539]\n",
      "  [1.         0.50752062 0.50852903 0.49810241 0.50102952 0.4947311\n",
      "   0.50046923 0.49000781 0.49422322 0.48543027]\n",
      "  [1.         0.62007232 0.67079484 0.67376652 0.67304434 0.68618886\n",
      "   0.68665851 0.69233506 0.69529406 0.70288601]]]\n",
      "\n",
      "full data\n",
      "[[[0.64779416 0.68590197 0.69517914 0.69903447 0.71459429 0.71267351\n",
      "   0.71409191 0.71673093 0.72399386 0.7219988 ]\n",
      "  [0.52154944 0.52310862 0.53282553 0.52718083 0.53709991 0.52978522\n",
      "   0.54277099 0.53688102 0.54443726 0.53999553]\n",
      "  [0.8726286  0.96482141 0.95083008 0.94447182 0.93691809 0.95239155\n",
      "   0.9493714  0.95276295 0.95638539 0.94038139]\n",
      "  [0.50752062 0.50852903 0.49810241 0.50102952 0.4947311  0.50046923\n",
      "   0.49000781 0.49422322 0.48543027 0.49026894]\n",
      "  [0.62007232 0.67079484 0.67376652 0.67304434 0.68618886 0.68665851\n",
      "   0.69233506 0.69529406 0.70288601 0.70206539]]]\n",
      "predictions: [-0.15575464069843292, 0.23807184398174286, 0.38706398010253906, 0.21107828617095947, 0.10108674317598343, 0.1720225214958191, 0.42928677797317505, 0.3034760355949402, 0.030546963214874268]\n",
      "\n",
      "\n",
      "prediction from 10 timesteps 0.4351702332496643 actual [0.]\n"
     ]
    }
   ],
   "source": [
    "outputlist=[]\n",
    "\n",
    "randomindex=random.randint(0,225)\n",
    "print(\"index=\",randomindex)\n",
    "exampledata=np.expand_dims(test_x[randomindex, 0:5, 0:10], axis=0)\n",
    "\n",
    "\n",
    "#print(temparray.shape)\n",
    "#temparray=np.expand_dims(temparray, axis=1)\n",
    "\n",
    "#print(temparray.shape)\n",
    "#print(temparray)\n",
    "\n",
    "#temparray2=test_x[randomindex, 0:5, 0]\n",
    "#temparray2=np.expand_dims(temparray2, axis=1)\n",
    "\n",
    "for i in range(9):\n",
    "    if i!=10:\n",
    "        temparray=np.ones((5,1)) #test_x[randomindex, 0:5, 0]   #zeroes or \"ones\" here seems to work equally well. \n",
    "    \n",
    "    for j in range(8-i):\n",
    "        #temparray2=test_x[randomindex, 0:5, 0]\n",
    "        #temparray2=np.expand_dims(temparray2, axis=1)\n",
    "        temparray=np.append(temparray,np.ones((5,1)),axis=1)       #zeroes or \"ones\" here seems to work equally well. \n",
    "        #temparray=np.append(temparray,temparray2,axis=1)\n",
    "        #temparray=np.append(np.zeros((5,1)),temparray,axis=1)   \n",
    "    \n",
    "    for j in range(i+1):\n",
    "\n",
    "        temparray2=test_x[randomindex, 0:5, j]\n",
    "        temparray2=np.expand_dims(temparray2, axis=1)\n",
    "        temparray=np.append(temparray,temparray2,axis=1)\n",
    "        #temparray=np.append(np.zeros((5,1)),temparray,axis=1)\n",
    "\n",
    "    \n",
    "    #print(temparray)\n",
    "    temparray=np.expand_dims(temparray, axis=0)\n",
    "    outputpartial=evaluate_episode(gru_model3, temparray)\n",
    "    \n",
    "    \n",
    "    outputlist.append(float(outputpartial))\n",
    "\n",
    "print(\"final partial data\")\n",
    "print(temparray)   \n",
    "print(\"\")\n",
    "print(\"full data\")\n",
    "print(exampledata)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"prediction from\",x,\" timesteps\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "print(\"predictions:\",outputlist)\n",
    "\n",
    "\n",
    "#print(\"full data\")\n",
    "#print(exampledata)\n",
    "print(\"\")\n",
    "#print(\"evaluating all 10 timesteps\")\n",
    "\n",
    "outputfull=evaluate_episode(gru_model3, exampledata)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "#print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "#print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "print(\"prediction from 10 timesteps\",float(outputfull),\"actual\",test_y[randomindex])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classifying progression of 10 actual forces and torques in a sucessful sequence longer than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7200, 30)\n",
      "['header0', 'header1', 'header2', 'header3', 'header4', 'header5', 'header6', 'header7', 'header8', 'header9', 'header10', 'header11', 'header12', 'header13', 'header14', 'header15', 'header16', 'header17', 'header18', 'header19', 'header20', 'header21', 'header22', 'header23', 'header24', 'header25', 'header26', 'header27', 'header28', 'header29']\n"
     ]
    }
   ],
   "source": [
    "originaldata=pd.read_csv('forcetorquebuttonresults_renormalized_10_06_2021_newrange.csv')#.head()\n",
    "print(originaldata.shape)\n",
    "headers=[]\n",
    "lookback=30 #save only the last 11 timesteps\n",
    "for i in range(lookback):  \n",
    "    label=str(i)\n",
    "    headers.append(\"header\"+label)\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header0</th>\n",
       "      <th>header1</th>\n",
       "      <th>header2</th>\n",
       "      <th>header3</th>\n",
       "      <th>header4</th>\n",
       "      <th>header5</th>\n",
       "      <th>header6</th>\n",
       "      <th>header7</th>\n",
       "      <th>header8</th>\n",
       "      <th>header9</th>\n",
       "      <th>...</th>\n",
       "      <th>header20</th>\n",
       "      <th>header21</th>\n",
       "      <th>header22</th>\n",
       "      <th>header23</th>\n",
       "      <th>header24</th>\n",
       "      <th>header25</th>\n",
       "      <th>header26</th>\n",
       "      <th>header27</th>\n",
       "      <th>header28</th>\n",
       "      <th>header29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4039</th>\n",
       "      <td>-0.146118</td>\n",
       "      <td>-0.150491</td>\n",
       "      <td>-0.161489</td>\n",
       "      <td>-0.145119</td>\n",
       "      <td>-0.144571</td>\n",
       "      <td>-0.139811</td>\n",
       "      <td>-0.140801</td>\n",
       "      <td>-0.155982</td>\n",
       "      <td>-0.166506</td>\n",
       "      <td>-0.181792</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4040</th>\n",
       "      <td>0.855510</td>\n",
       "      <td>0.854350</td>\n",
       "      <td>0.856338</td>\n",
       "      <td>0.850147</td>\n",
       "      <td>0.851591</td>\n",
       "      <td>0.854438</td>\n",
       "      <td>0.850040</td>\n",
       "      <td>0.839254</td>\n",
       "      <td>0.842253</td>\n",
       "      <td>0.845896</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4041</th>\n",
       "      <td>0.186981</td>\n",
       "      <td>0.186524</td>\n",
       "      <td>0.187637</td>\n",
       "      <td>0.185199</td>\n",
       "      <td>0.188515</td>\n",
       "      <td>0.183551</td>\n",
       "      <td>0.182902</td>\n",
       "      <td>0.192211</td>\n",
       "      <td>0.219140</td>\n",
       "      <td>0.220496</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4042</th>\n",
       "      <td>0.077426</td>\n",
       "      <td>0.079701</td>\n",
       "      <td>0.079563</td>\n",
       "      <td>0.080320</td>\n",
       "      <td>0.082692</td>\n",
       "      <td>0.082281</td>\n",
       "      <td>0.082844</td>\n",
       "      <td>0.103996</td>\n",
       "      <td>0.197891</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4043</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       header0   header1   header2   header3   header4   header5   header6  \\\n",
       "4039 -0.146118 -0.150491 -0.161489 -0.145119 -0.144571 -0.139811 -0.140801   \n",
       "4040  0.855510  0.854350  0.856338  0.850147  0.851591  0.854438  0.850040   \n",
       "4041  0.186981  0.186524  0.187637  0.185199  0.188515  0.183551  0.182902   \n",
       "4042  0.077426  0.079701  0.079563  0.080320  0.082692  0.082281  0.082844   \n",
       "4043  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       header7   header8   header9  ...  header20  header21  header22  \\\n",
       "4039 -0.155982 -0.166506 -0.181792  ...       NaN       NaN       NaN   \n",
       "4040  0.839254  0.842253  0.845896  ...       NaN       NaN       NaN   \n",
       "4041  0.192211  0.219140  0.220496  ...       NaN       NaN       NaN   \n",
       "4042  0.103996  0.197891  0.189500  ...       NaN       NaN       NaN   \n",
       "4043  0.000000  0.000000  0.000000  ...       NaN       NaN       NaN   \n",
       "\n",
       "      header23  header24  header25  header26  header27  header28  header29  \n",
       "4039       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "4040       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "4041       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "4042       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "4043       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originaldata.iloc[4039:4044]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0731408   0.03829234  0.0469334   0.00194419 -0.01112242 -0.02011151\n",
      "  -0.03633799 -0.03225345 -0.0420291   0.00937499]\n",
      " [-0.11749066 -0.23484093 -0.26258131 -0.25717197 -0.26656799 -0.25038209\n",
      "  -0.26268438 -0.26090061 -0.26164099 -0.21694467]\n",
      " [ 0.86082529  0.77558722  0.85436662  0.84721256  0.85877484  0.84311893\n",
      "   0.864341    0.85094293  0.84540413  0.70251442]\n",
      " [ 0.176776    0.27154119  0.30495647  0.30333233  0.30492832  0.29572228\n",
      "   0.30752579  0.3070787   0.3079597   0.27827674]\n",
      " [ 0.07638625  0.02011034 -0.00378486 -0.02415284 -0.03190367 -0.04353291\n",
      "  -0.05766036 -0.05307872 -0.05883769 -0.04239337]]\n",
      "(1, 5, 10)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "\n",
      "prediction from 10 timesteps 0.9415369629859924 actual 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(originaldata[headers[0:30]].iloc[4039:4044])\n",
    "#print(originaldata[headers[0:30]].iloc[4039:4044].to_numpy()\n",
    "classifytest=originaldata[headers[19:29]].iloc[4038:4043].to_numpy()\n",
    "labelstest=originaldata[headers[19:29]].iloc[4043].to_numpy()\n",
    "print(classifytest)\n",
    "classifytest=np.expand_dims(classifytest, axis=0)\n",
    "print(classifytest.shape)\n",
    "print(labelstest)\n",
    "\n",
    "outputfull=evaluate_episode(gru_model3, classifytest)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "#print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "#print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "print(\"prediction from 10 timesteps\",float(outputfull),\"actual\",labelstest[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction from timestep 0 - 10  : 0.10215329378843307 actual 0.0 OK\n",
      "prediction from timestep 1 - 11  : 0.11250180751085281 actual 0.0 OK\n",
      "prediction from timestep 2 - 12  : 0.014482356607913971 actual 0.0 OK\n",
      "prediction from timestep 3 - 13  : -0.0617784783244133 actual 0.0 OK\n",
      "prediction from timestep 4 - 14  : 0.1340702772140503 actual 0.0 OK\n",
      "prediction from timestep 5 - 15  : -0.08373420685529709 actual 0.0 OK\n",
      "prediction from timestep 6 - 16  : -0.030317164957523346 actual 0.0 OK\n",
      "prediction from timestep 7 - 17  : -0.10730362683534622 actual 0.0 OK\n",
      "prediction from timestep 8 - 18  : -0.061510197818279266 actual 0.0 OK\n",
      "prediction from timestep 9 - 19  : -0.02648114413022995 actual 0.0 OK\n",
      "prediction from timestep 10 - 20  : -0.12092877179384232 actual 0.0 OK\n",
      "prediction from timestep 11 - 21  : -0.0014658495783805847 actual 0.0 OK\n",
      "prediction from timestep 12 - 22  : 0.03255348652601242 actual 0.0 OK\n",
      "prediction from timestep 13 - 23  : 0.1300654113292694 actual 0.0 OK\n",
      "prediction from timestep 14 - 24  : 0.1292225420475006 actual 0.0 OK\n",
      "prediction from timestep 15 - 25  : 0.27901598811149597 actual 0.0 OK\n",
      "prediction from timestep 16 - 26  : -0.14482319355010986 actual 0.0 OK\n",
      "prediction from timestep 17 - 27  : -0.01857113093137741 actual 0.0 OK\n",
      "prediction from timestep 18 - 28  : 0.009739898145198822 actual 0.0 OK\n",
      "prediction from timestep 19 - 29  : 0.9846948981285095 actual 1.0 OK\n",
      "okcounter 20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "okcounter=0\n",
    "for i in range(20):\n",
    "    classifytest=originaldata[headers[i:10+i]].iloc[4296:4301].to_numpy()\n",
    "    labelstest=originaldata[headers[i:10+i]].iloc[4301].to_numpy()\n",
    "    #print(classifytest)\n",
    "    classifytest=np.expand_dims(classifytest, axis=0)\n",
    "    #print(classifytest.shape)\n",
    "    #print(labelstest)\n",
    "\n",
    "    outputfull=evaluate_episode(gru_model3, classifytest)\n",
    "\n",
    "    #print(\"\")\n",
    "\n",
    "    #print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "    #print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "    \n",
    "    if abs(float(outputfull)-labelstest[9])>0.3:\n",
    "        result=\"X\"\n",
    "    else:\n",
    "        result=\"OK\"\n",
    "        okcounter+=1\n",
    "    print(\"prediction from timestep\",i,\"-\",i+10,\" :\",float(outputfull),\"actual\",labelstest[9], result)\n",
    "print(\"okcounter\",okcounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header0</th>\n",
       "      <th>header1</th>\n",
       "      <th>header2</th>\n",
       "      <th>header3</th>\n",
       "      <th>header4</th>\n",
       "      <th>header5</th>\n",
       "      <th>header6</th>\n",
       "      <th>header7</th>\n",
       "      <th>header8</th>\n",
       "      <th>header9</th>\n",
       "      <th>...</th>\n",
       "      <th>header20</th>\n",
       "      <th>header21</th>\n",
       "      <th>header22</th>\n",
       "      <th>header23</th>\n",
       "      <th>header24</th>\n",
       "      <th>header25</th>\n",
       "      <th>header26</th>\n",
       "      <th>header27</th>\n",
       "      <th>header28</th>\n",
       "      <th>header29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4890</th>\n",
       "      <td>0.519653</td>\n",
       "      <td>0.629009</td>\n",
       "      <td>0.666283</td>\n",
       "      <td>0.757858</td>\n",
       "      <td>0.748447</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.751999</td>\n",
       "      <td>0.743304</td>\n",
       "      <td>0.741959</td>\n",
       "      <td>0.748569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785070</td>\n",
       "      <td>0.768524</td>\n",
       "      <td>0.756693</td>\n",
       "      <td>0.763045</td>\n",
       "      <td>0.771942</td>\n",
       "      <td>0.774374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4891</th>\n",
       "      <td>0.372140</td>\n",
       "      <td>0.333817</td>\n",
       "      <td>0.319136</td>\n",
       "      <td>0.330614</td>\n",
       "      <td>0.324397</td>\n",
       "      <td>0.318553</td>\n",
       "      <td>0.308498</td>\n",
       "      <td>0.310825</td>\n",
       "      <td>0.340429</td>\n",
       "      <td>0.380643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510981</td>\n",
       "      <td>0.545773</td>\n",
       "      <td>0.534438</td>\n",
       "      <td>0.555681</td>\n",
       "      <td>0.578675</td>\n",
       "      <td>0.561716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4892</th>\n",
       "      <td>0.932075</td>\n",
       "      <td>0.880805</td>\n",
       "      <td>0.871212</td>\n",
       "      <td>0.782250</td>\n",
       "      <td>0.917737</td>\n",
       "      <td>0.913229</td>\n",
       "      <td>0.930457</td>\n",
       "      <td>0.932578</td>\n",
       "      <td>0.922336</td>\n",
       "      <td>0.936276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951116</td>\n",
       "      <td>0.928739</td>\n",
       "      <td>0.959949</td>\n",
       "      <td>0.949016</td>\n",
       "      <td>0.937812</td>\n",
       "      <td>0.899633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>0.641091</td>\n",
       "      <td>0.669016</td>\n",
       "      <td>0.684142</td>\n",
       "      <td>0.675920</td>\n",
       "      <td>0.699291</td>\n",
       "      <td>0.686433</td>\n",
       "      <td>0.692765</td>\n",
       "      <td>0.690845</td>\n",
       "      <td>0.670727</td>\n",
       "      <td>0.643720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498684</td>\n",
       "      <td>0.474195</td>\n",
       "      <td>0.481877</td>\n",
       "      <td>0.466092</td>\n",
       "      <td>0.447252</td>\n",
       "      <td>0.446521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>0.550714</td>\n",
       "      <td>0.634439</td>\n",
       "      <td>0.686677</td>\n",
       "      <td>0.743846</td>\n",
       "      <td>0.772609</td>\n",
       "      <td>0.768783</td>\n",
       "      <td>0.769648</td>\n",
       "      <td>0.771199</td>\n",
       "      <td>0.775574</td>\n",
       "      <td>0.782100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835276</td>\n",
       "      <td>0.823710</td>\n",
       "      <td>0.817117</td>\n",
       "      <td>0.822949</td>\n",
       "      <td>0.825044</td>\n",
       "      <td>0.824857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       header0   header1   header2   header3   header4   header5   header6  \\\n",
       "4890  0.519653  0.629009  0.666283  0.757858  0.748447  0.748698  0.751999   \n",
       "4891  0.372140  0.333817  0.319136  0.330614  0.324397  0.318553  0.308498   \n",
       "4892  0.932075  0.880805  0.871212  0.782250  0.917737  0.913229  0.930457   \n",
       "4893  0.641091  0.669016  0.684142  0.675920  0.699291  0.686433  0.692765   \n",
       "4894  0.550714  0.634439  0.686677  0.743846  0.772609  0.768783  0.769648   \n",
       "4895  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       header7   header8   header9  ...  header20  header21  header22  \\\n",
       "4890  0.743304  0.741959  0.748569  ...  0.785070  0.768524  0.756693   \n",
       "4891  0.310825  0.340429  0.380643  ...  0.510981  0.545773  0.534438   \n",
       "4892  0.932578  0.922336  0.936276  ...  0.951116  0.928739  0.959949   \n",
       "4893  0.690845  0.670727  0.643720  ...  0.498684  0.474195  0.481877   \n",
       "4894  0.771199  0.775574  0.782100  ...  0.835276  0.823710  0.817117   \n",
       "4895  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "      header23  header24  header25  header26  header27  header28  header29  \n",
       "4890  0.763045  0.771942  0.774374       NaN       NaN       NaN       NaN  \n",
       "4891  0.555681  0.578675  0.561716       NaN       NaN       NaN       NaN  \n",
       "4892  0.949016  0.937812  0.899633       NaN       NaN       NaN       NaN  \n",
       "4893  0.466092  0.447252  0.446521       NaN       NaN       NaN       NaN  \n",
       "4894  0.822949  0.825044  0.824857       NaN       NaN       NaN       NaN  \n",
       "4895  0.000000  0.000000  1.000000       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[6 rows x 30 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originaldata.iloc[4890:4896]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction from timestep 0 - 10  : 0.004739541560411453 actual 0.0 OK\n",
      "prediction from timestep 1 - 11  : 0.001866895705461502 actual 0.0 OK\n",
      "prediction from timestep 2 - 12  : 0.001510579138994217 actual 0.0 OK\n",
      "prediction from timestep 3 - 13  : 0.03851709142327309 actual 0.0 OK\n",
      "prediction from timestep 4 - 14  : 0.003079596906900406 actual 0.0 OK\n",
      "prediction from timestep 5 - 15  : 0.02709074690937996 actual 0.0 OK\n",
      "prediction from timestep 6 - 16  : 0.022011790424585342 actual 0.0 OK\n",
      "prediction from timestep 7 - 17  : 0.004578161984682083 actual 0.0 OK\n",
      "prediction from timestep 8 - 18  : 0.022756803780794144 actual 0.0 OK\n",
      "prediction from timestep 9 - 19  : -0.05372391268610954 actual 0.0 OK\n",
      "prediction from timestep 10 - 20  : 0.32199326157569885 actual 0.0 X\n",
      "prediction from timestep 11 - 21  : 0.01846003159880638 actual 0.0 OK\n",
      "prediction from timestep 12 - 22  : -0.11743395030498505 actual 0.0 OK\n",
      "prediction from timestep 13 - 23  : 0.026684287935495377 actual 0.0 OK\n",
      "prediction from timestep 14 - 24  : -0.08368812501430511 actual 0.0 OK\n",
      "prediction from timestep 15 - 25  : 0.5015493035316467 actual 0.0 X\n",
      "prediction from timestep 16 - 26  : 1.030906319618225 actual 1.0 OK\n",
      "prediction from timestep 17 - 27  : nan actual nan OK\n",
      "prediction from timestep 18 - 28  : nan actual nan OK\n",
      "prediction from timestep 19 - 29  : nan actual nan OK\n",
      "okcounter 18\n"
     ]
    }
   ],
   "source": [
    "okcounter=0\n",
    "for i in range(20):\n",
    "    classifytest=originaldata[headers[i:10+i]].iloc[4890:4895].to_numpy()\n",
    "    labelstest=originaldata[headers[i:10+i]].iloc[4895].to_numpy()\n",
    "    #print(classifytest)\n",
    "    classifytest=np.expand_dims(classifytest, axis=0)\n",
    "    #print(classifytest.shape)\n",
    "    #print(labelstest)\n",
    "\n",
    "    outputfull=evaluate_episode(gru_model3, classifytest)\n",
    "\n",
    "    #print(\"\")\n",
    "\n",
    "    #print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "    #print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "    \n",
    "    if abs(float(outputfull)-labelstest[9])>0.3:\n",
    "        result=\"X\"\n",
    "    else:\n",
    "        result=\"OK\"\n",
    "        okcounter+=1\n",
    "    print(\"prediction from timestep\",i,\"-\",i+10,\" :\",float(outputfull),\"actual\",labelstest[9], result)\n",
    "print(\"okcounter\",okcounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_episode(model, data, verbose=False):\n",
    "\n",
    "   \n",
    "    model.eval()\n",
    "    inp = torch.from_numpy(np.array(data)) # should be 5x1\n",
    "    h = model.init_hidden(inp.shape[0])\n",
    "    #print(\"inp\",inp)\n",
    "    #print(\"labs\",labs)\n",
    "    #print(\"h\",h)\n",
    "    out, h = model(inp.to(device).float(), h)\n",
    "    #print(\"model output\",out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8454625996709277"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(278+13082)/(278+13082+2410+32)  #evaluation on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15802"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(278+13082+2410+32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate2(model, test_x, test_y):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []  #labels\n",
    "    #start_time = time.clock()\n",
    "    #for i in test_x.keys():\n",
    "    #for i in range( len( test_x ) ):    \n",
    "    inp = torch.from_numpy(np.array(test_x)) # should be 5x1\n",
    "    labs = torch.from_numpy(np.array(test_y)) #should be 1x1\n",
    "    h = model.init_hidden(inp.shape[0])\n",
    "    #print(\"inp\",inp)\n",
    "    #print(\"labs\",labs)\n",
    "    #print(\"h\",h)\n",
    "    out, h = model(inp.to(device).float(), h)\n",
    "    #outputs.append(label_scalers[i].inverse_transform(out.cpu().detach().numpy()).reshape(-1))\n",
    "    #targets.append(label_scalers[i].inverse_transform(labs.numpy()).reshape(-1))\n",
    "    outputs.append( out.cpu().detach().numpy().reshape(-1) )\n",
    "    targets.append( labs.numpy().reshape(-1) )\n",
    "\n",
    "    #print(\"Evaluation Time: {}\".format(str(time.clock()-start_time)))\n",
    "    sMAPE = 0\n",
    "    #for i in range(len(outputs)):\n",
    "    #    sMAPE += np.mean(abs(outputs[i]-targets[i])/(targets[i]+outputs[i])/2)/len(outputs)\n",
    "    #print(\"sMAPE: {}%\".format(sMAPE*100))\n",
    "    return outputs, targets#, sMAPE       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluatedataset(model,dataset,cutofflist=[0.2,0.3,0.4,0.5,0.6,0.7,0.75,0.8,0.9,1.0]):\n",
    "    headers=[]\n",
    "    counter_truepositive=[0] * len(cutofflist)\n",
    "    counter_falsenegative=[0] * len(cutofflist)\n",
    "    counter_truenegative=[0] * len(cutofflist)\n",
    "    counter_falsepositive=[0] * len(cutofflist)\n",
    "    \n",
    "    for i in range(30):  \n",
    "        label=str(i)\n",
    "        headers.append(\"header\"+label)\n",
    "\n",
    "    choppedheaders=[]\n",
    "    GRUoutputlist=[]\n",
    "    lookback=10 #save only the last 11 timesteps\n",
    "    for i in range(10):  \n",
    "        label=str(i)\n",
    "        choppedheaders.append(\"header\"+label)\n",
    "    #print(\"headers\",headers)    #header0 to header29\n",
    "    #print(\"choppedheaders\",choppedheaders)\n",
    "    for i in range(0,int((dataset.shape[0])-1),6):\n",
    "    #for i in range(0,12,6):    \n",
    "        #print(\"\")\n",
    "       \n",
    "        for h in range(10,len(headers)+1):\n",
    "            successflag=False\n",
    "            #print(headers[h-10:h])\n",
    "            if dataset[headers[h-1]].iloc[i+5]==0 or dataset[headers[h-1]].iloc[i+5]==1: #if label is 0 or 1  (ignores n/a values)\n",
    "\n",
    "                classifytest=originaldata[headers[h-10:h]].iloc[i:i+5].to_numpy()\n",
    "                labelstest=originaldata[headers[h-1]].iloc[i+5]\n",
    "                #print(classifytest)\n",
    "                #print(labelstest)\n",
    "               \n",
    "                #print(classifytest)\n",
    "                classifytest=np.expand_dims(classifytest, axis=0)\n",
    "                #print(classifytest.shape)\n",
    "                #print(labelstest)\n",
    "\n",
    "                outputfull=evaluate2(gru_model3, classifytest,labelstest)\n",
    "                GRUoutputlist.append(outputfull[0][0])\n",
    "                #print(\"GRU output\",float(outputfull[0]))\n",
    "                #print(\"GRU output\",outputfull[0][0])\n",
    "\n",
    "                cutoff=0.5\n",
    "                for k in range(len(cutofflist)):\n",
    "                    if labelstest==1  and outputfull[0][0]>= cutofflist[k]:\n",
    "                        counter_truepositive[k]+=1\n",
    "                    elif labelstest==1  and outputfull[0][0]< cutofflist[k]:\n",
    "                        counter_falsenegative[k]+=1\n",
    "                    elif labelstest==0 and outputfull[0][0]<= cutofflist[k]:\n",
    "                        counter_truenegative[k]+=1\n",
    "                    elif labelstest==0 and outputfull[0][0]> cutofflist[k]:\n",
    "                        counter_falsepositive[k]+=1\n",
    "       \n",
    "    for k in range(len(cutofflist)):\n",
    "        totalevalqty=counter_truepositive[k]+counter_falsenegative[k]+counter_truenegative[k]+counter_falsepositive[k]\n",
    "        print(\"At cuttoff of\",cutofflist[k],\" truepositive\",counter_truepositive[k],\"truenegative\",counter_truenegative[k],\"falsepositive\",counter_falsepositive[k],\"falsenegative\",counter_falsenegative[k],\n",
    "             \"Accuracy\",100*(counter_truepositive[k]+counter_truenegative[k])/totalevalqty,\"%\")\n",
    "   \n",
    "\n",
    "    plt.plot(GRUoutputlist)\n",
    "    #plt.ylabel('some numbers')\n",
    "    plt.show()\n",
    "    GRUoutputlist.sort()\n",
    "    plt.plot(GRUoutputlist)\n",
    "    #plt.ylabel('some numbers')\n",
    "    plt.show()\n",
    "    \n",
    "    #return counter_truepositive,counter_truenegative,counter_falsepositive,counter_falsenegative, ((counter_truepositive+counter_truenegative)/totalevalqty)\n",
    "                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sets\n",
      "At cuttoff of 0.3  truepositive 674 truenegative 6710 falsepositive 437 falsenegative 0 Accuracy: 94.41247922260581 %\n",
      "At cuttoff of 0.4  truepositive 674 truenegative 6835 falsepositive 312 falsenegative 0 Accuracy: 96.01074031453778 %\n",
      "At cuttoff of 0.5  truepositive 674 truenegative 6916 falsepositive 231 falsenegative 0 Accuracy: 97.0464135021097 %\n",
      "At cuttoff of 0.6  truepositive 673 truenegative 6966 falsepositive 181 falsenegative 1 Accuracy: 97.67293185014704 %\n",
      "At cuttoff of 0.7  truepositive 672 truenegative 7018 falsepositive 129 falsenegative 2 Accuracy: 98.3250223756553 %\n",
      "\n",
      "At cuttoff of 0.3  truepositive 1225 truenegative 12242 falsepositive 644 falsenegative 0 Accuracy: 95.43618453688612 %\n",
      "At cuttoff of 0.4  truepositive 1225 truenegative 12441 falsepositive 445 falsenegative 0 Accuracy: 96.84643186166821 %\n",
      "At cuttoff of 0.5  truepositive 1225 truenegative 12562 falsepositive 324 falsenegative 0 Accuracy: 97.7039189284955 %\n",
      "At cuttoff of 0.6  truepositive 1225 truenegative 12642 falsepositive 244 falsenegative 0 Accuracy: 98.27085252639785 %\n",
      "At cuttoff of 0.7  truepositive 1225 truenegative 12708 falsepositive 178 falsenegative 0 Accuracy: 98.73857274466728 %\n",
      "\n",
      "test set\n",
      "At cuttoff of 0.3  truepositive 786 truenegative 14173 falsepositive 929 falsenegative 84 Accuracy: 93.65765088905584 %\n",
      "At cuttoff of 0.4  truepositive 772 truenegative 14415 falsepositive 687 falsenegative 98 Accuracy: 95.08514901076884 %\n",
      "At cuttoff of 0.5  truepositive 761 truenegative 14575 falsepositive 527 falsenegative 109 Accuracy: 96.01803155522164 %\n",
      "At cuttoff of 0.6  truepositive 747 truenegative 14729 falsepositive 373 falsenegative 123 Accuracy: 96.8945654896068 %\n",
      "At cuttoff of 0.7  truepositive 727 truenegative 14823 falsepositive 279 falsenegative 143 Accuracy: 97.35787628349611 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training sets\")\n",
    "\n",
    "originaldata=pd.read_csv('forcetorquebuttonresults_renormalized_10_04_2021_newrange.csv')#.head()\n",
    "evaluatedataset(gru_model3,originaldata)\n",
    "print(\"\")\n",
    "\n",
    "originaldata=pd.read_csv('forcetorquebuttonresults_10_13_2021.csv')\n",
    "evaluatedataset(gru_model3,originaldata)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"test set\")\n",
    "originaldata=pd.read_csv('forcetorquebuttonresults_renormalized_10_06_2021_newrange.csv')#.head()\n",
    "evaluatedataset(gru_model3,originaldata)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5454, 30)\n"
     ]
    }
   ],
   "source": [
    "originaldata=pd.read_csv('forcetorquebuttonresults_cylindernobutton_10_19_2021.csv')\n",
    "print(originaldata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At cuttoff of 0.2  truepositive 310 truenegative 13501 falsepositive 1986 falsenegative 0 Accuracy 87.42799265683358 %\n",
      "At cuttoff of 0.3  truepositive 310 truenegative 14144 falsepositive 1343 falsenegative 0 Accuracy 91.4983857694499 %\n",
      "At cuttoff of 0.4  truepositive 310 truenegative 14530 falsepositive 957 falsenegative 0 Accuracy 93.94188770019623 %\n",
      "At cuttoff of 0.5  truepositive 310 truenegative 14813 falsepositive 674 falsenegative 0 Accuracy 95.73336709501804 %\n",
      "At cuttoff of 0.6  truepositive 309 truenegative 14999 falsepositive 488 falsenegative 1 Accuracy 96.90447553332912 %\n",
      "At cuttoff of 0.7  truepositive 308 truenegative 15132 falsepositive 355 falsenegative 2 Accuracy 97.74007722985377 %\n",
      "At cuttoff of 0.75  truepositive 305 truenegative 15177 falsepositive 310 falsenegative 5 Accuracy 98.0059504969298 %\n",
      "At cuttoff of 0.8  truepositive 304 truenegative 15228 falsepositive 259 falsenegative 6 Accuracy 98.32246629106793 %\n",
      "At cuttoff of 0.9  truepositive 298 truenegative 15320 falsepositive 167 falsenegative 12 Accuracy 98.8668734569855 %\n",
      "At cuttoff of 1.0  truepositive 85 truenegative 15417 falsepositive 70 falsenegative 225 Accuracy 98.13255681458504 %\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA4jklEQVR4nO2dd5xU1fXAv2d3WXpvIiBLU5oKuIINFUTFikmMwRijBiTW2H6JqNEYjf4s+SVGg4UYY6+osYGKWFCqi/QmywLC0paO9F3u7495s/tm5s3Mm5k3bed8P5/97Hv3tTP3vXvPveeee64YY1AURVEUO3npFkBRFEXJPFQ5KIqiKCGoclAURVFCUOWgKIqihKDKQVEURQmhIN0CxEOrVq1MUVFRusVQFEXJKmbPnr3ZGNPazblZqRyKioooKSlJtxiKoihZhYisdnuumpUURVGUEFQ5KIqiKCGoclAURVFCUOWgKIqihKDKQVEURQnBE+UgIs+JyCYRWRjm+GUiMl9EFojINBE51nZslZU+V0TUBUlRFCUD8Krn8DwwLMLxlcBpxpijgfuBcUHHBxtj+hpjij2SR1EURUkAT5SDMWYKsDXC8WnGmG3W7gyggxfPVRQlOsYY3ipZw76DVekWRcki0jHmMBKYaNs3wKciMltERoe7SERGi0iJiJRUVFQkXUhFqS1MXrKJ34+fz/99uizdoihZREpnSIvIYHzK4RRb8inGmHIRaQNMEpGlVk8kAGPMOCxzVHFxsa5QpCgu2bnvIACbfzyQZkmUbCJlPQcROQZ4FhhujNniTzfGlFv/NwHvAgNSJZOiKIHMLNvCsMemqAlKSY1yEJEjgHeAy40x39vSG4pIY/82cBbg6PGkKEryuee9RSzdsItVW3anWxQlzXhiVhKR14DTgVYishb4E1AHwBjzNHAP0BJ4UkQAKi3PpLbAu1ZaAfCqMeZjL2RSFMWHLhOvxIMnysEYc2mU46OAUQ7pZcCxoVcoSuIcqDzE2C9Kufb0rtSrk59ucdKOpFsAJavQGdJKreWlGav5x+TlPPNVWbpFUZSsQ5WDUmvxD6ruq8ztwdVssCo9/dUKFqzdkW4xFBuqHGohhw4Z/u/TZWz+cX+6RVFyjNJNP7Jsw66Yr3to4lIu+Oc31fuHDhlMEgZL9h2sYtLijZ7ftzaiyiFDKRrzEU99uSKua2es3MITn5dy+/j5rq/ZuHMfk5doofGCheU7WLN1T7rFqCaesYZ46+Whf/uKsx8LmaYUM13unMDVL86OeE7VIcOeA5Ux3ff+Dxdz9YslzPlhW/STcxxVDhnMwx8vjeu6Q4d8/2Mxp1w0diojX0hN3MPZq7cx9ovSlDwrHZz/xDcMeuSLdIsRF5JBo9afRWmsXPbsDHrd80nY4199X8GU7wOjKfxgKe2d+2JTKrlIVq4hrXjP+h37Uvasnz01DYDrB3dL2TNzmWwYc4iVil37mVEWNpwbAFc8NwuAVQ+dlwqRah2qHGoZD05Ywrgp6p2jOJBBvYJE2bFXQ4EkGzUr1TLsiiEbJj8tWLuDz3SAUEkRFbvUScMt2nNQ0orfQyWZXf9a1GBWEmRpHJ5UuYr2HBSllmN3Cb383zN5b265i2uSKZG3xOPymgw32dqGKocs4LsftvH50thNL5n+/e/YezDdIuQcXy/fzE2vz023GDGxadc+tu7WMYZUo8ohC/jpk9P4zfPh3Ux37TvIOf/4Oq7JR+lk+oot0U9SEkYc/FMfn7w8DZLEx4AHJtP//kkJ3WPr7gP86tmZHkmUG6hyqAVMLd3MkvU7+duk7F/pKxmtxEQ7UAerDvHxwvWemSJmlG1hdYpCYk8t3ey4NsPfJn3vcLY7jDHc/PqcNCv32EaSXpy+im9KNydJFm+44dXvQuZlpBNVDilg0bodzFoZ2Sc7EaqsSW95QS1EY1WLP396GiOf/zbh5xhj+GzxRqoO+e5742tzOC7BFl0wXrQSE6Gy6hCbdgbO+Xhi8nKuefk7vli2yZNnjBg3g9Me/dKTe0WidNMuLnt2Jne/5+0SKZWHDP+du47L/+19S3zxup28O2dtTNfsO3goaTOe563ZXv29J5sP56/n19bcjExAlUMKOO/xb7jkmelJu/8hq0WblxekHKxv+ttV25i8NPGK7ZNFGxn1YgnPTPGF9fhg3jq2JNTKT++gyL6DVQEF/6vvK7jm5dkMeHAyO/bUjIes3b4XgK27Yxsj2bHnILNXJ69REPX5e32zgP3fgWSB39a5j3/NLW/Mi+maMe/M5ydPTmP9jr2eyvLdD9sYPnYqXe+cwNINOz29dzagyqEWUK0ckhz7oMIK5Fe+zV0hLN++lwcnLOFQmJbXonXeFLhY4+v46XH3x4x5uyb+1BXPzeKzJT4lumt/4oPllz83k589NV09Y5KMP5rr7v3uvwM3b2T99poeZCrn4oyfHVvPKVmocqgF1LQMA9lfeSjlsti56bU5jJtSxry12x2P2+vMcAokEp8t3sikxRvpdc8nEc12/nz5cX8l+4PiTb0VpiDGW5/bA+7NtyqtM/72FR8v3BBy7sLyHVnfIt26+wAlq5zz/tNFG9iWwV5GxX+ZxAMfLU7qM/YdrGLsF6UcrHJfFv/nrdCe08LyHRxIcXn2RDmIyHMisklEHI2b4uNxESkVkfki0t927AoRWW79XeGFPIqPuWu2x3Xdxws3RFxgPlyFGsyKih9dP/OVmatdnwvw7aqtjHqxhKtf9HlxzV7tszkbYyjf7tyz6fOnT/jZU9N4cMKSqN46784pp2jMRxHzwc7cNdt55OOl/P2z0IHesord3P72fIwx/PWTGqeB85/4hmGPfR1y/tpte1w/14kZZVv4MYZWtJ/XZv0QcZKYMYanv1rBBisOlwEufnoaFz8dajLdtvsAo1+azagXw3vZ+e9nN+G5xamTHEmhOzk5bP7xAP/6emXMz/az72BV1N7KuCllPPrJMl6ZEdv3DT6z5KyVW1mzdQ/nP/ENf/5gUbyixoVXPYfngWERjp8DdLf+RgNPAYhIC3zrTQ8EBgB/EpHmHsnkmiXrd3Lty7Nj0u7Zyo69B7nk6ems2bqHg1WHQlrss1dv45qXZ3Pe46GVlp/gFszcNdtDWuQA26xCv3u/c0X3nW0Qcfx3gROznvsmcqEN1yIdN6WMkx/6nNJNgZXch/PXAbCwfCfjppRF9dbxH7eHW3AyDx06ZHh79louGjuVJ6OEWP908Ub+6SIa7SkPf8G1LzuHq95fWcXwsVPDttanlW5mxLgZ3PDqd9XmxkhMXLCeheW+Hs4d7yyIeO6Kih95aOJSrn3FJ1vVIUNZhc/ravWW3QHfxQGrLM1evY1pK5y9hKaWbuGhiUv5Y4QB85ten1O9PWLcdL60nAIC3LaDFMX6HXtDemQvTo+9co7GwAcn0/tP4aPCGmOqv6O9B53rln0HqwLKgZ9nvy7j1/+ZxSXPTGfTLp8yfmXmD5TF0OBKFE+UgzFmChBp5G048KLxMQNoJiLtgLOBScaYrcaYbcAkIiuZpHDLG3OZuHADyzcmlvG3vTmPojEfeSSVMx/MW8eufQfZuDM0iqpTa6oySOFNWLCeWau2MvaLUrrfNZHrX/2OcVNqKrWd+3wV+oqKUFfLnWEmrV00dip3/9dXwLfvOUC3Oycw6oUa76hb35zreN00myvkvKBezr8t5fDCtFX0ve9TFpbvoGjMRzw/1VlpPPzxUorGfMT/TvSFOV+zNbD38G0Ub7FwIcTveGdBdYv09+Pn8/dJ31cPYu+vrOKF6au4zWYGWFTubCbasfcgu6KEif500QbusSrKL5b5XBrHTVlB0ZiPqtfaWLFpN/PWbOePVn6/OvMHtu/xKcrpK7bwS8uXf9mGXfzcoUVv57j7J3HtK99x/hPfhHy35z7+NRMWrOfF6asoGvMRW3cfoNL63QsdfuNpj37JL/81o3r/2a9rYnz98l8z2XugpoFQvn0vRWM+4onPl1fLHY735q6r3p5RtpUr/+P7rj63O1gE6cAT//fzgB6Zk+nO/i5KN/3I9BVb+NeUMrbYFsiasHB9WLnW79gbdRLnso01Csw4jHIs27CLO99ZwE+fnMa0IDfbv3y0hCXWmJxdxw/5v68iPtNLUhVbqT2wxra/1koLlx6CiIzG1+vgiCOOSIqQTi8wFt7+LtTckqimt7tV3vjaHD6YV1NYLinuwCMXHxtR7m53TazeNsbw7pzAFvrEhRuYaLOHX/Wfmkr92a/L+MtHS3jxNwPo3Kohj9pMIn5l4OfNkrW8WVLz+/0DuwCb4gh2Vr59Lw9NXMrTX/kU1/lP+GIwPfXVCq48uXPU69du28M/LNNRtBb9cfdPCut19U3pZrq3aVS9/4/Jy2nTpC6XDezEmX+bUr0+gB97hRALxhhGvxTaW3jic5/SGvlCCS+PHEiLhoWAL0bQ4nU7ufPdBXy2ZCMndmnJt2F6E35WBc2tiOZp9uSXpdVrg6zbvpeC/MgODyWra1rAwd/ZI58s5U8X9AZqeigzLYUd64qFwQsplW32/a63Zq/lZQfzjZPp7nev1fRIhv6tpsKdumIzz181AICP5tcoh79++j2dWjakW5tGfDBvXbXs4LM8dG7VkMc+W85NZ3SnfmE+AJVVNeXykY+Xcd3pNSHq127bE7Ao0gMTloT9vfem2JzkJ2sC7xljxgHjAIqLiz11/wieQfryjNWc0+cwWjaqm/C9Y9X0m3buo9SmUAY8OLl6264YwFchjz61S/V+NF+lzndMiEmWv3zk+2B//dwsnri0X8Cxl2K0oW7cuY96BfkUFrjvrPoVQ+B93FUkd7/nvkBFqySXbwpU8He9u5DPl2wKUQzReOrL8CalL8NMfrK3Gss2/0jT+jVW17v+66tkt+w+ELFy8TN7daj5IhIHKw35efF5wAVfF8+4QjgGPfIFBQ5yeRGqPlLv7kabQmnfrH719jn/+JoBnVswa+VW6tXJ4+ahR4a9x7bdB7j/w8WMGBDYwI1kAXTqqaWCVHkrlQMdbfsdrLRw6WnBGFi+cRd//O/CkPgz+yurQkw08bDvYFW1jdeJC/85lV/+y/3kop+MnVa9nUyHyWCzT6wMfHAyJz/8Odv2hK+I4x1ATwfxzBtxMtX5+TFMpRQ8sGxfZ3nOD9vD3s+LxZvi7QWB85yK/ZVVnPboF57MAq5M0cQ0t/i95SKNW67bvpd+90/inTnlvDbrh1SJFjepUg7vA7+2vJZOAHYYY9YDnwBniUhzayD6LCstZeyvrGLJep9m/nLZpmr3z2DvhqP++LEnE9luf3s+5z/xTdi48hscxhIisTcBr5ZYeDbKALEbonnQXDR2asLPqM1k83SJih/389L01azekjlrayeLjTv3sdxBsdrrj8Qmj6YGT8xKIvIacDrQSkTW4vNAqgNgjHkamACcC5QCe4CrrGNbReR+wG/ovs8Yk9IppZtsZoq5a3Zw+lFtwp77XYSWmlv8rT3fxK1As5WbUMqRyPz5r0o43DgTpJtYZlgHN3K+Xr6Zr5dndmwjrxhomYI/vPGUgHR7XRPce8pEve+JcjDGXBrluAGuD3PsOeA5L+RIFbNWbuWLZZu4fVgPT+8bbyjlbG5Rxksu/OTnp61KtwhKAiQ5YEHSyZoB6dTgrsrxdw+9Vg6J4hSaORzpUijZXmBSSSatd/HS9NUc0bJBusVQUogqhyzHXsfnSgyfeEJt1AbCvt8kvnf/nd8oWRPxvNqCtl1q0NhKStZx1N0To5+kKGkgkp5OdB5VqlHlEIbF63c6ehxkGvaQ0/+duy7CmbWHg1Wm1rXwsiGctpJbqHIIwm4TP/PvU8KfmEE4RfxUah/Z1e7MTeIdU8tEk7AqBxsZ+H5csdbl+gqKoiSXsV/UzOrP9t6gKgcbWaobcpLa9q4S8uJSF7DaSZpfqyqHFJILIcGV2Fm3fW9i4RSytcubwfijE3tJtr0mdWW1kWy730NWOOlMINs8J2ozv/r3zOp1ESKRjsolE23hycTfCXv8s8iLQeUCOd9zSEaPvGjMR6zcHFrY/TGcwLc2QCwrpUUim4pvttthk4HTKmWZQqSV4WozqQ7sl4k6OOeVQyI8Pnl52O7nN6WR48jMWrmVW96Y64kcuda6g9gWk1cUt2z3MLR4tg8FqXIIIpaW7d8mfc/9HyR3gXLFmVvfDF2EvbaTe02A1BO8dkcuo8rBRjyFb48VMvt1FwOKOdjADyF4hTBFyRUiFX/HMcA01xeqHDxiTJTF2cG3CHuu80Uci+QoSqrJdpOQF+SUcvhxfyXPT13pqY3+o/nrGf1iiatz1wWtzpXOnkS0xe6V1JHod6Ad0tTjpg55Zab7pXQz0aqQU66s93+wmDdK1lDUqqHjoj7xvqBPF29MULLUMzFNITciudCKZGYhUZR4eHlGoKk52zojOdVz8K9fvO9g7ZqMlk0VajbJmm40rzKXWNZOcXc/T2/nCZ4oBxEZJiLLRKRURMY4HP+7iMy1/r4Xke22Y1W2Y+97IU8ipOMl7dp3kKlRXF8joRPacpsMrFeUGMnE+T8Jm5VEJB8YC5wJrAW+FZH3jTHVPp7GmFts598I9LPdYq8xpm+icnhBurT3Da/O4augNWVj4fuNtcP9TshN+7nb7y4X57Oki2RU1tn29rzoOQwASo0xZcaYA8DrwPAI518KvObBcz3B3j1Mddnzt/i/z4J1I7wisjufoijV1ILAe+0B+xqCa620EESkE9AZ+NyWXE9ESkRkhohcFO4hIjLaOq+koiL+VnasLNuwS2fjKooSQPl2b8PkZ6JpONXeSiOA8caYKltaJ2NMuYh0AT4XkQXGmBXBFxpjxgHjAIqLi5OSk4bQ3sPZj03hpK4tPXvGgcraNRjuJblqVlJXViUTl0X3oudQDnS07Xew0pwYQZBJyRhTbv0vA74kcDzCU+LN/1krt3omw4adgXMdhj02hfVB8x8UBTLTg0XJHbxQDt8C3UWks4gU4lMAIV5HItIDaA5Mt6U1F5G61nYr4GQg6cGKMqnQ5WrUS0XJZJJRR2SbQ0HCZiVjTKWI3AB8AuQDzxljFonIfUCJMcavKEYAr5vAHOoJPCMih/ApqofsXk6pwP4NGGNSqjiy7FvxhEgFJBO71oqSq3gy5mCMmQBMCEq7J2j/XofrpgFHeyGDkh1o/R8/udiYyBV+2Lon3SKEkFMzpOMl1Qt/KIqSW2Sio4oqByWlaOs3fg5p5ikpJKcC7ylKNvOvr1emW4Sc4CdPTmXOD9s9v2+2qfac6jk4NbzsA9CpbpgtWrcz+kmKYrH5x/3pFiEnSIZiyEZySjn4sTsk3f9hbM5RH8xb560wiqIoGUhOKgc7ExYErmsQzZU1lglx2ebXnAo0RxQlO8hJ5eCvoHbsPRiQ3q5pPU+fM2V5/GG4FWX1lsxzb1Ryh5xSDsG9ggue+CZg//iiFrzzXbjIH7Gz3VpcSLGhvakQ9ldWOaaXba4dodiV7CSnvZWCJ5488skyHfRTUk64lQlVjyrpJKd6DtFwoxgWlO9IgSS1mEwKbFVLUCWiJIOcUg5eFKK5a7YnfpNcRmsy11TscteL1QaLkgxySjn40bZr+tBIJO7Z5FI5KEoyyEnloKQPbeUqSnagykFRFCUFZJtFVZWDoiiKEoIqB0VRFCUEVQ6KoihKCJ4oBxEZJiLLRKRURMY4HL9SRCpEZK71N8p27AoRWW79XeGFPOHJMqOfoihKmkh4hrSI5ANjgTOBtcC3IvK+w1rQbxhjbgi6tgXwJ6AYX80927p2W6JyRZE5mbdXFEXJerzoOQwASo0xZcaYA8DrwHCX154NTDLGbLUUwiRgmAcypR1VP4qiJEK6lw71Qjm0B9bY9tdaacH8TETmi8h4EekY47WIyGgRKRGRkoqKCg/EVhRFUcKRqgHpD4AiY8wx+HoHL8R6A2PMOGNMsTGmuHXr1p4L6DU6uqEoSjbjhXIoBzra9jtYadUYY7YYY/yxAJ4FjnN7raIoipJ6vFAO3wLdRaSziBQCI4D37SeISDvb7oXAEmv7E+AsEWkuIs2Bs6y0pJKqFdqybUakoiiKn4S9lYwxlSJyA75KPR94zhizSETuA0qMMe8DvxORC4FKYCtwpXXtVhG5H5+CAbjPGON+Hc6Y0WFiRVEUN3iy2I8xZgIwISjtHtv2HcAdYa59DnjOCzmi42vKH6g6RGVV8j0B1GNWUZRsJSdXgrvh1Tn0ad8kqc+4+78LKchT7aAoSnaSs+EzFpbvTPozKnXxAkVRspScUg7rd+xLtwiKoihZQU4ph3Xb96ZbBEVRlKwgp5SDoiiK4o6cUg67D1SlWwRFUZSsIKeUQ7oDWSmKomQLOaUcFEVRFHeoclAURVFCUOWgKIqihKDKQVEURQlBlYOiKEoWcTAFceFAlYOiKEpWocpBURRFCSFV68SoclAURVFCUOWgKIqSRaQq1rMqB0VRFCUEVQ6KoihKCJ4oBxEZJiLLRKRURMY4HL9VRBaLyHwRmSwinWzHqkRkrvX3vhfyKIqi1FZMikakE14mVETygbHAmcBa4FsRed8Ys9h22hyg2BizR0SuBR4BfmEd22uM6ZuoHIqiKIp3eNFzGACUGmPKjDEHgNeB4fYTjDFfGGP2WLszgA4ePFdRFCXnyKYB6fbAGtv+WistHCOBibb9eiJSIiIzROSicBeJyGjrvJKKioqEBFYURVEik7BZKRZE5FdAMXCaLbmTMaZcRLoAn4vIAmPMiuBrjTHjgHEAxcXFqVKeiqIoOYkXPYdyoKNtv4OVFoCIDAXuAi40xuz3pxtjyq3/ZcCXQD8PZFIURVESwAvl8C3QXUQ6i0ghMAII8DoSkX7AM/gUwyZbenMRqWtttwJOBuwD2YqiKIqNVIXPSNisZIypFJEbgE+AfOA5Y8wiEbkPKDHGvA88CjQC3hIRgB+MMRcCPYFnROQQPkX1UJCXk6IoipIGPBlzMMZMACYEpd1j2x4a5rppwNFeyKAoiqJ4h86QVhRFySY0KquiKIqSLlQ5KIqiZBEmRV0HVQ6KoihKCKocFEVRlBBUOSiKoighqHJQFEXJInQNaUVRFCVtqHJQFEVRQlDloCiKkkVk03oOiqIoSi1DlYOiKEoWsWrL7pQ8R5WDoihKFlF1SGdIK4qiKEGoK6uiKIqSNlQ5KIqiKCGoclAURVFC8EQ5iMgwEVkmIqUiMsbheF0RecM6PlNEimzH7rDSl4nI2V7IoyiKoiRGwspBRPKBscA5QC/gUhHpFXTaSGCbMaYb8HfgYevaXsAIoDcwDHjSup+iKIrigEnRiLQXPYcBQKkxpswYcwB4HRgedM5w4AVrezxwhoiIlf66MWa/MWYlUGrdT1EURUkjXiiH9sAa2/5aK83xHGNMJbADaOnyWgBEZLSIlIhISUVFhQdiK4qiZB8aPiMIY8w4Y0yxMaa4devW6RZHURQlLRzKIrNSOdDRtt/BSnM8R0QKgKbAFpfXKoqiKCnGC+XwLdBdRDqLSCG+Aeb3g855H7jC2r4Y+Nz4RlXeB0ZY3kydge7ALA9kUhRFqZ2kyK5UkOgNjDGVInID8AmQDzxnjFkkIvcBJcaY94F/Ay+JSCmwFZ8CwTrvTWAxUAlcb4ypSlQmRVGU2kqKQislrhwAjDETgAlBaffYtvcBPw9z7QPAA17IEY13rjuJnz45LRWPUhRFSQr5eZKS52TNgLQX9D+iebpFUBRFSYgTurRIyXNySjkoiqJkO74pYslHlYOiKIoSgioHRXGgTeO66RZBUdKKKgdFcSBVHiGKkqnknHL4z1XHp1sEvvr96ekWQQGO7dA07LH6hcktGlcP6pzU+ytKouScchh8VJuE79GqUaDJoSAG17JB3VvRvln9hGXIRf52ybGe3q9uQfgAwPXrxB4c+JrTuro+967zAgMXX3lSEU3qeeJZriiekHPKIRZ+2s8xBiAlfxwasN+ldUPX93xp5EAK8jXb4+Gn/Tt4ej+v/cUbJ1C592zXOKIXypAeiTdqlOzntjOPTNmzcrqWatsk8qBjxxYN+Nevi6PeJ9E4WIlUKsHcdW5Pz+6Va/zPWUcy884zeOe6k1L+7J7tmtCzXeOwx1MVwz+T+dUJR7g+1025zUZuPKN7yp6V08phaM+2TBszhPOObudwrA03DunGmb3aJl2O8dekvjICaNe0nif3ufg4b1v0Tjj1zpo3qBPzfe4b3jvssRuGdKdtk3r0P6J5XAq/bkH8xUkQRp3SJezxTFMNg49yHxk50vhKLN/gXy462vVzCxN4F4qPnM7BVo3qcniz+vz158dyTNDg5NCebR3NP69dfUJI2qM/j98WftMZ3TnqsPAtRj9Ht2/K+ceEKrFgOrZwP55RxyPzVrc2jTy5TyS6tApVDtPGnBHTPW4e2p1fn1hUvW88rnJPdzGedWzHZoy/5sSQdBEYGGHmq5cdh8sGum+Bh+PwZvW54NjDo5634N6zXN/Tf7+Tu7UMOfbhjae4Fw5IzTSx8HRPQZlINjmtHG4Y0g2A+oX59OvYzNU1J3YN/XD7urw2ET648RQeuOjo6v0eYRRKh+YNXN/TqXL8/LbTHAunncIgpTJ6kHOL9+WRA6u3X716IGN/2d/xvHD29NIHzuHpXx0XVo76hbENGjeqG7/5rkPz+nx266n8LkK33k3P4UDlIYqLnJVA43rhe0JuY/gP631Y1HOCw8jMuydyBb7iwXNpFtRLM0QP4/Dwz46O+JvAuRK/pLhjSFqf9s6eZXef34sbBneL+Aw79erkhR1L9JKhCVoc5tx9pkeSxE9OK4dILWenojg7aCDaC2JpEIpN3P6dEo8T5eSt06V1IyRKu6tDUO8kL8zAbmebKeikrq0475h2HNEiVHmd0dNZORTk51UPGnvRcg4e8G1Q6FMW9w3vzRujA3uEwQpLBLq1acxZVqHv1a4Jf7X1GKeNGeJKOSxZvzMu2d3yz1/2i3pO8Lh30yjmufw8Ic9hsHzE8ZF7IL9wOH7d6e48ui4pjm6q7NamESNP6cz/nH0Uqx46z/Gclg0LA/a/uX2Io0byuvd7+pGJLUjWPEjudJDTyiFWWjYKHcAuaum+pe5IDLWe/Zu+NEzBjGWVqOsHu3e9jAcnlTHlD4ND0hoWFnD7sB6u7hlciQfz158fG7aCLMwPlOiRi4/hlqFHcvkJnRjYJbC39IdhPfjHiL7V+49e7FME/joyL8831nJsh6Y8+JOjObxZ/bhtGVec2Ile7ZpEPMdvmx/UvVXE8+ymUHvPzU48oXmCFZ/gUxrBPYpouH32IxdHN9VGUiB+J48RAwJ7Ia0a1XVs/JzTJ3yP67NbT40qC/hMv36Cv6dINIixB5wqVDlYBFepbuvYE2L4CBLF3/JtWJgftpAFyx3JX/+ivs7d62i2eLd1SyyV0M+Oi9zV999rYJeW/GNEX96+Nvwg/vnHhNrCR5/ahUuOD60obhra3dGFND9Pqk10w3ofVv2eex7WhJGndOapy3zmrvduOIVfWjb8ZvXDt/acxkz8/Hl4n7C9Lz/3XtibJy7tx//FMNfjFJsiOaJFg2rnimg9QydeHjWQm4d25/6L+gA15cWpnPQ+vEnYHkJwD8Q+cBwslZPH0WFNa3qtwb/DboKsVyef5Q+cw/+cdVR12qUDfO/J6bu8Zaizi+ixHZrSrU1jLj+hk+NxL5h062mO6U3r16HYAwtBvKhySJBEzR0xmZVcXBOi5Gwpvz21S4CycBPdsUUC3Vu3ldCZvdrGNB4wvG97jgtTaPxPfCto0PfOc3tWm9Ee+EkfrjypKOpz+h/RjD9d0IuHflYz1pOXJ9x9fi86OpjHCgvyws55ucaqLO327nevO4nfn32U4/nBNCgsiDoAHGl8ZlD3VtSz3r1I6Hu91cF/3t4r6Nq6ETeHqUCDuW94H/4QpifYsmEhyx84p3q/nVXZ23t7/jLl5Cl4z/m9OL7I9+4PD5pMOqzPYQFjcXXy8wK+cf/v8ac8HPRenZ718ihf76t98+RMXP345kG0b1afZy4/jlevDuzpzfvTWYy3NYIu6hvdAcBLVDkkSKKLffvt3m7wf+fG1Gzb6/fXrj4hQJ5g+/6g7q1Zcv+wmOQLN/DtBjc9hzl3n0nDugU0KCxg1CnhXR7dZrP/mccXtQirQC4b2Il7Lwzv0lpzL+GqkzvTrIF7BVlZ5SyohGxAvyOac30Mg6nRGBbBNAKBcyW+Cxrw/N0Z3fn92UcFtNZn3HEGS+5z/l4iv1rnPOjephGXn1gUMNbnb7y0aFDo6nupX5jPm789kVdGDeTco6MPvjthL0eR6NqmUfWAuv3cP57nzVyiAZ1b0OMwnznx7N6HcVLXyCbD/LzUVtcJPU1EWojIJBFZbv0PKY0i0ldEpovIIhGZLyK/sB17XkRWishc669vIvIkQrx1fLyqwe9VEm0inh1/S/yQMSGt8iPbNuLEri0Dfsd/rz85SNbYpX368vCt0WhEK+sTfjcoYODNaRAuVgOIvYJp7TBGlGyqMjhin18yf2t66pghTLxpUPXx6wfXzOvp2KI+9erkR/UIc56c5/zWfl7cIfys9BhetIhwcrdWjj1fN+XYX3ainRpuHk0s4XK8JEXLOFSTqCoaA0w2xnQHJlv7wewBfm2M6Q0MAx4TkWa24783xvS1/uYmKI8rxv6yP+/fcHLEc9xWpPEqlXp1Ys96v332t6d1rf5QOrdsyJFtG3HvBf6WcI1AwaaDeGRtEsUVMSJRPuZeh0cehI3vkTUPvf0cn2kjFgWcKNEGjN2Y2gaEcXUFwtZoQ3u6cJ00fhl8tG9Wn54OA+Ff/2EwH944KCQd4OzebWnduC5XnVwU/Xlx4sX8E6eKVIKOhSsPHZrX5+WRAzmmQzNHmcKZY6NV3uMuPy7QNJi57Qgg8TWkhwOnW9svAF8Ct9tPMMZ8b9teJyKbgNbA9gSfHTfnOUwm69+pGS/NWE2X1g0pq9gdcGz6HUPCFupEP+RYWgP5eVLtsud3iayTn8cnt9i9KZLfvBARmjeow7Y9ByOf54EsseZugc0jya+AvZDDLfcN78P1g7sx6JEvHI9H+17KHjwXEeh8x4SI5wUT/B0FB4e0PzvaN+c0nuKnTeN6fHtXZJfu4Pu7Ngm6Oy1u/HL53VbbNXOenV2YnxcwmA+Bv8HeW3rysv7MXbOdcVPKIj77t6d2YUiPNpzV+zA+mLcu7Hm/P/so13Oukk2iPYe2xpj11vYGIGLzRUQGAIXAClvyA5a56e8iEraJJyKjRaREREoqKioSFDuUn/TrwNQxQxjY2eeVYv8Y2jWtz2Fhpvm7+fD/6mIG9YDOLaoH2uz89tQu3H1+r5D06tZPUGXj/7D8HjQBH3V0UR1Z9pdhTLxpEA1tJgY3dvhYu8Ejjg+d/BTLvdo3q88p3SK33JNNYUEeHRIYvMzLk4iOAm7e4Te3D2aygweMqe45eFcNZ4I/vlv8v/s3J3fmrWtOZPBRbbjjnB6uXEmdQuz8tH97zj26neOxYO44t2dIxIWjHULGXz+4GyeF+YZTbcyKqhxE5DMRWejwN9x+nvGp07Dfroi0A14CrjLGHLKS7wB6AMcDLQjqdQTdf5wxptgYU9y6dWITTMLRvln9mCs0/wBwJG8bN7GH3vztibwVFGOpQWE+d5zbk5EOA7XVdtOgHM+zehcP/uTokGvipW5BPj3bNeFd2xiGmwIV68fsNI/ETzQlXK9OHlPHDIlp8DhZiAgTfudslklFL6ZD8waOE9uqlYOHIrwyynkuRSLY3/Xk205j2pghnt4/L0843jLd/fa0riwOM+huxz9vwj4O0dgq8/E2usac425uT7qIqhyMMUONMX0c/t4DNlqVvr/y3+R0DxFpAnwE3GWMmWG793rjYz/wH2CAFz/KC9y+cP+HfFbv2KbLR7v/oO6tWHjv2WGPx1PA3Ub2dHOav4d189Dw4SS8WAg93TFy4iXsPJQ0GpqrzUoe3rND8wYhITtiub/9W3P6Xrq2bhTishrxfhHy1/XnGOE8EaF7W58HX7iQHm6JNbZZKudUQeJmpfeBK6ztK4D3gk8QkULgXeBFY8z4oGN+xSLARcDCBOVJmFgLTqJFPVxLMk8k4sQoN3MegvGqWhKgVWNfCz1SwU1Fxe53tXRSaNkc5XpQ91YRJ84F4yavk9FzgPgU3qe3nMrXDrPlwaNQKQ454oFuAODkbq2YfNtpKYlGbOdnKX5eogPSDwFvishIYDVwCYCIFAPXGGNGWWmnAi1F5Erruistz6RXRKQ1vvcxF7gmQXm8w+UXGu88h2iXRburv4BHe779aO8oIRpi4epBXWjVqC4XR1iAJxWud26ekWoXQAh8v6+OGkj59r0xXf+SFfqiaMxHnsnk1r8/VtwPONe8iCOt1rf93WRTL7Fr69BYTMmSf/Jtp7H3QFWS7h6ehJSDMWYLEBI32RhTAoyytl8GXg5zvbfGRA+IuSJJsKCFD4MRVT3E9Pyl9w+rniHrxPNXHR/xeDB18vMco2fa8cK+3sZyQ3UT1jwT6XFYY07q1orxs9d6cr9EKvae7ZrwyaKN1Xmaapx6GKno3TWtX4cdew/SqrG73+0kUsSoBEn+EU6KKBXoDOkwuH3d3ds2iu0Cl/ePZq93q8TcVs+nH9XGe5tmHLqh/xHNAvaP6dCMd647yTG8QzaRrpXchttCLtw4pDvjrzmR4zpFDrUdK8G/LJ6xJntDwuuc8o+JBIeaj4ds6t0kiiqHBIm0SH0qiFaQEilowWECYq3f4jHnvOgQSbT/Ec0TWnc7m8cegmne0OctM/rU8KvG2TnDmhzXslFd8vMk7FoSGYEHNW8mvutUx0TyCu8WL85R/F1lr7/JaDP0qwekk1ganGbPgvtKP1+Em87ozoDO7iukWBfkycTKAEJNKF54boGvMbLqofMo3fRj1IlXABcc0459B6vCRuD1gkx8B54Purv5jWEe+tiIfo7pmY72HIKI1U7u/2i8rqSjVZL+yiYDyyUAp3RrRcO6Bdxy5pGcHMfENKcZvpGIVBmkY0C65tnJebhrs6IIlxR3zIo1lQdby6xGW9sinTjlu39Geaq9l5JN5n8xaSLZraFwysRvLog2CJWptk9/bCG3Zg8nXhk1MOY1gzONZH8/we8/nQowuIkS0zwH2/YFxx7O4vvOTijm1hVWKPa2TZwjGrgh1qxs1aguqx46L6lrPqQDNSsFEfMM6QSjcAa3LN16DPk//psirGkMxNW1CFexpWoCVzw9jUzDv6hNNrTYEyUeV9ZwxBLC3olfndCJX9WySjpdqHIIg1szkV83xFpthjvf7eS2+oX5YdfNDXyO705hQyVHINwVqQxk5xbHSXCpF6Oanu0ac93pXatjXHlNssxV8XBGz7ZMXrqJxnUL2LW/MqZrU/ErvGjU+EOXD+qenNA9mUjtb9bEiH8d2G5t4vOrf+wXfWM6P7hw1LGiilZWHQo9OQ7eve5krj29a9pi0CcbV5Pgki9G6DNF+MOwHtVLjdZmLh3QkQX3nkVRmBnd/gBzRzrMVcnEMTMnxduobgFTfj84YFXA2o72HIK4+LgO9O/UPOkTT5rV97kkBpuR/C6blR4tGtOnfdOEY8D4aW+FynAznpCJhT6deO2wkEmqXkSqV0zz7QceH963Pcd2aBZWeThdk07CvasjWkZX9L87ozsdYogFlcmocghCRGJSDNWurA5xaxrVLQi7KMqd5/aka+tGDO3ZJiB9eN/Dee6bldWLoWcSjevVcWXKUpJPJlWmfiKZbyIpBkiNO2y0PDuxS0uml22pHtSOh2yfrGlHlUOCmAhjDgv/HD6qasO6BfzGIRR3u6b1mRVlMZVMpqhlQ75evpmm9RNYQc5jMqEX4/UYQcfmDbh0QEf6dWzOH96eT5/DvekdekEmjkm5wb9yYvMMCPueCahySBC3Fc9fLurDjr2RV06rDdx1Xk8G92hN3wxZzSpTqG+ZDxNadtVGXp7wvz89BvAtt5oJcwMeH9GPp79aEZcrajJ7QhccezhvlqyNHjYkO3Va0lDl4BHRbMqZ6l735wt70y8onlEi3h316uQzpEdsa1skm0wo8+f0OYw7z+2RlO/AqzGlROnSuhGPXBx91cNUM6h7a3fm0EzoYmYQqhwSpEm9wCzMJBdDN0S0r2bXT8lo8vKE0ad2TbcYGcdZvdoya+XWhJZWVZKDKoc4OafPYUxcuIHWLsMAZxIf3zyIVZt3Rz9RW1JKkhl5Smd+flxHx2VNU06KGkNFLRuweuue1DwsAVQ5xElwlNBsqkd7HNaEHoel30adbNIVJltxj4hkhmKwkeyvZvJtp2fFt6nKIU7Czx6uRSTpx7wx+gQ27Nznyb38M7/PClrH2E62mfqCySTPr9qM119JYX4eBxwms/q+2cz/JhNSDiLSAngDKAJWAZcYY7Y5nFcFLLB2fzDGXGildwZeB1oCs4HLjTEHEpEpVYTo/cxvCLimuFMLZpRtpU3j+IOXRWKgh4sK1cnPY+adZ9Ra98Pv7j6zeta8kl18e9dQ9lemfnlPr0g0fMYYYLIxpjsw2dp3Yq8xpq/1d6Et/WHg78aYbsA2YGSC8qQNv4dPljdSAbjlzCP57NbT6NYmPcsTxkrbJvVqbYC7Fg0LA2YfK8nHK5NP0wZ1aJNAdNh0k2iJGg68YG2/AFzk9kLx9fWHAOPjuT5TydYJQHby8yRrFIOieEW2mx+9JlHl0NYYs97a3gCEc3CvJyIlIjJDRC6y0loC240x/jCOa4Gwy1WJyGjrHiUVFRUJiq3kAv4Fg24c0i3NkijZQLumvlZ+Ex3jAVyMOYjIZ4DTaN9d9h1jjBGRcP2xTsaYchHpAnwuIguAHbEIaowZB4wDKC4uzjgLv70n+vSv+rP3YPbaGmsL9eq4C2uuKAC3nXUkvQ9vwulH5k5Y7khEVQ7GmLCBfkRko4i0M8asF5F2wKYw9yi3/peJyJdAP+BtoJmIFFi9hw5AeRy/IaMQgWF92qVbDEVRYqRuQT7Dk7jWdraRqFnpfeAKa/sK4L3gE0SkuYjUtbZbAScDi41v1OcL4OJI1yvZwd3n9+LhHIp1ryi1nUSVw0PAmSKyHBhq7SMixSLyrHVOT6BERObhUwYPGWMWW8duB24VkVJ8YxD/TlCetOGPb3N4LYnlHisjT+nML47PvDDjiqLER0LzHIwxW4AzHNJLgFHW9jTAsUlpjCkDBiQiQ6Zw7WldGXxUm4QWR1cURckUaqdzeBrIyxNVDIqi1BpUOSiKoighqHJQFEVRQlDloCiKooSgykFRFEUJQZWDoiiKEoIqB0VRFCUEVQ6KoihKCKoc4qTQWibUvxKZoihKbUKXCY2Te87vRevGdRkWYXlKRVGUbEWVQ5w0bVCHMef0SLcYiqIoSUHNSoqiKEoIqhwURVGUEFQ5KIqiKCGoclAURVFCUOWgKIqihKDKQVEURQlBlYOiKIoSgioHRVEUJQQxxqRbhpgRkQpgdZyXtwI2eyiOl2SqbJkqF2SubJkqF2SubJkqF2SubLHK1ckY09rNiVmpHBJBREqMMcXplsOJTJUtU+WCzJUtU+WCzJUtU+WCzJUtmXKpWUlRFEUJQZWDoiiKEkIuKodx6RYgApkqW6bKBZkrW6bKBZkrW6bKBZkrW9LkyrkxB0VRFCU6udhzUBRFUaKgykFRFEUJIaeUg4gME5FlIlIqImNS8LyOIvKFiCwWkUUicpOV3kJEJonIcut/cytdRORxS775ItLfdq8rrPOXi8gVHsmXLyJzRORDa7+ziMy0nv+GiBRa6XWt/VLreJHtHndY6ctE5GyP5GomIuNFZKmILBGREzMhz0TkFus9LhSR10SkXrryTESeE5FNIrLQluZZHonIcSKywLrmcRFxvR5uGNketd7nfBF5V0SaRcuPcOU1XJ7HI5ft2G0iYkSkVabkmZV+o5Vvi0TkkZTmmTEmJ/6AfGAF0AUoBOYBvZL8zHZAf2u7MfA90At4BBhjpY8BHra2zwUmAgKcAMy00lsAZdb/5tZ2cw/kuxV4FfjQ2n8TGGFtPw1ca21fBzxtbY8A3rC2e1n5WBfobOVvvgdyvQCMsrYLgWbpzjOgPbASqG/LqyvTlWfAqUB/YKEtzbM8AmZZ54p17TkJynYWUGBtP2yTzTE/iFBew+V5PHJZ6R2BT/BNrG2VQXk2GPgMqGvtt0llniWtYsy0P+BE4BPb/h3AHSmW4T3gTGAZ0M5Kawcss7afAS61nb/MOn4p8IwtPeC8OGXpAEwGhgAfWh/0ZlsBrs4vq+CcaG0XWOdJcB7az0tArqb4KmEJSk9rnuFTDmusSqHAyrOz05lnQFFQZeJJHlnHltrSA86LR7agYz8BXrG2HfODMOU10ncar1zAeOBYYBU1yiHteYavQh/qcF5K8iyXzEr+wu1nrZWWEiyzQj9gJtDWGLPeOrQBaBtFxmTI/hjwB+CQtd8S2G6MqXR4RvXzreM7rPOTIVdnoAL4j/hMXs+KSEPSnGfGmHLgr8APwHp8eTCbzMgzP17lUXtrOxkyAvwGX8s6HtkifacxIyLDgXJjzLygQ5mQZ0cCgyxz0FcicnycssWVZ7mkHNKGiDQC3gZuNsbstB8zPlWeUn9iETkf2GSMmZ3K57qkAF/3+iljTD9gNz4TSTVpyrPmwHB8yutwoCEwLJUyxEI68sgNInIXUAm8kgGyNADuBO5JtyxhKMDXUz0B+D3wZizjGImSS8qhHJ9t0U8HKy2piEgdfIrhFWPMO1byRhFpZx1vB2yKIqPXsp8MXCgiq4DX8ZmW/gE0E5ECh2dUP9863hTYkgS5wNeqWWuMmWntj8enLNKdZ0OBlcaYCmPMQeAdfPmYCXnmx6s8Kre2PZVRRK4Ezgcus5RXPLJtIXyex0pXfMp+nlUWOgDfichhcciVjDxbC7xjfMzC18tvFYds8eVZPLbObPzDp4XL8H0M/sGa3kl+pgAvAo8FpT9K4MDhI9b2eQQOgs2y0lvgs8M3t/5WAi08kvF0agak3yJw0Oo6a/t6AgdX37S2exM4MFaGNwPSXwNHWdv3WvmV1jwDBgKLgAbWs14AbkxnnhFqo/YsjwgdXD03QdmGAYuB1kHnOeYHEcpruDyPR66gY6uoGXPIhDy7BrjP2j4Sn8lIUpVnSasYM/EPnwfC9/hG9O9KwfNOwde1nw/Mtf7OxWcDnAwsx+eN4P+4BBhrybcAKLbd6zdAqfV3lYcynk6NcuhifeCl1sfk95KoZ+2XWse72K6/y5J3GTF4Z0SRqS9QYuXbf61CmPY8A/4MLAUWAi9ZhTMteQa8hm/s4yC+FuZIL/MIKLZ+5wrgnwQ5CMQhWym+ys1fDp6Olh+EKa/h8jweuYKOr6JGOWRCnhUCL1v3/A4Ykso80/AZiqIoSgi5NOagKIqiuESVg6IoihKCKgdFURQlBFUOiqIoSgiqHBRFUZQQVDkoiqIoIahyUBRFUUL4f9TmbrCJ79aiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "originaldata=pd.read_csv('forcetorquebuttonresults_cylindernobutton_10_19_2021.csv')\n",
    "evaluatedataset(gru_model3,originaldata)\n",
    "\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8742799265683358"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " (310+13501)/(310+13501+1986)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "prediction from timestep 0 - 10  : -0.008711494505405426 actual 0.0 OK\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "prediction from timestep 1 - 11  : 0.003979824483394623 actual 0.0 OK\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "prediction from timestep 2 - 12  : -0.01775369793176651 actual 0.0 OK\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "prediction from timestep 3 - 13  : 0.2741720378398895 actual 0.0 OK\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "prediction from timestep 4 - 14  : 0.1268426775932312 actual 0.0 OK\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "prediction from timestep 5 - 15  : 0.24690017104148865 actual 0.0 OK\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "prediction from timestep 6 - 16  : -0.008548252284526825 actual 0.0 OK\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "prediction from timestep 7 - 17  : -0.055137209594249725 actual 0.0 OK\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "prediction from timestep 8 - 18  : 0.06283382326364517 actual 0.0 OK\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "prediction from timestep 9 - 19  : 0.08400257676839828 actual 0.0 OK\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "prediction from timestep 10 - 20  : 0.0022062137722969055 actual 0.0 OK\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "prediction from timestep 11 - 21  : 0.09089038521051407 actual 0.0 OK\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "prediction from timestep 12 - 22  : -0.08540303260087967 actual 0.0 OK\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "prediction from timestep 13 - 23  : 0.10594020038843155 actual 0.0 OK\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "prediction from timestep 14 - 24  : -0.013198427855968475 actual 0.0 OK\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "prediction from timestep 15 - 25  : -0.18492355942726135 actual 0.0 OK\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "prediction from timestep 16 - 26  : 0.06619591265916824 actual 0.0 OK\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "prediction from timestep 17 - 27  : 0.3649759590625763 actual 0.0 X\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "prediction from timestep 18 - 28  : 0.0794048085808754 actual 0.0 OK\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "prediction from timestep 19 - 29  : 0.6382549405097961 actual 0.0 X\n",
      "okcounter 18\n"
     ]
    }
   ],
   "source": [
    "row=897\n",
    "\n",
    "headers=[]\n",
    "for i in range(30):  \n",
    "    label=str(i)\n",
    "    headers.append(\"header\"+label)\n",
    "\n",
    "choppedheaders=[]\n",
    "lookback=10 #save only the last 11 timesteps\n",
    "for i in range(10):  \n",
    "    label=str(i)\n",
    "    choppedheaders.append(\"header\"+label)\n",
    "\n",
    "okcounter=0\n",
    "for i in range(20):\n",
    "    classifytest=originaldata[headers[i:10+i]].iloc[row*6:(row*6)+5].to_numpy()\n",
    "    #print(classifytest)\n",
    "    labelstest=originaldata[headers[i:10+i]].iloc[(row*6)+5].to_numpy()\n",
    "    print(labelstest)\n",
    "    #print(classifytest)\n",
    "    classifytest=np.expand_dims(classifytest, axis=0)\n",
    "    #print(classifytest.shape)\n",
    "    #print(labelstest)\n",
    "\n",
    "    outputfull=evaluate_episode(gru_model3, classifytest)\n",
    "\n",
    "    #print(\"\")\n",
    "\n",
    "    #print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "    #print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "    \n",
    "    if abs(float(outputfull)-labelstest[9])>0.3:\n",
    "        result=\"X\"\n",
    "    else:\n",
    "        result=\"OK\"\n",
    "        okcounter+=1\n",
    "    print(\"prediction from timestep\",i,\"-\",i+10,\" :\",float(outputfull),\"actual\",labelstest[9], result)\n",
    "print(\"okcounter\",okcounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
