{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll be using a GRU model for a time series prediction task and we will compare the performance of the GRU model against an LSTM model as well. The dataset that we will be using is the Hourly Energy Consumption dataset which can be found on [Kaggle](https://www.kaggle.com/robikscube/hourly-energy-consumption). The dataset contains power consumption data across different regions around the United States recorded on an hourly basis.\n",
    "\n",
    "You can run the code implementation in this article on FloydHub using their GPUs on the cloud by clicking the following link and using the main.ipynb notebook.\n",
    "\n",
    "[![Run on FloydHub](https://static.floydhub.com/button/button-small.svg)](https://floydhub.com/run?template=https://github.com/gabrielloye/https://github.com/gabrielloye/GRU_Prediction)\n",
    "\n",
    "This will speed up the training process significantly. Alternatively, the link to the GitHub repository can be found [here]().\n",
    "\n",
    "The goal of this implementation is to create a model that can accurately predict the energy usage in the next hour given historical usage data. We will be using both the GRU and LSTM model to train on a set of historical data and evaluate both models on an unseen test set. To do so, we’ll start with feature selection, data-preprocessing, followed by defining, training and eventually evaluating the models.\n",
    "\n",
    "We will be using the PyTorch library to implement both types of models along with other common Python libraries used in data analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.python-engineer.com/posts/pytorch-rnn-lstm-gru/\n",
    "\n",
    "#https://blog.floydhub.com/gru-with-pytorch/\n",
    "\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import MinMaxScaler,QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Local ###\n",
    "#from data_processing import *\n",
    "\n",
    "\n",
    "\n",
    "# Define data root directory\n",
    "\n",
    "#data_dir = \"./data/\"\n",
    "#print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of **12** *.csv* files containing hourly energy trend data (*'est_hourly.paruqet'* and *'pjm_hourly_est.csv'* are not used). In our next step, we will be reading these files and pre-processing these data in this order:\n",
    "- Getting the time data of each individual time step and generalizing them\n",
    "    - Hour of the day *i.e. 0-23*\n",
    "    - Day of the week *i.e. 1-7*\n",
    "    - Month *i.e. 1-12*\n",
    "    - Day of the year *i.e. 1-365*\n",
    "    \n",
    "    \n",
    "- Scale the data to values between 0 and 1\n",
    "    - Algorithms tend to perform better or converge faster when features are on a relatively similar scale and/or close to normally distributed\n",
    "    - Scaling preserves the shape of the original distribution and doesn't reduce the importance of outliers.\n",
    "    \n",
    "    \n",
    "- Group the data into sequences to be used as inputs to the model and store their corresponding labels\n",
    "    - The **sequence length** or **lookback period** is the number of data points in history that the model will use to make the prediction\n",
    "    - The label will be the next data point in time after the last one in the input sequence\n",
    "    \n",
    "\n",
    "- The inputs and labels will then be split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "choppeddata=pd.read_csv('choppeddata_9_21_2021.csv')#.head()\n",
    "\n",
    "choppedheaders=[]\n",
    "lookback=11 #save only the last 11 timesteps\n",
    "for i in range(lookback):  \n",
    "    label=str(i)\n",
    "    choppedheaders.append(\"header\"+label)\n",
    "\n",
    "#put chopped data in np.arrays\n",
    "State=np.zeros((96,5,11)) #96 runs,with 5 sets of data (x,y,z,roll,pitch) each, and each run is 11 timesteps long\n",
    "Labels=np.zeros((96,11)) #96 runs, each run is 11 timesteps long\n",
    "runcounter=0\n",
    "\n",
    "for i in range(0,575,6):\n",
    "            State[runcounter][0][:]=(choppeddata[choppedheaders[:]].iloc[i]).tolist()\n",
    "            State[runcounter][1][:]=(choppeddata[choppedheaders[:]].iloc[i+1]).tolist()\n",
    "            State[runcounter][2][:]=(choppeddata[choppedheaders[:]].iloc[i+2]).tolist()\n",
    "            State[runcounter][3][:]=(choppeddata[choppedheaders[:]].iloc[i+3]).tolist()\n",
    "            State[runcounter][4][:]=(choppeddata[choppedheaders[:]].iloc[i+4]).tolist()\n",
    "            Labels[runcounter][:]=(choppeddata[choppedheaders[:]].iloc[i+5]).tolist()  #labels   \n",
    "            runcounter+=1\n",
    "#print(State[0])\n",
    "#print(Labels)\n",
    "print(Labels[:,10]) #just getting finals labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]]\n",
      "(4, 3)\n",
      "[ 2  5  8 11]\n"
     ]
    }
   ],
   "source": [
    "j = np.array([[ 0,  1,  2],\n",
    "              [ 3,  4,  5],\n",
    "              [ 6,  7,  8],\n",
    "              [ 9, 10, 11]])\n",
    "print(j)\n",
    "print(j.shape)\n",
    "print(j[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 5, 11)\n",
      "Train\n",
      "[[0.66067274 0.70430639 0.67520184 0.68615223 0.67641444 0.68186801\n",
      "  0.6758689  0.68460397 0.68511599 0.70822891 0.72352148]\n",
      " [0.59001962 0.57353245 0.60273334 0.61739001 0.59798504 0.60680647\n",
      "  0.59784728 0.59608482 0.60003762 0.60154628 0.58328973]\n",
      " [0.86593884 0.83491177 0.94853401 0.93162722 0.9459562  0.93877476\n",
      "  0.94461182 0.93864763 0.94677179 0.92434139 0.93277732]\n",
      " [0.42719015 0.44386521 0.42301241 0.40947675 0.42378999 0.42103409\n",
      "  0.42091323 0.42617751 0.42432461 0.41765465 0.43021535]\n",
      " [0.68492613 0.73713396 0.71732474 0.72483717 0.72541902 0.72632117\n",
      "  0.72377245 0.73094436 0.72926961 0.74526455 0.75568234]]\n",
      "72\n",
      "Test\n",
      "[[0.50901364 0.53791286 0.51748383 0.53651339 0.53188663 0.52694585\n",
      "  0.5205152  0.51844995 0.53539513 0.53282207 0.51940971]\n",
      " [0.45338884 0.47082336 0.46394748 0.44508077 0.45347655 0.42774596\n",
      "  0.44400104 0.43419636 0.42854116 0.42113377 0.43428465]\n",
      " [0.87219985 0.94368344 0.93634421 0.94400243 0.93876059 0.93731456\n",
      "  0.94509448 0.94018378 0.9326403  0.93959207 0.90537104]\n",
      " [0.56127783 0.55701783 0.5577849  0.57835875 0.57050771 0.58683968\n",
      "  0.57835769 0.58553005 0.58957983 0.59637244 0.58583786]\n",
      " [0.54292365 0.56247124 0.55369696 0.5645506  0.55805379 0.55435267\n",
      "  0.55444977 0.55478551 0.56086609 0.56180994 0.55298571]]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "#X= range(0,575,6)\n",
    "#y= range(0,575,6)\n",
    "\n",
    "X=State\n",
    "y=Labels[:,10]\n",
    "print(X.shape)\n",
    "\n",
    "y=y.reshape(96,1)\n",
    "\n",
    "random_seed=int(time.time())\n",
    "#print(int(time.time()))\n",
    "train_x, test_x, train_y,test_y = train_test_split(X, y, test_size=.25, #0.33, \n",
    "                                                   random_state=random_seed)\n",
    "print(\"Train\")\n",
    "print(train_x[0])\n",
    "print(train_y.size)\n",
    "print(\"Test\")\n",
    "print(test_x[0])\n",
    "print(test_y[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 5, 11)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)  #example was (980185, 90, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of 980,185 sequences of training data\n",
    "\n",
    "To improve the speed of our training, we can process the data in batches so that the model does not need to update its weights as frequently. The Torch *Dataset* and *DataLoader* classes are useful for splitting our data into batches and shuffling them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "#a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels.\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "test_data   = TensorDataset( torch.from_numpy( test_x ), torch.from_numpy( test_y ) )\n",
    "test_loader = DataLoader( test_data, shuffle = True, batch_size = batch_size, drop_last = True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f40bdaf3350>\n"
     ]
    }
   ],
   "source": [
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check if we have any GPUs to speed up our training time by many folds. If you’re using FloydHub with GPU to run this code, the training time will be significantly reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(device)\n",
    "\n",
    "\n",
    "def get_torch_device( v=0 ):\n",
    "    # torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "    is_cuda = torch.cuda.is_available()\n",
    "    # If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "    if is_cuda:\n",
    "        device = torch.device(\"cuda\")\n",
    "        if v:  print( \"CUDA Available!\" )\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        if v:  print( \"NO CUDA\" )\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden\n",
    "def train(train_loader, learn_rate, hidden_dim=128, EPOCHS=500, model_type=\"GRU\"):\n",
    "    losslist=[]\n",
    "    # Setting common hyperparameters\n",
    "    input_dim = next(iter(train_loader))[0].shape[2]  #  = 11\n",
    "    #print(input_dim)\n",
    "    #print(\"input_dim\",input_dim)\n",
    "    output_dim = 1\n",
    "    n_layers = 2\n",
    "    # Instantiating the models\n",
    "    if model_type == \"GRU\":\n",
    "        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    else:\n",
    "        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Defining loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    \n",
    "    model.train()\n",
    "    print(\"Starting Training of {} model\".format(model_type))\n",
    "    epoch_times = []\n",
    "    # Start training loop\n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        start_time = time.clock()\n",
    "        h = model.init_hidden(batch_size)\n",
    "        avg_loss = 0.\n",
    "        counter = 0\n",
    "        for x, label in train_loader:\n",
    "            #print(\"x\",x)\n",
    "            #print(\"label\",label)\n",
    "            counter += 1\n",
    "            if model_type == \"GRU\":\n",
    "                h = h.data\n",
    "            else:\n",
    "                h = tuple([e.data for e in h])\n",
    "            model.zero_grad()\n",
    "            \n",
    "            out, h = model(x.to(device).float(), h)\n",
    "            #print(\"out\",out)\n",
    "            loss = criterion(out, label.to(device).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "            \n",
    "            if counter%20000 == 0:\n",
    "                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter, len(train_loader), avg_loss/counter))\n",
    "        current_time = time.clock()\n",
    "        if epoch%20 == 0:\n",
    "            print(\"Epoch {}/{} Done, Total Loss: {}\".format(epoch, EPOCHS, avg_loss/len(train_loader)))\n",
    "        \n",
    "            print(\"Total Time Elapsed: {} seconds\".format(str(current_time-start_time)))\n",
    "        losslist.append(avg_loss/len(train_loader))\n",
    "        epoch_times.append(current_time-start_time)\n",
    "    print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n",
    "    plt.plot(losslist)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.show()\n",
    "    return model\n",
    "\n",
    "def evaluate(model, test_x, test_y):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []\n",
    "    start_time = time.clock()\n",
    "    #for i in test_x.keys():\n",
    "    for i in range( len( test_x ) ):    \n",
    "        inp = torch.from_numpy(np.array(test_x[i])) # should be 5x1\n",
    "        labs = torch.from_numpy(np.array(test_y[i])) #should be 1x1\n",
    "        h = model.init_hidden(inp.shape[0])\n",
    "        #print(\"inp\",inp)\n",
    "        #print(\"labs\",labs)\n",
    "        #print(\"h\",h)\n",
    "        out, h = model(inp.to(device).float(), h)\n",
    "        #outputs.append(label_scalers[i].inverse_transform(out.cpu().detach().numpy()).reshape(-1))\n",
    "        #targets.append(label_scalers[i].inverse_transform(labs.numpy()).reshape(-1))\n",
    "        outputs.append( out.cpu().detach().numpy().reshape(-1) )\n",
    "        targets.append( labs.numpy().reshape(-1) )\n",
    "        \n",
    "    print(\"Evaluation Time: {}\".format(str(time.clock()-start_time)))\n",
    "    sMAPE = 0\n",
    "    for i in range(len(outputs)):\n",
    "        sMAPE += np.mean(abs(outputs[i]-targets[i])/(targets[i]+outputs[i])/2)/len(outputs)\n",
    "    print(\"sMAPE: {}%\".format(sMAPE*100))\n",
    "    return outputs, targets, sMAPE\n",
    "                               \n",
    "def evaluate2(model, test_x, test_y):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []\n",
    "    start_time = time.clock()\n",
    "    #for i in test_x.keys():\n",
    "    #for i in range( len( test_x ) ):    \n",
    "    inp = torch.from_numpy(np.array(test_x)) # should be 5x1\n",
    "    labs = torch.from_numpy(np.array(test_y)) #should be 1x1\n",
    "    h = model.init_hidden(inp.shape[0])\n",
    "    #print(\"inp\",inp)\n",
    "    #print(\"labs\",labs)\n",
    "    #print(\"h\",h)\n",
    "    out, h = model(inp.to(device).float(), h)\n",
    "    #outputs.append(label_scalers[i].inverse_transform(out.cpu().detach().numpy()).reshape(-1))\n",
    "    #targets.append(label_scalers[i].inverse_transform(labs.numpy()).reshape(-1))\n",
    "    outputs.append( out.cpu().detach().numpy().reshape(-1) )\n",
    "    targets.append( labs.numpy().reshape(-1) )\n",
    "        \n",
    "    print(\"Evaluation Time: {}\".format(str(time.clock()-start_time)))\n",
    "    sMAPE = 0\n",
    "    for i in range(len(outputs)):\n",
    "        sMAPE += np.mean(abs(outputs[i]-targets[i])/(targets[i]+outputs[i])/2)/len(outputs)\n",
    "    print(\"sMAPE: {}%\".format(sMAPE*100))\n",
    "    return outputs, targets, sMAPE                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training of GRU model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:44: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:67: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/500 Done, Total Loss: 0.22824055949846903\n",
      "Total Time Elapsed: 0.42497700000000016 seconds\n",
      "Epoch 40/500 Done, Total Loss: 0.19123266554541057\n",
      "Total Time Elapsed: 0.4442619999999984 seconds\n",
      "Epoch 60/500 Done, Total Loss: 0.17814971009890238\n",
      "Total Time Elapsed: 0.4034720000000007 seconds\n",
      "Epoch 80/500 Done, Total Loss: 0.1593889743089676\n",
      "Total Time Elapsed: 0.6687569999999994 seconds\n",
      "Epoch 100/500 Done, Total Loss: 0.15321586115492714\n",
      "Total Time Elapsed: 0.42043499999999767 seconds\n",
      "Epoch 120/500 Done, Total Loss: 0.14536812322007286\n",
      "Total Time Elapsed: 0.4496299999999991 seconds\n",
      "Epoch 140/500 Done, Total Loss: 0.12950144045882755\n",
      "Total Time Elapsed: 0.4932539999999932 seconds\n",
      "Epoch 160/500 Done, Total Loss: 0.12104778985182445\n",
      "Total Time Elapsed: 0.5323429999999973 seconds\n",
      "Epoch 180/500 Done, Total Loss: 0.09544661061631309\n",
      "Total Time Elapsed: 0.4245559999999955 seconds\n",
      "Epoch 200/500 Done, Total Loss: 0.10965718825658162\n",
      "Total Time Elapsed: 0.540645000000012 seconds\n",
      "Epoch 220/500 Done, Total Loss: 0.08863654422263305\n",
      "Total Time Elapsed: 0.44190500000000554 seconds\n",
      "Epoch 240/500 Done, Total Loss: 0.08956929689480199\n",
      "Total Time Elapsed: 0.5819390000000055 seconds\n",
      "Epoch 260/500 Done, Total Loss: 0.06796769001003769\n",
      "Total Time Elapsed: 0.4074280000000101 seconds\n",
      "Epoch 280/500 Done, Total Loss: 0.0678834304627445\n",
      "Total Time Elapsed: 0.4728849999999909 seconds\n",
      "Epoch 300/500 Done, Total Loss: 0.04670616818798913\n",
      "Total Time Elapsed: 0.40542500000000814 seconds\n",
      "Epoch 320/500 Done, Total Loss: 0.05341275667564736\n",
      "Total Time Elapsed: 0.44967900000000327 seconds\n",
      "Epoch 340/500 Done, Total Loss: 0.05258671628932158\n",
      "Total Time Elapsed: 0.39531900000000064 seconds\n",
      "Epoch 360/500 Done, Total Loss: 0.029484884451246925\n",
      "Total Time Elapsed: 0.4163649999999848 seconds\n",
      "Epoch 380/500 Done, Total Loss: 0.03053841708848874\n",
      "Total Time Elapsed: 0.4128649999999823 seconds\n",
      "Epoch 400/500 Done, Total Loss: 0.027470300077564187\n",
      "Total Time Elapsed: 0.5336110000000076 seconds\n",
      "Epoch 420/500 Done, Total Loss: 0.028780218834678333\n",
      "Total Time Elapsed: 0.5489200000000096 seconds\n",
      "Epoch 440/500 Done, Total Loss: 0.028523726026631065\n",
      "Total Time Elapsed: 0.5549200000000098 seconds\n",
      "Epoch 460/500 Done, Total Loss: 0.02204495823631684\n",
      "Total Time Elapsed: 0.47408300000000736 seconds\n",
      "Epoch 480/500 Done, Total Loss: 0.02136075325931112\n",
      "Total Time Elapsed: 0.5663520000000233 seconds\n",
      "Epoch 500/500 Done, Total Loss: 0.018526237457990646\n",
      "Total Time Elapsed: 0.5834270000000004 seconds\n",
      "Total Training Time: 245.814909 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 0.001#0.001\n",
    "gru_model = train(train_loader, lr, model_type=\"GRU\")\n",
    "\n",
    "#The target size means the label size!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_81968/3312255129.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#h = model.init_hidden(inp.shape[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#print(\"inp\",inp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_81968/2830187747.py\u001b[0m in \u001b[0;36minit_hidden\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GRU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure"
     ]
    }
   ],
   "source": [
    "model=gru_model\n",
    "i=1\n",
    "inp = torch.from_numpy(np.array(test_x))\n",
    "labs = torch.from_numpy(np.array(test_y))\n",
    "#h = model.init_hidden(inp.shape[0])\n",
    "h = model.init_hidden(inp.shape[0])\n",
    "#print(\"inp\",inp)\n",
    "\n",
    "#print(\"INP SHAPE\",inp.shape)\n",
    "#print(\"INP SHAPE[0]\",inp.shape[0])\n",
    "#print(\"labs\",labs)\n",
    "#print(\"h\",h)\n",
    "#print(\"h.shape\",h.shape)\n",
    "#print(inp.to(device).float())\n",
    "#print(inp.to(device).float().shape)\n",
    "print(inp.to(device).float().shape)\n",
    "\n",
    "out, h = model(inp.to(device).float(), h)\n",
    "#print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Time: 0.022149999999999892\n",
      "sMAPE: 1.055325718671533%\n",
      "[array([-7.3618658e-02,  9.8243004e-01,  9.6595168e-01,  9.7385561e-01,\n",
      "       -1.0710596e-01,  9.7495830e-01,  1.0029546e+00, -1.1340419e-02,\n",
      "        9.4081098e-01,  1.5489599e-02,  1.0237291e+00, -1.4569107e-03,\n",
      "        9.9926215e-01,  9.6292406e-01,  1.0372440e+00,  9.9232954e-01,\n",
      "       -2.0386243e-02,  1.8636370e-02,  9.8773569e-01,  9.9762005e-01,\n",
      "       -4.2590111e-02,  9.7904545e-01,  1.0026344e+00,  9.5723277e-01,\n",
      "       -9.3992986e-04,  9.9707299e-01,  6.0111932e-02,  1.0196114e+00,\n",
      "        9.9926394e-01,  9.8935169e-01,  6.1628096e-02,  9.5956409e-01,\n",
      "        9.6774179e-01,  9.8263341e-01,  9.9145943e-01,  9.9661845e-01,\n",
      "        1.0162412e+00,  1.0472741e+00,  1.0231850e+00, -8.1685539e-03,\n",
      "        9.7263831e-01,  1.4361089e-02,  1.0271791e+00,  4.4654958e-02,\n",
      "        8.7298211e-03,  9.5959789e-01,  6.3012298e-03, -1.7566899e-02,\n",
      "        9.9679643e-01,  9.8661357e-01,  9.6943319e-01,  6.6272609e-02,\n",
      "        9.3804735e-01,  4.6346039e-02,  9.8781985e-01, -1.7333798e-02,\n",
      "        8.4618086e-01,  9.9601346e-01, -7.6258622e-02, -2.2871695e-02,\n",
      "        9.8578924e-01, -1.5715437e-02,  3.2791104e-03,  6.0087796e-03,\n",
      "        1.0029367e+00, -3.6124475e-02,  2.8371276e-02,  1.0001315e+00,\n",
      "        1.2075361e-03,  9.8650938e-01,  9.6186149e-01,  1.4843686e-02],\n",
      "      dtype=float32)]\n",
      "0.9749583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:110: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:125: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "#gru_outputs, targets, gru_sMAPE = evaluate2(gru_model, test_x, test_y)\n",
    "gru_outputs, targets, gru_sMAPE = evaluate2(gru_model, train_x, train_y)\n",
    "#print(test_y)\n",
    "print(gru_outputs)\n",
    "print(gru_outputs[0][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Time: 0.0166579999999783\n",
      "sMAPE: 11.10482370706016%\n",
      "24\n",
      "72\n",
      "1.0171337\n",
      "successess vs training data= 66 /72\n",
      "Evaluation Time: 0.022106000000007953\n",
      "sMAPE: 26.959528698024055%\n",
      "1.0 1.0005274 tensor(1.0005)\n",
      "0.0 1.0269966 tensor(1.0270)\n",
      "0.0 1.0669843 tensor(1.0670)\n",
      "0.0 0.020787999 tensor(0.0208)\n",
      "1.0 1.073992 tensor(1.0740)\n",
      "0.0 0.24167858 tensor(0.2417)\n",
      "1.0 0.93969786 tensor(0.9397)\n",
      "1.0 0.5938621 tensor(0.5939)\n",
      "0.0 0.8885737 tensor(0.8886)\n",
      "0.0 0.9044461 tensor(0.9044)\n",
      "0.0 1.1014279 tensor(1.1014)\n",
      "0.0 0.17135726 tensor(0.1714)\n",
      "1.0 0.34176075 tensor(0.3418)\n",
      "1.0 0.5907218 tensor(0.5907)\n",
      "0.0 0.99151444 tensor(0.9915)\n",
      "1.0 1.1222554 tensor(1.1223)\n",
      "0.0 0.9993213 tensor(0.9993)\n",
      "1.0 1.059385 tensor(1.0594)\n",
      "1.0 0.9743906 tensor(0.9744)\n",
      "0.0 0.6269203 tensor(0.6269)\n",
      "1.0 0.5327496 tensor(0.5327)\n",
      "1.0 0.03923215 tensor(0.0392)\n",
      "1.0 0.21191923 tensor(0.2119)\n",
      "0.0 0.9050136 tensor(0.9050)\n",
      "successess vs test data= 10 /72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:110: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:125: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "#print(test_y.reshape(-1))\n",
    "\n",
    "m = nn.ReLU()\n",
    "#m = nn.Sigmoid()\n",
    "#output = m(input)\n",
    "\n",
    "gru_outputs, targets, gru_sMAPE = evaluate2(gru_model, train_x, train_y)\n",
    "#print(test_y)\n",
    "#print(gru_outputs)\n",
    "#print(gru_outputs[0][5])\n",
    "\n",
    "\n",
    "testy=test_y.reshape(-1)\n",
    "trainy=train_y.reshape(-1)\n",
    "\n",
    "print(testy.size)\n",
    "print(trainy.size)\n",
    "print(gru_outputs[0][4])\n",
    "successcounter=0\n",
    "for i in range(72):\n",
    "    #print(testy[i],gru_outputs[0][i],m(torch.tensor(gru_outputs[0][i])))\n",
    "    #print(train[i],gru_outputs[0][i],m(torch.tensor(gru_outputs[0][i])))\n",
    "    #print(trainy[i],gru_outputs[0][i], m(torch.tensor(gru_outputs[0][i])))\n",
    "    \n",
    "    \n",
    "    if abs(trainy[i]-gru_outputs[0][i])<0.2 :\n",
    "        successcounter+=1\n",
    "    #print(testy[i])\n",
    "    #print\n",
    "    #output = m(input)\n",
    "print(\"successess vs training data=\" ,successcounter,\"/72\")\n",
    "\n",
    "\n",
    "successcounter=0\n",
    "\n",
    "gru_outputs, targets, gru_sMAPE = evaluate2(gru_model, test_x, test_y)\n",
    "\n",
    "for i in range(24):\n",
    "    #print(testy[i],gru_outputs[0][i],m(torch.tensor(gru_outputs[0][i])))\n",
    "    #print(train[i],gru_outputs[0][i],m(torch.tensor(gru_outputs[0][i])))\n",
    "    print(trainy[i],gru_outputs[0][i], m(torch.tensor(gru_outputs[0][i])))\n",
    "    \n",
    "    \n",
    "    if abs(testy[i]-gru_outputs[0][i])<0.2 :\n",
    "        successcounter+=1\n",
    "    #print(testy[i])\n",
    "    #print\n",
    "    #output = m(input)\n",
    "print(\"successess vs test data=\" ,successcounter,\"/72\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
