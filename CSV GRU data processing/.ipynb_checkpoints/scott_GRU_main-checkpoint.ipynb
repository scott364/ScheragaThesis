{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll be using a GRU model for a time series prediction task and we will compare the performance of the GRU model against an LSTM model as well. The dataset that we will be using is the Hourly Energy Consumption dataset which can be found on [Kaggle](https://www.kaggle.com/robikscube/hourly-energy-consumption). The dataset contains power consumption data across different regions around the United States recorded on an hourly basis.\n",
    "\n",
    "You can run the code implementation in this article on FloydHub using their GPUs on the cloud by clicking the following link and using the main.ipynb notebook.\n",
    "\n",
    "[![Run on FloydHub](https://static.floydhub.com/button/button-small.svg)](https://floydhub.com/run?template=https://github.com/gabrielloye/https://github.com/gabrielloye/GRU_Prediction)\n",
    "\n",
    "This will speed up the training process significantly. Alternatively, the link to the GitHub repository can be found [here]().\n",
    "\n",
    "The goal of this implementation is to create a model that can accurately predict the energy usage in the next hour given historical usage data. We will be using both the GRU and LSTM model to train on a set of historical data and evaluate both models on an unseen test set. To do so, weâ€™ll start with feature selection, data-preprocessing, followed by defining, training and eventually evaluating the models.\n",
    "\n",
    "We will be using the PyTorch library to implement both types of models along with other common Python libraries used in data analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Define data root directory\n",
    "#data_dir = \"./data/\"\n",
    "#print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizeddataframe=pd.read_csv('forcetorquebuttonresults_09_21_2021.csv')#.head()\n",
    "originaldataframe=normalizeddataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#normalizeddataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of **12** *.csv* files containing hourly energy trend data (*'est_hourly.paruqet'* and *'pjm_hourly_est.csv'* are not used). In our next step, we will be reading these files and pre-processing these data in this order:\n",
    "- Getting the time data of each individual time step and generalizing them\n",
    "    - Hour of the day *i.e. 0-23*\n",
    "    - Day of the week *i.e. 1-7*\n",
    "    - Month *i.e. 1-12*\n",
    "    - Day of the year *i.e. 1-365*\n",
    "    \n",
    "    \n",
    "- Scale the data to values between 0 and 1\n",
    "    - Algorithms tend to perform better or converge faster when features are on a relatively similar scale and/or close to normally distributed\n",
    "    - Scaling preserves the shape of the original distribution and doesn't reduce the importance of outliers.\n",
    "    \n",
    "    \n",
    "- Group the data into sequences to be used as inputs to the model and store their corresponding labels\n",
    "    - The **sequence length** or **lookback period** is the number of data points in history that the model will use to make the prediction\n",
    "    - The label will be the next data point in time after the last one in the input sequence\n",
    "    \n",
    "\n",
    "- The inputs and labels will then be split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.14936999999999934\n",
      "-0.014936999999999978\n"
     ]
    }
   ],
   "source": [
    "#Un Normalize data\n",
    "\n",
    "xforcemin=-10\n",
    "xforcemax=10\n",
    "yforcemin=-10\n",
    "yforcemax=10\n",
    "\n",
    "zforcemin=-15\n",
    "zforcemax=10\n",
    "rolltorquemin=-2\n",
    "rolltorquemax=2\n",
    "pitchtorquemin=-2\n",
    "pitchtorquemax=2\n",
    "yawtorquemin=-.1\n",
    "yawtorquemax=.1\n",
    "\n",
    "xforce_normalized=-0.014937\n",
    "\n",
    "xforce_original=(((xforce_normalized+1)/2)*(xforcemax-xforcemin)+xforcemin)\n",
    "print(xforce_original)\n",
    "xforce_normalized2=((xforce_original-xforcemin)/(xforcemax-xforcemin)*2)-1\n",
    "\n",
    "print(xforce_normalized2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizeddataframe=pd.read_csv('forcetorquebuttonresults_09_21_2021.csv')#.head()\n",
    "originaldataframe=normalizeddataframe\n",
    "#unnormalizerange=range(0,5,575)\n",
    "#print(unnormalizerange)\n",
    "\n",
    "for i in range(0,575,6):\n",
    "  \n",
    "    originaldataframe.iloc[i]=(((normalizeddataframe.iloc[i]+1)/2)*(xforcemax-xforcemin)+xforcemin)\n",
    "    originaldataframe.iloc[i+1]=(((normalizeddataframe.iloc[i+1]+1)/2)*(yforcemax-yforcemin)+yforcemin)\n",
    "    originaldataframe.iloc[i+2]=(((normalizeddataframe.iloc[i+2]+1)/2)*(zforcemax-zforcemin)+zforcemin)\n",
    "    originaldataframe.iloc[i+3]=(((normalizeddataframe.iloc[i+3]+1)/2)*(rolltorquemax-rolltorquemin)+rolltorquemin)\n",
    "    originaldataframe.iloc[i+4]=(((normalizeddataframe.iloc[i+4]+1)/2)*(pitchtorquemax-pitchtorquemin)+pitchtorquemin)\n",
    "    \n",
    "\n",
    "originaldataframe\n",
    "originaldataframe.to_csv('forcetorquebuttonresults_unnormalized_09_21_2021.csv', index=False)  \n",
    "print(\"data output to file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xforcemin= -22.0667781829834 xforcemax= 21.32257652282715\n",
      "yforcemin= -33.593490600585945 yforcemax= 21.48625946044922\n",
      "zforcemin= -134.9068450927734 zforcemax= 7.664425373077393\n",
      "rolltorquemin= -4.071350574493408 rolltorquemax= 5.534818649291992\n",
      "pitchtorquemin= -5.719254970550537 pitchtorquemax= 5.162374019622803\n"
     ]
    }
   ],
   "source": [
    "#Find new min and max values for each set of data\n",
    "\n",
    "originaldataframe=pd.read_csv('forcetorquebuttonresults_unnormalized_09_21_2021.csv')#.head()\n",
    "\n",
    "xforcemin=999\n",
    "xforcemax=-999\n",
    "yforcemin=999\n",
    "yforcemax=-999\n",
    "zforcemin=999\n",
    "zforcemax=-999\n",
    "rolltorquemin=999\n",
    "rolltorquemax=-999\n",
    "pitchtorquemin=999\n",
    "pitchtorquemax=-999\n",
    "\n",
    "\n",
    "for i in range(0,575,6):\n",
    "    xtempmin=originaldataframe.iloc[i].min(axis=0)\n",
    "    xtempmax=originaldataframe.iloc[i].max(axis=0)\n",
    "    ytempmin=originaldataframe.iloc[i+1].min(axis=0)\n",
    "    ytempmax=originaldataframe.iloc[i+1].max(axis=0)\n",
    "    ztempmin=originaldataframe.iloc[i+2].min(axis=0)\n",
    "    ztempmax=originaldataframe.iloc[i+2].max(axis=0)\n",
    "    rolltempmin=originaldataframe.iloc[i+3].min(axis=0)\n",
    "    rolltempmax=originaldataframe.iloc[i+3].max(axis=0)\n",
    "    pitchtempmin=originaldataframe.iloc[i+4].min(axis=0)\n",
    "    pitchtempmax=originaldataframe.iloc[i+4].max(axis=0)\n",
    "    \n",
    "    if xtempmin<xforcemin:\n",
    "        xforcemin=xtempmin\n",
    "    if ytempmin<yforcemin:\n",
    "        yforcemin=ytempmin\n",
    "    if ztempmin<zforcemin:\n",
    "        zforcemin=ztempmin\n",
    "        #print(\"row\",i+2,\"new min =\",zforcemin)\n",
    "    #if ztempmin<-50:\n",
    "        #print(\"row\",i+2,\"low z =\",zforcemin)\n",
    "        \n",
    "    if rolltempmin<rolltorquemin:\n",
    "        rolltorquemin=rolltempmin\n",
    "   \n",
    "        \n",
    "    if xtempmax>xforcemax:\n",
    "        xforcemax=xtempmax\n",
    "    if ytempmax>yforcemax:\n",
    "        yforcemax=ytempmax\n",
    "    if ztempmax>zforcemax:\n",
    "        zforcemax=ztempmax\n",
    "        #print(\"new max=\",zforcemax)\n",
    "    if rolltempmax>rolltorquemax:\n",
    "        rolltorquemax=rolltempmax\n",
    "\n",
    "    if pitchtempmin<pitchtorquemin:\n",
    "        pitchtorquemin=pitchtempmin    \n",
    "        \n",
    "    if pitchtempmax>pitchtorquemax:\n",
    "        pitchtorquemax=pitchtempmax   \n",
    "   \n",
    " \n",
    "    \n",
    "print(\"xforcemin=\",xforcemin,\"xforcemax=\",xforcemax)\n",
    "print(\"yforcemin=\",yforcemin,\"yforcemax=\",yforcemax)\n",
    "print(\"zforcemin=\",zforcemin,\"zforcemax=\",zforcemax)\n",
    "print(\"rolltorquemin=\",rolltorquemin,\"rolltorquemax=\",rolltorquemax)\n",
    "print(\"pitchtorquemin=\",pitchtorquemin,\"pitchtorquemax=\",pitchtorquemax)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create quantile transformers\n",
    "\n",
    "originaldataframe=pd.read_csv('forcetorquebuttonresults_unnormalized_09_21_2021.csv')#.head()\n",
    "\n",
    "xforcemin=999\n",
    "xforcemax=-999\n",
    "yforcemin=999\n",
    "yforcemax=-999\n",
    "zforcemin=999\n",
    "zforcemax=-999\n",
    "rolltorquemin=999\n",
    "rolltorquemax=-999\n",
    "pitchtorquemin=999\n",
    "pitchtorquemax=-999\n",
    "\n",
    "\n",
    "for i in range(0,575,6):\n",
    "    xtempmin=originaldataframe.iloc[i].min(axis=0)\n",
    "    xtempmax=originaldataframe.iloc[i].max(axis=0)\n",
    "    ytempmin=originaldataframe.iloc[i+1].min(axis=0)\n",
    "    ytempmax=originaldataframe.iloc[i+1].max(axis=0)\n",
    "    ztempmin=originaldataframe.iloc[i+2].min(axis=0)\n",
    "    ztempmax=originaldataframe.iloc[i+2].max(axis=0)\n",
    "    rolltempmin=originaldataframe.iloc[i+3].min(axis=0)\n",
    "    rolltempmax=originaldataframe.iloc[i+3].max(axis=0)\n",
    "    pitchtempmin=originaldataframe.iloc[i+4].min(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#originaldataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test1)\n",
    "#print(normalizeddataframe.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header0</th>\n",
       "      <th>header1</th>\n",
       "      <th>header2</th>\n",
       "      <th>header3</th>\n",
       "      <th>header4</th>\n",
       "      <th>header5</th>\n",
       "      <th>header6</th>\n",
       "      <th>header7</th>\n",
       "      <th>header8</th>\n",
       "      <th>header9</th>\n",
       "      <th>...</th>\n",
       "      <th>header20</th>\n",
       "      <th>header21</th>\n",
       "      <th>header22</th>\n",
       "      <th>header23</th>\n",
       "      <th>header24</th>\n",
       "      <th>header25</th>\n",
       "      <th>header26</th>\n",
       "      <th>header27</th>\n",
       "      <th>header28</th>\n",
       "      <th>header29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001494</td>\n",
       "      <td>-0.006114</td>\n",
       "      <td>-0.002769</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.004409</td>\n",
       "      <td>-0.004502</td>\n",
       "      <td>-0.004180</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>-0.004193</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104987</td>\n",
       "      <td>-0.047108</td>\n",
       "      <td>-0.112094</td>\n",
       "      <td>-0.100577</td>\n",
       "      <td>-0.040931</td>\n",
       "      <td>-0.058437</td>\n",
       "      <td>-0.100992</td>\n",
       "      <td>-0.085715</td>\n",
       "      <td>-0.083076</td>\n",
       "      <td>-0.019339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029401</td>\n",
       "      <td>0.031186</td>\n",
       "      <td>0.054998</td>\n",
       "      <td>0.044918</td>\n",
       "      <td>0.068072</td>\n",
       "      <td>0.026208</td>\n",
       "      <td>0.025993</td>\n",
       "      <td>0.035039</td>\n",
       "      <td>0.048243</td>\n",
       "      <td>0.062763</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167204</td>\n",
       "      <td>-0.154656</td>\n",
       "      <td>-0.159713</td>\n",
       "      <td>-0.431183</td>\n",
       "      <td>-0.340838</td>\n",
       "      <td>-0.326700</td>\n",
       "      <td>-0.343063</td>\n",
       "      <td>-0.458384</td>\n",
       "      <td>-0.504819</td>\n",
       "      <td>-0.386363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.160614</td>\n",
       "      <td>0.170542</td>\n",
       "      <td>0.134455</td>\n",
       "      <td>0.150562</td>\n",
       "      <td>0.137968</td>\n",
       "      <td>0.162312</td>\n",
       "      <td>0.160939</td>\n",
       "      <td>0.163658</td>\n",
       "      <td>0.156357</td>\n",
       "      <td>0.158699</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.691840</td>\n",
       "      <td>-1.771973</td>\n",
       "      <td>-1.708544</td>\n",
       "      <td>-1.643269</td>\n",
       "      <td>-1.698463</td>\n",
       "      <td>0.029310</td>\n",
       "      <td>0.120428</td>\n",
       "      <td>0.075578</td>\n",
       "      <td>0.168152</td>\n",
       "      <td>0.029451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.021709</td>\n",
       "      <td>-0.026145</td>\n",
       "      <td>-0.034432</td>\n",
       "      <td>-0.034932</td>\n",
       "      <td>-0.036271</td>\n",
       "      <td>-0.033615</td>\n",
       "      <td>-0.026524</td>\n",
       "      <td>-0.028578</td>\n",
       "      <td>-0.032416</td>\n",
       "      <td>-0.030951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109933</td>\n",
       "      <td>0.135964</td>\n",
       "      <td>0.122471</td>\n",
       "      <td>0.274029</td>\n",
       "      <td>0.290201</td>\n",
       "      <td>0.271022</td>\n",
       "      <td>0.249000</td>\n",
       "      <td>0.339047</td>\n",
       "      <td>0.354345</td>\n",
       "      <td>0.325709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001143</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>-0.000305</td>\n",
       "      <td>0.005120</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>-0.003509</td>\n",
       "      <td>-0.000297</td>\n",
       "      <td>-0.004837</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.309165</td>\n",
       "      <td>-0.800369</td>\n",
       "      <td>-1.300103</td>\n",
       "      <td>-1.264863</td>\n",
       "      <td>-0.705196</td>\n",
       "      <td>-0.849624</td>\n",
       "      <td>-1.253531</td>\n",
       "      <td>-1.147455</td>\n",
       "      <td>-1.114735</td>\n",
       "      <td>-0.571323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    header0   header1   header2   header3   header4   header5   header6  \\\n",
       "0 -0.001494 -0.006114 -0.002769  0.002177 -0.002500 -0.004409 -0.004502   \n",
       "1  0.029401  0.031186  0.054998  0.044918  0.068072  0.026208  0.025993   \n",
       "2  0.160614  0.170542  0.134455  0.150562  0.137968  0.162312  0.160939   \n",
       "3 -0.021709 -0.026145 -0.034432 -0.034932 -0.036271 -0.033615 -0.026524   \n",
       "4 -0.001143  0.002904 -0.000305  0.005120  0.002741 -0.003509 -0.000297   \n",
       "\n",
       "    header7   header8   header9  ...  header20  header21  header22  header23  \\\n",
       "0 -0.004180 -0.000122 -0.004193  ... -0.104987 -0.047108 -0.112094 -0.100577   \n",
       "1  0.035039  0.048243  0.062763  ... -0.167204 -0.154656 -0.159713 -0.431183   \n",
       "2  0.163658  0.156357  0.158699  ... -1.691840 -1.771973 -1.708544 -1.643269   \n",
       "3 -0.028578 -0.032416 -0.030951  ...  0.109933  0.135964  0.122471  0.274029   \n",
       "4 -0.004837  0.003761  0.001875  ... -1.309165 -0.800369 -1.300103 -1.264863   \n",
       "\n",
       "   header24  header25  header26  header27  header28  header29  \n",
       "0 -0.040931 -0.058437 -0.100992 -0.085715 -0.083076 -0.019339  \n",
       "1 -0.340838 -0.326700 -0.343063 -0.458384 -0.504819 -0.386363  \n",
       "2 -1.698463  0.029310  0.120428  0.075578  0.168152  0.029451  \n",
       "3  0.290201  0.271022  0.249000  0.339047  0.354345  0.325709  \n",
       "4 -0.705196 -0.849624 -1.253531 -1.147455 -1.114735 -0.571323  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizeddataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61e3522b86c41fd8deab6157726bd95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# The scaler objects will be stored in this dictionary so that our output test data from the model can be re-scaled during evaluation\n",
    "label_scalers = {}\n",
    "\n",
    "train_x = []\n",
    "test_x = {}\n",
    "test_y = {}\n",
    "\n",
    "for file in tqdm_notebook(os.listdir(data_dir)): \n",
    "    # Skipping the files we're not using\n",
    "    if file[-4:] != \".csv\" or file == \"pjm_hourly_est.csv\":\n",
    "        continue\n",
    "    \n",
    "    # Store csv file in a Pandas DataFrame\n",
    "    df = pd.read_csv(data_dir + file, parse_dates=[0])\n",
    "    # Processing the time data into suitable input formats\n",
    "    df['hour'] = df.apply(lambda x: x['Datetime'].hour,axis=1)\n",
    "    df['dayofweek'] = df.apply(lambda x: x['Datetime'].dayofweek,axis=1)\n",
    "    df['month'] = df.apply(lambda x: x['Datetime'].month,axis=1)\n",
    "    df['dayofyear'] = df.apply(lambda x: x['Datetime'].dayofyear,axis=1)\n",
    "    df = df.sort_values(\"Datetime\").drop(\"Datetime\",axis=1)\n",
    "    \n",
    "    # Scaling the input data\n",
    "    sc = MinMaxScaler()\n",
    "    label_sc = MinMaxScaler()\n",
    "    data = sc.fit_transform(df.values)\n",
    "    # Obtaining the Scale for the labels(usage data) so that output can be re-scaled to actual value during evaluation\n",
    "    label_sc.fit(df.iloc[:,0].values.reshape(-1,1))\n",
    "    label_scalers[file] = label_sc\n",
    "    \n",
    "    # Define lookback period and split inputs/labels\n",
    "    lookback = 90\n",
    "    inputs = np.zeros((len(data)-lookback,lookback,df.shape[1]))\n",
    "    labels = np.zeros(len(data)-lookback)\n",
    "    \n",
    "    for i in range(lookback, len(data)):\n",
    "        inputs[i-lookback] = data[i-lookback:i]\n",
    "        labels[i-lookback] = data[i,0]\n",
    "    inputs = inputs.reshape(-1,lookback,df.shape[1])\n",
    "    labels = labels.reshape(-1,1)\n",
    "    \n",
    "    # Split data into train/test portions and combining all data from different files into a single array\n",
    "    test_portion = int(0.1*len(inputs))\n",
    "    if len(train_x) == 0:\n",
    "        train_x = inputs[:-test_portion]\n",
    "        train_y = labels[:-test_portion]\n",
    "    else:\n",
    "        train_x = np.concatenate((train_x,inputs[:-test_portion]))\n",
    "        train_y = np.concatenate((train_y,labels[:-test_portion]))\n",
    "    test_x[file] = (inputs[-test_portion:])\n",
    "    test_y[file] = (labels[-test_portion:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(980185, 90, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of 980,185 sequences of training data\n",
    "\n",
    "To improve the speed of our training, we can process the data in batches so that the model does not need to update its weights as frequently. The Torch *Dataset* and *DataLoader* classes are useful for splitting our data into batches and shuffling them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check if we have any GPUs to speed up our training time by many folds. If youâ€™re using FloydHub with GPU to run this code, the training time will be significantly reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll be defining the structure of the GRU and LSTM models. Both models have the same structure, with the only difference being the **recurrent layer** (GRU/LSTM) and the initializing of the hidden state. The hidden state for the LSTM is a tuple containing both the **cell state** and the **hidden state**, whereas the GRU only has a single hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden\n",
    "\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.lstm(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training process is defined in a function below so that we can reproduce it for both models. Both models will have the same number of **dimensions** in the *hidden state* and *layers*, trained over the same number of **epochs** and **learning rate**, and trained and tested on the exact same set of data.\n",
    "\n",
    "For the purpose of comparing the performance of both models as well, we'll being tracking the time it takes for the model to train and eventually comparing the final accuracy of both models on the test set. For our accuracy measure, we'll use *Symmetric Mean Absolute Percentage Error (sMAPE)* to evaluate the models. *sMAPE* is the sum of the **absolute difference** between the predicted and actual values divided by the average of the predicted and actual value, therefore giving a percentage measuring the amount of error. \n",
    "\n",
    "This is the formula for *sMAPE*:\n",
    "\n",
    "$sMAPE = \\frac{100%}{n} \\sum_{t=1}^n \\frac{|F_t - A_t|}{(|F_t + A_t|)/2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, learn_rate, hidden_dim=256, EPOCHS=5, model_type=\"GRU\"):\n",
    "    \n",
    "    # Setting common hyperparameters\n",
    "    input_dim = next(iter(train_loader))[0].shape[2]\n",
    "    output_dim = 1\n",
    "    n_layers = 2\n",
    "    # Instantiating the models\n",
    "    if model_type == \"GRU\":\n",
    "        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    else:\n",
    "        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Defining loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    \n",
    "    model.train()\n",
    "    print(\"Starting Training of {} model\".format(model_type))\n",
    "    epoch_times = []\n",
    "    # Start training loop\n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        start_time = time.clock()\n",
    "        h = model.init_hidden(batch_size)\n",
    "        avg_loss = 0.\n",
    "        counter = 0\n",
    "        for x, label in train_loader:\n",
    "            counter += 1\n",
    "            if model_type == \"GRU\":\n",
    "                h = h.data\n",
    "            else:\n",
    "                h = tuple([e.data for e in h])\n",
    "            model.zero_grad()\n",
    "            \n",
    "            out, h = model(x.to(device).float(), h)\n",
    "            loss = criterion(out, label.to(device).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "            if counter%200 == 0:\n",
    "                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter, len(train_loader), avg_loss/counter))\n",
    "        current_time = time.clock()\n",
    "        print(\"Epoch {}/{} Done, Total Loss: {}\".format(epoch, EPOCHS, avg_loss/len(train_loader)))\n",
    "        print(\"Time Elapsed for Epoch: {} seconds\".format(str(current_time-start_time)))\n",
    "        epoch_times.append(current_time-start_time)\n",
    "    print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n",
    "    return model\n",
    "\n",
    "def evaluate(model, test_x, test_y, label_scalers):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []\n",
    "    start_time = time.clock()\n",
    "    for i in test_x.keys():\n",
    "        inp = torch.from_numpy(np.array(test_x[i]))\n",
    "        labs = torch.from_numpy(np.array(test_y[i]))\n",
    "        h = model.init_hidden(inp.shape[0])\n",
    "        out, h = model(inp.to(device).float(), h)\n",
    "        outputs.append(label_scalers[i].inverse_transform(out.cpu().detach().numpy()).reshape(-1))\n",
    "        targets.append(label_scalers[i].inverse_transform(labs.numpy()).reshape(-1))\n",
    "    print(\"Evaluation Time: {}\".format(str(time.clock()-start_time)))\n",
    "    sMAPE = 0\n",
    "    for i in range(len(outputs)):\n",
    "        sMAPE += np.mean(abs(outputs[i]-targets[i])/(targets[i]+outputs[i])/2)/len(outputs)\n",
    "    print(\"sMAPE: {}%\".format(sMAPE*100))\n",
    "    return outputs, targets, sMAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training of GRU model\n",
      "Epoch 1......Step: 200/957....... Average Loss for Epoch: 0.006068045466963668\n",
      "Epoch 1......Step: 400/957....... Average Loss for Epoch: 0.00339295689118444\n",
      "Epoch 1......Step: 600/957....... Average Loss for Epoch: 0.002416420340402207\n",
      "Epoch 1......Step: 800/957....... Average Loss for Epoch: 0.0018970439098484348\n",
      "Epoch 1/5 Done, Total Loss: 0.0016335768315337974\n",
      "Time Elapsed for Epoch: 180.094723 seconds\n",
      "Epoch 2......Step: 200/957....... Average Loss for Epoch: 0.0002500653800962027\n",
      "Epoch 2......Step: 400/957....... Average Loss for Epoch: 0.00024024876929615858\n",
      "Epoch 2......Step: 600/957....... Average Loss for Epoch: 0.00023239032923205136\n",
      "Epoch 2......Step: 800/957....... Average Loss for Epoch: 0.00022369524755049496\n",
      "Epoch 2/5 Done, Total Loss: 0.00021872715933283436\n",
      "Time Elapsed for Epoch: 180.25017699999998 seconds\n",
      "Epoch 3......Step: 200/957....... Average Loss for Epoch: 0.00017353565825033003\n",
      "Epoch 3......Step: 400/957....... Average Loss for Epoch: 0.0001724563007155666\n",
      "Epoch 3......Step: 600/957....... Average Loss for Epoch: 0.0001672183921133789\n",
      "Epoch 3......Step: 800/957....... Average Loss for Epoch: 0.00016318113342094875\n",
      "Epoch 3/5 Done, Total Loss: 0.00016009079403205763\n",
      "Time Elapsed for Epoch: 180.83372100000003 seconds\n",
      "Epoch 4......Step: 200/957....... Average Loss for Epoch: 0.000144169718005287\n",
      "Epoch 4......Step: 400/957....... Average Loss for Epoch: 0.00013929959117376712\n",
      "Epoch 4......Step: 600/957....... Average Loss for Epoch: 0.00013487234421821387\n",
      "Epoch 4......Step: 800/957....... Average Loss for Epoch: 0.00013171503585908794\n",
      "Epoch 4/5 Done, Total Loss: 0.00012953954319337767\n",
      "Time Elapsed for Epoch: 180.62579500000004 seconds\n",
      "Epoch 5......Step: 200/957....... Average Loss for Epoch: 0.00011400249368307414\n",
      "Epoch 5......Step: 400/957....... Average Loss for Epoch: 0.00011499241069031995\n",
      "Epoch 5......Step: 600/957....... Average Loss for Epoch: 0.0001157219948557516\n",
      "Epoch 5......Step: 800/957....... Average Loss for Epoch: 0.00011644823979622742\n",
      "Epoch 5/5 Done, Total Loss: 0.00011507780687554322\n",
      "Time Elapsed for Epoch: 181.04594699999996 seconds\n",
      "Total Training Time: 902.850363 seconds\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "gru_model = train(train_loader, lr, model_type=\"GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training of LSTM model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-11c4166a9570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"LSTM\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-f22d39df36a8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, learn_rate, hidden_dim, EPOCHS, model_type)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstm_model = train(train_loader, lr, model_type=\"LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the training time of both models, the GRU model is the clear winner in terms of speed, as we have mentioned earlier. The GRU finished 5 training epochs 72 seconds faster than the LSTM model.\n",
    "\n",
    "Moving on to measuring the accuracy of both models, weâ€™ll now use our evaluate() function and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Time: 4.838130999999976\n",
      "sMAPE: 0.2644234794074204%\n"
     ]
    }
   ],
   "source": [
    "gru_outputs, targets, gru_sMAPE = evaluate(gru_model, test_x, test_y, label_scalers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input and parameter tensors are not at the same device, found input tensor at cpu and parameter tensor at cuda:0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-55faa713afd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlstm_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_sMAPE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_scalers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-f22d39df36a8>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, test_x, test_y, label_scalers)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mlabs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_scalers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_scalers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-aa7aa2cc62d1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 577\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    578\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input and parameter tensors are not at the same device, found input tensor at cpu and parameter tensor at cuda:0"
     ]
    }
   ],
   "source": [
    "lstm_outputs, targets, lstm_sMAPE = evaluate(lstm_model, test_x, test_y, label_scalers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the LSTM model may have made smaller errors and edged the GRU model slightly in terms of performance accuracy, the difference is insignificant and thus inconclusive. There have been many other tests conducted by others comparing both these models but there has largely been no clear winner as to which is the better architecture overall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
