{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4 - Kaggle Competition\n",
    "## CSCI 5622 - Spring 2019\n",
    "#Scott Scheraga\n",
    "***\n",
    "For this assignment, I used a Gradient Boosting Classifier with n_estimators=50,max_depth=13, and min_samples_leaf=200, which generated the best results in a comparison study I did. To process the data, I batched the two lowest average output native-country countries, so that the training sets would more easily be compared to the holdout sets. \n",
    "\n",
    "\n",
    "I created a new collumn \"capitalchange\" which is the sum of the capital gain and loss collumns, and decided to keep the 'capital-gain'and 'capital-loss' sets.\n",
    "I created dummy variables/did one-hot encoding for all categorical data. For the continuous data, I applied a min-max scaler to hours-per-week, but then did a standard normalizer to \"age\",'education-num',\"fnlwgt\",'capital-gain','capital-loss',and \"capitalchange\". I then created a holdout set of 25% of the training data. Lastly, I trainined the classifier using KFold cross validation with 10 splits. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix,roc_curve, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from random import seed\n",
    "from random import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self,features):\n",
    "        self.features=features\n",
    "        \n",
    "    def preprocess(self):    \n",
    "        \n",
    "        #self.features= pd.read_csv(\"traincombined.csv\")\n",
    "        \n",
    "        #https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8\n",
    "        #self.features=self.features.drop(columns = [])\n",
    "        \n",
    "        #self.features=self.features.drop(columns = \n",
    "          #  [\"workclass\",\"race\", \"educatio'DataFrame' object has no attribute 'ravel'n\",\"marital-status\",\"occupation\",\n",
    "         #    \"relationship\",\"race\",\"occupation\",\"sex\",\"fnlwgt\"])\n",
    "\n",
    "        \"\"\"\n",
    "        #print(self.features['education'].value_counts())\n",
    "        self.features['sex']=np.where(self.features['sex'] ==' Female',\n",
    "                                                1, self.features['sex'])\n",
    "        self.features['sex']=np.where(self.features['sex'] ==' Male',\n",
    "                                                0, self.features['sex'])\n",
    "        \n",
    "        #I might be losing data heere. Try splitting!\n",
    "        \n",
    "        self.features['education']=np.where(self.features['education'] ==' Preschool',\n",
    "                                                ' Some-school', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' 1st-4th',\n",
    "                                                ' Some-school', self.features['education'])       \n",
    "        self.features['education']=np.where(self.features['education'] ==' 5th-6th',\n",
    "                                                ' Some-school', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' 7th-8th',\n",
    "                                                ' Some-school', self.features['education'])  \n",
    "        \n",
    "        self.features['education']=np.where(self.features['education'] ==' 9th',\n",
    "                                                ' Some-school', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' 10th',\n",
    "                                                ' Some-school', self.features['education'])       \n",
    "        self.features['education']=np.where(self.features['education'] ==' 11th',\n",
    "                                                ' Some-school', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' 12th',\n",
    "                                                ' Some-school', self.features['education'])\n",
    "        \n",
    "        \n",
    "        self.features['education']=np.where(self.features['education'] ==' Assoc-voc',\n",
    "                                                ' Assoc-professional', self.features['education'])    \n",
    "        self.features['education']=np.where(self.features['education'] ==' Prof-school',\n",
    "                                                ' Assoc-professional', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' Assoc-acdm',\n",
    "                                                ' Assoc-professional', self.features['education'])        \n",
    "        self.features['education']=np.where(self.features['education'] ==' Some-college',\n",
    "                                                ' HS-grad or Some-college', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' HS-grad',\n",
    "                                                ' HS-grad or Some-college', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' Masters',\n",
    "                                                ' Graduate-degree', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' Doctorate',\n",
    "                                                ' Graduate-degree', self.features['education'])\n",
    "       \n",
    "       \n",
    "        self.features['marital-status']=np.where(self.features['marital-status'] ==' Divorced',\n",
    "                                                ' Not Married', self.features['marital-status'])    \n",
    "        self.features['marital-status']=np.where(self.features['marital-status'] ==' Never-married',\n",
    "                                                ' Not Married', self.features['marital-status'])    \n",
    "        self.features['marital-status']=np.where(self.features['marital-status'] ==' Separated',\n",
    "                                                ' Not Married', self.features['marital-status'])    \n",
    "        self.features['marital-status']=np.where(self.features['marital-status'] ==' Widowed',\n",
    "                                                ' Not Married', self.features['marital-status'])  \n",
    "        self.features['marital-status']=np.where(self.features['marital-status'] ==' Married-spouse-absent',\n",
    "                                                ' Not Married', self.features['marital-status'])        \n",
    "        self.features['marital-status']=np.where(self.features['marital-status'] ==' Married-civ-spouse',\n",
    "                                                ' Married', self.features['marital-status'])    \n",
    "        self.features['marital-status']=np.where(self.features['marital-status'] ==' Married-AF-spouse',\n",
    "                                                ' Married', self.features['marital-status'])  \n",
    "        \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Never-worked',\n",
    "                                                ' Zero', self.features['workclass']) \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Without-pay',\n",
    "                                                ' Zero', self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' ?',\n",
    "                                                ' Low', self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Private',\n",
    "                                                ' Low', self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' State-gov',\n",
    "                                                ' Mid', self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Self-emp-not-inc',\n",
    "                                                ' Mid', self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Local-gov',\n",
    "                                                ' Mid', self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Federal-gov',\n",
    "                                                ' High', self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Self-emp-inc',\n",
    "                                                ' High', self.features['workclass'])  \n",
    "        \n",
    "        #Label Encoding\n",
    "        \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Never-worked',\n",
    "                                                1, self.features['workclass']) \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Without-pay',\n",
    "                                                1, self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' ?',\n",
    "                                                2, self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Private',\n",
    "                                                2, self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' State-gov',\n",
    "                                                3, self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Self-emp-not-inc',\n",
    "                                                3, self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Local-gov',\n",
    "                                                3, self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Federal-gov',\n",
    "                                                4, self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Self-emp-inc',\n",
    "                                                4, self.features['workclass']) \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        #0 mean output from test set\n",
    "        country1 = [' Holand-Netherlands', ' Outlying-US(Guam-USVI-etc)']\n",
    "        #less than 0.1 mean output from test set\n",
    "        country2 = [' Dominican-Republic',' Columbia',' Guatemala',' Mexico', \n",
    "                    ' Nicaragua',' Peru',' Vietnam', ' Honduras',' Guatemala',' El-Salvador',' Haiti']\n",
    "        # 0.1 to 0.2 mean output from test set\n",
    "        country3 = [' Puerto-Rico',' Trinadad&Tobago',' Portugal',' Laos', \n",
    "                    ' Jamaica',' Ecuador',' Thailand']\n",
    "        #0.2-0.3 mean output from test set\n",
    "        country4 = [' Poland',' South',' Ireland',' Hungary',' United-States',\n",
    "                    ' Scotland',' ?',' Ecuador',' Cuba',' China',' Greece'] \n",
    "        #0.3-0.4 mean output from test set\n",
    "        country5 = [' Hong',' Philippines',' Germany',' Canada',' England',\n",
    "                    ' Italy',' Cambodia',' Yugoslavia',' Japan',' Taiwan']         \n",
    "        #greater than 0.4 mean output from test set\n",
    "        country6 = [' India',' France',' Iran']      \n",
    "        \n",
    "        \n",
    "        for x in country1:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                ' countrygroup1', self.features['native-country']) \n",
    "        \"\"\" \n",
    "        for x in country2:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                ' countrygroup2', self.features['native-country']) \n",
    "        for x in country3:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                ' countrygroup3', self.features['native-country'])  \n",
    "         \n",
    "        for x in country4:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                ' countrygroup4', self.features['native-country']) \n",
    "        for x in country5:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                ' countrygroup5', self.features['native-country'])         \n",
    "        for x in country6:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                ' countrygroup6', self.features['native-country'])          \n",
    "        \n",
    "        #Label Encoding\n",
    "        \n",
    "        for x in country1:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                1, self.features['native-country']) \n",
    "        for x in country2:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                2, self.features['native-country']) \n",
    "        for x in country3:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                3, self.features['native-country'])         \n",
    "        for x in country4:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                4, self.features['native-country']) \n",
    "        for x in country5:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                5, self.features['native-country'])         \n",
    "        for x in country6:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                6, self.features['native-country'])          \n",
    "             \n",
    "        \"\"\"\n",
    "        \n",
    "        #https://towardsdatascience.com/preprocessing-with-sklearn-a-complete-and-comprehensive-guide-670cb98fcfb9\n",
    "        #https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "\n",
    "        #self.features['education-num'] = preprocessing.scale(self.features['education-num'])\n",
    "        #self.features[\"fnlwgt\"] = preprocessing.scale(self.features[\"fnlwgt\"])\n",
    "        \n",
    "    \n",
    "        \n",
    "        #scaler1 = MinMaxScaler(feature_range = (0,1))\n",
    "        #scaler1.fit_transform(self.features['capital-gain'].values.reshape(-1, 1))\n",
    "        #scaler2 = MinMaxScaler(feature_range = (0,1))\n",
    "        #scaler2.fit_transform(self.features['capital-loss'].values.reshape(-1, 1))\n",
    "        #scaler3 = MinMaxScaler()\n",
    "        #scaler3.fit_transform(self.features['age'].values.reshape(-1, 1))\n",
    "        #scaler4 = MinMaxScaler(feature_range = (0,1))\n",
    "        #scaler4.fit_transform(self.features['education-num'].values.reshape(-1, 1))\n",
    "        #scaler5 = MinMaxScaler()\n",
    "        #scaler5.fit_transform(self.features['fnlwgt'].values.reshape(-1, 1))\n",
    "\n",
    "        \n",
    "     \n",
    "        #self.features['capital-gain']=np.where(self.features['capital-gain'].astype(float) < 149,\n",
    "          #                                      ' Low', self.features['capital-gain'])\n",
    "        \n",
    "        #self.features['capital-gain']=np.where((self.features['capital-gain'].astype(float) > 149) &\n",
    "        #         (self.features['capital-gain'].astype(float) <2077),' Mid-Low', self.features['capital-gain'])        \n",
    "        #self.features['capital-gain']=np.where((self.features['capital-gain'] > 2077) &\n",
    "           #      (self.features['capital-gain'] <4006),' Mid-High', self.features['capital-gain']) \n",
    "       \n",
    "        #self.features['capital-gain']=np.where(int(self.features['capital-gain']) > 4006,\n",
    "        #                                        ' High', self.features['capital-gain'])        \n",
    "\n",
    "      \n",
    "\n",
    "        #Reference: https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8\n",
    "        \"\"\"\"\"\"\n",
    "        self.features.insert(2,\"capitalchange\",self.features['capital-loss']+self.features['capital-gain'])\n",
    "           \n",
    "        \n",
    "        #print(self.features)\n",
    "        category_variables=['marital-status',\"sex\",\"race\",'workclass',\n",
    "                            \"relationship\",\"occupation\",'native-country','education'] #'education',,'workclass'\n",
    "        for var in category_variables:\n",
    "            cat_list='var'+'_'+var\n",
    "            cat_list = pd.get_dummies(self.features[var], prefix=var)\n",
    "            data1=self.features.join(cat_list)\n",
    "            self.features=data1\n",
    "            \n",
    "        category_variables=['marital-status',\"race\",\"sex\",'workclass',\n",
    "                            \"relationship\",\"occupation\",'native-country','education'] #,\"relationship\"'education',\n",
    "        self.features_vars=self.features.columns.values.tolist()\n",
    "        to_keep=[i for i in self.features_vars if i not in category_variables]\n",
    "        \n",
    "        #'education',\n",
    "        \n",
    "        data_final=self.features[to_keep]\n",
    "        #data_final=data_final.drop(columns = [   \n",
    "         #   'education_ Graduate-degree','education_ HS-grad or Some-college',\n",
    "         #   'education_ Assoc-professional','education_ Bachelors']) \n",
    "        \n",
    "        \n",
    "        #'workclass_ Low','workclass_ Mid','education_ Bachelors'\n",
    "        \n",
    "\n",
    "   \n",
    "       \n",
    "        \n",
    "        return data_final\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 108)\n",
      "(16281, 108)\n",
      "(32561, 108)\n",
      "(16281, 108)\n",
      "Epoch #: 0  Score:  0.8641444539982803   Train Score:  0.8947128947128947\n",
      "Epoch #: 1  Score:  0.8635302788355239   Train Score:  0.8958503958503958\n",
      "Epoch #: 2  Score:  0.8652499692912419   Train Score:  0.893029393029393\n",
      "Epoch #: 3  Score:  0.8658641444539983   Train Score:  0.8920738920738921\n",
      "Epoch #: 4  Score:  0.8637759489006265   Train Score:  0.8932568932568933\n",
      "Epoch #: 5  Score:  0.8631617737378701   Train Score:  0.8941213941213941\n",
      "Epoch #: 6  Score:  0.8669696597469598   Train Score:  0.8938028938028938\n",
      "Epoch #: 7  Score:  0.8656184743888957   Train Score:  0.8929383929383929\n",
      "Epoch #: 8  Score:  0.8670924947795111   Train Score:  0.8929383929383929\n",
      "Epoch #: 9  Score:  0.8634074438029726   Train Score:  0.8937573937573937\n",
      "SCORE:  0.8670924947795111\n",
      "   \n",
      "R2 score: 0.259161711536982\n",
      "Mean squared error: 0.1365925561970274\n",
      "Variance 0.1179350297885893\n",
      "   \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC No Skill= 0.5\n",
      "AUC Logisitic= 0.7856062689141923\n",
      "[0 0 0 ... 1 0 1]\n",
      "Data Saved to file\n"
     ]
    }
   ],
   "source": [
    "traindatafeatures= pd.read_csv(\"train-features_scottannotated.csv\")\n",
    "trainoutput= pd.read_csv(\"train-output_scottannotated.csv\")\n",
    "testdatafeatures= pd.read_csv(\"test-features_scottannotated.csv\")  \n",
    "\"\"\"\n",
    "#Fill in missing data:\n",
    "catfeatures=['workclass','education','marital-status','occupation',\n",
    "             'relationship','race','sex','native-country',]\n",
    "\n",
    "continfeatures=['age','fnlwgt','education-num','hours-per-week']\n",
    "\n",
    "#NAs = pd.concat([testdatafeatures.isnull().sum()], axis=1,keys=['Train']) \n",
    "#print(NAs[NAs.sum(axis=1) > 0])\n",
    "#NAs = pd.concat([train.isnull().sum()], axis=1, keys=[‘Train’])\n",
    "#NAs[NAs.sum(axis=1) > 0]\n",
    "\n",
    "for a in continfeatures:\n",
    "        traindatafeatures[a] = traindatafeatures[a].fillna(int(traindatafeatures[a].mean()))\n",
    "        testdatafeatures[a] = testdatafeatures[a].fillna(int(testdatafeatures[a].mean()))\n",
    "for b in catfeatures:\n",
    "        traindatafeatures[b] = traindatafeatures[b].fillna(traindatafeatures[b].mode()[0])\n",
    "        testdatafeatures[b] = testdatafeatures[b].fillna(testdatafeatures[b].mode()[0])\n",
    "\"\"\"\n",
    "\n",
    "data_train = Data(traindatafeatures).preprocess()\n",
    "data_test= Data(testdatafeatures).preprocess()\n",
    "#print(data_train.shape)\n",
    "#print(data_test.shape)\n",
    "\n",
    "#print(data_train.info())\n",
    "\n",
    "#print(data_test.info())\n",
    "\n",
    "#Data_train= (32561, 45)\n",
    "#Data_Test= (16281, 45)\n",
    "\n",
    "combinedData = pd.concat([data_train,data_test])\n",
    "\n",
    "normscalefeatures=[\"age\",'education-num',\"fnlwgt\",'capital-gain','capital-loss',\"capitalchange\"]#,,'capital-gain','capital-loss'\n",
    "for n in normscalefeatures:\n",
    "        # self.features[n] = preprocessing.normalize(self.features[n])\n",
    "        #data_train[n] = preprocessing.scale(data_train[n])\n",
    "        #data_test[n] = preprocessing.scale(data_test[n])\n",
    "        combinedData[n] = preprocessing.scale(combinedData[n])\n",
    "\n",
    "    \n",
    "minmaxscalefeatures=[\"hours-per-week\"]\n",
    "for n in minmaxscalefeatures:\n",
    "        # self.features[n] = preprocessing.normalize(self.features[n])\n",
    "        #data_train[n] = preprocessing.scale(data_train[n])\n",
    "        #data_test[n] = preprocessing.scale(data_test[n])\n",
    "        scaler1 = MinMaxScaler(feature_range = (0,1))\n",
    "        combinedData[n]= scaler1.fit_transform(combinedData[n].values.reshape(-1, 1))        \n",
    "\"\"\"\"\"\" \n",
    "dfs = np.split(combinedData, [32561], axis=0)\n",
    "data_train =dfs[0]\n",
    "data_test= dfs[1]\n",
    "print(dfs[0].shape)\n",
    "print(dfs[1].shape)        \n",
    "        \n",
    "#print(trainoutput)\n",
    "trainoutputArray=np.asarray(trainoutput)\n",
    "np.transpose(trainoutputArray)\n",
    "\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "# Add noisy features to make the problem harder\n",
    "random_state = np.random.RandomState(7)\n",
    "n_samples, n_features = data_train.shape\n",
    "n_samplestest, n_featurestest = data_test.shape\n",
    "data_train = np.c_[data_train, random_state.randn(n_samples, 0)]\n",
    "data_test = np.c_[data_test, random_state.randn(n_samplestest, 0)]\n",
    "\"\"\"\"\"\"\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)\n",
    "#data_test.preprocess()\n",
    "\n",
    "#print(trainoutputArray.ravel())\n",
    "\n",
    "#data_final_vars=data_train.columns.values.tolist()\n",
    "#print(data_train.columns.values)\n",
    "\n",
    "\n",
    "x_train, x_holdout, y_train, y_holdout = train_test_split(\n",
    "             data_train, trainoutputArray.ravel(), test_size=0.25, random_state=1555)\n",
    "\n",
    "\n",
    "\n",
    "#https://towardsdatascience.com/machine-learning-part-18-boosting-algorithms-gradient-boosting-in-python-ef5ae6965be4\n",
    "\n",
    "#best_regressor.fit(X_train, y_train)\n",
    "#model= AdaBoostClassifier(n_estimators=150)\n",
    "#bestmodel = AdaBoostClassifier(n_estimators=150)\n",
    "#r=50\n",
    "#g=13\n",
    "#h=200\n",
    "\n",
    "model=ensemble.GradientBoostingClassifier(learning_rate=.25,\n",
    "                                         n_estimators=50,max_depth=13,min_samples_leaf=200)\n",
    "bestmodel=ensemble.GradientBoostingClassifier(learning_rate=.25,\n",
    "                                             n_estimators=50,max_depth=13,min_samples_leaf=200)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "bestscore=0\n",
    "score=0\n",
    "nestimators=[20,30,40,50,60,70,80]\n",
    "maxdepth=[5,7,9,11,13,15]\n",
    "minsamplesplit=[200]#,400,600,800,1000\n",
    "#Best result 0.8688121852352291 nestimators= 50  maxdepth=  13 minsamplesplit=  200\n",
    "\n",
    "for r in nestimators:\n",
    "    for g in maxdepth:\n",
    "        for h in minsamplesplit:\n",
    "\n",
    "            model=ensemble.GradientBoostingClassifier(learning_rate=.25,\n",
    "                n_estimators=r,max_depth=g,min_samples_leaf=h)\n",
    "    #bestmodel=ensemble.GradientBoostingClassifier(learning_rate=.25)\n",
    "\n",
    "            model.fit(x_train, y_train)\n",
    "            score = model.score(x_holdout, y_holdout)\n",
    "            if score>bestscore:\n",
    "                bestscore=score\n",
    "                print (\"New best score: \",bestscore,\"nestimators=\",r,\" maxdepth= \",g,\"minsamplesplit= \",h )\n",
    "\n",
    "print(\"Best SCORE: \",bestscore)\n",
    "#https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_regression.html\n",
    "\n",
    "\"\"\"\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "#https://towardsdatascience.com/cross-validation-a-beginners-guide-5b8ca04962cd\n",
    "trainindexcounter=0\n",
    "bestscore=0\n",
    "score=0\n",
    "bestmodel\n",
    "kf = KFold(n_splits=10) # Define the split - into 2 folds \n",
    "#kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    x_trainfold, x_testfold = x_train[train_index], x_train[test_index]\n",
    "    y_trainfold, y_testfold = y_train[train_index], y_train[test_index]\n",
    "    model.fit(x_trainfold, y_trainfold)\n",
    "    score = model.score(x_holdout, y_holdout)\n",
    "    trainscore = model.score(x_trainfold, y_trainfold)\n",
    "    print(\"Epoch #:\", trainindexcounter, \" Score: \",score, \"  Train Score: \",trainscore) \n",
    "    trainindexcounter+=1\n",
    "    \n",
    "    if score>bestscore:\n",
    "        bestscore=score\n",
    "        bestmodel=model\n",
    "    #if trainindexcounter==1:\n",
    "         # break\n",
    "    \n",
    "score=bestscore    \n",
    "model=bestmodel\n",
    "print(\"SCORE: \",score)\n",
    "#print(confusion_matrix(y_holdout, modeloutput.predict(x_holdout)))\n",
    "finalpredictions=model.predict(x_holdout)\n",
    "#predictions= model.predict(data_test)\n",
    "#print(predictions)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#tn, fp, fn, tp = confusion_matrix(y_holdout, finalpredictions).ravel()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#print(\"tn=\",tn,\" fp=\" ,fp,\" fn=\", fn,\" tp=\", tp)\n",
    "print (\"   \")\n",
    "print(\"R2 score:\",  r2_score(y_holdout,finalpredictions))\n",
    "print(\"Mean squared error:\", mean_squared_error(\n",
    "              y_holdout,finalpredictions))\n",
    "\n",
    "#variance calc\n",
    "#https://www.bmc.com/blogs/mean-squared-error-r2-and-variance-in-regression-analysis/\n",
    "er = []\n",
    "g = 0\n",
    "for i in range(len(y_holdout)):\n",
    "    #print( \"actual=\", y_holdout[i], \" observed=\", finalpredictions[i])\n",
    "    x = (y_holdout[i] - finalpredictions[i]) **2\n",
    "    er.append(x)\n",
    "    g = g + x\n",
    "v = np.var(er)\n",
    "\n",
    "print (\"Variance\", v)\n",
    "print (\"   \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
    "ns_probs = [0 for _ in range(len(y_holdout))]\n",
    "ns_auc = roc_auc_score(y_holdout, ns_probs)\n",
    "\n",
    "lr_probs=model.predict_proba(x_holdout)\n",
    "lr_probs = lr_probs[:, 1]\n",
    "fpr, tpr,_=roc_curve(y_holdout,lr_probs) \n",
    "lr_auc= roc_auc_score( y_holdout,finalpredictions)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "##Adding the ROC\n",
    "plt.plot(fpr, tpr, color='red', lw=2,label='ROC curve') #lw=2,\n",
    "##Random FPR and TPR\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "##Title and label\n",
    "plt.xlabel('FPR- False Positive')\n",
    "plt.ylabel('TPR-True Positive')\n",
    "plt.title('ROC curve')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "print(\"AUC No Skill=\",ns_auc)\n",
    "print(\"AUC Logisitic=\",lr_auc)\n",
    "\n",
    "\n",
    "#https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6\n",
    "\n",
    "\n",
    "\n",
    "predictions= model.predict(data_test)\n",
    "print(predictions)\n",
    "    \n",
    "        # dictionary of lists  \n",
    "dict = {'Category': predictions }  \n",
    "   \n",
    "df = pd.DataFrame(dict) \n",
    "  \n",
    "        # saving the dataframe \n",
    "df.to_csv('ScottSubmission4.csv') \n",
    "print(\"Data Saved to file\")\n",
    "\n",
    "\n",
    "\n",
    "#Professor suggests I look into:\n",
    "#ensembles : random forest, etc  or neural nets\n",
    "#svm, neural nets and random forest have more variables I can tweak thant log regression\n",
    "#.8728 at learning rate of .25\n",
    "\n",
    "#naive bayes-  potentially not great..\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "#https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a\n",
    "#https://towardsdatascience.com/logistic-regression-model-tuning-with-scikit-learn-part-1-425142e01af5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
