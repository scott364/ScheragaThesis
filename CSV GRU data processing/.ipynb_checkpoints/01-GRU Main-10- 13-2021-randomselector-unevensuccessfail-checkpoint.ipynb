{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll be using a GRU model for a time series prediction task and we will compare the performance of the GRU model against an LSTM model as well. The dataset that we will be using is the Hourly Energy Consumption dataset which can be found on [Kaggle](https://www.kaggle.com/robikscube/hourly-energy-consumption). The dataset contains power consumption data across different regions around the United States recorded on an hourly basis.\n",
    "\n",
    "You can run the code implementation in this article on FloydHub using their GPUs on the cloud by clicking the following link and using the main.ipynb notebook.\n",
    "\n",
    "[![Run on FloydHub](https://static.floydhub.com/button/button-small.svg)](https://floydhub.com/run?template=https://github.com/gabrielloye/https://github.com/gabrielloye/GRU_Prediction)\n",
    "\n",
    "This will speed up the training process significantly. Alternatively, the link to the GitHub repository can be found [here]().\n",
    "\n",
    "The goal of this implementation is to create a model that can accurately predict the energy usage in the next hour given historical usage data. We will be using both the GRU and LSTM model to train on a set of historical data and evaluate both models on an unseen test set. To do so, weâ€™ll start with feature selection, data-preprocessing, followed by defining, training and eventually evaluating the models.\n",
    "\n",
    "We will be using the PyTorch library to implement both types of models along with other common Python libraries used in data analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.python-engineer.com/posts/pytorch-rnn-lstm-gru/\n",
    "\n",
    "#https://blog.floydhub.com/gru-with-pytorch/\n",
    "\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import MinMaxScaler,QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Local ###\n",
    "#from data_processing import *\n",
    "\n",
    "\n",
    "\n",
    "# Define data root directory\n",
    "\n",
    "#data_dir = \"./data/\"\n",
    "#print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of **12** *.csv* files containing hourly energy trend data (*'est_hourly.paruqet'* and *'pjm_hourly_est.csv'* are not used). In our next step, we will be reading these files and pre-processing these data in this order:\n",
    "- Getting the time data of each individual time step and generalizing them\n",
    "    - Hour of the day *i.e. 0-23*\n",
    "    - Day of the week *i.e. 1-7*\n",
    "    - Month *i.e. 1-12*\n",
    "    - Day of the year *i.e. 1-365*\n",
    "    \n",
    "    \n",
    "- Scale the data to values between 0 and 1\n",
    "    - Algorithms tend to perform better or converge faster when features are on a relatively similar scale and/or close to normally distributed\n",
    "    - Scaling preserves the shape of the original distribution and doesn't reduce the importance of outliers.\n",
    "    \n",
    "    \n",
    "- Group the data into sequences to be used as inputs to the model and store their corresponding labels\n",
    "    - The **sequence length** or **lookback period** is the number of data points in history that the model will use to make the prediction\n",
    "    - The label will be the next data point in time after the last one in the input sequence\n",
    "    \n",
    "\n",
    "- The inputs and labels will then be split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(device)\n",
    "\n",
    "\n",
    "def get_torch_device( v=0 ):\n",
    "    # torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "    is_cuda = torch.cuda.is_available()\n",
    "    # If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "    if is_cuda:\n",
    "        device = torch.device(\"cuda\")\n",
    "        if v:  print( \"CUDA Available!\" )\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        if v:  print( \"NO CUDA\" )\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16176, 10)\n",
      "(20880, 10)\n",
      "(37056, 10)\n"
     ]
    }
   ],
   "source": [
    "#choppeddata=pd.read_csv('choppeddata_10_06_2021.csv')#.head()\n",
    "choppeddata1=pd.read_csv('choppeddata_10_04_2021_randomselector_uneven.csv')#.head()\n",
    "choppeddata2=pd.read_csv('choppeddata_10_06_2021_randomselector_uneven.csv')#.head()\n",
    "print(choppeddata1.shape)\n",
    "print(choppeddata2.shape)\n",
    "frames = [choppeddata1, choppeddata2]\n",
    "choppeddata = pd.concat(frames)\n",
    "print(choppeddata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "choppeddata=pd.read_csv('choppeddata_10_04_2021_randomselector_uneven.csv')#.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16176, 10)\n",
      "total runs: 2696\n"
     ]
    }
   ],
   "source": [
    "print(choppeddata.shape)\n",
    "runqty=int(choppeddata.shape[0]/6)\n",
    "print(\"total runs:\",runqty)\n",
    "choppedheaders=[]\n",
    "lookback=10 #save only the last 11 timesteps\n",
    "for i in range(lookback):  \n",
    "    label=str(i)\n",
    "    choppedheaders.append(\"header\"+label)\n",
    "\n",
    "#put chopped data in np.arrays\n",
    "State=np.zeros((runqty,5,lookback)) #96 runs,with 5 sets of data (x,y,z,roll,pitch) each, and each run is 11 timesteps long\n",
    "Labels=np.zeros((runqty,lookback)) #96 runs, each run is 11 timesteps long\n",
    "runcounter=0\n",
    "\n",
    "for i in range(0,choppeddata.shape[0],6):\n",
    "            State[runcounter][0][:]=(choppeddata[choppedheaders[:]].iloc[i]).tolist()\n",
    "            State[runcounter][1][:]=(choppeddata[choppedheaders[:]].iloc[i+1]).tolist()\n",
    "            State[runcounter][2][:]=(choppeddata[choppedheaders[:]].iloc[i+2]).tolist()\n",
    "            State[runcounter][3][:]=(choppeddata[choppedheaders[:]].iloc[i+3]).tolist()\n",
    "            State[runcounter][4][:]=(choppeddata[choppedheaders[:]].iloc[i+4]).tolist()\n",
    "            Labels[runcounter][:]=(choppeddata[choppedheaders[:]].iloc[i+5]).tolist()  #labels   \n",
    "            runcounter+=1\n",
    "#print(State[0])\n",
    "#print(Labels)\n",
    "#print(Labels[:,9]) #just getting finals labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (2696, 5, 10)\n",
      "Test set X size 33700\n",
      "Train set Y size 2022\n",
      "Test set X size 33700\n",
      "Test set Y size 674\n"
     ]
    }
   ],
   "source": [
    "#X= range(0,575,6)\n",
    "#y= range(0,575,6)\n",
    "\n",
    "X=State\n",
    "y=Labels[:,lookback-1]\n",
    "print(\"x.shape\",X.shape)\n",
    "\n",
    "y=y.reshape(runqty,1)\n",
    "\n",
    "random_seed=int(time.time())\n",
    "#print(int(time.time()))\n",
    "train_x, test_x, train_y,test_y = train_test_split(X, y, test_size=.25, #0.33, \n",
    "                                                   random_state=random_seed)\n",
    "#print(\"Train\")\n",
    "#print(train_x[0])\n",
    "#print(train_y[0])\n",
    "print(\"Test set X size\", test_x.size)\n",
    "print(\"Train set Y size\", train_y.size)\n",
    "#print(test_x[0])\n",
    "#print(test_y[0])\n",
    "print(\"Test set X size\", test_x.size)\n",
    "print(\"Test set Y size\", test_y.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of 980,185 sequences of training data\n",
    "\n",
    "To improve the speed of our training, we can process the data in batches so that the model does not need to update its weights as frequently. The Torch *Dataset* and *DataLoader* classes are useful for splitting our data into batches and shuffling them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f8ebb2f8dd0>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "#a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels.\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "test_data   = TensorDataset( torch.from_numpy( test_x ), torch.from_numpy( test_y ) )\n",
    "test_loader = DataLoader( test_data, shuffle = True, batch_size = batch_size, drop_last = True )\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check if we have any GPUs to speed up our training time by many folds. If youâ€™re using FloydHub with GPU to run this code, the training time will be significantly reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden\n",
    "    \n",
    "def train(train_loader, learn_rate, hidden_dim=128, EPOCHS=400, model_type=\"GRU\"):\n",
    "    #got  109 / 180 on training set, 29 / 60 on test set from 128 hidden dim, 50 epoch, batch size of 4, lr =0.001\n",
    "    #Got training data= 146 / 180, success vs test data= 38 / 60 with same as above but 100 epoch\n",
    "    #Got training data= 172 / 180, success vs test data= 46 / 60 with same as above but 200 epoch\n",
    "    #Got training data= 165 / 180, success vs test data= 52 / 60 with same as above but 200 epoch\n",
    "    \n",
    "    losslist=[]\n",
    "    # Setting common hyperparameters\n",
    "    input_dim = next(iter(train_loader))[0].shape[2]  #  = 11\n",
    "    #print(input_dim)\n",
    "    #print(\"input_dim\",input_dim)\n",
    "    output_dim = 1\n",
    "    n_layers = 2\n",
    "    # Instantiating the models\n",
    "    if model_type == \"GRU\":\n",
    "        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    else:\n",
    "        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Defining loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    \n",
    "    model.train()\n",
    "    print(\"Starting Training of {} model\".format(model_type))\n",
    "    epoch_times = []\n",
    "    # Start training loop\n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        start_time = time.clock()\n",
    "        h = model.init_hidden(batch_size)\n",
    "        avg_loss = 0.\n",
    "        counter = 0\n",
    "        for x, label in train_loader:\n",
    "            #print(\"x\",x)\n",
    "            #print(\"label\",label)\n",
    "            counter += 1\n",
    "            if model_type == \"GRU\":\n",
    "                h = h.data\n",
    "            else:\n",
    "                h = tuple([e.data for e in h])\n",
    "            model.zero_grad()\n",
    "            \n",
    "            out, h = model(x.to(device).float(), h)\n",
    "            #print(\"out\",out)\n",
    "            loss = criterion(out, label.to(device).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "            \n",
    "            if counter%20000 == 0:\n",
    "                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter, len(train_loader), avg_loss/counter))\n",
    "        current_time = time.clock()\n",
    "        if epoch%40 == 0:\n",
    "            print(\"Epoch {}/{} Done, Total Loss: {}   Time Elapsed: {} seconds\".format(epoch, EPOCHS, avg_loss/len(train_loader),str(current_time-start_time)))\n",
    "        \n",
    "            #print(\"Total\".format())\n",
    "        losslist.append(avg_loss/len(train_loader))\n",
    "        epoch_times.append(current_time-start_time)\n",
    "    print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n",
    "    plt.plot(losslist)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.show()\n",
    "    return model\n",
    "\n",
    "def train_existing_model(model,train_loader, learn_rate, hidden_dim=128, EPOCHS=400, model_type=\"GRU\"):\n",
    "    #got  109 / 180 on training set, 29 / 60 on test set from 128 hidden dim, 50 epoch, batch size of 4, lr =0.001\n",
    "    #Got training data= 146 / 180, success vs test data= 38 / 60 with same as above but 100 epoch\n",
    "    #Got training data= 172 / 180, success vs test data= 46 / 60 with same as above but 200 epoch\n",
    "    #Got training data= 165 / 180, success vs test data= 52 / 60 with same as above but 200 epoch\n",
    "    \n",
    "    losslist=[]\n",
    "    # Setting common hyperparameters\n",
    "    input_dim = next(iter(train_loader))[0].shape[2]  #  = 11\n",
    "    #print(input_dim)\n",
    "    #print(\"input_dim\",input_dim)\n",
    "    output_dim = 1\n",
    "    n_layers = 2\n",
    "    # Instantiating the models\n",
    "    \"\"\"\n",
    "    if model_type == \"GRU\":\n",
    "        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    else:\n",
    "        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    \"\"\"    \n",
    "        \n",
    "    model.to(device)\n",
    "    \n",
    "    # Defining loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    \n",
    "    model.train()\n",
    "    print(\"Starting Training of {} model\".format(model_type))\n",
    "    epoch_times = []\n",
    "    # Start training loop\n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        start_time = time.clock()\n",
    "        h = model.init_hidden(batch_size)\n",
    "        avg_loss = 0.\n",
    "        counter = 0\n",
    "        for x, label in train_loader:\n",
    "            #print(\"x\",x)\n",
    "            #print(\"label\",label)\n",
    "            counter += 1\n",
    "            if model_type == \"GRU\":\n",
    "                h = h.data\n",
    "            else:\n",
    "                h = tuple([e.data for e in h])\n",
    "            model.zero_grad()\n",
    "            \n",
    "            out, h = model(x.to(device).float(), h)\n",
    "            #print(\"out\",out)\n",
    "            loss = criterion(out, label.to(device).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "            \n",
    "            if counter%20000 == 0:\n",
    "                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter, len(train_loader), avg_loss/counter))\n",
    "        current_time = time.clock()\n",
    "        if epoch%40 == 0:\n",
    "            print(\"Epoch {}/{} Done, Total Loss: {}   Time Elapsed: {} seconds\".format(epoch, EPOCHS, avg_loss/len(train_loader),str(current_time-start_time)))\n",
    "        \n",
    "            #print(\"Total\".format())\n",
    "        losslist.append(avg_loss/len(train_loader))\n",
    "        epoch_times.append(current_time-start_time)\n",
    "    print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n",
    "    plt.plot(losslist)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.show()\n",
    "    return model,losslist\n",
    "\n",
    "\n",
    "def evaluate(model, test_x, test_y):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []\n",
    "    start_time = time.clock()\n",
    "    #for i in test_x.keys():\n",
    "    for i in range( len( test_x ) ):    \n",
    "        inp = torch.from_numpy(np.array(test_x[i])) # should be 5x1\n",
    "        labs = torch.from_numpy(np.array(test_y[i])) #should be 1x1\n",
    "        h = model.init_hidden(inp.shape[0])\n",
    "        #print(\"inp\",inp)\n",
    "        #print(\"labs\",labs)\n",
    "        #print(\"h\",h)\n",
    "        out, h = model(inp.to(device).float(), h)\n",
    "        #outputs.append(label_scalers[i].inverse_transform(out.cpu().detach().numpy()).reshape(-1))\n",
    "        #targets.append(label_scalers[i].inverse_transform(labs.numpy()).reshape(-1))\n",
    "        outputs.append( out.cpu().detach().numpy().reshape(-1) )\n",
    "        targets.append( labs.numpy().reshape(-1) )\n",
    "        \n",
    "    print(\"Evaluation Time: {}\".format(str(time.clock()-start_time)))\n",
    "    sMAPE = 0\n",
    "    for i in range(len(outputs)):\n",
    "        sMAPE += np.mean(abs(outputs[i]-targets[i])/(targets[i]+outputs[i])/2)/len(outputs)\n",
    "    print(\"sMAPE: {}%\".format(sMAPE*100))\n",
    "    return outputs, targets, sMAPE\n",
    "                               \n",
    "def evaluate2(model, test_x, test_y):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []  #labels\n",
    "    start_time = time.clock()\n",
    "    #for i in test_x.keys():\n",
    "    #for i in range( len( test_x ) ):    \n",
    "    inp = torch.from_numpy(np.array(test_x)) # should be 5x1\n",
    "    labs = torch.from_numpy(np.array(test_y)) #should be 1x1\n",
    "    h = model.init_hidden(inp.shape[0])\n",
    "    #print(\"inp\",inp)\n",
    "    #print(\"labs\",labs)\n",
    "    #print(\"h\",h)\n",
    "    out, h = model(inp.to(device).float(), h)\n",
    "    #outputs.append(label_scalers[i].inverse_transform(out.cpu().detach().numpy()).reshape(-1))\n",
    "    #targets.append(label_scalers[i].inverse_transform(labs.numpy()).reshape(-1))\n",
    "    outputs.append( out.cpu().detach().numpy().reshape(-1) )\n",
    "    targets.append( labs.numpy().reshape(-1) )\n",
    "        \n",
    "    print(\"Evaluation Time: {}\".format(str(time.clock()-start_time)))\n",
    "    sMAPE = 0\n",
    "    for i in range(len(outputs)):\n",
    "        sMAPE += np.mean(abs(outputs[i]-targets[i])/(targets[i]+outputs[i])/2)/len(outputs)\n",
    "    print(\"sMAPE: {}%\".format(sMAPE*100))\n",
    "    return outputs, targets, sMAPE                               \n",
    "\n",
    "def evaluatefull(model, train_x, train_y, test_x, test_y,maxdifference=0.2, verbose=False):\n",
    "\n",
    "    m = nn.ReLU()\n",
    "    #m = nn.Sigmoid()\n",
    "    #output = m(input)\n",
    "    print(\"Vs Training Set\")\n",
    "    gru_outputs, targets, gru_sMAPE = evaluate2(gru_model, train_x, train_y)\n",
    "    #print(test_y)\n",
    "    #print(gru_outputs)\n",
    "    #print(gru_outputs[0][5])\n",
    "\n",
    "\n",
    "    testy=test_y.reshape(-1)\n",
    "    trainy=train_y.reshape(-1)\n",
    "\n",
    "\n",
    "    #print(\"Train size:\",trainy.size)\n",
    "    print(gru_outputs[0][4])\n",
    "    train_successcounter=0\n",
    "    for i in range(int(trainy.size)):\n",
    "        #print(testy[i],gru_outputs[0][i],m(torch.tensor(gru_outputs[0][i])))\n",
    "        #print(train[i],gru_outputs[0][i],m(torch.tensor(gru_outputs[0][i])))\n",
    "\n",
    "\n",
    "        #print(trainy[i],gru_outputs[0][i], m(torch.tensor(gru_outputs[0][i])))\n",
    "\n",
    "\n",
    "        if abs(trainy[i]-gru_outputs[0][i])<maxdifference :\n",
    "            train_successcounter+=1\n",
    "        #print(testy[i])\n",
    "        #print\n",
    "        #output = m(input)\n",
    "\n",
    "\n",
    "\n",
    "    test_successcounter=0\n",
    "    print(\"Vs Test Set\")\n",
    "    gru_outputs, targets, gru_sMAPE = evaluate2(gru_model, test_x, test_y)\n",
    "    #print(\"test size: \",testy.size)\n",
    "\n",
    "    for i in range(int(testy.size)):\n",
    "\n",
    "\n",
    "        #, m(torch.tensor(gru_outputs[0][i])))\n",
    "\n",
    "\n",
    "        if abs(testy[i]-gru_outputs[0][i])<maxdifference :\n",
    "            test_successcounter+=1\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"OK\" )\n",
    "        else:\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"X\" )\n",
    "            #print(testy[i])\n",
    "        #print\n",
    "        #output = m(input)\n",
    "    print(\"\")\n",
    "    print(\" vs training data=\" ,train_successcounter,\"/\",trainy.size, \" vs test data=\" ,\n",
    "          test_successcounter,\"/\",testy.size,int(100*test_successcounter/testy.size),\"%\", \"at max difference\",maxdifference )\n",
    "    return ( train_successcounter ,test_successcounter)\n",
    "\n",
    "\n",
    "\n",
    "def evaluatefull_cutoff(model, train_x, train_y, test_x, test_y,cutoff=0.5, verbose=False):\n",
    "\n",
    "    #m = nn.ReLU()\n",
    "    #m = nn.Sigmoid()\n",
    "    #output = m(input)\n",
    "    \n",
    "    #gru_outputs, targets, gru_sMAPE = evaluate2(gru_model, train_x, train_y)\n",
    "    gru_outputs, targets= evaluate2(gru_model, train_x, train_y)\n",
    "    #print(test_y)\n",
    "    #print(gru_outputs)\n",
    "    #print(gru_outputs[0][5])\n",
    "\n",
    "\n",
    "    testy=test_y.reshape(-1)\n",
    "    trainy=train_y.reshape(-1)\n",
    "    #print(\"Vs Training Set\")\n",
    "    #print(gru_outputs[0][4])\n",
    "    train_successcounter=0\n",
    "    train_failzerocounter=0\n",
    "    train_failonecounter=0\n",
    "    for i in range(int(trainy.size)):\n",
    "        \n",
    "        if trainy[i]==1  and gru_outputs[0][i]> cutoff:\n",
    "            train_successcounter+=1\n",
    "            if verbose==True:\n",
    "                print(trainy[i],gru_outputs[0][i], \"OK\" )\n",
    "        elif trainy[i]==0 and gru_outputs[0][i]<= cutoff :\n",
    "            train_successcounter+=1\n",
    "            if verbose==True:\n",
    "                print(trainy[i],gru_outputs[0][i], \"OK\" )           \n",
    "        else:\n",
    "            if verbose==True:\n",
    "                print(trainy[i],gru_outputs[0][i], \"X\" )        \n",
    "           \n",
    "            if trainy[i]==1:\n",
    "                train_failonecounter+=1\n",
    "            if trainy[i]==0:   \n",
    "                train_failzerocounter+=1\n",
    "    #print(\"TRAINING SET: Fails for button not pressed:\",  train_failzerocounter,\"Fails for button pressed:\", train_failonecounter )        \n",
    "    test_successcounter=0\n",
    "    test_failzerocounter=0\n",
    "    test_failonecounter=0\n",
    "    \n",
    "    #gru_outputs, targets, gru_sMAPE = evaluate2(gru_model, test_x, test_y)\n",
    "    gru_outputs, targets = evaluate2(gru_model, test_x, test_y)\n",
    "    #print(\"Vs Test Set\")\n",
    "    #print(gru_outputs[0][4])\n",
    "    #print(\"test size: \",testy.size)\n",
    "\n",
    "    for i in range(int(testy.size)):\n",
    "        \n",
    "        if testy[i]==1 and gru_outputs[0][i]> cutoff :\n",
    "            test_successcounter+=1\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"OK\" )\n",
    "        elif testy[i]==0 and gru_outputs[0][i]<= cutoff   :\n",
    "            test_successcounter+=1\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"OK\" )           \n",
    "        else:\n",
    "            #if verbose==True:\n",
    "            #print(testy[i],gru_outputs[0][i], \"X\" )\n",
    "            if testy[i]==1:\n",
    "                test_failonecounter+=1\n",
    "            if testy[i]==0:   \n",
    "                test_failzerocounter+=1\n",
    "            #print(testy[i])\n",
    "        #print\n",
    "        #output = m(input)\n",
    "    #print(\"\")\n",
    "    \n",
    "    print(\" vs training data=\" ,train_successcounter,\"/\",trainy.size, \" vs test data=\" ,\n",
    "          test_successcounter,\"/\",testy.size,round((100*test_successcounter/testy.size),2),\"%\", \"at cutoff\",cutoff )\n",
    "    print(\"TEST SET: Fails for button not pressed:\",  test_failzerocounter,\"Fails for button pressed:\", test_failonecounter , \"Total Fails:\",test_failzerocounter+test_failonecounter)\n",
    "    print(\"\")\n",
    "    return ( train_successcounter ,test_successcounter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (2696, 5, 10)\n",
      "Starting Training of GRU model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:72: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/1200 Done, Total Loss: 0.06589963454161844   Time Elapsed: 5.261123000000225 seconds\n",
      "Epoch 80/1200 Done, Total Loss: 0.060820104746473216   Time Elapsed: 5.847811999999976 seconds\n",
      "Epoch 120/1200 Done, Total Loss: 0.0543098327193764   Time Elapsed: 4.167324999999437 seconds\n",
      "Epoch 160/1200 Done, Total Loss: 0.05025803546110789   Time Elapsed: 4.219817000000148 seconds\n",
      "Epoch 200/1200 Done, Total Loss: 0.04865843521076299   Time Elapsed: 5.3956480000006195 seconds\n",
      "Epoch 240/1200 Done, Total Loss: 0.0484411443735192   Time Elapsed: 3.8669239999999263 seconds\n",
      "Epoch 280/1200 Done, Total Loss: 0.043691075443925836   Time Elapsed: 3.7401239999999234 seconds\n",
      "Epoch 320/1200 Done, Total Loss: 0.04048634288714282   Time Elapsed: 5.427888000000166 seconds\n",
      "Epoch 360/1200 Done, Total Loss: 0.0468950036410538   Time Elapsed: 4.273009999999886 seconds\n",
      "Epoch 400/1200 Done, Total Loss: 0.03367109691339826   Time Elapsed: 4.765435000000252 seconds\n",
      "Epoch 440/1200 Done, Total Loss: 0.033097251791447874   Time Elapsed: 4.482021000000714 seconds\n",
      "Epoch 480/1200 Done, Total Loss: 0.03215883431645731   Time Elapsed: 4.335041999999703 seconds\n",
      "Epoch 520/1200 Done, Total Loss: 0.027969959443287243   Time Elapsed: 5.72728300000017 seconds\n",
      "Epoch 560/1200 Done, Total Loss: 0.026188357703624262   Time Elapsed: 5.417516999999862 seconds\n",
      "Epoch 600/1200 Done, Total Loss: 0.022826408146924916   Time Elapsed: 4.283722000000125 seconds\n",
      "Epoch 640/1200 Done, Total Loss: 0.02152341988218564   Time Elapsed: 6.696707999999489 seconds\n",
      "Epoch 680/1200 Done, Total Loss: 0.023673105426871822   Time Elapsed: 6.170133999999962 seconds\n",
      "Epoch 720/1200 Done, Total Loss: 0.01657524518299079   Time Elapsed: 4.229380000000674 seconds\n",
      "Epoch 760/1200 Done, Total Loss: 0.014580625456772627   Time Elapsed: 4.208437000000231 seconds\n",
      "Epoch 800/1200 Done, Total Loss: 0.014826380414888263   Time Elapsed: 4.0557149999985995 seconds\n",
      "Epoch 840/1200 Done, Total Loss: 0.014704857021570206   Time Elapsed: 4.811756000000969 seconds\n",
      "Epoch 880/1200 Done, Total Loss: 0.0102716756038486   Time Elapsed: 3.9930249999997613 seconds\n",
      "Epoch 920/1200 Done, Total Loss: 0.009950340936137806   Time Elapsed: 3.9694990000007238 seconds\n",
      "Epoch 960/1200 Done, Total Loss: 0.010902622322891914   Time Elapsed: 5.602149999998801 seconds\n",
      "Epoch 1000/1200 Done, Total Loss: 0.009216244402711116   Time Elapsed: 4.676120000000083 seconds\n",
      "Epoch 1040/1200 Done, Total Loss: 0.007409447464086707   Time Elapsed: 4.358071999999083 seconds\n",
      "Epoch 1080/1200 Done, Total Loss: 0.005870702734682709   Time Elapsed: 5.913126999999804 seconds\n",
      "Epoch 1120/1200 Done, Total Loss: 0.005773063472819529   Time Elapsed: 4.572480999999243 seconds\n",
      "Epoch 1160/1200 Done, Total Loss: 0.006264151144211018   Time Elapsed: 4.618582999999489 seconds\n",
      "Epoch 1200/1200 Done, Total Loss: 0.0037817234480162225   Time Elapsed: 8.227586999999403 seconds\n",
      "Total Training Time: 5919.162226999989 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vs Training Set\n",
      "Evaluation Time: 0.19870599999921978\n",
      "sMAPE: -1.9362900803041458%\n",
      "1.0687302\n",
      "Vs Test Set\n",
      "Evaluation Time: 0.06716499999856751\n",
      "sMAPE: 8.640138694891112%\n",
      "\n",
      " vs training data= 2018 / 2022  vs test data= 583 / 674 86 % at max difference 0.2\n",
      "Vs Training Set\n",
      "Evaluation Time: 0.14693799999986368\n",
      "sMAPE: -1.9362900803041458%\n",
      "1.0687302\n",
      "Vs Test Set\n",
      "Evaluation Time: 0.061238000000230386\n",
      "sMAPE: 8.640138694891112%\n",
      "\n",
      " vs training data= 2020 / 2022  vs test data= 598 / 674 88 % at max difference 0.3\n",
      "Vs Training Set\n",
      "Evaluation Time: 0.18466800000169314\n",
      "sMAPE: -1.9362900803041458%\n",
      "1.0687302\n",
      "Vs Test Set\n",
      "Evaluation Time: 0.0680370000009134\n",
      "sMAPE: 8.640138694891112%\n",
      "\n",
      " vs training data= 2022 / 2022  vs test data= 614 / 674 91 % at max difference 0.4\n",
      "Vs Training Set\n",
      "Evaluation Time: 0.19269599999825004\n",
      "sMAPE: -1.9362900803041458%\n",
      "1.0687302\n",
      "Vs Test Set\n",
      "Evaluation Time: 0.05023400000027323\n",
      "sMAPE: 8.640138694891112%\n",
      "\n",
      " vs training data= 2022 / 2022  vs test data= 627 / 674 93 % at max difference 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:115: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:130: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0005\n",
    "batch_size = 32\n",
    "#a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels.\n",
    "\n",
    "X=State\n",
    "y=Labels[:,lookback-1]\n",
    "print(\"x.shape\",X.shape)\n",
    "y=y.reshape(runqty,1)\n",
    "\n",
    "\n",
    "random_seed=int(time.time())\n",
    "train_x, test_x, train_y,test_y = train_test_split(X, y, test_size=.25, #0.33, \n",
    "                                                   random_state=random_seed)\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "test_data   = TensorDataset( torch.from_numpy( test_x ), torch.from_numpy( test_y ) )\n",
    "test_loader = DataLoader( test_data, shuffle = True, batch_size = batch_size, drop_last = True )\n",
    "\n",
    "\n",
    "gru_model,losslist = train(train_loader, lr , hidden_dim=128, EPOCHS=1200, model_type=\"GRU\")\n",
    "train2 ,test2=evaluatefull(gru_model, train_x, train_y, test_x, test_y,maxdifference=.2)\n",
    "train3 ,test3=evaluatefull(gru_model, train_x, train_y, test_x, test_y,maxdifference=.3)\n",
    "train4 ,test4=evaluatefull(gru_model, train_x, train_y, test_x, test_y,maxdifference=.4)\n",
    "train5 ,test5=evaluatefull(gru_model, train_x, train_y, test_x, test_y,maxdifference=.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losslist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42846/1505425211.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosslist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'losslist' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(losslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training of GRU model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:117: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:140: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/500 Done, Total Loss: 0.004097338083998433   Time Elapsed: 7.320529000000533 seconds\n",
      "Epoch 80/500 Done, Total Loss: 0.0037441652190561094   Time Elapsed: 6.919711000000461 seconds\n",
      "Epoch 120/500 Done, Total Loss: 0.005133579276309955   Time Elapsed: 9.878357999999935 seconds\n",
      "Epoch 160/500 Done, Total Loss: 0.003993770126105537   Time Elapsed: 6.33213699999942 seconds\n",
      "Epoch 200/500 Done, Total Loss: 0.003922862423923872   Time Elapsed: 7.5237900000010995 seconds\n",
      "Epoch 240/500 Done, Total Loss: 0.003261406180663182   Time Elapsed: 8.338477000001149 seconds\n",
      "Epoch 280/500 Done, Total Loss: 0.00375315565098491   Time Elapsed: 4.257243000000017 seconds\n",
      "Epoch 320/500 Done, Total Loss: 0.0024796666703113014   Time Elapsed: 8.444962999999916 seconds\n",
      "Epoch 360/500 Done, Total Loss: 0.002968502955304252   Time Elapsed: 7.275397999999768 seconds\n",
      "Epoch 400/500 Done, Total Loss: 0.002702725483917646   Time Elapsed: 3.6951500000013766 seconds\n",
      "Epoch 440/500 Done, Total Loss: 0.004145189920174224   Time Elapsed: 5.9615799999992305 seconds\n",
      "Epoch 480/500 Done, Total Loss: 0.002551663185595461   Time Elapsed: 3.9986100000005536 seconds\n",
      "Total Training Time: 2891.0393829999994 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vs Training Set\n",
      "Evaluation Time: 0.20899000000099477\n",
      "sMAPE: 0.43415500258347134%\n",
      "1.0041623\n",
      "Vs Test Set\n",
      "Evaluation Time: 0.06400399999984074\n",
      "sMAPE: 10.06005890538224%\n",
      "\n",
      " vs training data= 2022 / 2022  vs test data= 584 / 674 86 % at max difference 0.2\n",
      "Vs Training Set\n",
      "Evaluation Time: 0.1445480000002135\n",
      "sMAPE: 0.43415500258347134%\n",
      "1.0041623\n",
      "Vs Test Set\n",
      "Evaluation Time: 0.061635000000023865\n",
      "sMAPE: 10.06005890538224%\n",
      "\n",
      " vs training data= 2022 / 2022  vs test data= 601 / 674 89 % at max difference 0.3\n",
      "Vs Training Set\n",
      "Evaluation Time: 0.11696699999993143\n",
      "sMAPE: 0.43415500258347134%\n",
      "1.0041623\n",
      "Vs Test Set\n",
      "Evaluation Time: 0.04388699999981327\n",
      "sMAPE: 10.06005890538224%\n",
      "\n",
      " vs training data= 2022 / 2022  vs test data= 613 / 674 90 % at max difference 0.4\n",
      "Vs Training Set\n",
      "Evaluation Time: 0.16941199999928358\n",
      "sMAPE: 0.43415500258347134%\n",
      "1.0041623\n",
      "Vs Test Set\n",
      "Evaluation Time: 0.04598299999997835\n",
      "sMAPE: 10.06005890538224%\n",
      "\n",
      " vs training data= 2022 / 2022  vs test data= 623 / 674 92 % at max difference 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:184: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:199: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "gru_model2= train_existing_model(gru_model,train_loader, lr , hidden_dim=128, EPOCHS=500, model_type=\"GRU\")\n",
    "\n",
    "train2 ,test2=evaluatefull(gru_model2, train_x, train_y, test_x, test_y,maxdifference=.2)\n",
    "train3 ,test3=evaluatefull(gru_model2, train_x, train_y, test_x, test_y,maxdifference=.3)\n",
    "train4 ,test4=evaluatefull(gru_model2, train_x, train_y, test_x, test_y,maxdifference=.4)\n",
    "train5 ,test5=evaluatefull(gru_model2, train_x, train_y, test_x, test_y,maxdifference=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_episode(model, data,  maxdifference=0.2, verbose=False):\n",
    "\n",
    "   \n",
    "    model.eval()\n",
    "    inp = torch.from_numpy(np.array(data)) # should be 5x1\n",
    "    h = model.init_hidden(inp.shape[0])\n",
    "    #print(\"inp\",inp)\n",
    "    #print(\"labs\",labs)\n",
    "    #print(\"h\",h)\n",
    "    out, h = model(inp.to(device).float(), h)\n",
    "    #print(\"model output\",out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_14_2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type GRUNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class '__main__.GRUNet'>: it's not the same object as __main__.GRUNet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42846/135778076.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtodaydate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoday\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%m_%d_%Y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtodaydate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"currentmodel_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtodaydate\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#torch.save(gru_model,\"currentmodel_10_13_2021.pt\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0mserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_storages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class '__main__.GRUNet'>: it's not the same object as __main__.GRUNet"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import time\n",
    "from datetime import date\n",
    "\n",
    "today = date.today()    \n",
    "todaydate = today.strftime(\"%m_%d_%Y\")\n",
    "print(todaydate)\n",
    "torch.save(gru_model,\"currentmodel_\"+todaydate+\".pt\")\n",
    "#torch.save(gru_model,\"currentmodel_10_13_2021.pt\")\n",
    "\n",
    "#currentmodel_10_13_2021\n",
    "print(\"model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "gru_model3=torch.load('currentmodel_10_13_2021.pt')\n",
    "gru_model3.eval()\n",
    "print(\"loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index= 44\n",
      "(1, 5, 10)\n",
      "prediction 0.2498023509979248   actual [0.]\n"
     ]
    }
   ],
   "source": [
    "randomindex=random.randint(0,225)\n",
    "print(\"index=\",randomindex)\n",
    "\n",
    "exampledata=np.expand_dims(test_x[207, 0:5, 0:10], axis=0)\n",
    "\n",
    "print(exampledata.shape)\n",
    "prediction=evaluate_episode(gru_model3, exampledata)\n",
    "\n",
    "print(\"prediction\",float(prediction), \"  actual\",test_y[randomindex])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## simlulate a buffer of 10 timesteps entering the classifier over a 1 episode, and classifying them. Filling empty data with zeroes or ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index= 188\n",
      "final partial data\n",
      "[[[1.         0.64779416 0.68590197 0.69517914 0.69903447 0.71459429\n",
      "   0.71267351 0.71409191 0.71673093 0.72399386]\n",
      "  [1.         0.52154944 0.52310862 0.53282553 0.52718083 0.53709991\n",
      "   0.52978522 0.54277099 0.53688102 0.54443726]\n",
      "  [1.         0.8726286  0.96482141 0.95083008 0.94447182 0.93691809\n",
      "   0.95239155 0.9493714  0.95276295 0.95638539]\n",
      "  [1.         0.50752062 0.50852903 0.49810241 0.50102952 0.4947311\n",
      "   0.50046923 0.49000781 0.49422322 0.48543027]\n",
      "  [1.         0.62007232 0.67079484 0.67376652 0.67304434 0.68618886\n",
      "   0.68665851 0.69233506 0.69529406 0.70288601]]]\n",
      "\n",
      "full data\n",
      "[[[0.64779416 0.68590197 0.69517914 0.69903447 0.71459429 0.71267351\n",
      "   0.71409191 0.71673093 0.72399386 0.7219988 ]\n",
      "  [0.52154944 0.52310862 0.53282553 0.52718083 0.53709991 0.52978522\n",
      "   0.54277099 0.53688102 0.54443726 0.53999553]\n",
      "  [0.8726286  0.96482141 0.95083008 0.94447182 0.93691809 0.95239155\n",
      "   0.9493714  0.95276295 0.95638539 0.94038139]\n",
      "  [0.50752062 0.50852903 0.49810241 0.50102952 0.4947311  0.50046923\n",
      "   0.49000781 0.49422322 0.48543027 0.49026894]\n",
      "  [0.62007232 0.67079484 0.67376652 0.67304434 0.68618886 0.68665851\n",
      "   0.69233506 0.69529406 0.70288601 0.70206539]]]\n",
      "predictions: [-0.15575464069843292, 0.23807184398174286, 0.38706398010253906, 0.21107828617095947, 0.10108674317598343, 0.1720225214958191, 0.42928677797317505, 0.3034760355949402, 0.030546963214874268]\n",
      "\n",
      "\n",
      "prediction from 10 timesteps 0.4351702332496643 actual [0.]\n"
     ]
    }
   ],
   "source": [
    "outputlist=[]\n",
    "\n",
    "randomindex=random.randint(0,225)\n",
    "print(\"index=\",randomindex)\n",
    "exampledata=np.expand_dims(test_x[randomindex, 0:5, 0:10], axis=0)\n",
    "\n",
    "\n",
    "#print(temparray.shape)\n",
    "#temparray=np.expand_dims(temparray, axis=1)\n",
    "\n",
    "#print(temparray.shape)\n",
    "#print(temparray)\n",
    "\n",
    "#temparray2=test_x[randomindex, 0:5, 0]\n",
    "#temparray2=np.expand_dims(temparray2, axis=1)\n",
    "\n",
    "for i in range(9):\n",
    "    if i!=10:\n",
    "        temparray=np.ones((5,1)) #test_x[randomindex, 0:5, 0]   #zeroes or \"ones\" here seems to work equally well. \n",
    "    \n",
    "    for j in range(8-i):\n",
    "        #temparray2=test_x[randomindex, 0:5, 0]\n",
    "        #temparray2=np.expand_dims(temparray2, axis=1)\n",
    "        temparray=np.append(temparray,np.ones((5,1)),axis=1)       #zeroes or \"ones\" here seems to work equally well. \n",
    "        #temparray=np.append(temparray,temparray2,axis=1)\n",
    "        #temparray=np.append(np.zeros((5,1)),temparray,axis=1)   \n",
    "    \n",
    "    for j in range(i+1):\n",
    "\n",
    "        temparray2=test_x[randomindex, 0:5, j]\n",
    "        temparray2=np.expand_dims(temparray2, axis=1)\n",
    "        temparray=np.append(temparray,temparray2,axis=1)\n",
    "        #temparray=np.append(np.zeros((5,1)),temparray,axis=1)\n",
    "\n",
    "    \n",
    "    #print(temparray)\n",
    "    temparray=np.expand_dims(temparray, axis=0)\n",
    "    outputpartial=evaluate_episode(gru_model3, temparray)\n",
    "    \n",
    "    \n",
    "    outputlist.append(float(outputpartial))\n",
    "\n",
    "print(\"final partial data\")\n",
    "print(temparray)   \n",
    "print(\"\")\n",
    "print(\"full data\")\n",
    "print(exampledata)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"prediction from\",x,\" timesteps\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "print(\"predictions:\",outputlist)\n",
    "\n",
    "\n",
    "#print(\"full data\")\n",
    "#print(exampledata)\n",
    "print(\"\")\n",
    "#print(\"evaluating all 10 timesteps\")\n",
    "\n",
    "outputfull=evaluate_episode(gru_model3, exampledata)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "#print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "#print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "print(\"prediction from 10 timesteps\",float(outputfull),\"actual\",test_y[randomindex])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classifying progression of 10 actual forces and torques in a sucessful sequence longer than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7200, 30)\n",
      "['header0', 'header1', 'header2', 'header3', 'header4', 'header5', 'header6', 'header7', 'header8', 'header9', 'header10', 'header11', 'header12', 'header13', 'header14', 'header15', 'header16', 'header17', 'header18', 'header19', 'header20', 'header21', 'header22', 'header23', 'header24', 'header25', 'header26', 'header27', 'header28', 'header29']\n"
     ]
    }
   ],
   "source": [
    "originaldata=pd.read_csv('forcetorquebuttonresults_renormalized_10_06_2021.csv')#.head()\n",
    "print(originaldata.shape)\n",
    "headers=[]\n",
    "lookback=30 #save only the last 11 timesteps\n",
    "for i in range(lookback):  \n",
    "    label=str(i)\n",
    "    headers.append(\"header\"+label)\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header0</th>\n",
       "      <th>header1</th>\n",
       "      <th>header2</th>\n",
       "      <th>header3</th>\n",
       "      <th>header4</th>\n",
       "      <th>header5</th>\n",
       "      <th>header6</th>\n",
       "      <th>header7</th>\n",
       "      <th>header8</th>\n",
       "      <th>header9</th>\n",
       "      <th>...</th>\n",
       "      <th>header20</th>\n",
       "      <th>header21</th>\n",
       "      <th>header22</th>\n",
       "      <th>header23</th>\n",
       "      <th>header24</th>\n",
       "      <th>header25</th>\n",
       "      <th>header26</th>\n",
       "      <th>header27</th>\n",
       "      <th>header28</th>\n",
       "      <th>header29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4039</th>\n",
       "      <td>0.376258</td>\n",
       "      <td>0.371196</td>\n",
       "      <td>0.374959</td>\n",
       "      <td>0.381994</td>\n",
       "      <td>0.378138</td>\n",
       "      <td>0.375871</td>\n",
       "      <td>0.375117</td>\n",
       "      <td>0.372087</td>\n",
       "      <td>0.372973</td>\n",
       "      <td>0.372174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313334</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>0.300916</td>\n",
       "      <td>0.295691</td>\n",
       "      <td>0.304691</td>\n",
       "      <td>0.297850</td>\n",
       "      <td>0.298842</td>\n",
       "      <td>0.298431</td>\n",
       "      <td>0.323285</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4040</th>\n",
       "      <td>0.932410</td>\n",
       "      <td>0.930584</td>\n",
       "      <td>0.929513</td>\n",
       "      <td>0.928026</td>\n",
       "      <td>0.928930</td>\n",
       "      <td>0.929664</td>\n",
       "      <td>0.929868</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.930946</td>\n",
       "      <td>0.929839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887794</td>\n",
       "      <td>0.927183</td>\n",
       "      <td>0.923606</td>\n",
       "      <td>0.929387</td>\n",
       "      <td>0.921559</td>\n",
       "      <td>0.932170</td>\n",
       "      <td>0.925471</td>\n",
       "      <td>0.922702</td>\n",
       "      <td>0.851257</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4041</th>\n",
       "      <td>0.639841</td>\n",
       "      <td>0.640750</td>\n",
       "      <td>0.639536</td>\n",
       "      <td>0.639553</td>\n",
       "      <td>0.639504</td>\n",
       "      <td>0.639946</td>\n",
       "      <td>0.638688</td>\n",
       "      <td>0.639430</td>\n",
       "      <td>0.639626</td>\n",
       "      <td>0.639553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.689476</td>\n",
       "      <td>0.707595</td>\n",
       "      <td>0.706714</td>\n",
       "      <td>0.707579</td>\n",
       "      <td>0.702587</td>\n",
       "      <td>0.708988</td>\n",
       "      <td>0.708745</td>\n",
       "      <td>0.709223</td>\n",
       "      <td>0.693128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4042</th>\n",
       "      <td>0.546462</td>\n",
       "      <td>0.547252</td>\n",
       "      <td>0.546158</td>\n",
       "      <td>0.546371</td>\n",
       "      <td>0.546241</td>\n",
       "      <td>0.545721</td>\n",
       "      <td>0.546231</td>\n",
       "      <td>0.545329</td>\n",
       "      <td>0.545053</td>\n",
       "      <td>0.544635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516504</td>\n",
       "      <td>0.504406</td>\n",
       "      <td>0.494093</td>\n",
       "      <td>0.490169</td>\n",
       "      <td>0.484280</td>\n",
       "      <td>0.477127</td>\n",
       "      <td>0.479447</td>\n",
       "      <td>0.476531</td>\n",
       "      <td>0.484857</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4043</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       header0   header1   header2   header3   header4   header5   header6  \\\n",
       "4039  0.376258  0.371196  0.374959  0.381994  0.378138  0.375871  0.375117   \n",
       "4040  0.932410  0.930584  0.929513  0.928026  0.928930  0.929664  0.929868   \n",
       "4041  0.639841  0.640750  0.639536  0.639553  0.639504  0.639946  0.638688   \n",
       "4042  0.546462  0.547252  0.546158  0.546371  0.546241  0.545721  0.546231   \n",
       "4043  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       header7   header8   header9  ...  header20  header21  header22  \\\n",
       "4039  0.372087  0.372973  0.372174  ...  0.313334  0.297908  0.300916   \n",
       "4040  0.929412  0.930946  0.929839  ...  0.887794  0.927183  0.923606   \n",
       "4041  0.639430  0.639626  0.639553  ...  0.689476  0.707595  0.706714   \n",
       "4042  0.545329  0.545053  0.544635  ...  0.516504  0.504406  0.494093   \n",
       "4043  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "      header23  header24  header25  header26  header27  header28  header29  \n",
       "4039  0.295691  0.304691  0.297850  0.298842  0.298431  0.323285       NaN  \n",
       "4040  0.929387  0.921559  0.932170  0.925471  0.922702  0.851257       NaN  \n",
       "4041  0.707579  0.702587  0.708988  0.708745  0.709223  0.693128       NaN  \n",
       "4042  0.490169  0.484280  0.477127  0.479447  0.476531  0.484857       NaN  \n",
       "4043  0.000000  0.000000  0.000000  0.000000  0.000000  1.000000       NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originaldata.iloc[4039:4044]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.54251199 0.52489482 0.52926319 0.5065195  0.49991385 0.49536954\n",
      "  0.48716645 0.48923134 0.48428939 0.51027604]\n",
      " [0.37858933 0.31333356 0.29790778 0.30091579 0.29569087 0.30469148\n",
      "  0.29785046 0.29884238 0.29843066 0.32328525]\n",
      " [0.93041265 0.88779361 0.92718331 0.92360628 0.92938742 0.92155946\n",
      "  0.9321705  0.92547146 0.92270207 0.85125721]\n",
      " [0.63809043 0.68947554 0.70759451 0.70671384 0.70757924 0.7025874\n",
      "  0.70898769 0.70874526 0.70922296 0.69312779]\n",
      " [0.54499817 0.51650444 0.50440577 0.49409301 0.49016859 0.48428045\n",
      "  0.47712741 0.4794472  0.4765313  0.48485743]]\n",
      "(1, 5, 10)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "\n",
      "prediction from 10 timesteps 1.0079834461212158 actual 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(originaldata[headers[0:30]].iloc[4039:4044])\n",
    "#print(originaldata[headers[0:30]].iloc[4039:4044].to_numpy()\n",
    "classifytest=originaldata[headers[19:29]].iloc[4038:4043].to_numpy()\n",
    "labelstest=originaldata[headers[19:29]].iloc[4043].to_numpy()\n",
    "print(classifytest)\n",
    "classifytest=np.expand_dims(classifytest, axis=0)\n",
    "print(classifytest.shape)\n",
    "print(labelstest)\n",
    "\n",
    "outputfull=evaluate_episode(gru_model3, classifytest)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "#print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "#print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "print(\"prediction from 10 timesteps\",float(outputfull),\"actual\",labelstest[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_episode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42846/1200241008.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#print(labelstest)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0moutputfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#print(\"\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate_episode' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "okcounter=0\n",
    "for i in range(20):\n",
    "    classifytest=originaldata[headers[i:10+i]].iloc[4296:4301].to_numpy()\n",
    "    labelstest=originaldata[headers[i:10+i]].iloc[4301].to_numpy()\n",
    "    #print(classifytest)\n",
    "    classifytest=np.expand_dims(classifytest, axis=0)\n",
    "    #print(classifytest.shape)\n",
    "    #print(labelstest)\n",
    "\n",
    "    outputfull=evaluate_episode(gru_model3, classifytest)\n",
    "\n",
    "    #print(\"\")\n",
    "\n",
    "    #print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "    #print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "    \n",
    "    if abs(float(outputfull)-labelstest[9])>0.3:\n",
    "        result=\"X\"\n",
    "    else:\n",
    "        result=\"OK\"\n",
    "        okcounter+=1\n",
    "    print(\"prediction from timestep\",i,\"-\",i+10,\" :\",float(outputfull),\"actual\",labelstest[9], result)\n",
    "print(\"okcounter\",okcounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header0</th>\n",
       "      <th>header1</th>\n",
       "      <th>header2</th>\n",
       "      <th>header3</th>\n",
       "      <th>header4</th>\n",
       "      <th>header5</th>\n",
       "      <th>header6</th>\n",
       "      <th>header7</th>\n",
       "      <th>header8</th>\n",
       "      <th>header9</th>\n",
       "      <th>...</th>\n",
       "      <th>header20</th>\n",
       "      <th>header21</th>\n",
       "      <th>header22</th>\n",
       "      <th>header23</th>\n",
       "      <th>header24</th>\n",
       "      <th>header25</th>\n",
       "      <th>header26</th>\n",
       "      <th>header27</th>\n",
       "      <th>header28</th>\n",
       "      <th>header29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4890</th>\n",
       "      <td>0.519653</td>\n",
       "      <td>0.629009</td>\n",
       "      <td>0.666283</td>\n",
       "      <td>0.757858</td>\n",
       "      <td>0.748447</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.751999</td>\n",
       "      <td>0.743304</td>\n",
       "      <td>0.741959</td>\n",
       "      <td>0.748569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785070</td>\n",
       "      <td>0.768524</td>\n",
       "      <td>0.756693</td>\n",
       "      <td>0.763045</td>\n",
       "      <td>0.771942</td>\n",
       "      <td>0.774374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4891</th>\n",
       "      <td>0.372140</td>\n",
       "      <td>0.333817</td>\n",
       "      <td>0.319136</td>\n",
       "      <td>0.330614</td>\n",
       "      <td>0.324397</td>\n",
       "      <td>0.318553</td>\n",
       "      <td>0.308498</td>\n",
       "      <td>0.310825</td>\n",
       "      <td>0.340429</td>\n",
       "      <td>0.380643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510981</td>\n",
       "      <td>0.545773</td>\n",
       "      <td>0.534438</td>\n",
       "      <td>0.555681</td>\n",
       "      <td>0.578675</td>\n",
       "      <td>0.561716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4892</th>\n",
       "      <td>0.932075</td>\n",
       "      <td>0.880805</td>\n",
       "      <td>0.871212</td>\n",
       "      <td>0.782250</td>\n",
       "      <td>0.917737</td>\n",
       "      <td>0.913229</td>\n",
       "      <td>0.930457</td>\n",
       "      <td>0.932578</td>\n",
       "      <td>0.922336</td>\n",
       "      <td>0.936276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951116</td>\n",
       "      <td>0.928739</td>\n",
       "      <td>0.959949</td>\n",
       "      <td>0.949016</td>\n",
       "      <td>0.937812</td>\n",
       "      <td>0.899633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>0.641091</td>\n",
       "      <td>0.669016</td>\n",
       "      <td>0.684142</td>\n",
       "      <td>0.675920</td>\n",
       "      <td>0.699291</td>\n",
       "      <td>0.686433</td>\n",
       "      <td>0.692765</td>\n",
       "      <td>0.690845</td>\n",
       "      <td>0.670727</td>\n",
       "      <td>0.643720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498684</td>\n",
       "      <td>0.474195</td>\n",
       "      <td>0.481877</td>\n",
       "      <td>0.466092</td>\n",
       "      <td>0.447252</td>\n",
       "      <td>0.446521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>0.550714</td>\n",
       "      <td>0.634439</td>\n",
       "      <td>0.686677</td>\n",
       "      <td>0.743846</td>\n",
       "      <td>0.772609</td>\n",
       "      <td>0.768783</td>\n",
       "      <td>0.769648</td>\n",
       "      <td>0.771199</td>\n",
       "      <td>0.775574</td>\n",
       "      <td>0.782100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835276</td>\n",
       "      <td>0.823710</td>\n",
       "      <td>0.817117</td>\n",
       "      <td>0.822949</td>\n",
       "      <td>0.825044</td>\n",
       "      <td>0.824857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       header0   header1   header2   header3   header4   header5   header6  \\\n",
       "4890  0.519653  0.629009  0.666283  0.757858  0.748447  0.748698  0.751999   \n",
       "4891  0.372140  0.333817  0.319136  0.330614  0.324397  0.318553  0.308498   \n",
       "4892  0.932075  0.880805  0.871212  0.782250  0.917737  0.913229  0.930457   \n",
       "4893  0.641091  0.669016  0.684142  0.675920  0.699291  0.686433  0.692765   \n",
       "4894  0.550714  0.634439  0.686677  0.743846  0.772609  0.768783  0.769648   \n",
       "4895  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       header7   header8   header9  ...  header20  header21  header22  \\\n",
       "4890  0.743304  0.741959  0.748569  ...  0.785070  0.768524  0.756693   \n",
       "4891  0.310825  0.340429  0.380643  ...  0.510981  0.545773  0.534438   \n",
       "4892  0.932578  0.922336  0.936276  ...  0.951116  0.928739  0.959949   \n",
       "4893  0.690845  0.670727  0.643720  ...  0.498684  0.474195  0.481877   \n",
       "4894  0.771199  0.775574  0.782100  ...  0.835276  0.823710  0.817117   \n",
       "4895  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "      header23  header24  header25  header26  header27  header28  header29  \n",
       "4890  0.763045  0.771942  0.774374       NaN       NaN       NaN       NaN  \n",
       "4891  0.555681  0.578675  0.561716       NaN       NaN       NaN       NaN  \n",
       "4892  0.949016  0.937812  0.899633       NaN       NaN       NaN       NaN  \n",
       "4893  0.466092  0.447252  0.446521       NaN       NaN       NaN       NaN  \n",
       "4894  0.822949  0.825044  0.824857       NaN       NaN       NaN       NaN  \n",
       "4895  0.000000  0.000000  1.000000       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[6 rows x 30 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originaldata.iloc[4890:4896]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gru_model3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42846/841414770.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#print(labelstest)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0moutputfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#print(\"\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gru_model3' is not defined"
     ]
    }
   ],
   "source": [
    "okcounter=0\n",
    "for i in range(20):\n",
    "    classifytest=originaldata[headers[i:10+i]].iloc[4890:4895].to_numpy()\n",
    "    labelstest=originaldata[headers[i:10+i]].iloc[4895].to_numpy()\n",
    "    #print(classifytest)\n",
    "    classifytest=np.expand_dims(classifytest, axis=0)\n",
    "    #print(classifytest.shape)\n",
    "    #print(labelstest)\n",
    "\n",
    "    outputfull=evaluate_episode(gru_model3, classifytest)\n",
    "\n",
    "    #print(\"\")\n",
    "\n",
    "    #print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "    #print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "    \n",
    "    if abs(float(outputfull)-labelstest[9])>0.3:\n",
    "        result=\"X\"\n",
    "    else:\n",
    "        result=\"OK\"\n",
    "        okcounter+=1\n",
    "    print(\"prediction from timestep\",i,\"-\",i+10,\" :\",float(outputfull),\"actual\",labelstest[9], result)\n",
    "print(\"okcounter\",okcounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
