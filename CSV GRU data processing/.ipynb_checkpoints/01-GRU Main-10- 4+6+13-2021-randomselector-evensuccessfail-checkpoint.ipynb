{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll be using a GRU model for a time series prediction task and we will compare the performance of the GRU model against an LSTM model as well. The dataset that we will be using is the Hourly Energy Consumption dataset which can be found on [Kaggle](https://www.kaggle.com/robikscube/hourly-energy-consumption). The dataset contains power consumption data across different regions around the United States recorded on an hourly basis.\n",
    "\n",
    "You can run the code implementation in this article on FloydHub using their GPUs on the cloud by clicking the following link and using the main.ipynb notebook.\n",
    "\n",
    "[![Run on FloydHub](https://static.floydhub.com/button/button-small.svg)](https://floydhub.com/run?template=https://github.com/gabrielloye/https://github.com/gabrielloye/GRU_Prediction)\n",
    "\n",
    "This will speed up the training process significantly. Alternatively, the link to the GitHub repository can be found [here]().\n",
    "\n",
    "The goal of this implementation is to create a model that can accurately predict the energy usage in the next hour given historical usage data. We will be using both the GRU and LSTM model to train on a set of historical data and evaluate both models on an unseen test set. To do so, weâ€™ll start with feature selection, data-preprocessing, followed by defining, training and eventually evaluating the models.\n",
    "\n",
    "We will be using the PyTorch library to implement both types of models along with other common Python libraries used in data analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.python-engineer.com/posts/pytorch-rnn-lstm-gru/\n",
    "\n",
    "#https://blog.floydhub.com/gru-with-pytorch/\n",
    "\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import MinMaxScaler,QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Local ###\n",
    "#from data_processing import *\n",
    "\n",
    "\n",
    "\n",
    "# Define data root directory\n",
    "\n",
    "#data_dir = \"./data/\"\n",
    "#print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of **12** *.csv* files containing hourly energy trend data (*'est_hourly.paruqet'* and *'pjm_hourly_est.csv'* are not used). In our next step, we will be reading these files and pre-processing these data in this order:\n",
    "- Getting the time data of each individual time step and generalizing them\n",
    "    - Hour of the day *i.e. 0-23*\n",
    "    - Day of the week *i.e. 1-7*\n",
    "    - Month *i.e. 1-12*\n",
    "    - Day of the year *i.e. 1-365*\n",
    "    \n",
    "    \n",
    "- Scale the data to values between 0 and 1\n",
    "    - Algorithms tend to perform better or converge faster when features are on a relatively similar scale and/or close to normally distributed\n",
    "    - Scaling preserves the shape of the original distribution and doesn't reduce the importance of outliers.\n",
    "    \n",
    "    \n",
    "- Group the data into sequences to be used as inputs to the model and store their corresponding labels\n",
    "    - The **sequence length** or **lookback period** is the number of data points in history that the model will use to make the prediction\n",
    "    - The label will be the next data point in time after the last one in the input sequence\n",
    "    \n",
    "\n",
    "- The inputs and labels will then be split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(device)\n",
    "\n",
    "\n",
    "def get_torch_device( v=0 ):\n",
    "    # torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "    is_cuda = torch.cuda.is_available()\n",
    "    # If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "    if is_cuda:\n",
    "        device = torch.device(\"cuda\")\n",
    "        if v:  print( \"CUDA Available!\" )\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        if v:  print( \"NO CUDA\" )\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8088, 10)\n",
      "(10440, 10)\n",
      "(14700, 10)\n",
      "contatenated data size:\n",
      "(33228, 10)\n"
     ]
    }
   ],
   "source": [
    "#choppeddata=pd.read_csv('choppeddata_10_06_2021.csv')#.head()\n",
    "choppeddata1=pd.read_csv('choppeddata_10_04_2021_randomselector_even.csv')#.head()\n",
    "choppeddata2=pd.read_csv('choppeddata_10_06_2021_randomselector_even.csv')#.head()\n",
    "choppeddata3=pd.read_csv('choppeddata_10_13_2021_randomselector_even.csv')#.head()\n",
    "\n",
    "\n",
    "print(choppeddata1.shape)\n",
    "print(choppeddata2.shape)\n",
    "print(choppeddata3.shape)\n",
    "frames = [choppeddata1, choppeddata2,choppeddata3]\n",
    "choppeddata = pd.concat(frames)\n",
    "print(\"contatenated data size:\")\n",
    "print(choppeddata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33228, 10)\n",
      "total runs: 5538\n"
     ]
    }
   ],
   "source": [
    "print(choppeddata.shape)\n",
    "runqty=int(choppeddata.shape[0]/6)\n",
    "print(\"total runs:\",runqty)\n",
    "choppedheaders=[]\n",
    "lookback=10 #save only the last 11 timesteps\n",
    "for i in range(lookback):  \n",
    "    label=str(i)\n",
    "    choppedheaders.append(\"header\"+label)\n",
    "\n",
    "#put chopped data in np.arrays\n",
    "State=np.zeros((runqty,5,lookback)) #96 runs,with 5 sets of data (x,y,z,roll,pitch) each, and each run is 11 timesteps long\n",
    "Labels=np.zeros((runqty,lookback)) #96 runs, each run is 11 timesteps long\n",
    "runcounter=0\n",
    "\n",
    "for i in range(0,choppeddata.shape[0],6):\n",
    "            State[runcounter][0][:]=(choppeddata[choppedheaders[:]].iloc[i]).tolist()\n",
    "            State[runcounter][1][:]=(choppeddata[choppedheaders[:]].iloc[i+1]).tolist()\n",
    "            State[runcounter][2][:]=(choppeddata[choppedheaders[:]].iloc[i+2]).tolist()\n",
    "            State[runcounter][3][:]=(choppeddata[choppedheaders[:]].iloc[i+3]).tolist()\n",
    "            State[runcounter][4][:]=(choppeddata[choppedheaders[:]].iloc[i+4]).tolist()\n",
    "            Labels[runcounter][:]=(choppeddata[choppedheaders[:]].iloc[i+5]).tolist()  #labels   \n",
    "            runcounter+=1\n",
    "#print(State[0])\n",
    "#print(Labels)\n",
    "#print(Labels[:,9]) #just getting finals labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set X size (4153, 5, 10)\n",
      "Train set Y size (4153, 1)\n",
      "Test set X size (1385, 5, 10)\n",
      "Test set Y size (1385, 1)\n"
     ]
    }
   ],
   "source": [
    "#X= range(0,575,6)\n",
    "#y= range(0,575,6)\n",
    "\n",
    "X=State\n",
    "y=Labels[:,lookback-1]\n",
    "#print(\"x.shape\",X.shape)\n",
    "\n",
    "y=y.reshape(runqty,1)\n",
    "\n",
    "random_seed=int(time.time())\n",
    "#print(int(time.time()))\n",
    "train_x, test_x, train_y,test_y = train_test_split(X, y, test_size=.25, #0.33, \n",
    "                                                   random_state=random_seed)\n",
    "#print(\"Train\")\n",
    "#print(train_x[0])\n",
    "#print(train_y[0])\n",
    "print(\"Test set X size\", train_x.shape)\n",
    "print(\"Train set Y size\", train_y.shape)\n",
    "#print(test_x[0])\n",
    "#print(test_y[0])\n",
    "print(\"Test set X size\", test_x.shape)\n",
    "print(\"Test set Y size\", test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of 980,185 sequences of training data\n",
    "\n",
    "To improve the speed of our training, we can process the data in batches so that the model does not need to update its weights as frequently. The Torch *Dataset* and *DataLoader* classes are useful for splitting our data into batches and shuffling them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f679264e2d0>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "#a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels.\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "test_data   = TensorDataset( torch.from_numpy( test_x ), torch.from_numpy( test_y ) )\n",
    "test_loader = DataLoader( test_data, shuffle = True, batch_size = batch_size, drop_last = True )\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check if we have any GPUs to speed up our training time by many folds. If youâ€™re using FloydHub with GPU to run this code, the training time will be significantly reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden\n",
    "def train(train_loader, learn_rate, hidden_dim=128, EPOCHS=400, model_type=\"GRU\"):\n",
    "    #got  109 / 180 on training set, 29 / 60 on test set from 128 hidden dim, 50 epoch, batch size of 4, lr =0.001\n",
    "    #Got training data= 146 / 180, success vs test data= 38 / 60 with same as above but 100 epoch\n",
    "    #Got training data= 172 / 180, success vs test data= 46 / 60 with same as above but 200 epoch\n",
    "    #Got training data= 165 / 180, success vs test data= 52 / 60 with same as above but 200 epoch\n",
    "    \n",
    "    losslist=[]\n",
    "    # Setting common hyperparameters\n",
    "    input_dim = next(iter(train_loader))[0].shape[2]  #  = 11\n",
    "    #print(input_dim)\n",
    "    #print(\"input_dim\",input_dim)\n",
    "    output_dim = 1\n",
    "    n_layers = 2\n",
    "    # Instantiating the models\n",
    "    if model_type == \"GRU\":\n",
    "        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    else:\n",
    "        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Defining loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    \n",
    "    model.train()\n",
    "    print(\"Starting Training of {} model\".format(model_type))\n",
    "    epoch_times = []\n",
    "    # Start training loop\n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        start_time = time.clock()\n",
    "        h = model.init_hidden(batch_size)\n",
    "        avg_loss = 0.\n",
    "        counter = 0\n",
    "        for x, label in train_loader:\n",
    "            #print(\"x\",x)\n",
    "            #print(\"label\",label)\n",
    "            counter += 1\n",
    "            if model_type == \"GRU\":\n",
    "                h = h.data\n",
    "            else:\n",
    "                h = tuple([e.data for e in h])\n",
    "            model.zero_grad()\n",
    "            \n",
    "            out, h = model(x.to(device).float(), h)\n",
    "            #print(\"out\",out)\n",
    "            loss = criterion(out, label.to(device).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "            \n",
    "            if counter%20000 == 0:\n",
    "                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter, len(train_loader), avg_loss/counter))\n",
    "        current_time = time.clock()\n",
    "        if epoch%40 == 0:\n",
    "            print(\"Epoch {}/{} Done, Total Loss: {}   Time Elapsed: {} seconds\".format(epoch, EPOCHS, avg_loss/len(train_loader),str(current_time-start_time)))\n",
    "        \n",
    "            #print(\"Total\".format())\n",
    "        losslist.append(avg_loss/len(train_loader))\n",
    "        epoch_times.append(current_time-start_time)\n",
    "    print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n",
    "    plt.plot(losslist)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.show()\n",
    "    return model,losslist\n",
    "\n",
    "def train_existing_model(model,train_loader, learn_rate, hidden_dim=128, EPOCHS=400, model_type=\"GRU\"):\n",
    "    #got  109 / 180 on training set, 29 / 60 on test set from 128 hidden dim, 50 epoch, batch size of 4, lr =0.001\n",
    "    #Got training data= 146 / 180, success vs test data= 38 / 60 with same as above but 100 epoch\n",
    "    #Got training data= 172 / 180, success vs test data= 46 / 60 with same as above but 200 epoch\n",
    "    #Got training data= 165 / 180, success vs test data= 52 / 60 with same as above but 200 epoch\n",
    "    \n",
    "    losslist=[]\n",
    "    # Setting common hyperparameters\n",
    "    input_dim = next(iter(train_loader))[0].shape[2]  #  = 11\n",
    "    #print(input_dim)\n",
    "    #print(\"input_dim\",input_dim)\n",
    "    output_dim = 1\n",
    "    n_layers = 2\n",
    "    # Instantiating the models\n",
    "    \"\"\"\n",
    "    if model_type == \"GRU\":\n",
    "        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    else:\n",
    "        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    \"\"\"    \n",
    "        \n",
    "    model.to(device)\n",
    "    \n",
    "    # Defining loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    \n",
    "    model.train()\n",
    "    print(\"Starting Training of {} model\".format(model_type))\n",
    "    epoch_times = []\n",
    "    # Start training loop\n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        start_time = time.clock()\n",
    "        h = model.init_hidden(batch_size)\n",
    "        avg_loss = 0.\n",
    "        counter = 0\n",
    "        for x, label in train_loader:\n",
    "            #print(\"x\",x)\n",
    "            #print(\"label\",label)\n",
    "            counter += 1\n",
    "            if model_type == \"GRU\":\n",
    "                h = h.data\n",
    "            else:\n",
    "                h = tuple([e.data for e in h])\n",
    "            model.zero_grad()\n",
    "            \n",
    "            out, h = model(x.to(device).float(), h)\n",
    "            #print(\"out\",out)\n",
    "            loss = criterion(out, label.to(device).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "            \n",
    "            if counter%20000 == 0:\n",
    "                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter, len(train_loader), avg_loss/counter))\n",
    "        current_time = time.clock()\n",
    "        if epoch%40 == 0:\n",
    "            print(\"Epoch {}/{} Done, Total Loss: {}   Time Elapsed: {} seconds\".format(epoch, EPOCHS, avg_loss/len(train_loader),str(current_time-start_time)))\n",
    "        \n",
    "            #print(\"Total\".format())\n",
    "        losslist.append(avg_loss/len(train_loader))\n",
    "        epoch_times.append(current_time-start_time)\n",
    "    print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n",
    "    plt.plot(losslist)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.show()\n",
    "    return model,losslist\n",
    "\n",
    "\n",
    "def evaluate(model, test_x, test_y):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []\n",
    "    start_time = time.clock()\n",
    "    #for i in test_x.keys():\n",
    "    for i in range( len( test_x ) ):    \n",
    "        inp = torch.from_numpy(np.array(test_x[i])) # should be 5x1\n",
    "        labs = torch.from_numpy(np.array(test_y[i])) #should be 1x1\n",
    "        h = model.init_hidden(inp.shape[0])\n",
    "        #print(\"inp\",inp)\n",
    "        #print(\"labs\",labs)\n",
    "        #print(\"h\",h)\n",
    "        out, h = model(inp.to(device).float(), h)\n",
    "        #outputs.append(label_scalers[i].inverse_transform(out.cpu().detach().numpy()).reshape(-1))\n",
    "        #targets.append(label_scalers[i].inverse_transform(labs.numpy()).reshape(-1))\n",
    "        outputs.append( out.cpu().detach().numpy().reshape(-1) )\n",
    "        targets.append( labs.numpy().reshape(-1) )\n",
    "        \n",
    "    print(\"Evaluation Time: {}\".format(str(time.clock()-start_time)))\n",
    "    sMAPE = 0\n",
    "    for i in range(len(outputs)):\n",
    "        sMAPE += np.mean(abs(outputs[i]-targets[i])/(targets[i]+outputs[i])/2)/len(outputs)\n",
    "    print(\"sMAPE: {}%\".format(sMAPE*100))\n",
    "    return outputs, targets, sMAPE\n",
    "                               \n",
    "def evaluate2(model, test_x, test_y):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []  #labels\n",
    "    start_time = time.clock()\n",
    "    #for i in test_x.keys():\n",
    "    #for i in range( len( test_x ) ):    \n",
    "    inp = torch.from_numpy(np.array(test_x)) # should be 5x1\n",
    "    labs = torch.from_numpy(np.array(test_y)) #should be 1x1\n",
    "    h = model.init_hidden(inp.shape[0])\n",
    "    #print(\"inp\",inp)\n",
    "    #print(\"labs\",labs)\n",
    "    #print(\"h\",h)\n",
    "    out, h = model(inp.to(device).float(), h)\n",
    "    #outputs.append(label_scalers[i].inverse_transform(out.cpu().detach().numpy()).reshape(-1))\n",
    "    #targets.append(label_scalers[i].inverse_transform(labs.numpy()).reshape(-1))\n",
    "    outputs.append( out.cpu().detach().numpy().reshape(-1) )\n",
    "    targets.append( labs.numpy().reshape(-1) )\n",
    "        \n",
    "    #print(\"Evaluation Time: {}\".format(str(time.clock()-start_time)))\n",
    "    sMAPE = 0\n",
    "    #for i in range(len(outputs)):\n",
    "    #    sMAPE += np.mean(abs(outputs[i]-targets[i])/(targets[i]+outputs[i])/2)/len(outputs)\n",
    "    #print(\"sMAPE: {}%\".format(sMAPE*100))\n",
    "    return outputs, targets#, sMAPE                               \n",
    "\n",
    "def evaluatefull_maxdiff(model, train_x, train_y, test_x, test_y,maxdifference=0.2, verbose=False):\n",
    "\n",
    "    #m = nn.ReLU()\n",
    "    #m = nn.Sigmoid()\n",
    "    #output = m(input)\n",
    "    print(\"Vs Training Set\")\n",
    "    gru_outputs, targets, gru_sMAPE = evaluate2(gru_model, train_x, train_y)\n",
    "    #print(test_y)\n",
    "    #print(gru_outputs)\n",
    "    #print(gru_outputs[0][5])\n",
    "\n",
    "\n",
    "    testy=test_y.reshape(-1)\n",
    "    trainy=train_y.reshape(-1)\n",
    "\n",
    "\n",
    "    #print(\"Train size:\",trainy.size)\n",
    "    print(gru_outputs[0][4])\n",
    "    train_successcounter=0\n",
    "    for i in range(int(trainy.size)):\n",
    "        #print(testy[i],gru_outputs[0][i],m(torch.tensor(gru_outputs[0][i])))\n",
    "        #print(train[i],gru_outputs[0][i],m(torch.tensor(gru_outputs[0][i])))\n",
    "\n",
    "\n",
    "        #print(trainy[i],gru_outputs[0][i], m(torch.tensor(gru_outputs[0][i])))\n",
    "\n",
    "\n",
    "        if abs(trainy[i]-gru_outputs[0][i])<maxdifference :\n",
    "            train_successcounter+=1\n",
    "        #print(testy[i])\n",
    "        #print\n",
    "        #output = m(input)\n",
    "\n",
    "\n",
    "\n",
    "    test_successcounter=0\n",
    "    print(\"Vs Test Set\")\n",
    "    gru_outputs, targets, gru_sMAPE = evaluate2(gru_model, test_x, test_y)\n",
    "    #print(\"test size: \",testy.size)\n",
    "\n",
    "    for i in range(int(testy.size)):\n",
    "\n",
    "\n",
    "        #, m(torch.tensor(gru_outputs[0][i])))\n",
    "\n",
    "\n",
    "        if abs(testy[i]-gru_outputs[0][i])<maxdifference :\n",
    "            test_successcounter+=1\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"OK\" )\n",
    "        else:\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"X\" )\n",
    "            #print(testy[i])\n",
    "        #print\n",
    "        #output = m(input)\n",
    "    print(\"\")\n",
    "    print(\" vs training data=\" ,train_successcounter,\"/\",trainy.size, \" vs test data=\" ,\n",
    "          test_successcounter,\"/\",testy.size,int(100*test_successcounter/testy.size),\"%\", \"at max difference\",maxdifference )\n",
    "    return ( train_successcounter ,test_successcounter)\n",
    "\n",
    "\n",
    "def evaluatefull_cutoff(model, train_x, train_y, test_x, test_y,cutoff=0.5, verbose=False):\n",
    "\n",
    "    #m = nn.ReLU()\n",
    "    #m = nn.Sigmoid()\n",
    "    #output = m(input)\n",
    "    \n",
    "    #gru_outputs, targets, gru_sMAPE = evaluate2(gru_model, train_x, train_y)\n",
    "    gru_outputs, targets= evaluate2(gru_model, train_x, train_y)\n",
    "    #print(test_y)\n",
    "    #print(gru_outputs)\n",
    "    #print(gru_outputs[0][5])\n",
    "\n",
    "\n",
    "    testy=test_y.reshape(-1)\n",
    "    trainy=train_y.reshape(-1)\n",
    "    #print(\"Vs Training Set\")\n",
    "    #print(gru_outputs[0][4])\n",
    "    train_successcounter=0\n",
    "    train_failzerocounter=0\n",
    "    train_failonecounter=0\n",
    "    for i in range(int(trainy.size)):\n",
    "        \n",
    "        if trainy[i]==1  and gru_outputs[0][i]> cutoff:\n",
    "            train_successcounter+=1\n",
    "            if verbose==True:\n",
    "                print(trainy[i],gru_outputs[0][i], \"OK\" )\n",
    "        elif trainy[i]==0 and gru_outputs[0][i]<= cutoff :\n",
    "            train_successcounter+=1\n",
    "            if verbose==True:\n",
    "                print(trainy[i],gru_outputs[0][i], \"OK\" )           \n",
    "        else:\n",
    "            if verbose==True:\n",
    "                print(trainy[i],gru_outputs[0][i], \"X\" )        \n",
    "           \n",
    "            if trainy[i]==1:\n",
    "                train_failonecounter+=1\n",
    "            if trainy[i]==0:   \n",
    "                train_failzerocounter+=1\n",
    "    #print(\"TRAINING SET: Fails for button not pressed:\",  train_failzerocounter,\"Fails for button pressed:\", train_failonecounter )        \n",
    "    test_successcounter=0\n",
    "    test_failzerocounter=0\n",
    "    test_failonecounter=0\n",
    "    \n",
    "    #gru_outputs, targets, gru_sMAPE = evaluate2(gru_model, test_x, test_y)\n",
    "    gru_outputs, targets = evaluate2(gru_model, test_x, test_y)\n",
    "    #print(\"Vs Test Set\")\n",
    "    #print(gru_outputs[0][4])\n",
    "    #print(\"test size: \",testy.size)\n",
    "\n",
    "    for i in range(int(testy.size)):\n",
    "        \n",
    "        if testy[i]==1 and gru_outputs[0][i]> cutoff :\n",
    "            test_successcounter+=1\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"OK\" )\n",
    "        elif testy[i]==0 and gru_outputs[0][i]<= cutoff   :\n",
    "            test_successcounter+=1\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"OK\" )           \n",
    "        else:\n",
    "            #if verbose==True:\n",
    "            #print(testy[i],gru_outputs[0][i], \"X\" )\n",
    "            if testy[i]==1:\n",
    "                test_failonecounter+=1\n",
    "            if testy[i]==0:   \n",
    "                test_failzerocounter+=1\n",
    "            #print(testy[i])\n",
    "        #print\n",
    "        #output = m(input)\n",
    "    #print(\"\")\n",
    "    \n",
    "    print(\" vs training data=\" ,train_successcounter,\"/\",trainy.size, \" vs test data=\" ,\n",
    "          test_successcounter,\"/\",testy.size,round((100*test_successcounter/testy.size),2),\"%\", \"at cutoff\",cutoff )\n",
    "    print(\"TEST SET: Fails for button not pressed:\",  test_failzerocounter,\"Fails for button pressed:\", test_failonecounter , \"Total Fails:\",test_failzerocounter+test_failonecounter)\n",
    "    print(\"\")\n",
    "    return ( train_successcounter ,test_successcounter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (5538, 5, 10)\n",
      "Starting Training of GRU model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:72: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/1000 Done, Total Loss: 0.054581048468835366   Time Elapsed: 0.2759270000000029 seconds\n",
      "Epoch 80/1000 Done, Total Loss: 0.05167240854497104   Time Elapsed: 0.2822090000000017 seconds\n",
      "Epoch 120/1000 Done, Total Loss: 0.04504400181273619   Time Elapsed: 0.27167200000000236 seconds\n",
      "Epoch 160/1000 Done, Total Loss: 0.039689590587721084   Time Elapsed: 0.29128400000000454 seconds\n",
      "Epoch 200/1000 Done, Total Loss: 0.03353307369280635   Time Elapsed: 0.27801000000000897 seconds\n",
      "Epoch 240/1000 Done, Total Loss: 0.028756023325069352   Time Elapsed: 0.29498999999999853 seconds\n",
      "Epoch 280/1000 Done, Total Loss: 0.02344985729960595   Time Elapsed: 0.2997610000000037 seconds\n",
      "Epoch 320/1000 Done, Total Loss: 0.019245800278835403   Time Elapsed: 0.28753799999999785 seconds\n",
      "Epoch 360/1000 Done, Total Loss: 0.019092121697572427   Time Elapsed: 0.2804490000000044 seconds\n",
      "Epoch 400/1000 Done, Total Loss: 0.015509888696729732   Time Elapsed: 0.2690120000000036 seconds\n",
      "Epoch 440/1000 Done, Total Loss: 0.01176834706209831   Time Elapsed: 0.27928500000001577 seconds\n",
      "Epoch 480/1000 Done, Total Loss: 0.01018892200627588   Time Elapsed: 0.27900099999999384 seconds\n",
      "Epoch 520/1000 Done, Total Loss: 0.008626102674716377   Time Elapsed: 0.28267199999999093 seconds\n",
      "Epoch 560/1000 Done, Total Loss: 0.008490397630966911   Time Elapsed: 0.29776699999999323 seconds\n",
      "Epoch 600/1000 Done, Total Loss: 0.007560039300096128   Time Elapsed: 0.2732780000000048 seconds\n",
      "Epoch 640/1000 Done, Total Loss: 0.005938006687707218   Time Elapsed: 0.2833300000000065 seconds\n",
      "Epoch 680/1000 Done, Total Loss: 0.009898871301615597   Time Elapsed: 0.2812399999999968 seconds\n",
      "Epoch 720/1000 Done, Total Loss: 0.0069514521309210694   Time Elapsed: 0.27501100000000633 seconds\n",
      "Epoch 760/1000 Done, Total Loss: 0.004522698218464967   Time Elapsed: 0.2742629999999906 seconds\n",
      "Epoch 800/1000 Done, Total Loss: 0.003930477833360896   Time Elapsed: 0.27801399999998466 seconds\n",
      "Epoch 840/1000 Done, Total Loss: 0.003980747979069345   Time Elapsed: 0.28362199999997983 seconds\n",
      "Epoch 880/1000 Done, Total Loss: 0.003796765686810565   Time Elapsed: 0.2790069999999787 seconds\n",
      "Epoch 920/1000 Done, Total Loss: 0.003735929249258813   Time Elapsed: 0.27518499999996493 seconds\n",
      "Epoch 960/1000 Done, Total Loss: 0.003204360622335081   Time Elapsed: 0.27963499999998476 seconds\n",
      "Epoch 1000/1000 Done, Total Loss: 0.0031490911785585357   Time Elapsed: 0.28194100000001754 seconds\n",
      "Total Training Time: 281.44761700000004 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'gru_model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6364/2127938717.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mgru_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosslist\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GRU\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#1500  #had low total loss with batch size 32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtrain2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluatefull_cutoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mtrain3\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluatefull_cutoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mtrain4\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest4\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluatefull_cutoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gru_model2' is not defined"
     ]
    }
   ],
   "source": [
    "lr = 0.0005\n",
    "batch_size = 32\n",
    "#a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels.\n",
    "\n",
    "X=State\n",
    "y=Labels[:,lookback-1]\n",
    "print(\"x.shape\",X.shape)\n",
    "y=y.reshape(runqty,1)\n",
    "\n",
    "\n",
    "random_seed=int(time.time())\n",
    "train_x, test_x, train_y,test_y = train_test_split(X, y, test_size=.25, #0.33, \n",
    "                                                   random_state=random_seed)\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "test_data   = TensorDataset( torch.from_numpy( test_x ), torch.from_numpy( test_y ) )\n",
    "test_loader = DataLoader( test_data, shuffle = True, batch_size = batch_size, drop_last = True )\n",
    "\n",
    "\n",
    "gru_model, losslist =train(train_loader, lr , hidden_dim=128, EPOCHS=600, model_type=\"GRU\") #1500  #had low total loss with batch size 32\n",
    "\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "\n",
    "gru_model, losslist =train_existing_model(gru_model,train_loader, lr , hidden_dim=400, EPOCHS=1000, model_type=\"GRU\")\n",
    "\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model, train_x, train_y, test_x, test_y,cutoff=.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " vs training data= 4149 / 4153  vs test data= 1255 / 1385 90.61 % at cutoff 0.2\n",
      "TEST SET: Fails for button not pressed: 100 Fails for button pressed: 30 Total Fails: 130\n",
      "\n",
      " vs training data= 4150 / 4153  vs test data= 1272 / 1385 91.84 % at cutoff 0.3\n",
      "TEST SET: Fails for button not pressed: 70 Fails for button pressed: 43 Total Fails: 113\n",
      "\n",
      " vs training data= 4150 / 4153  vs test data= 1287 / 1385 92.92 % at cutoff 0.4\n",
      "TEST SET: Fails for button not pressed: 48 Fails for button pressed: 50 Total Fails: 98\n",
      "\n",
      " vs training data= 4153 / 4153  vs test data= 1297 / 1385 93.65 % at cutoff 0.5\n",
      "TEST SET: Fails for button not pressed: 32 Fails for button pressed: 56 Total Fails: 88\n",
      "\n",
      " vs training data= 4153 / 4153  vs test data= 1294 / 1385 93.43 % at cutoff 0.6\n",
      "TEST SET: Fails for button not pressed: 24 Fails for button pressed: 67 Total Fails: 91\n",
      "\n",
      " vs training data= 4152 / 4153  vs test data= 1292 / 1385 93.29 % at cutoff 0.7\n",
      "TEST SET: Fails for button not pressed: 19 Fails for button pressed: 74 Total Fails: 93\n",
      "\n",
      " vs training data= 4152 / 4153  vs test data= 1279 / 1385 92.35 % at cutoff 0.8\n",
      "TEST SET: Fails for button not pressed: 18 Fails for button pressed: 88 Total Fails: 106\n",
      "\n",
      " vs training data= 4141 / 4153  vs test data= 1254 / 1385 90.54 % at cutoff 0.9\n",
      "TEST SET: Fails for button not pressed: 14 Fails for button pressed: 117 Total Fails: 131\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:184: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#plt.plot(losslist)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model, train_x, train_y, test_x, test_y,cutoff=.2)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model, train_x, train_y, test_x, test_y,cutoff=.3)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model, train_x, train_y, test_x, test_y,cutoff=.4)\n",
    "train5 ,test5=evaluatefull_cutoff(gru_model, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train5 ,test5=evaluatefull_cutoff(gru_model, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train5 ,test5=evaluatefull_cutoff(gru_model, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "train5 ,test5=evaluatefull_cutoff(gru_model, train_x, train_y, test_x, test_y,cutoff=.8)\n",
    "train5 ,test5=evaluatefull_cutoff(gru_model, train_x, train_y, test_x, test_y,cutoff=.9)\n",
    "\n",
    "\n",
    "#train5 ,test5=evaluatefull_cutoff(gru_model, train_x, train_y, test_x, test_y,cutoff=.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_episode(model, data,  maxdifference=0.2, verbose=False):\n",
    "\n",
    "   \n",
    "    model.eval()\n",
    "    inp = torch.from_numpy(np.array(data)) # should be 5x1\n",
    "    h = model.init_hidden(inp.shape[0])\n",
    "    #print(\"inp\",inp)\n",
    "    #print(\"labs\",labs)\n",
    "    #print(\"h\",h)\n",
    "    out, h = model(inp.to(device).float(), h)\n",
    "    #print(\"model output\",out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_14_2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type GRUNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class '__main__.GRUNet'>: it's not the same object as __main__.GRUNet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6364/3276016527.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtodaydate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoday\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%m_%d_%Y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtodaydate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"currentmodel_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtodaydate\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"even.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#torch.save(gru_model,\"currentmodel_10_13_2021.pt\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0mserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_storages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class '__main__.GRUNet'>: it's not the same object as __main__.GRUNet"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import time\n",
    "from datetime import date\n",
    "\n",
    "today = date.today()    \n",
    "todaydate = today.strftime(\"%m_%d_%Y\")\n",
    "print(todaydate)\n",
    "torch.save(gru_model,\"currentmodel_\"+todaydate+\"even.pt\")\n",
    "#torch.save(gru_model,\"currentmodel_10_13_2021.pt\")\n",
    "\n",
    "#currentmodel_10_13_2021\n",
    "print(\"model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6364/1810813145.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgru_model3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'currentmodel_10_14_2021even.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgru_model3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "gru_model3=torch.load('currentmodel_10_14_2021even.pt')\n",
    "gru_model3.eval()\n",
    "print(\"loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SET: Fails for button not pressed: 3 Fails for button pressed: 0\n",
      "0.0 0.96670616 X\n",
      "0.0 0.4590286 X\n",
      "0.0 0.8554573 X\n",
      "0.0 0.43348053 X\n",
      "1.0 0.30085868 X\n",
      "1.0 -0.041357845 X\n",
      "1.0 0.11579703 X\n",
      "1.0 -0.2758111 X\n",
      "0.0 0.9368769 X\n",
      "1.0 0.27103406 X\n",
      "1.0 -0.030549169 X\n",
      "1.0 -0.050017387 X\n",
      "1.0 0.089607015 X\n",
      "0.0 0.97196364 X\n",
      "0.0 0.5402534 X\n",
      "1.0 0.3947886 X\n",
      "0.0 0.41542444 X\n",
      "1.0 -0.14241931 X\n",
      "0.0 0.4468537 X\n",
      "0.0 0.5566195 X\n",
      "0.0 0.5182539 X\n",
      "1.0 0.21331719 X\n",
      "1.0 -0.0006326288 X\n",
      "0.0 0.85560906 X\n",
      "1.0 0.04176686 X\n",
      "0.0 0.500702 X\n",
      "0.0 0.8878634 X\n",
      "0.0 0.97343564 X\n",
      "0.0 0.45467928 X\n",
      "0.0 0.47410166 X\n",
      "1.0 -0.0026881546 X\n",
      "0.0 0.4020866 X\n",
      "1.0 -0.04831761 X\n",
      "1.0 0.28360242 X\n",
      "1.0 0.13630623 X\n",
      "0.0 1.0117841 X\n",
      "1.0 0.061260782 X\n",
      "0.0 0.43656534 X\n",
      "1.0 0.23997557 X\n",
      "0.0 0.6920028 X\n",
      "0.0 1.0265716 X\n",
      "0.0 0.63674915 X\n",
      "1.0 -0.10386804 X\n",
      "1.0 0.175526 X\n",
      "1.0 0.26160365 X\n",
      "0.0 0.40900466 X\n",
      "1.0 0.38711667 X\n",
      "0.0 1.0811509 X\n",
      "0.0 0.9617406 X\n",
      "1.0 0.3886251 X\n",
      "0.0 0.41461936 X\n",
      "1.0 0.24937426 X\n",
      "0.0 0.4324446 X\n",
      "0.0 0.6068131 X\n",
      "1.0 0.18212597 X\n",
      "1.0 -0.0352633 X\n",
      "1.0 0.23636773 X\n",
      "0.0 0.56591415 X\n",
      "0.0 0.59739804 X\n",
      "0.0 1.0728303 X\n",
      "1.0 0.23121881 X\n",
      "1.0 0.20952767 X\n",
      "1.0 -0.11462125 X\n",
      "1.0 0.10505067 X\n",
      "0.0 0.4001479 X\n",
      "1.0 -0.016280323 X\n",
      "0.0 0.4356265 X\n",
      "1.0 0.38347343 X\n",
      "0.0 0.9937531 X\n",
      "1.0 0.3963847 X\n",
      "0.0 0.6025859 X\n",
      "0.0 0.5195569 X\n",
      "0.0 0.44582063 X\n",
      "1.0 0.3935737 X\n",
      "1.0 0.28135222 X\n",
      "0.0 0.9552871 X\n",
      "0.0 0.8977984 X\n",
      "0.0 0.9462347 X\n",
      "1.0 0.17651963 X\n",
      "1.0 0.13938108 X\n",
      "1.0 0.017879933 X\n",
      "0.0 0.9449427 X\n",
      "1.0 0.27834722 X\n",
      "1.0 0.043334574 X\n",
      "0.0 0.59941936 X\n",
      "1.0 0.19225055 X\n",
      "1.0 -0.0067701936 X\n",
      "1.0 -0.01878485 X\n",
      "0.0 1.046671 X\n",
      "1.0 -0.063958555 X\n",
      "1.0 0.2470625 X\n",
      "0.0 0.64229953 X\n",
      "1.0 -0.025810033 X\n",
      "0.0 0.49278656 X\n",
      "0.0 0.45353767 X\n",
      "1.0 0.25037757 X\n",
      "1.0 0.1365045 X\n",
      "0.0 0.71267176 X\n",
      "TEST SET: Fails for button not pressed: 48 Fails for button pressed: 50\n",
      " vs training data= 4150 / 4153  vs test data= 1287 / 1385 92.92 % at cutoff 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:184: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=-1)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.05)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.1)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.2)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.3)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.4)\n",
    "train5 ,test5=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.8)\n",
    "train5 ,test5=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.9)\n",
    "train5 ,test5=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.95)\n",
    "train5 ,test5=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.99)\n",
    "train5 ,test5=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=29)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model, train_x, train_y, test_x, test_y,cutoff=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index= 44\n",
      "(1, 5, 10)\n",
      "prediction 0.2498023509979248   actual [0.]\n"
     ]
    }
   ],
   "source": [
    "randomindex=random.randint(0,225)\n",
    "print(\"index=\",randomindex)\n",
    "\n",
    "exampledata=np.expand_dims(test_x[207, 0:5, 0:10], axis=0)\n",
    "\n",
    "print(exampledata.shape)\n",
    "prediction=evaluate_episode(gru_model3, exampledata)\n",
    "\n",
    "print(\"prediction\",float(prediction), \"  actual\",test_y[randomindex])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## simlulate a buffer of 10 timesteps entering the classifier over a 1 episode, and classifying them. Filling empty data with zeroes or ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index= 188\n",
      "final partial data\n",
      "[[[1.         0.64779416 0.68590197 0.69517914 0.69903447 0.71459429\n",
      "   0.71267351 0.71409191 0.71673093 0.72399386]\n",
      "  [1.         0.52154944 0.52310862 0.53282553 0.52718083 0.53709991\n",
      "   0.52978522 0.54277099 0.53688102 0.54443726]\n",
      "  [1.         0.8726286  0.96482141 0.95083008 0.94447182 0.93691809\n",
      "   0.95239155 0.9493714  0.95276295 0.95638539]\n",
      "  [1.         0.50752062 0.50852903 0.49810241 0.50102952 0.4947311\n",
      "   0.50046923 0.49000781 0.49422322 0.48543027]\n",
      "  [1.         0.62007232 0.67079484 0.67376652 0.67304434 0.68618886\n",
      "   0.68665851 0.69233506 0.69529406 0.70288601]]]\n",
      "\n",
      "full data\n",
      "[[[0.64779416 0.68590197 0.69517914 0.69903447 0.71459429 0.71267351\n",
      "   0.71409191 0.71673093 0.72399386 0.7219988 ]\n",
      "  [0.52154944 0.52310862 0.53282553 0.52718083 0.53709991 0.52978522\n",
      "   0.54277099 0.53688102 0.54443726 0.53999553]\n",
      "  [0.8726286  0.96482141 0.95083008 0.94447182 0.93691809 0.95239155\n",
      "   0.9493714  0.95276295 0.95638539 0.94038139]\n",
      "  [0.50752062 0.50852903 0.49810241 0.50102952 0.4947311  0.50046923\n",
      "   0.49000781 0.49422322 0.48543027 0.49026894]\n",
      "  [0.62007232 0.67079484 0.67376652 0.67304434 0.68618886 0.68665851\n",
      "   0.69233506 0.69529406 0.70288601 0.70206539]]]\n",
      "predictions: [-0.15575464069843292, 0.23807184398174286, 0.38706398010253906, 0.21107828617095947, 0.10108674317598343, 0.1720225214958191, 0.42928677797317505, 0.3034760355949402, 0.030546963214874268]\n",
      "\n",
      "\n",
      "prediction from 10 timesteps 0.4351702332496643 actual [0.]\n"
     ]
    }
   ],
   "source": [
    "outputlist=[]\n",
    "\n",
    "randomindex=random.randint(0,225)\n",
    "print(\"index=\",randomindex)\n",
    "exampledata=np.expand_dims(test_x[randomindex, 0:5, 0:10], axis=0)\n",
    "\n",
    "\n",
    "#print(temparray.shape)\n",
    "#temparray=np.expand_dims(temparray, axis=1)\n",
    "\n",
    "#print(temparray.shape)\n",
    "#print(temparray)\n",
    "\n",
    "#temparray2=test_x[randomindex, 0:5, 0]\n",
    "#temparray2=np.expand_dims(temparray2, axis=1)\n",
    "\n",
    "for i in range(9):\n",
    "    if i!=10:\n",
    "        temparray=np.ones((5,1)) #test_x[randomindex, 0:5, 0]   #zeroes or \"ones\" here seems to work equally well. \n",
    "    \n",
    "    for j in range(8-i):\n",
    "        #temparray2=test_x[randomindex, 0:5, 0]\n",
    "        #temparray2=np.expand_dims(temparray2, axis=1)\n",
    "        temparray=np.append(temparray,np.ones((5,1)),axis=1)       #zeroes or \"ones\" here seems to work equally well. \n",
    "        #temparray=np.append(temparray,temparray2,axis=1)\n",
    "        #temparray=np.append(np.zeros((5,1)),temparray,axis=1)   \n",
    "    \n",
    "    for j in range(i+1):\n",
    "\n",
    "        temparray2=test_x[randomindex, 0:5, j]\n",
    "        temparray2=np.expand_dims(temparray2, axis=1)\n",
    "        temparray=np.append(temparray,temparray2,axis=1)\n",
    "        #temparray=np.append(np.zeros((5,1)),temparray,axis=1)\n",
    "\n",
    "    \n",
    "    #print(temparray)\n",
    "    temparray=np.expand_dims(temparray, axis=0)\n",
    "    outputpartial=evaluate_episode(gru_model3, temparray)\n",
    "    \n",
    "    \n",
    "    outputlist.append(float(outputpartial))\n",
    "\n",
    "print(\"final partial data\")\n",
    "print(temparray)   \n",
    "print(\"\")\n",
    "print(\"full data\")\n",
    "print(exampledata)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"prediction from\",x,\" timesteps\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "print(\"predictions:\",outputlist)\n",
    "\n",
    "\n",
    "#print(\"full data\")\n",
    "#print(exampledata)\n",
    "print(\"\")\n",
    "#print(\"evaluating all 10 timesteps\")\n",
    "\n",
    "outputfull=evaluate_episode(gru_model3, exampledata)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "#print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "#print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "print(\"prediction from 10 timesteps\",float(outputfull),\"actual\",test_y[randomindex])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classifying progression of 10 actual forces and torques in a sucessful sequence longer than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7200, 30)\n",
      "['header0', 'header1', 'header2', 'header3', 'header4', 'header5', 'header6', 'header7', 'header8', 'header9', 'header10', 'header11', 'header12', 'header13', 'header14', 'header15', 'header16', 'header17', 'header18', 'header19', 'header20', 'header21', 'header22', 'header23', 'header24', 'header25', 'header26', 'header27', 'header28', 'header29']\n"
     ]
    }
   ],
   "source": [
    "originaldata=pd.read_csv('forcetorquebuttonresults_renormalized_10_06_2021_newrange.csv')#.head()\n",
    "print(originaldata.shape)\n",
    "headers=[]\n",
    "lookback=30 #save only the last 11 timesteps\n",
    "for i in range(lookback):  \n",
    "    label=str(i)\n",
    "    headers.append(\"header\"+label)\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header0</th>\n",
       "      <th>header1</th>\n",
       "      <th>header2</th>\n",
       "      <th>header3</th>\n",
       "      <th>header4</th>\n",
       "      <th>header5</th>\n",
       "      <th>header6</th>\n",
       "      <th>header7</th>\n",
       "      <th>header8</th>\n",
       "      <th>header9</th>\n",
       "      <th>...</th>\n",
       "      <th>header20</th>\n",
       "      <th>header21</th>\n",
       "      <th>header22</th>\n",
       "      <th>header23</th>\n",
       "      <th>header24</th>\n",
       "      <th>header25</th>\n",
       "      <th>header26</th>\n",
       "      <th>header27</th>\n",
       "      <th>header28</th>\n",
       "      <th>header29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4039</th>\n",
       "      <td>0.376258</td>\n",
       "      <td>0.371196</td>\n",
       "      <td>0.374959</td>\n",
       "      <td>0.381994</td>\n",
       "      <td>0.378138</td>\n",
       "      <td>0.375871</td>\n",
       "      <td>0.375117</td>\n",
       "      <td>0.372087</td>\n",
       "      <td>0.372973</td>\n",
       "      <td>0.372174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313334</td>\n",
       "      <td>0.297908</td>\n",
       "      <td>0.300916</td>\n",
       "      <td>0.295691</td>\n",
       "      <td>0.304691</td>\n",
       "      <td>0.297850</td>\n",
       "      <td>0.298842</td>\n",
       "      <td>0.298431</td>\n",
       "      <td>0.323285</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4040</th>\n",
       "      <td>0.932410</td>\n",
       "      <td>0.930584</td>\n",
       "      <td>0.929513</td>\n",
       "      <td>0.928026</td>\n",
       "      <td>0.928930</td>\n",
       "      <td>0.929664</td>\n",
       "      <td>0.929868</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.930946</td>\n",
       "      <td>0.929839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887794</td>\n",
       "      <td>0.927183</td>\n",
       "      <td>0.923606</td>\n",
       "      <td>0.929387</td>\n",
       "      <td>0.921559</td>\n",
       "      <td>0.932170</td>\n",
       "      <td>0.925471</td>\n",
       "      <td>0.922702</td>\n",
       "      <td>0.851257</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4041</th>\n",
       "      <td>0.639841</td>\n",
       "      <td>0.640750</td>\n",
       "      <td>0.639536</td>\n",
       "      <td>0.639553</td>\n",
       "      <td>0.639504</td>\n",
       "      <td>0.639946</td>\n",
       "      <td>0.638688</td>\n",
       "      <td>0.639430</td>\n",
       "      <td>0.639626</td>\n",
       "      <td>0.639553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.689476</td>\n",
       "      <td>0.707595</td>\n",
       "      <td>0.706714</td>\n",
       "      <td>0.707579</td>\n",
       "      <td>0.702587</td>\n",
       "      <td>0.708988</td>\n",
       "      <td>0.708745</td>\n",
       "      <td>0.709223</td>\n",
       "      <td>0.693128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4042</th>\n",
       "      <td>0.546462</td>\n",
       "      <td>0.547252</td>\n",
       "      <td>0.546158</td>\n",
       "      <td>0.546371</td>\n",
       "      <td>0.546241</td>\n",
       "      <td>0.545721</td>\n",
       "      <td>0.546231</td>\n",
       "      <td>0.545329</td>\n",
       "      <td>0.545053</td>\n",
       "      <td>0.544635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516504</td>\n",
       "      <td>0.504406</td>\n",
       "      <td>0.494093</td>\n",
       "      <td>0.490169</td>\n",
       "      <td>0.484280</td>\n",
       "      <td>0.477127</td>\n",
       "      <td>0.479447</td>\n",
       "      <td>0.476531</td>\n",
       "      <td>0.484857</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4043</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       header0   header1   header2   header3   header4   header5   header6  \\\n",
       "4039  0.376258  0.371196  0.374959  0.381994  0.378138  0.375871  0.375117   \n",
       "4040  0.932410  0.930584  0.929513  0.928026  0.928930  0.929664  0.929868   \n",
       "4041  0.639841  0.640750  0.639536  0.639553  0.639504  0.639946  0.638688   \n",
       "4042  0.546462  0.547252  0.546158  0.546371  0.546241  0.545721  0.546231   \n",
       "4043  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       header7   header8   header9  ...  header20  header21  header22  \\\n",
       "4039  0.372087  0.372973  0.372174  ...  0.313334  0.297908  0.300916   \n",
       "4040  0.929412  0.930946  0.929839  ...  0.887794  0.927183  0.923606   \n",
       "4041  0.639430  0.639626  0.639553  ...  0.689476  0.707595  0.706714   \n",
       "4042  0.545329  0.545053  0.544635  ...  0.516504  0.504406  0.494093   \n",
       "4043  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "      header23  header24  header25  header26  header27  header28  header29  \n",
       "4039  0.295691  0.304691  0.297850  0.298842  0.298431  0.323285       NaN  \n",
       "4040  0.929387  0.921559  0.932170  0.925471  0.922702  0.851257       NaN  \n",
       "4041  0.707579  0.702587  0.708988  0.708745  0.709223  0.693128       NaN  \n",
       "4042  0.490169  0.484280  0.477127  0.479447  0.476531  0.484857       NaN  \n",
       "4043  0.000000  0.000000  0.000000  0.000000  0.000000  1.000000       NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originaldata.iloc[4039:4044]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.54251199 0.52489482 0.52926319 0.5065195  0.49991385 0.49536954\n",
      "  0.48716645 0.48923134 0.48428939 0.51027604]\n",
      " [0.37858933 0.31333356 0.29790778 0.30091579 0.29569087 0.30469148\n",
      "  0.29785046 0.29884238 0.29843066 0.32328525]\n",
      " [0.93041265 0.88779361 0.92718331 0.92360628 0.92938742 0.92155946\n",
      "  0.9321705  0.92547146 0.92270207 0.85125721]\n",
      " [0.63809043 0.68947554 0.70759451 0.70671384 0.70757924 0.7025874\n",
      "  0.70898769 0.70874526 0.70922296 0.69312779]\n",
      " [0.54499817 0.51650444 0.50440577 0.49409301 0.49016859 0.48428045\n",
      "  0.47712741 0.4794472  0.4765313  0.48485743]]\n",
      "(1, 5, 10)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "\n",
      "prediction from 10 timesteps 1.0079834461212158 actual 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(originaldata[headers[0:30]].iloc[4039:4044])\n",
    "#print(originaldata[headers[0:30]].iloc[4039:4044].to_numpy()\n",
    "classifytest=originaldata[headers[19:29]].iloc[4038:4043].to_numpy()\n",
    "labelstest=originaldata[headers[19:29]].iloc[4043].to_numpy()\n",
    "print(classifytest)\n",
    "classifytest=np.expand_dims(classifytest, axis=0)\n",
    "print(classifytest.shape)\n",
    "print(labelstest)\n",
    "\n",
    "outputfull=evaluate_episode(gru_model3, classifytest)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "#print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "#print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "print(\"prediction from 10 timesteps\",float(outputfull),\"actual\",labelstest[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction from timestep 0 - 10  : -0.00722537562251091 actual 0.0 OK\n",
      "prediction from timestep 1 - 11  : -0.002346884459257126 actual 0.0 OK\n",
      "prediction from timestep 2 - 12  : 0.7899943590164185 actual 0.0 X\n",
      "prediction from timestep 3 - 13  : -0.029703717678785324 actual 0.0 OK\n",
      "prediction from timestep 4 - 14  : 0.012947771698236465 actual 0.0 OK\n",
      "prediction from timestep 5 - 15  : -0.028719600290060043 actual 0.0 OK\n",
      "prediction from timestep 6 - 16  : -0.07998156547546387 actual 0.0 OK\n",
      "prediction from timestep 7 - 17  : -0.02647894248366356 actual 0.0 OK\n",
      "prediction from timestep 8 - 18  : -0.02107241377234459 actual 0.0 OK\n",
      "prediction from timestep 9 - 19  : -0.0006447099149227142 actual 0.0 OK\n",
      "prediction from timestep 10 - 20  : 0.015007872134447098 actual 0.0 OK\n",
      "prediction from timestep 11 - 21  : -0.04580749198794365 actual 0.0 OK\n",
      "prediction from timestep 12 - 22  : -0.04300672933459282 actual 0.0 OK\n",
      "prediction from timestep 13 - 23  : 0.0236160047352314 actual 0.0 OK\n",
      "prediction from timestep 14 - 24  : 0.004362095147371292 actual 0.0 OK\n",
      "prediction from timestep 15 - 25  : 0.055279213935136795 actual 0.0 OK\n",
      "prediction from timestep 16 - 26  : 0.033414456993341446 actual 0.0 OK\n",
      "prediction from timestep 17 - 27  : 0.0197611041367054 actual 0.0 OK\n",
      "prediction from timestep 18 - 28  : 0.029821131378412247 actual 0.0 OK\n",
      "prediction from timestep 19 - 29  : 0.9979590773582458 actual 1.0 OK\n",
      "okcounter 19\n"
     ]
    }
   ],
   "source": [
    "\n",
    "okcounter=0\n",
    "for i in range(20):\n",
    "    classifytest=originaldata[headers[i:10+i]].iloc[4296:4301].to_numpy()\n",
    "    labelstest=originaldata[headers[i:10+i]].iloc[4301].to_numpy()\n",
    "    #print(classifytest)\n",
    "    classifytest=np.expand_dims(classifytest, axis=0)\n",
    "    #print(classifytest.shape)\n",
    "    #print(labelstest)\n",
    "\n",
    "    outputfull=evaluate_episode(gru_model3, classifytest)\n",
    "\n",
    "    #print(\"\")\n",
    "\n",
    "    #print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "    #print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "    \n",
    "    if abs(float(outputfull)-labelstest[9])>0.3:\n",
    "        result=\"X\"\n",
    "    else:\n",
    "        result=\"OK\"\n",
    "        okcounter+=1\n",
    "    print(\"prediction from timestep\",i,\"-\",i+10,\" :\",float(outputfull),\"actual\",labelstest[9], result)\n",
    "print(\"okcounter\",okcounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header0</th>\n",
       "      <th>header1</th>\n",
       "      <th>header2</th>\n",
       "      <th>header3</th>\n",
       "      <th>header4</th>\n",
       "      <th>header5</th>\n",
       "      <th>header6</th>\n",
       "      <th>header7</th>\n",
       "      <th>header8</th>\n",
       "      <th>header9</th>\n",
       "      <th>...</th>\n",
       "      <th>header20</th>\n",
       "      <th>header21</th>\n",
       "      <th>header22</th>\n",
       "      <th>header23</th>\n",
       "      <th>header24</th>\n",
       "      <th>header25</th>\n",
       "      <th>header26</th>\n",
       "      <th>header27</th>\n",
       "      <th>header28</th>\n",
       "      <th>header29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4890</th>\n",
       "      <td>0.519653</td>\n",
       "      <td>0.629009</td>\n",
       "      <td>0.666283</td>\n",
       "      <td>0.757858</td>\n",
       "      <td>0.748447</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.751999</td>\n",
       "      <td>0.743304</td>\n",
       "      <td>0.741959</td>\n",
       "      <td>0.748569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785070</td>\n",
       "      <td>0.768524</td>\n",
       "      <td>0.756693</td>\n",
       "      <td>0.763045</td>\n",
       "      <td>0.771942</td>\n",
       "      <td>0.774374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4891</th>\n",
       "      <td>0.372140</td>\n",
       "      <td>0.333817</td>\n",
       "      <td>0.319136</td>\n",
       "      <td>0.330614</td>\n",
       "      <td>0.324397</td>\n",
       "      <td>0.318553</td>\n",
       "      <td>0.308498</td>\n",
       "      <td>0.310825</td>\n",
       "      <td>0.340429</td>\n",
       "      <td>0.380643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510981</td>\n",
       "      <td>0.545773</td>\n",
       "      <td>0.534438</td>\n",
       "      <td>0.555681</td>\n",
       "      <td>0.578675</td>\n",
       "      <td>0.561716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4892</th>\n",
       "      <td>0.932075</td>\n",
       "      <td>0.880805</td>\n",
       "      <td>0.871212</td>\n",
       "      <td>0.782250</td>\n",
       "      <td>0.917737</td>\n",
       "      <td>0.913229</td>\n",
       "      <td>0.930457</td>\n",
       "      <td>0.932578</td>\n",
       "      <td>0.922336</td>\n",
       "      <td>0.936276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951116</td>\n",
       "      <td>0.928739</td>\n",
       "      <td>0.959949</td>\n",
       "      <td>0.949016</td>\n",
       "      <td>0.937812</td>\n",
       "      <td>0.899633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>0.641091</td>\n",
       "      <td>0.669016</td>\n",
       "      <td>0.684142</td>\n",
       "      <td>0.675920</td>\n",
       "      <td>0.699291</td>\n",
       "      <td>0.686433</td>\n",
       "      <td>0.692765</td>\n",
       "      <td>0.690845</td>\n",
       "      <td>0.670727</td>\n",
       "      <td>0.643720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498684</td>\n",
       "      <td>0.474195</td>\n",
       "      <td>0.481877</td>\n",
       "      <td>0.466092</td>\n",
       "      <td>0.447252</td>\n",
       "      <td>0.446521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>0.550714</td>\n",
       "      <td>0.634439</td>\n",
       "      <td>0.686677</td>\n",
       "      <td>0.743846</td>\n",
       "      <td>0.772609</td>\n",
       "      <td>0.768783</td>\n",
       "      <td>0.769648</td>\n",
       "      <td>0.771199</td>\n",
       "      <td>0.775574</td>\n",
       "      <td>0.782100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835276</td>\n",
       "      <td>0.823710</td>\n",
       "      <td>0.817117</td>\n",
       "      <td>0.822949</td>\n",
       "      <td>0.825044</td>\n",
       "      <td>0.824857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       header0   header1   header2   header3   header4   header5   header6  \\\n",
       "4890  0.519653  0.629009  0.666283  0.757858  0.748447  0.748698  0.751999   \n",
       "4891  0.372140  0.333817  0.319136  0.330614  0.324397  0.318553  0.308498   \n",
       "4892  0.932075  0.880805  0.871212  0.782250  0.917737  0.913229  0.930457   \n",
       "4893  0.641091  0.669016  0.684142  0.675920  0.699291  0.686433  0.692765   \n",
       "4894  0.550714  0.634439  0.686677  0.743846  0.772609  0.768783  0.769648   \n",
       "4895  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       header7   header8   header9  ...  header20  header21  header22  \\\n",
       "4890  0.743304  0.741959  0.748569  ...  0.785070  0.768524  0.756693   \n",
       "4891  0.310825  0.340429  0.380643  ...  0.510981  0.545773  0.534438   \n",
       "4892  0.932578  0.922336  0.936276  ...  0.951116  0.928739  0.959949   \n",
       "4893  0.690845  0.670727  0.643720  ...  0.498684  0.474195  0.481877   \n",
       "4894  0.771199  0.775574  0.782100  ...  0.835276  0.823710  0.817117   \n",
       "4895  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "      header23  header24  header25  header26  header27  header28  header29  \n",
       "4890  0.763045  0.771942  0.774374       NaN       NaN       NaN       NaN  \n",
       "4891  0.555681  0.578675  0.561716       NaN       NaN       NaN       NaN  \n",
       "4892  0.949016  0.937812  0.899633       NaN       NaN       NaN       NaN  \n",
       "4893  0.466092  0.447252  0.446521       NaN       NaN       NaN       NaN  \n",
       "4894  0.822949  0.825044  0.824857       NaN       NaN       NaN       NaN  \n",
       "4895  0.000000  0.000000  1.000000       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[6 rows x 30 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originaldata.iloc[4890:4896]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction from timestep 0 - 10  : 0.004739541560411453 actual 0.0 OK\n",
      "prediction from timestep 1 - 11  : 0.001866895705461502 actual 0.0 OK\n",
      "prediction from timestep 2 - 12  : 0.001510579138994217 actual 0.0 OK\n",
      "prediction from timestep 3 - 13  : 0.03851709142327309 actual 0.0 OK\n",
      "prediction from timestep 4 - 14  : 0.003079596906900406 actual 0.0 OK\n",
      "prediction from timestep 5 - 15  : 0.02709074690937996 actual 0.0 OK\n",
      "prediction from timestep 6 - 16  : 0.022011790424585342 actual 0.0 OK\n",
      "prediction from timestep 7 - 17  : 0.004578161984682083 actual 0.0 OK\n",
      "prediction from timestep 8 - 18  : 0.022756803780794144 actual 0.0 OK\n",
      "prediction from timestep 9 - 19  : -0.05372391268610954 actual 0.0 OK\n",
      "prediction from timestep 10 - 20  : 0.32199326157569885 actual 0.0 X\n",
      "prediction from timestep 11 - 21  : 0.01846003159880638 actual 0.0 OK\n",
      "prediction from timestep 12 - 22  : -0.11743395030498505 actual 0.0 OK\n",
      "prediction from timestep 13 - 23  : 0.026684287935495377 actual 0.0 OK\n",
      "prediction from timestep 14 - 24  : -0.08368812501430511 actual 0.0 OK\n",
      "prediction from timestep 15 - 25  : 0.5015493035316467 actual 0.0 X\n",
      "prediction from timestep 16 - 26  : 1.030906319618225 actual 1.0 OK\n",
      "prediction from timestep 17 - 27  : nan actual nan OK\n",
      "prediction from timestep 18 - 28  : nan actual nan OK\n",
      "prediction from timestep 19 - 29  : nan actual nan OK\n",
      "okcounter 18\n"
     ]
    }
   ],
   "source": [
    "okcounter=0\n",
    "for i in range(20):\n",
    "    classifytest=originaldata[headers[i:10+i]].iloc[4890:4895].to_numpy()\n",
    "    labelstest=originaldata[headers[i:10+i]].iloc[4895].to_numpy()\n",
    "    #print(classifytest)\n",
    "    classifytest=np.expand_dims(classifytest, axis=0)\n",
    "    #print(classifytest.shape)\n",
    "    #print(labelstest)\n",
    "\n",
    "    outputfull=evaluate_episode(gru_model3, classifytest)\n",
    "\n",
    "    #print(\"\")\n",
    "\n",
    "    #print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "    #print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "    \n",
    "    if abs(float(outputfull)-labelstest[9])>0.3:\n",
    "        result=\"X\"\n",
    "    else:\n",
    "        result=\"OK\"\n",
    "        okcounter+=1\n",
    "    print(\"prediction from timestep\",i,\"-\",i+10,\" :\",float(outputfull),\"actual\",labelstest[9], result)\n",
    "print(\"okcounter\",okcounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
