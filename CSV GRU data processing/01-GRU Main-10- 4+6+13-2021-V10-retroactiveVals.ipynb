{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll be using a GRU model for a time series prediction task and we will compare the performance of the GRU model against an LSTM model as well. The dataset that we will be using is the Hourly Energy Consumption dataset which can be found on [Kaggle](https://www.kaggle.com/robikscube/hourly-energy-consumption). The dataset contains power consumption data across different regions around the United States recorded on an hourly basis.\n",
    "\n",
    "You can run the code implementation in this article on FloydHub using their GPUs on the cloud by clicking the following link and using the main.ipynb notebook.\n",
    "\n",
    "[![Run on FloydHub](https://static.floydhub.com/button/button-small.svg)](https://floydhub.com/run?template=https://github.com/gabrielloye/https://github.com/gabrielloye/GRU_Prediction)\n",
    "\n",
    "This will speed up the training process significantly. Alternatively, the link to the GitHub repository can be found [here]().\n",
    "\n",
    "The goal of this implementation is to create a model that can accurately predict the energy usage in the next hour given historical usage data. We will be using both the GRU and LSTM model to train on a set of historical data and evaluate both models on an unseen test set. To do so, we’ll start with feature selection, data-preprocessing, followed by defining, training and eventually evaluating the models.\n",
    "\n",
    "We will be using the PyTorch library to implement both types of models along with other common Python libraries used in data analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.python-engineer.com/posts/pytorch-rnn-lstm-gru/\n",
    "\n",
    "#https://blog.floydhub.com/gru-with-pytorch/\n",
    "\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import MinMaxScaler,QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Local ###\n",
    "#from data_processing import *\n",
    "\n",
    "\n",
    "\n",
    "# Define data root directory\n",
    "\n",
    "#data_dir = \"./data/\"\n",
    "#print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of **12** *.csv* files containing hourly energy trend data (*'est_hourly.paruqet'* and *'pjm_hourly_est.csv'* are not used). In our next step, we will be reading these files and pre-processing these data in this order:\n",
    "- Getting the time data of each individual time step and generalizing them\n",
    "    - Hour of the day *i.e. 0-23*\n",
    "    - Day of the week *i.e. 1-7*\n",
    "    - Month *i.e. 1-12*\n",
    "    - Day of the year *i.e. 1-365*\n",
    "    \n",
    "    \n",
    "- Scale the data to values between 0 and 1\n",
    "    - Algorithms tend to perform better or converge faster when features are on a relatively similar scale and/or close to normally distributed\n",
    "    - Scaling preserves the shape of the original distribution and doesn't reduce the importance of outliers.\n",
    "    \n",
    "    \n",
    "- Group the data into sequences to be used as inputs to the model and store their corresponding labels\n",
    "    - The **sequence length** or **lookback period** is the number of data points in history that the model will use to make the prediction\n",
    "    - The label will be the next data point in time after the last one in the input sequence\n",
    "    \n",
    "\n",
    "- The inputs and labels will then be split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(device)\n",
    "\n",
    "\n",
    "def get_torch_device( v=0 ):\n",
    "    # torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "    is_cuda = torch.cuda.is_available()\n",
    "    # If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "    if is_cuda:\n",
    "        device = torch.device(\"cuda\")\n",
    "        if v:  print( \"CUDA Available!\" )\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        if v:  print( \"NO CUDA\" )\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contatenated data size:\n",
      "(109812, 10)\n",
      "contatenated data testset size:\n",
      "(65844, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#choppeddata_testset=pd.read_csv('choppeddata_10_04_2021_3Xcopiedsuccess.csv')#.head()\n",
    "#choppeddata2=pd.read_csv('choppeddata_10_06_2021_3Xcopiedsuccess.csv')#.head()\n",
    "#choppeddata3=pd.read_csv('choppeddata_10_13_2021_3Xcopiedsuccess.csv')#.head()\n",
    "\n",
    "\n",
    "#choppeddata1=pd.read_csv('choppeddata_10_04_2021_3Xcopiedsuccess.csv')#.head()\n",
    "\n",
    "#choppeddata2=pd.read_csv('choppeddata_10_06_2021_3Xcopiedsuccess.csv')#.head()\n",
    "#choppeddata3=pd.read_csv('choppeddata_10_13_2021_3Xcopiedsuccess.csv')#.head()\n",
    "\n",
    "#choppeddata1=pd.read_csv('choppeddata_10_04_2021_randomselector_even.csv')#.head()\n",
    "#choppeddata2=pd.read_csv('choppeddata_10_06_2021_randomselector_even.csv')#.head()\n",
    "#choppeddata3=pd.read_csv('choppeddata_10_13_2021_randomselector_even.csv')#.head()\n",
    "\n",
    "\n",
    "\n",
    "#choppeddata_testset1=pd.read_csv('choppeddata_10_23_2021_3Xcopiedsuccess_fromGRUlookahead.csv')#.head()\n",
    "#choppeddata_testset2=pd.read_csv('choppeddata_10_23_2021_3Xcopiedsuccess_fromGRUlookahead_pos2rewardifbuttonpress.csv')#.head()\n",
    "\n",
    "\n",
    "choppeddata1=pd.read_csv('choppeddata_10_04_2021_V10-retroactiveVals.csv')\n",
    "choppeddata_testset=pd.read_csv('choppeddata_10_06_2021_V10-retroactiveVals.csv')\n",
    "choppeddata3=pd.read_csv('choppeddata_10_13_2021_V10-retroactiveVals.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(choppeddata1.shape)\n",
    "#print(choppeddata2.shape)\n",
    "#print(choppeddata3.shape)\n",
    "\n",
    "#frames = [choppeddata1,choppeddata2,choppeddata3]\n",
    "frames = [choppeddata1,choppeddata3]\n",
    "choppeddata = pd.concat(frames)\n",
    "\n",
    "#frames2 = [choppeddata_testset1,choppeddata_testset2]\n",
    "#choppeddata_testset = pd.concat(frames2)\n",
    "\n",
    "\n",
    "\n",
    "print(\"contatenated data size:\")\n",
    "print(choppeddata.shape)\n",
    "\n",
    "print(\"contatenated data testset size:\")\n",
    "print(choppeddata_testset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109812, 10)\n",
      "total runs: 18302\n",
      "(18302, 5, 10)\n",
      "(18302, 10)\n"
     ]
    }
   ],
   "source": [
    "print(choppeddata.shape)\n",
    "runqty=int(choppeddata.shape[0]/6)\n",
    "print(\"total runs:\",runqty)\n",
    "choppedheaders=[]\n",
    "lookback=10 #save only the last 11 timesteps\n",
    "for i in range(lookback):  \n",
    "    label=str(i)\n",
    "    choppedheaders.append(\"header\"+label)\n",
    "\n",
    "#put chopped data in np.arrays\n",
    "State=np.zeros((runqty,5,lookback)) #96 runs,with 5 sets of data (x,y,z,roll,pitch) each, and each run is 11 timesteps long\n",
    "Labels=np.zeros((runqty,lookback)) #96 runs, each run is 11 timesteps long\n",
    "runcounter=0\n",
    "\n",
    "for i in range(0,choppeddata.shape[0],6):\n",
    "            State[runcounter][0][:]=(choppeddata[choppedheaders[:]].iloc[i]).tolist()\n",
    "            State[runcounter][1][:]=(choppeddata[choppedheaders[:]].iloc[i+1]).tolist()\n",
    "            State[runcounter][2][:]=(choppeddata[choppedheaders[:]].iloc[i+2]).tolist()\n",
    "            State[runcounter][3][:]=(choppeddata[choppedheaders[:]].iloc[i+3]).tolist()\n",
    "            State[runcounter][4][:]=(choppeddata[choppedheaders[:]].iloc[i+4]).tolist()\n",
    "            Labels[runcounter][:]=(choppeddata[choppedheaders[:]].iloc[i+5]).tolist()  #labels   \n",
    "            runcounter+=1\n",
    "#print(State[0])\n",
    "#print(Labels)\n",
    "#print(Labels[:,9]) #just getting finals labels\n",
    "\n",
    "print(State.shape)\n",
    "print(Labels.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65844, 10)\n",
      "total runs: 10974\n",
      "(10974, 5, 10)\n",
      "(10974, 10)\n"
     ]
    }
   ],
   "source": [
    "#make test set with data outside of training set, because of duplication of successful runs. \n",
    "\n",
    "\n",
    "print(choppeddata_testset.shape)\n",
    "runqty_testset=int(choppeddata_testset.shape[0]/6)\n",
    "print(\"total runs:\",runqty_testset)\n",
    "\n",
    "#put chopped data in np.arrays\n",
    "State_testset=np.zeros((runqty_testset,5,lookback)) #96 runs,with 5 sets of data (x,y,z,roll,pitch) each, and each run is 11 timesteps long\n",
    "Labels_testset=np.zeros((runqty_testset,lookback)) #96 runs, each run is 11 timesteps long\n",
    "runcounter=0\n",
    "\n",
    "for i in range(0,choppeddata_testset.shape[0],6):\n",
    "            State_testset[runcounter][0][:]=(choppeddata_testset[choppedheaders[:]].iloc[i]).tolist()\n",
    "            State_testset[runcounter][1][:]=(choppeddata_testset[choppedheaders[:]].iloc[i+1]).tolist()\n",
    "            State_testset[runcounter][2][:]=(choppeddata_testset[choppedheaders[:]].iloc[i+2]).tolist()\n",
    "            State_testset[runcounter][3][:]=(choppeddata_testset[choppedheaders[:]].iloc[i+3]).tolist()\n",
    "            State_testset[runcounter][4][:]=(choppeddata_testset[choppedheaders[:]].iloc[i+4]).tolist()\n",
    "            Labels_testset[runcounter][:]=(choppeddata_testset[choppedheaders[:]].iloc[i+5]).tolist()  #labels   \n",
    "            runcounter+=1\n",
    "\n",
    "print(State_testset.shape)\n",
    "print(Labels_testset.shape)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of 980,185 sequences of training data\n",
    "\n",
    "To improve the speed of our training, we can process the data in batches so that the model does not need to update its weights as frequently. The Torch *Dataset* and *DataLoader* classes are useful for splitting our data into batches and shuffling them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f67d6586390>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check if we have any GPUs to speed up our training time by many folds. If you’re using FloydHub with GPU to run this code, the training time will be significantly reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden\n",
    "def train(train_loader, learn_rate, hidden_dim=128, EPOCHS=400, model_type=\"GRU\"):\n",
    "    #got  109 / 180 on training set, 29 / 60 on test set from 128 hidden dim, 50 epoch, batch size of 4, lr =0.001\n",
    "    #Got training data= 146 / 180, success vs test data= 38 / 60 with same as above but 100 epoch\n",
    "    #Got training data= 172 / 180, success vs test data= 46 / 60 with same as above but 200 epoch\n",
    "    #Got training data= 165 / 180, success vs test data= 52 / 60 with same as above but 200 epoch\n",
    "    \n",
    "    losslist=[]\n",
    "    # Setting common hyperparameters\n",
    "    input_dim = next(iter(train_loader))[0].shape[2]  #  = 11\n",
    "    #print(input_dim)\n",
    "    #print(\"input_dim\",input_dim)\n",
    "    output_dim = 1\n",
    "    n_layers = 2\n",
    "    # Instantiating the models\n",
    "    if model_type == \"GRU\":\n",
    "        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    else:\n",
    "        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Defining loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    \n",
    "    model.train()\n",
    "    print(\"Starting Training of {} model\".format(model_type))\n",
    "    epoch_times = []\n",
    "    # Start training loop\n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        start_time = time.clock()\n",
    "        h = model.init_hidden(batch_size)\n",
    "        avg_loss = 0.\n",
    "        counter = 0\n",
    "        for x, label in train_loader:\n",
    "            #print(\"x\",x)\n",
    "            #print(\"label\",label)\n",
    "            counter += 1\n",
    "            if model_type == \"GRU\":\n",
    "                h = h.data\n",
    "            else:\n",
    "                h = tuple([e.data for e in h])\n",
    "            model.zero_grad()\n",
    "            \n",
    "            out, h = model(x.to(device).float(), h)\n",
    "            #print(\"out\",out)\n",
    "            loss = criterion(out, label.to(device).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "            \n",
    "            if counter%20000 == 0:\n",
    "                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter, len(train_loader), avg_loss/counter))\n",
    "        current_time = time.clock()\n",
    "        if epoch%40 == 0:\n",
    "            print(\"Epoch {}/{} Done, Total Loss: {}   Time Elapsed: {} seconds\".format(epoch, EPOCHS, avg_loss/len(train_loader),str(current_time-start_time)))\n",
    "        \n",
    "            #print(\"Total\".format())\n",
    "        losslist.append(avg_loss/len(train_loader))\n",
    "        epoch_times.append(current_time-start_time)\n",
    "    print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n",
    "    plt.plot(losslist)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.show()\n",
    "    return model,losslist\n",
    "\n",
    "def train_existing_model(model,train_loader, learn_rate, hidden_dim=128, EPOCHS=400, model_type=\"GRU\"):\n",
    "    #got  109 / 180 on training set, 29 / 60 on test set from 128 hidden dim, 50 epoch, batch size of 4, lr =0.001\n",
    "    #Got training data= 146 / 180, success vs test data= 38 / 60 with same as above but 100 epoch\n",
    "    #Got training data= 172 / 180, success vs test data= 46 / 60 with same as above but 200 epoch\n",
    "    #Got training data= 165 / 180, success vs test data= 52 / 60 with same as above but 200 epoch\n",
    "    \n",
    "    losslist=[]\n",
    "    # Setting common hyperparameters\n",
    "    input_dim = next(iter(train_loader))[0].shape[2]  #  = 11\n",
    "    #print(input_dim)\n",
    "    #print(\"input_dim\",input_dim)\n",
    "    output_dim = 1\n",
    "    n_layers = 2\n",
    "    # Instantiating the models\n",
    "    \"\"\"\n",
    "    if model_type == \"GRU\":\n",
    "        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    else:\n",
    "        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "    \"\"\"    \n",
    "        \n",
    "    model.to(device)\n",
    "    \n",
    "    # Defining loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    \n",
    "    model.train()\n",
    "    print(\"Starting Training of {} model\".format(model_type))\n",
    "    epoch_times = []\n",
    "    # Start training loop\n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        start_time = time.clock()\n",
    "        h = model.init_hidden(batch_size)\n",
    "        avg_loss = 0.\n",
    "        counter = 0\n",
    "        for x, label in train_loader:\n",
    "            #print(\"x\",x)\n",
    "            #print(\"label\",label)\n",
    "            counter += 1\n",
    "            if model_type == \"GRU\":\n",
    "                h = h.data\n",
    "            else:\n",
    "                h = tuple([e.data for e in h])\n",
    "            model.zero_grad()\n",
    "            \n",
    "            out, h = model(x.to(device).float(), h)\n",
    "            #print(\"out\",out)\n",
    "            loss = criterion(out, label.to(device).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "            \n",
    "            if counter%20000 == 0:\n",
    "                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter, len(train_loader), avg_loss/counter))\n",
    "        current_time = time.clock()\n",
    "        if epoch%40 == 0:\n",
    "            print(\"Epoch {}/{} Done, Total Loss: {}   Time Elapsed: {} seconds\".format(epoch, EPOCHS, avg_loss/len(train_loader),str(current_time-start_time)))\n",
    "        \n",
    "            #print(\"Total\".format())\n",
    "        losslist.append(avg_loss/len(train_loader))\n",
    "        epoch_times.append(current_time-start_time)\n",
    "    print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n",
    "    plt.plot(losslist)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.show()\n",
    "    return model,losslist\n",
    "\n",
    "\n",
    "def evaluate(model, test_x, test_y):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []\n",
    "    start_time = time.clock()\n",
    "    #for i in test_x.keys():\n",
    "    for i in range( len( test_x ) ):    \n",
    "        inp = torch.from_numpy(np.array(test_x[i])) # should be 5x1\n",
    "        labs = torch.from_numpy(np.array(test_y[i])) #should be 1x1\n",
    "        h = model.init_hidden(inp.shape[0])\n",
    "        #print(\"inp\",inp)\n",
    "        #print(\"labs\",labs)\n",
    "        #print(\"h\",h)\n",
    "        out, h = model(inp.to(device).float(), h)\n",
    "        #outputs.append(label_scalers[i].inverse_transform(out.cpu().detach().numpy()).reshape(-1))\n",
    "        #targets.append(label_scalers[i].inverse_transform(labs.numpy()).reshape(-1))\n",
    "        outputs.append( out.cpu().detach().numpy().reshape(-1) )\n",
    "        targets.append( labs.numpy().reshape(-1) )\n",
    "        \n",
    "    print(\"Evaluation Time: {}\".format(str(time.clock()-start_time)))\n",
    "    sMAPE = 0\n",
    "    for i in range(len(outputs)):\n",
    "        sMAPE += np.mean(abs(outputs[i]-targets[i])/(targets[i]+outputs[i])/2)/len(outputs)\n",
    "    print(\"sMAPE: {}%\".format(sMAPE*100))\n",
    "    return outputs, targets, sMAPE\n",
    "                               \n",
    "def evaluate2(model, test_x, test_y):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []  #labels\n",
    "    #start_time = time.clock()\n",
    "    #for i in test_x.keys():\n",
    "    #for i in range( len( test_x ) ):    \n",
    "    inp = torch.from_numpy(np.array(test_x)) # should be 5x1\n",
    "    labs = torch.from_numpy(np.array(test_y)) #should be 1x1\n",
    "    h = model.init_hidden(inp.shape[0])\n",
    "    #print(\"inp\",inp)\n",
    "    #print(\"labs\",labs)\n",
    "    #print(\"h\",h)\n",
    "    out, h = model(inp.to(device).float(), h)\n",
    "    #outputs.append(label_scalers[i].inverse_transform(out.cpu().detach().numpy()).reshape(-1))\n",
    "    #targets.append(label_scalers[i].inverse_transform(labs.numpy()).reshape(-1))\n",
    "    outputs.append( out.cpu().detach().numpy().reshape(-1) )\n",
    "    targets.append( labs.numpy().reshape(-1) )\n",
    "        \n",
    "    #print(\"Evaluation Time: {}\".format(str(time.clock()-start_time)))\n",
    "    sMAPE = 0\n",
    "    #for i in range(len(outputs)):\n",
    "    #    sMAPE += np.mean(abs(outputs[i]-targets[i])/(targets[i]+outputs[i])/2)/len(outputs)\n",
    "    #print(\"sMAPE: {}%\".format(sMAPE*100))\n",
    "    return outputs, targets#, sMAPE                               \n",
    "\n",
    "def evaluatefull_maxdiff(gru_model, train_x, train_y, test_x, test_y,maxdifference=0.2, verbose=False):\n",
    "\n",
    "    #m = nn.ReLU()\n",
    "    #m = nn.Sigmoid()\n",
    "    #output = m(input)\n",
    "    print(\"Vs Training Set\")\n",
    "    gru_outputs, targets = evaluate2(gru_model, train_x, train_y)\n",
    "    #print(test_y)\n",
    "    #print(gru_outputs)\n",
    "    #print(gru_outputs[0][5])\n",
    "\n",
    "\n",
    "    testy=test_y.reshape(-1)\n",
    "    trainy=train_y.reshape(-1)\n",
    "\n",
    "\n",
    "    #print(\"Train size:\",trainy.size)\n",
    "    print(gru_outputs[0][4])\n",
    "    train_successcounter=0\n",
    "    for i in range(int(trainy.size)):\n",
    "        #print(testy[i],gru_outputs[0][i],m(torch.tensor(gru_outputs[0][i])))\n",
    "        #print(train[i],gru_outputs[0][i],m(torch.tensor(gru_outputs[0][i])))\n",
    "\n",
    "\n",
    "        #print(trainy[i],gru_outputs[0][i], m(torch.tensor(gru_outputs[0][i])))\n",
    "\n",
    "\n",
    "        if abs(trainy[i]-gru_outputs[0][i])<maxdifference :\n",
    "            train_successcounter+=1\n",
    "        #print(testy[i])\n",
    "        #print\n",
    "        #output = m(input)\n",
    "\n",
    "\n",
    "\n",
    "    test_successcounter=0\n",
    "    print(\"Vs Test Set\")\n",
    "    gru_outputs, targets = evaluate2(gru_model, test_x, test_y)\n",
    "    #print(\"test size: \",testy.size)\n",
    "\n",
    "    for i in range(int(testy.size)):\n",
    "\n",
    "\n",
    "        #, m(torch.tensor(gru_outputs[0][i])))\n",
    "\n",
    "\n",
    "        if abs(testy[i]-gru_outputs[0][i])<maxdifference :\n",
    "            test_successcounter+=1\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"OK\" )\n",
    "        else:\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"X\" )\n",
    "            #print(testy[i])\n",
    "        #print\n",
    "        #output = m(input)\n",
    "    print(\"\")\n",
    "    print(\" vs training data=\" ,train_successcounter,\"/\",trainy.size, \" vs test data=\" ,\n",
    "          test_successcounter,\"/\",testy.size,int(100*test_successcounter/testy.size),\"%\", \"at max difference\",maxdifference )\n",
    "    return ( train_successcounter ,test_successcounter)\n",
    "\n",
    "\n",
    "def evaluatefull_cutoff(gru_model, train_x, train_y, test_x, test_y,cutoff=0.5, verbose=False):\n",
    "\n",
    "    #m = nn.ReLU()\n",
    "    #m = nn.Sigmoid()\n",
    "    #output = m(input)\n",
    "    \n",
    "    #gru_outputs, targets, gru_sMAPE = evaluate2(gru_model, train_x, train_y)\n",
    "    gru_outputs, targets= evaluate2(gru_model, train_x, train_y)\n",
    "    #print(test_y)\n",
    "    #print(gru_outputs)\n",
    "    #print(gru_outputs[0][5])\n",
    "\n",
    "\n",
    "    testy=test_y.reshape(-1)\n",
    "    trainy=train_y.reshape(-1)\n",
    "    #print(\"Vs Training Set\")\n",
    "    #print(gru_outputs[0][4])\n",
    "    traincounter_falsenegative=0\n",
    "    traincounter_falsepositive=0\n",
    "    \n",
    "    traincounter_truenegative=0\n",
    "    traincounter_truepositive=0\n",
    "    for i in range(int(trainy.size)):\n",
    "        \n",
    "        if trainy[i]==1  and gru_outputs[0][i]>= cutoff:\n",
    "            traincounter_truepositive+=1\n",
    "            if verbose==True:\n",
    "                print(trainy[i],gru_outputs[0][i], \"OK-truepositive\" )\n",
    "        elif trainy[i]==1  and gru_outputs[0][i]< cutoff:\n",
    "            traincounter_falsenegative+=1\n",
    "            if verbose==True:\n",
    "                print(trainy[i],gru_outputs[0][i], \"X-falsenegative\" )       \n",
    "                \n",
    "        elif trainy[i]==0 and gru_outputs[0][i]<= cutoff :\n",
    "            traincounter_truenegative+=1\n",
    "            if verbose==True:\n",
    "                print(trainy[i],gru_outputs[0][i], \"OK-truenegative\" )           \n",
    "        elif trainy[i]==0 and gru_outputs[0][i]> cutoff:\n",
    "            traincounter_falsepositive+=1\n",
    "            if verbose==True:\n",
    "                print(trainy[i],gru_outputs[0][i], \"X-falsepositive\" )     \n",
    "                \n",
    "           \n",
    "    #print(\"TRAINING SET: Fails for button not pressed:\",  train_failzerocounter,\"Fails for button pressed:\", train_failonecounter )        \n",
    "    test_successcounter=0\n",
    "    test_failzerocounter=0\n",
    "    test_failonecounter=0\n",
    "    \n",
    "    #gru_outputs, targets, gru_sMAPE = evaluate2(gru_model, test_x, test_y)\n",
    "    gru_outputs, targets = evaluate2(gru_model, test_x, test_y)\n",
    "    #print(\"Vs Test Set\")\n",
    "    #print(gru_outputs[0][4])\n",
    "    #print(\"test size: \",testy.size)\n",
    "\n",
    "\n",
    "    testcounter_falsenegative=0\n",
    "    testcounter_falsepositive=0\n",
    "    \n",
    "    testcounter_truenegative=0\n",
    "    testcounter_truepositive=0\n",
    "    for i in range(int(testy.size)):\n",
    "        \n",
    "        if testy[i]==1  and gru_outputs[0][i]>= cutoff:\n",
    "            testcounter_truepositive+=1\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"OK-truepositive\" )\n",
    "        elif testy[i]==1  and gru_outputs[0][i]< cutoff:\n",
    "            testcounter_falsenegative+=1\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"X-falsenegative\" )       \n",
    "                \n",
    "        elif testy[i]==0 and gru_outputs[0][i]<= cutoff :\n",
    "            testcounter_truenegative+=1\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"OK-truenegative\" )           \n",
    "        elif testy[i]==0 and gru_outputs[0][i]> cutoff:\n",
    "            testcounter_falsepositive+=1\n",
    "            if verbose==True:\n",
    "                print(testy[i],gru_outputs[0][i], \"X-falsepositive\" )   \n",
    "    \n",
    "    print(\" vs training data=\" ,traincounter_truepositive+traincounter_truenegative,\"/\",trainy.size, \" vs test data=\" ,\n",
    "          testcounter_truepositive+testcounter_truenegative,\"/\",testy.size,round((100*(testcounter_truepositive+testcounter_truenegative)/testy.size),2),\"%\", \"at cutoff\",cutoff )\n",
    "    \n",
    "    \n",
    "    print(\"TEST SET: True Positives\",testcounter_truepositive,\"True Negatives\", testcounter_truenegative,\" False Positives\",testcounter_falsepositive,\"False Negatives\", testcounter_falsenegative)\n",
    "    print(\"\")\n",
    "    return ( traincounter_truepositive+traincounter_truenegative, testcounter_truepositive+testcounter_truenegative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (18302, 5, 10)\n",
      "lookback-1 9\n",
      "y.shape (18302, 1)\n",
      "x.testsetshape (10974, 5, 10)\n",
      "Starting Training of GRU model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:49: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:72: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/500 Done, Total Loss: 0.0667667681167663   Time Elapsed: 0.40259699999995746 seconds\n",
      "Epoch 80/500 Done, Total Loss: 0.0515380840958424   Time Elapsed: 0.37373700000000554 seconds\n",
      "Epoch 120/500 Done, Total Loss: 0.04376854275313901   Time Elapsed: 0.3878789999999981 seconds\n",
      "Epoch 160/500 Done, Total Loss: 0.03609125024940766   Time Elapsed: 0.366217000000006 seconds\n",
      "Epoch 200/500 Done, Total Loss: 0.030500550964243815   Time Elapsed: 0.37203400000004194 seconds\n",
      "Epoch 240/500 Done, Total Loss: 0.02666473839904221   Time Elapsed: 0.3686660000000188 seconds\n",
      "Epoch 280/500 Done, Total Loss: 0.023544079335537593   Time Elapsed: 0.36841299999997545 seconds\n",
      "Epoch 320/500 Done, Total Loss: 0.020497665924190635   Time Elapsed: 0.3855389999999943 seconds\n",
      "Epoch 360/500 Done, Total Loss: 0.018383595961290345   Time Elapsed: 0.3750419999999508 seconds\n",
      "Epoch 400/500 Done, Total Loss: 0.016734021748612885   Time Elapsed: 0.39100799999999936 seconds\n",
      "Epoch 440/500 Done, Total Loss: 0.015681580082893793   Time Elapsed: 0.38012000000003354 seconds\n",
      "Epoch 480/500 Done, Total Loss: 0.014321031934306236   Time Elapsed: 0.3722050000000081 seconds\n",
      "Total Training Time: 188.64702600000038 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAl/klEQVR4nO3deXxddZ3/8dcnN3vSLM1S2qZb2kKb0g1CWxRQQbBsRbFKgVEcGero8JgZR50BQUVccRRE4ecDRJRFQAdBK6AFCrJbGkqhG923pFvapGmzb5/fH/c23qYpTdskNzn3/Xw88uCec7659/Mt6Tvffs8532PujoiIBFdCrAsQEZHepaAXEQk4Bb2ISMAp6EVEAk5BLyIScAp6EZGAU9CLiAScgl7impltNrOPxroOkd6koBcRCTgFvUgnZpZiZj81s+2Rr5+aWUrkWL6ZPWVm+8ysysxeMbOEyLH/MbMKMztgZmvM7LzY9kQkLDHWBYj0QzcBs4BpgAN/Am4GvgF8BSgHCiJtZwFuZqcA1wNnuPt2MxsNhPq2bJGuaUQvcrirgVvdfbe7VwLfBj4TOdYCDAVGuXuLu7/i4QWj2oAUoMTMktx9s7tviEn1Ip0o6EUONwzYErW9JbIP4H+B9cCzZrbRzG4AcPf1wH8CtwC7zewxMxuGSD+goBc53HZgVNT2yMg+3P2Au3/F3YuBOcB/HZyLd/dH3P2syPc6cFvfli3SNQW9CCSZWerBL+BR4GYzKzCzfOCbwMMAZnaJmY0zMwNqCE/ZtJvZKWZ2buSkbSPQALTHpjsih1LQi8AzhIP54FcqUAa8CywHlgLfjbQdDzwP1AJvAP/P3V8kPD//Q2APsBMoBG7suy6IHJnpwSMiIsGmEb2ISMAp6EVEAk5BLyIScAp6EZGA63dLIOTn5/vo0aNjXYaIyIDy1ltv7XH3gq6O9bugHz16NGVlZbEuQ0RkQDGzLUc6pqkbEZGAU9CLiAScgl5EJOAU9CIiAaegFxEJOAW9iEjAKehFRAIuMEFf29TK7c+tZdm2fbEuRUSkXwlM0De3tvOzRetYtrU61qWIiPQrgQn6lMRwV5pa9VAfEZFoCnoRkYALTNAnhhIIJRjNCnoRkUMEJughPKpvam2LdRkiIv1KAINeI3oRkWgBC/oQTS0KehGRaMEK+iRN3YiIdBasoNfUjYjIYQIW9CEFvYhIJ90KejObbWZrzGy9md3QxfFzzGypmbWa2dwujmeZWbmZ3dUTRR9Jsq66ERE5zFGD3sxCwN3AhUAJcKWZlXRqthX4HPDIEd7mO8DLx19m96QkJuhkrIhIJ90Z0c8A1rv7RndvBh4DLotu4O6b3f1d4LCUNbPTgSHAsz1Q7/vSHL2IyOG6E/TDgW1R2+WRfUdlZgnAT4CvHqXdfDMrM7OyysrK7rx1l8Jz9Jq6ERGJ1tsnY78EPOPu5e/XyN3vdfdSdy8tKCg47g8LX16pEb2ISLTEbrSpAEZEbRdF9nXHmcDZZvYlIBNINrNadz/shG5P0By9iMjhuhP0S4DxZjaGcMDPA67qzpu7+9UHX5vZ54DS3gp5CE/dNLcp6EVEoh116sbdW4HrgYXAauD37r7SzG41szkAZnaGmZUDnwLuMbOVvVn0kYRH9JqjFxGJ1p0RPe7+DPBMp33fjHq9hPCUzvu9x2+A3xxzhcdAc/QiIocL3J2xre1Oq6ZvREQ6BCro05JCADRo+kZEpEOggj49JRz09c0KehGRgwIV9Jkp4VMOtU2tMa5ERKT/CFTQpyeHg76+SSN6EZGDAhX0GZGpG43oRUT+IVhBf3BE36ygFxE5KFhBrzl6EZHDBCzoddWNiEhnAQv68Ii+TiN6EZEOgQr69MgNU3W66kZEpEOggj4xlEBqUgJ1OhkrItIhUEEP4StvNHUjIvIPwQv6FAW9iEi0wAV9enKIOl11IyLSIXBBn6kRvYjIIQIX9OkpiRrRi4hECVzQZ6aENKIXEYkSuKBPT06kXkEvItIhcEGfmZKotW5ERKJ0K+jNbLaZrTGz9WZ2QxfHzzGzpWbWamZzo/ZPM7M3zGylmb1rZlf0ZPFdSU8OUd/chrv39keJiAwIRw16MwsBdwMXAiXAlWZW0qnZVuBzwCOd9tcDn3X3ScBs4KdmlnOCNb+vjJREWtudplY9IFxEBCCxG21mAOvdfSOAmT0GXAasOtjA3TdHjh2Sru6+Nur1djPbDRQA+0608CPJSP7HCpapkbVvRETiWXemboYD26K2yyP7jomZzQCSgQ1dHJtvZmVmVlZZWXmsb30IrWApInKoPjkZa2ZDgYeAf3b3w+ZU3P1edy9199KCgoIT+qyOoNfCZiIiQPeCvgIYEbVdFNnXLWaWBTwN3OTufz+28o6dRvQiIofqTtAvAcab2RgzSwbmAQu68+aR9k8CD7r748dfZvcNSg0H/f4GBb2ICHQj6N29FbgeWAisBn7v7ivN7FYzmwNgZmeYWTnwKeAeM1sZ+fZPA+cAnzOzZZGvab3RkYNy05MB2NfQ3JsfIyIyYHTnqhvc/RngmU77vhn1egnhKZ3O3/cw8PAJ1nhMctKSAKiua+nLjxUR6bcCd2dsVloSZrCvQUEvIgIBDPpQgpGVmsS+ek3diIhAAIMeIDc9iX31GtGLiEBAgz47PZlqjehFRICABn1uehI1mqMXEQECGvQ5aUka0YuIRAQz6NOTNUcvIhIRyKDPTU/mQGMrrW1aqlhEJJBBn5MevmlK8/QiIgEP+mpN34iIBDXow+vd1Gi9GxGRYAZ9brrWuxEROSiQQZ+TdnAFSwW9iEgwgz7j4IheUzciIoEM+kEpiaQmJbBzf2OsSxERiblABr2ZMTwnjYrqhliXIiISc4EMeoDhuelU7FPQi4gEN+hz0hT0IiIEOOiLctOoqmumrkkPCReR+BbYoJ84dBAA75bXxLgSEZHY6lbQm9lsM1tjZuvN7IYujp9jZkvNrNXM5nY6do2ZrYt8XdNThR/N6aMGYwZvbqrqq48UEemXjhr0ZhYC7gYuBEqAK82spFOzrcDngEc6fe9g4FvATGAG8C0zyz3xso8uOy2JU4YMYunW6r74OBGRfqs7I/oZwHp33+juzcBjwGXRDdx9s7u/C3ReF/hjwHPuXuXu1cBzwOweqLtbTh4yiA2VtX31cSIi/VJ3gn44sC1quzyyrzu69b1mNt/MysysrLKysptvfXRjCzKp2NdAQ3Nbj72niMhA0y9Oxrr7ve5e6u6lBQUFPfa+YwszcIdNe+p67D1FRAaa7gR9BTAiarsosq87TuR7T1hxfiagoBeR+NadoF8CjDezMWaWDMwDFnTz/RcCF5hZbuQk7AWRfX2iaHAaAOXV9X31kSIi/c5Rg97dW4HrCQf0auD37r7SzG41szkAZnaGmZUDnwLuMbOVke+tAr5D+JfFEuDWyL4+kZWaRHZaEuVa80ZE4lhidxq5+zPAM532fTPq9RLC0zJdfe/9wP0nUOMJKcpNY5tG9CISx/rFydjeNCI3XSN6EYlrgQ/6otw0yqvrcfdYlyIiEhNxEfSNLe3sqdXTpkQkPsVB0KcDuvJGROJX4IN+xOCDQa95ehGJT4EP+uG54WvptbiZiMSrwAd9ZkoiF00+iV+/tlnTNyISlwIf9ADXnlUMwJqdB2JciYhI34uLoB9XEF7zZv1uLVksIvEnLoI+Oz2J/MwUrU0vInEpLoIe4JSTMllRsT/WZYiI9Lm4CfqZY/JYvXM/1XW6cUpE4kvcBP0HxubhDq9t2BPrUkRE+lTcBP30kbkUDkrhT8u2x7oUEZE+FTdBH0ow5kwdxt/W7NYzZEUkrsRN0AN8YFweLW3O29t0l6yIxI+4CvrTRw3GDJZsUtCLSPyIq6DPTkuiOD+DFdtrYl2KiEifiaugB5g4NIvVO3Q9vYjEj7gM+vLqBi1wJiJxo1tBb2azzWyNma03sxu6OJ5iZr+LHF9sZqMj+5PM7AEzW25mq83sxh6u/5idM76AUILxxYeX6vGCIhIXjhr0ZhYC7gYuBEqAK82spFOza4Fqdx8H3AHcFtn/KSDF3ScDpwNfOPhLIFYmF2Xz3Y+fyvKKGl5ep5unRCT4ujOinwGsd/eN7t4MPAZc1qnNZcADkdePA+eZmQEOZJhZIpAGNAMxnyC//LThJIcSeG29gl5Egq87QT8c2Ba1XR7Z12Ubd28FaoA8wqFfB+wAtgI/dveqzh9gZvPNrMzMyiorK4+5E8cqJTFEybAslm3b1+ufJSISa719MnYG0AYMA8YAXzGz4s6N3P1edy9199KCgoJeLils2ogclpfX0Niiu2RFJNi6E/QVwIio7aLIvi7bRKZpsoG9wFXAX929xd13A68BpSdadE/46MQhNLS0sXDlzliXIiLSq7oT9EuA8WY2xsySgXnAgk5tFgDXRF7PBV7w8CUtW4FzAcwsA5gFvNcThZ+oD4zNo7ggg5ueXMFGPZBERALsqEEfmXO/HlgIrAZ+7+4rzexWM5sTafYrIM/M1gP/BRy8BPNuINPMVhL+hfFrd3+3pztxPBISjIeunUm7O1/+3TL21jbFuiQRkV5h/e1a8tLSUi8rK+uzz/vt4i3c9OQKrpo5ku9/YnKffa6ISE8ys7fcvcup8bi7M7azq2eO4vLpw/nzsu00terErIgET9wHPcD5JUM40NTK6h0HYl2KiEiPU9AD00bmAPDdp1bR2tYe22JERHqYgh44KSsVgLIt1Ty9fEeMqxER6VkKesDMePxfzwTgz+/soK29f52gFhE5EQr6iNLRg/noxEKeX72Ln7+wLtbliIj0GAV9lBsvmkhSyPjp8+v46wrdMSsiwaCgjzK2IJNHr5sFwPeeWaX16kUkEBT0nZSOHswPLp/MtqoGVlTsV9iLyICnoO/C+SVDALj0rlf54V/7xdI8IiLHTUHfhfzMFD7/wTEA3PPSRuY/WMbuA40xrkpE5Pgo6I/gG5dM5LUbziU/M5lnV+3ily9vjHVJIiLHRUF/BGbG8Jw0Flx/FuMKM/njsu3s3q9RvYgMPAr6oxiWk8atcyZReaCJGd9fxAatXS8iA4yCvhs+MC6fH1weXsL4rc3VMa5GROTYKOi76YrSEaQlhbhz0Trqm1tjXY6ISLcp6LspIcEoGJRCxb4GTv/O83zwhy+woqIm1mWJiByVgv4Y/HTeNAAaWtqo2NfAHc+tjW1BIiLdoKA/BqeNzOVHc6eQnZbEFaUj+NvaSvY3tsS6LBGR96WgP0afLh3Bsm+ez9zSItranYt/9gpvbqqKdVkiIkfUraA3s9lmtsbM1pvZDV0cTzGz30WOLzaz0VHHppjZG2a20syWm1lqD9YfE2bG9BE5nD0+n21VDXzl/5ZpTRwR6beOGvRmFgLuBi4ESoArzaykU7NrgWp3HwfcAdwW+d5E4GHgX919EvBhIBBzHYmhBB66dia3f3oq26oaeHbVrliXJCLSpe6M6GcA6919o7s3A48Bl3VqcxnwQOT148B5ZmbABcC77v4OgLvvdfe2nim9f7ho8lAmnDSILzz0Flfc8wY19YH4PSYiAdKdoB8ObIvaLo/s67KNu7cCNUAecDLgZrbQzJaa2X+feMn9S2pSiN/+y0y+esHJLNlcxXef1jr2ItK/JPbB+58FnAHUA4vM7C13XxTdyMzmA/MBRo4c2csl9by8zBSuP3c8jS3t3PXiehau3MnXZk/gM7NGxbo0EZFujegrgBFR20WRfV22iczLZwN7CY/+X3b3Pe5eDzwDnNb5A9z9XncvdffSgoKCY+9FP/Ff55/MjRdOYH9jK9/44woWrd5FW7trhC8iMdWdoF8CjDezMWaWDMwDFnRqswC4JvJ6LvCCh9NtITDZzNIjvwA+BKzqmdL7n4QE4wsfGsuNF04A4NoHyhj79We4/pG3aW9X2ItIbBx16sbdW83sesKhHQLud/eVZnYrUObuC4BfAQ+Z2XqgivAvA9y92sxuJ/zLwoFn3P3pXupLv3HVzJG0tLWzeW89j79VztPLd3D2+HzmzRh401IiMvBZf5tWKC0t9bKysliX0WPcnU/+4nW2VTdw65xJFOWmM7koO9ZliUjARM5/lnZ1THfG9jIz46aLS6g80MQXf7uUS+96lR88szrWZYlIHOntq24EOH1ULo9eN4sEg0ff3Mo9L29kzrRhTBqmkb2I9D6N6PvImWPzmFmcx40XTSQ5lMDFP3uV+17Rc2hFpPcp6PvYkKxUnvy3D3DG6Fx+8uxaHntzK7v0LFoR6UUK+hiYNCybb885labWNm54Yjkzv7+I/3zsbVra2mNdmogEkII+RkqGZfHmTR/lC+cUA/DHZdv5/G+WcOfz66hr0qMKRaTn6GRsDOVnpvC1j53Ch08p5M1NVdzx/FpeWbeH5rY2vvaxCeyoaWBodlqsyxSRAU5BH2OJoQTOHJvHrOLB5GYkcefz67j7xQ38adl2yqsbuO2Tk7niDN1oJSLHT1M3/YSZ8dkzR/PaDecyZ+owyqsbAPju06vZfaCRrXvreWVdZYyrFJGBSHfG9kNt7c7O/Y00trRx0Z2v0NT6j5O0f7/xPE7KHvAP6RKRHqY7YweYUIIxPCeNsQWZPPD5GXxwXF7Hsc/9+k2u/c0S1u8+EMMKRWQg0Rx9PzerOI9ZxXk0t7bzxNJybnhiOe/tPMCi93bzyHUzmTF6MIkh/b4WkSNTQgwQyYkJzJsxkqf//Szmnl4EwFW/XMzV9y3Wevci8r4U9APMpGHZ/PhTU/nOZZMAWLypinE3/YXn9HByETkCTd0MUFfPHMX4IYNY8M52XlpTyXUPlnHzxRPZUdPIl88/mcwU/a8VkTBddRMAjS1tXHDHy2ytqu/Y9+NPTeUT08PPcA8lWKxKE5E+oqtuAi41KcTPr5zO9JE5DIqM5L/+5HLm3PUqM773PG9vrY5xhSISSxrRB9De2iYu/fmrbK8Jr4pZnJ/B7VdMw90pr27g0qnDYlyhiPS09xvRayI3gPIyU/jlNaU8+uZWPjg2ny/+dikfv/u1juMzxgxmSJZuuhKJFxrRx4FHFm+lzZ1lW/fxh6XlAEwcmsX3PnEqp43MjXF1ItITNEcf566aOZLPzBrFj+ZO6di3s6aBub94nUcWb2Xr3nqaW9t1Pb5IQHVr6sbMZgN3AiHgPnf/YafjKcCDwOnAXuAKd98cdXwksAq4xd1/3DOly7EKJRjPfvkcctKSSE0OMf/BMr7+5PKO4+eXDOHez5yOma7SEQmSo47ozSwE3A1cCJQAV5pZSadm1wLV7j4OuAO4rdPx24G/nHi5cqJOHjKIwqxUslKT+MYlJaQnhzqOPbdqF99asJKNlbVs2lNHY0tbDCsVkZ7SnRH9DGC9u28EMLPHgMsIj9APugy4JfL6ceAuMzN3dzP7OLAJqOupoqVnTBqWzeKvn0dbu1Nd38LDf9/Cr17dxINvbAEgMyWRh/9lJlOLsjXKFxnAuhP0w4FtUdvlwMwjtXH3VjOrAfLMrBH4H+B84KtH+gAzmw/MBxg5Ug/Z6EuDUpMAyElP5uaLJ3JSVipLNlfx7Kpd1Da1dlytc+GpJ3HZtGF8dOIQLaImMsD09uWVtwB3uHvt+40I3f1e4F4IX3XTyzXJEZgZ151TzHWR59g+sbScd8tr+H3ZNv6yYid/WbGTcYWZ3DpnEllpSUwalqWRvsgA0J2grwBGRG0XRfZ11abczBKBbMInZWcCc83sR0AO0G5mje5+14kWLr3v8tOKuPy0Iv79vPG8vmEPCWZ8/cnlXHXfYgDmnTGC739iMgAJWmZBpN/qTtAvAcab2RjCgT4PuKpTmwXANcAbwFzgBQ9fq3f2wQZmdgtQq5AfeAZnJHPJlPDdtINSE/nF3zZQOCiFx5Zs47El25g+MoeHrp2phdRE+qmj/s2MzLlfDywkfHnl/e6+0sxuBcrcfQHwK+AhM1sPVBH+ZSABdPb4As4eX4C7U5iVyr0vb+TtrfuY8b3nGT9kEDPHDObLHz2ZtKireUQktnRnrJwQd+cvK3bypd8u7dg3fWQOP7h8Mmt2HmBqUQ6j8zNiWKFIfHi/O2MV9NIjdu1v5OG/hy/L/PkL60lOTKA58lDz3/7LTB58YzOfPK2I00blUlHdwNQROTGsViR4FPTSpyr2NfBP9y1m054j3zqx6CsfYmxBZh9WJRJsCnrpc40tbTS2tLFy+35+tHANKytqyE5LYm9dMwDDc9K4ZMpQMlMSOXNsHjnpyYwrzKSptY2URM3vixwrBb3EnLtT29TK42+VM64wkx8/u5Z3tu3rOJ6eHOKmiydy05MrePDzMzjn5ILYFSsyACnopV+qb26l8kATf3irnF++somGyNo6CQazivO4euYo9jU0c8bowYwryKSptV1X84gcgYJe+r21uw5w85MryM1IYu2u2kPm9/Mykvn49OE8+uZW/v7188hKTaK+uZWUxJCehysSoaCXAaWmIbzA2i/+toHaptZDjpnBmPwMtuytZ0pRNg98fgZZkfV6ROKZgl4GpPrmVtzhpbWVvLy2kkGpiTz09y00trR3tPnA2DzunDedtOQQKYkJJGnBNYlTCnoJjB01DTS1tDM6P4PfvLaJW/68ioPrqrnDnKnD+OcPjmbaiBwtuCZxRQ8Hl8AYmp3W8XrejJG8un4PIwdnsGJ7DW9uqmLBO9tZ8M52AD4xfThnFudRNDiNM4vzaHcor65nVJ7u1JX4ohG9BIa7s6e2mV/8bQP3v7bpkGNFuWmUVzcA8K1LS7h48lAKs1JjUaZIr9DUjcSdzXvquOvF9Vw2bRhrd9XynadWHdbm1ssmUZyfSVpyiK/93zuMzEvnl58t1Ty/DEgKeol7jS1t4bX0Z4xkQ2Ut//OH5V22u3z6cMYPGURGSoiLJg9lzc4D7KhpZO7pRR1t6ppaydCSzNLPaI5e4l5qUojbPz0NgNLRgykYlIKZsWzrPrZW1XP9ueN46I0t/Ob1zR3fc98rm9haVQ+Er/M/v2QIz6/axT0vb+TFr36YMVqVUwYIjehFIlra2vnmn1ZQ39xGS1s7r2/Yy776li7bnj0+n3s/U0pDSxsZKSGtzyMxp6kbkeNw8O/G8ooaMlMSOfcnLwFw7oRCXnhvd0e71KQEpo/IZVxhJvNmjGDiSVl6tKL0OQW9SA94b+d+Nu+pZ/apJ/HjhWt4Ymk5nz5jBK9v2MuSzVUc/Ks0PCeNotw0WtraaWlz8jOT+fxZY8hISaSt3clITuS2v77H7Z+eSl5mSmw7JYGhoBfpBe7ecVNWdV0za3Yd4E/LKlhRsZ+Wtnbe23kAgMyUROqbW2nv9FftOx8/lTOLB5OTnky+Al9OkIJeJAY2Vtbyx7cr+PxZY7jyl4tZvWM/ADnpSeyrbyE5lEBzW3g5h7yMZC6dOoyquma2VdfzxQ+NZdbYPHbvb2Rc4aBYdkMGCAW9SIztqGngqXd2MPvUk8jPTOGltbv50cI17KxppL65jdz0JKo7nfjNy0hmb10zV84YyccmDWFIVioPvL6ZV9bt4YYLJ3Dp1GG0tztbqup1BZCceNCb2WzgTiAE3OfuP+x0PAV4EDgd2Atc4e6bzex84IdAMtAMfM3dX3i/z1LQS7zZW9tETnoyb2+tZtf+Jl7fsIeNlXXUN7eybnct9c1tXX7f1z52Cn98u4J1u2u577OlfGRCIQmG1viJUycU9GYWAtYC5wPlwBLgSndfFdXmS8AUd/9XM5sHfMLdrzCz6cAud99uZqcCC919+Pt9noJe5FDrdh1gxfYatu9r5OcvrKOxpZ1Reels2Vt/SLshWSm0tDlXzxzJntomFq3eTUNzGxdNHsr3PnEqibrjN9BONOjPBG5x949Ftm8EcPcfRLVZGGnzhpklAjuBAo96cwsPM/YCQ9296Uifp6AXObLGlvA1/pkpidQ1t/HSmkp+tmgda3YdoDg/g43v80D2j04cQnFBBkkhY0pRDtlpSSzeWMUlU4dSnJ9BfXMbGSmJem7vAHWid8YOB7ZFbZcDM4/Uxt1bzawGyAP2RLX5JLC0q5A3s/nAfICRI0d2oySR+JSaFCI1KRzCmSmJXDxlKB+bNASAxFAC7e3OgaZW7n91E29s3MvYgkz2N7Swasd+nl+9C1Yf/p53LlrbcUVQydAsVu3Yz+CMZP5p5kguP62IUXnpVNU1k52WpH8VDFB9sgSCmU0CbgMu6Oq4u98L3AvhEX1f1CQSFNHhm5BgZKcl8eXzT+bLndot3riXEYPTyUxNZFNlHXvrmshMSeKpd7fzx7crOPvkAjbsrgWgqq6Zn72wnp+9sJ7stCRqGlpIMPjIKYWMyssgMyXEX1bsJJRgXDp1GOMLM2l3aGt3zhidq5VB+5nuBH0FMCJquyiyr6s25ZGpm2zC0zSYWRHwJPBZd99wwhWLyHGZWZzX8XrqiJyO1zPGDObbcyZ1nMQ90NjCjppGfr9kG79+fTOzigczpSiHLXvrePyt8o7R/8ShWWQkh/jfhWsO+ZxBqYkMz0mjZFgWYwsyqW1qZcJJg0hPTuTcCYUdz/lds/MAo/LSSU0KUdvUypJNVXz4lAKdTO4F3ZmjTyR8MvY8woG+BLjK3VdGtfk3YHLUydjL3f3TZpYDvAR8292f6E5BmqMX6T9a29oP+RfDtqp6ctKTSEkMkZwY3v+TZ9fwwOubufmSEtbsPMDyihpCZqzYXsOBxtbD3vPs8fkMzU7l92XlfPiUAm6+uIQbn3iXJZur+dHcKUwtyiEvUzeRHaueuLzyIuCnhC+vvN/dv2dmtwJl7r7AzFKBh4DpQBUwz903mtnNwI3Auqi3u8Ddd3MECnqRgaexpa3j3MFBVXXNvLy2ko+cUsiWqjqWV9SweGMVy7bt61gV9P0My05lbGEmuenJ1Da1cuqwLAqzUmlubSclKYH6pjZa253zS4YwrjDzkO+tqW8hJSnhsJqCTDdMiUi/4e7UNLSQk57Mpj11/G3Nbk4flUtxQSbf+fMqnlm+gw+My+OtLdVkpSaxv7GVtvb2w24oi3bKkEHUNbdy1rh8RudncNcL68lJT+KGCydQnJ9JY2sba3ce4OIpQ9m1v5H9ja2Uba7in2aNIj05GKu1K+hFZMCrrmumpa2d5MQEXlpbyaDUREqGZvOXFTt4duUuyrZU0dJ2bHmWlhQiPTnE5acNZ9Hq3Vw1cyTl1Q1MHDqI5MQEzp0whL21TVTXtzAiN41VO/Zz5ti8fnn5qYJeRAKvvd15e9s+RuelMzgjmZXb95NgxtPLt5OaGGJ4bhoPvL6ZKUU5lI7OpaXNefrd7by4pvKYPmfi0CzyM5PJSksiZMaHTi5gbGFmZDmLVpZt28fYgkz21Daxp7aZ8YWZ/PMHR3ecZD6YuZ1POtc2tZKamHDcl7Aq6EVEjuC5VbsYnJEEwL0vb+TfzxtPghkbKmu5+Y8rOHdCIWeMHsyfllUwJCuV1zfsJSUxgeq6ZjJTE9m1/4j3f3ZIDiUwtjCT+ubWjjuai/MzKC7IoCg3nRGD03lzU/hBN49eN+u4nmegoBcROQ7t7f6+odvW7vxuyTYcp2RoFglmrNl5gK1V9UwuymZ/QwsV+xp4Z9s+VmwPL1998KllhYNS2H3g0F8SN100kevOKT6uWvXMWBGR43C0kXUowbhq5qF380ffo9CVtnZn2bZqphTl0NbuPPjGZrbsrWfCSYO4euaoEy25Swp6EZE+FEowTh81GICkEMw/Z2yvf6YWrhARCTgFvYhIwCnoRUQCTkEvIhJwCnoRkYBT0IuIBJyCXkQk4BT0IiIB1++WQDCzSmDLCbxFPoc+qzYeqM/xQX2OD8fb51HuXtDVgX4X9CfKzMqOtN5DUKnP8UF9jg+90WdN3YiIBJyCXkQk4IIY9PfGuoAYUJ/jg/ocH3q8z4GboxcRkUMFcUQvIiJRFPQiIgEXmKA3s9lmtsbM1pvZDbGup6eY2f1mttvMVkTtG2xmz5nZush/cyP7zcx+FvkzeNfMTotd5cfPzEaY2YtmtsrMVprZf0T2B7bfZpZqZm+a2TuRPn87sn+MmS2O9O13ZpYc2Z8S2V4fOT46ph04AWYWMrO3zeypyHag+2xmm81suZktM7OyyL5e/dkORNCbWQi4G7gQKAGuNLOS2FbVY34DzO607wZgkbuPBxZFtiHc//GRr/nAL/qoxp7WCnzF3UuAWcC/Rf5/BrnfTcC57j4VmAbMNrNZwG3AHe4+DqgGro20vxaojuy/I9JuoPoPYHXUdjz0+SPuPi3qevne/dl29wH/BZwJLIzavhG4MdZ19WD/RgMrorbXAEMjr4cCayKv7wGu7KrdQP4C/gScHy/9BtKBpcBMwndIJkb2d/ycAwuBMyOvEyPtLNa1H0dfiyLBdi7wFGBx0OfNQH6nfb36sx2IET0wHNgWtV0e2RdUQ9x9R+T1TmBI5HXg/hwi/zyfDiwm4P2OTGEsA3YDzwEbgH3u3hppEt2vjj5HjtcAeX1acM/4KfDfQHtkO4/g99mBZ83sLTObH9nXqz/bejj4AOfubmaBvEbWzDKBPwD/6e77zazjWBD77e5twDQzywGeBCbEtqLeZWaXALvd/S0z+3CMy+lLZ7l7hZkVAs+Z2XvRB3vjZzsoI/oKYETUdlFkX1DtMrOhAJH/7o7sD8yfg5klEQ7537r7E5Hdge83gLvvA14kPG2RY2YHB2TR/eroc+R4NrC3bys9YR8E5pjZZuAxwtM3dxLsPuPuFZH/7ib8C30GvfyzHZSgXwKMj5ytTwbmAQtiXFNvWgBcE3l9DeE57IP7Pxs5Uz8LqIn65+CAYeGh+6+A1e5+e9ShwPbbzAoiI3nMLI3wOYnVhAN/bqRZ5z4f/LOYC7zgkUncgcLdb3T3IncfTfjv7AvufjUB7rOZZZjZoIOvgQuAFfT2z3asT0z04AmOi4C1hOc1b4p1PT3Yr0eBHUAL4fm5awnPSy4C1gHPA4MjbY3w1UcbgOVAaazrP84+n0V4HvNdYFnk66Ig9xuYArwd6fMK4JuR/cXAm8B64P+AlMj+1Mj2+sjx4lj34QT7/2HgqaD3OdK3dyJfKw9mVW//bGsJBBGRgAvK1I2IiByBgl5EJOAU9CIiAaegFxEJOAW9iEjAKehFRAJOQS8iEnD/HyWUWbUf7otDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vs Training Set\n",
      "-0.11739524\n",
      "Vs Test Set\n",
      "\n",
      " vs training data= 18243 / 18301  vs test data= 8697 / 10920 79 % at max difference 0.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntrain2 ,test2=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.1)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.2)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.3)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.7)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.8)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.9)\\n\\n\\ngru_model2, losslist2 =train_existing_model(gru_model1,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\ntrain2 ,test2=evaluatefull_maxdiff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,maxdifference=0.4)\\n\\ntrain2 ,test2=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.1)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.2)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.3)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.7)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.8)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.9)\\n\\ngru_model3, losslist3 =train_existing_model(gru_model2,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\ntrain2 ,test2=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.7)\\n\\n\\ngru_model4, losslist4 =train_existing_model(gru_model3,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\n\\ntrain2 ,test2=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.7)\\n\\ngru_model5, losslist5 =train_existing_model(gru_model4,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\ntrain2 ,test2=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.7)\\n\\ngru_model6, losslist6 =train_existing_model(gru_model5,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\ntrain2 ,test2=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.7)\\n\\ngru_model7, losslist7 =train_existing_model(gru_model6,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\ntrain2 ,test2=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.7)\\n\\ngru_model8, losslist8 =train_existing_model(gru_model7,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\\ntrain2 ,test2=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.7)\\n\\nfulllosslist=losslist1+losslist2+losslist3+losslist4+losslist5+losslist6+losslist7+losslist8\\nplt.plot(fulllosslist)\\nplt.title(\"Loss\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0005\n",
    "batch_size = 64*2\n",
    "lookback=10\n",
    "#a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels.\n",
    "\n",
    "#X=State[:,:,0:9]\n",
    "X=State[:,:,:]\n",
    "print(\"x.shape\",X.shape)\n",
    "print(\"lookback-1\",lookback-1)\n",
    "y=Labels[:,lookback-1]\n",
    "y=y.reshape(runqty,1)\n",
    "print(\"y.shape\",y.shape)\n",
    "\n",
    "X_testset=State_testset[:,:,:]\n",
    "y_testset=Labels_testset[:,lookback-1]\n",
    "print(\"x.testsetshape\",X_testset.shape)\n",
    "y_testset=y_testset.reshape(runqty_testset,1)\n",
    "\n",
    "\n",
    "random_seed=int(time.time())\n",
    "#print(int(time.time()))\n",
    "train_x_trainset, test_x_trainset, train_y_trainset,test_y_trainset = train_test_split(X, y, test_size= float(.00001),#.25 #0.33, \n",
    "                                                   random_state=random_seed)\n",
    "\n",
    "train_x_testset, test_x_testset, train_y_testset,test_y_testset = train_test_split(X_testset, y_testset, test_size=.995,#.25 #0.33, \n",
    "                                                   random_state=random_seed)\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x_trainset), torch.from_numpy(train_y_trainset))\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "test_data   = TensorDataset( torch.from_numpy( test_x_testset ), torch.from_numpy( test_y_testset) )\n",
    "test_loader = DataLoader( test_data, shuffle = True, batch_size = batch_size, drop_last = True )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gru_model1, losslist1 =train(train_loader, lr , hidden_dim=128, EPOCHS=500 ,model_type=\"GRU\") #1500  #had low total loss with batch size 32\n",
    "\n",
    "train2 ,test2=evaluatefull_maxdiff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,maxdifference=0.4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.1)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.2)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.3)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.7)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.8)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.9)\n",
    "\n",
    "\n",
    "gru_model2, losslist2 =train_existing_model(gru_model1,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "train2 ,test2=evaluatefull_maxdiff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,maxdifference=0.4)\n",
    "\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.1)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.2)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.3)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.7)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.8)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model2, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.9)\n",
    "\n",
    "gru_model3, losslist3 =train_existing_model(gru_model2,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model3, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "\n",
    "\n",
    "gru_model4, losslist4 =train_existing_model(gru_model3,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model4, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "\n",
    "gru_model5, losslist5 =train_existing_model(gru_model4,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model5, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "\n",
    "gru_model6, losslist6 =train_existing_model(gru_model5,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model6, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "\n",
    "gru_model7, losslist7 =train_existing_model(gru_model6,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model7, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "\n",
    "gru_model8, losslist8 =train_existing_model(gru_model7,train_loader, lr , hidden_dim=128, EPOCHS=200, model_type=\"GRU\")\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model8, train_x, train_y, test_x, test_y,cutoff=.7)\n",
    "\n",
    "fulllosslist=losslist1+losslist2+losslist3+losslist4+losslist5+losslist6+losslist7+losslist8\n",
    "plt.plot(fulllosslist)\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_25_2021\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import date\n",
    "\n",
    "today = date.today()    \n",
    "todaydate = today.strftime(\"%m_%d_%Y\")\n",
    "print(todaydate)\n",
    "torch.save(gru_model1,\"currentmodel_V10_retroactiveVals\"+todaydate+\".pt\")\n",
    "\n",
    "\n",
    "print(\"model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vs Training Set\n",
      "0.03553606\n",
      "Vs Test Set\n",
      "\n",
      " vs training data= 18140 / 18301  vs test data= 8351 / 10920 76 % at max difference 0.4\n"
     ]
    }
   ],
   "source": [
    "train2 ,test2=evaluatefull_maxdiff(gru_model1, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,maxdifference=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.1)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.2)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.3)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.7)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.8)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.9)\\n\\n\\nprint(\"\")\\nprint(\"\")\\n\\ntrain2 ,test2=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.1)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.2)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.3)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.4)\\ntrain2 ,test2=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)\\ntrain3 ,test3=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.6)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.7)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.8)\\ntrain4 ,test4=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.9)\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.1)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.2)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.3)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.7)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.8)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.9)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.1)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.2)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.3)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.7)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.8)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model4, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.9)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_episode(model, data, verbose=False):\n",
    "\n",
    "   \n",
    "    model.eval()\n",
    "    inp = torch.from_numpy(np.array(data)) # should be 5x1\n",
    "    h = model.init_hidden(inp.shape[0])\n",
    "    #print(\"inp\",inp)\n",
    "    #print(\"labs\",labs)\n",
    "    #print(\"h\",h)\n",
    "    out, h = model(inp.to(device).float(), h)\n",
    "    #print(\"model output\",out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_24_2021\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import date\n",
    "\n",
    "today = date.today()    \n",
    "todaydate = today.strftime(\"%m_%d_%Y\")\n",
    "print(todaydate)\n",
    "torch.save(gru_model1,\"currentmodel_3datasets_1steplookhead_model1_\"+todaydate+\".pt\")\n",
    "torch.save(gru_model2,\"currentmodel_3datasets_1steplookhead_model2_\"+todaydate+\".pt\")\n",
    "torch.save(gru_model3,\"currentmodel_3datasets_1steplookhead_model3_\"+todaydate+\".pt\")\n",
    "torch.save(gru_model4,\"currentmodel_3datasets_1steplookhead_model4_\"+todaydate+\".pt\")\n",
    "print(\"model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "gru_model3=torch.load('currentmodel_9steplookhead10_23_2021.pt',map_location=torch.device('cpu'))\n",
    "gru_model3.eval()\n",
    "print(\"loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x_trainset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8751/1960168386.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluatefull_cutoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_testset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_testset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluatefull_cutoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_testset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_testset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluatefull_cutoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_testset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_testset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluatefull_cutoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_testset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_testset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluatefull_cutoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_trainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_testset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_testset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_x_trainset' is not defined"
     ]
    }
   ],
   "source": [
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.1)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.2)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.3)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.4)\n",
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)\n",
    "train3 ,test3=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.6)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.7)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.8)\n",
    "train4 ,test4=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " vs training data= 12561 / 12569  vs test data= 4039 / 4042 99.93 % at cutoff 0.5\n",
      "TEST SET: True Positives 2021 True Negatives 2018\n",
      "TEST SET: False Positives 3 False Negatives 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:184: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "train2 ,test2=evaluatefull_cutoff(gru_model3, train_x_trainset, train_y_trainset, test_x_testset, test_y_testset,cutoff=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index= 44\n",
      "(1, 5, 10)\n",
      "prediction 0.2498023509979248   actual [0.]\n"
     ]
    }
   ],
   "source": [
    "randomindex=random.randint(0,225)\n",
    "print(\"index=\",randomindex)\n",
    "\n",
    "exampledata=np.expand_dims(test_x[207, 0:5, 0:10], axis=0)\n",
    "\n",
    "print(exampledata.shape)\n",
    "prediction=evaluate_episode(gru_model3, exampledata)\n",
    "\n",
    "print(\"prediction\",float(prediction), \"  actual\",test_y[randomindex])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## simlulate a buffer of 10 timesteps entering the classifier over a 1 episode, and classifying them. Filling empty data with zeroes or ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index= 188\n",
      "final partial data\n",
      "[[[1.         0.64779416 0.68590197 0.69517914 0.69903447 0.71459429\n",
      "   0.71267351 0.71409191 0.71673093 0.72399386]\n",
      "  [1.         0.52154944 0.52310862 0.53282553 0.52718083 0.53709991\n",
      "   0.52978522 0.54277099 0.53688102 0.54443726]\n",
      "  [1.         0.8726286  0.96482141 0.95083008 0.94447182 0.93691809\n",
      "   0.95239155 0.9493714  0.95276295 0.95638539]\n",
      "  [1.         0.50752062 0.50852903 0.49810241 0.50102952 0.4947311\n",
      "   0.50046923 0.49000781 0.49422322 0.48543027]\n",
      "  [1.         0.62007232 0.67079484 0.67376652 0.67304434 0.68618886\n",
      "   0.68665851 0.69233506 0.69529406 0.70288601]]]\n",
      "\n",
      "full data\n",
      "[[[0.64779416 0.68590197 0.69517914 0.69903447 0.71459429 0.71267351\n",
      "   0.71409191 0.71673093 0.72399386 0.7219988 ]\n",
      "  [0.52154944 0.52310862 0.53282553 0.52718083 0.53709991 0.52978522\n",
      "   0.54277099 0.53688102 0.54443726 0.53999553]\n",
      "  [0.8726286  0.96482141 0.95083008 0.94447182 0.93691809 0.95239155\n",
      "   0.9493714  0.95276295 0.95638539 0.94038139]\n",
      "  [0.50752062 0.50852903 0.49810241 0.50102952 0.4947311  0.50046923\n",
      "   0.49000781 0.49422322 0.48543027 0.49026894]\n",
      "  [0.62007232 0.67079484 0.67376652 0.67304434 0.68618886 0.68665851\n",
      "   0.69233506 0.69529406 0.70288601 0.70206539]]]\n",
      "predictions: [-0.15575464069843292, 0.23807184398174286, 0.38706398010253906, 0.21107828617095947, 0.10108674317598343, 0.1720225214958191, 0.42928677797317505, 0.3034760355949402, 0.030546963214874268]\n",
      "\n",
      "\n",
      "prediction from 10 timesteps 0.4351702332496643 actual [0.]\n"
     ]
    }
   ],
   "source": [
    "outputlist=[]\n",
    "\n",
    "randomindex=random.randint(0,225)\n",
    "print(\"index=\",randomindex)\n",
    "exampledata=np.expand_dims(test_x[randomindex, 0:5, 0:10], axis=0)\n",
    "\n",
    "\n",
    "#print(temparray.shape)\n",
    "#temparray=np.expand_dims(temparray, axis=1)\n",
    "\n",
    "#print(temparray.shape)\n",
    "#print(temparray)\n",
    "\n",
    "#temparray2=test_x[randomindex, 0:5, 0]\n",
    "#temparray2=np.expand_dims(temparray2, axis=1)\n",
    "\n",
    "for i in range(9):\n",
    "    if i!=10:\n",
    "        temparray=np.ones((5,1)) #test_x[randomindex, 0:5, 0]   #zeroes or \"ones\" here seems to work equally well. \n",
    "    \n",
    "    for j in range(8-i):\n",
    "        #temparray2=test_x[randomindex, 0:5, 0]\n",
    "        #temparray2=np.expand_dims(temparray2, axis=1)\n",
    "        temparray=np.append(temparray,np.ones((5,1)),axis=1)       #zeroes or \"ones\" here seems to work equally well. \n",
    "        #temparray=np.append(temparray,temparray2,axis=1)\n",
    "        #temparray=np.append(np.zeros((5,1)),temparray,axis=1)   \n",
    "    \n",
    "    for j in range(i+1):\n",
    "\n",
    "        temparray2=test_x[randomindex, 0:5, j]\n",
    "        temparray2=np.expand_dims(temparray2, axis=1)\n",
    "        temparray=np.append(temparray,temparray2,axis=1)\n",
    "        #temparray=np.append(np.zeros((5,1)),temparray,axis=1)\n",
    "\n",
    "    \n",
    "    #print(temparray)\n",
    "    temparray=np.expand_dims(temparray, axis=0)\n",
    "    outputpartial=evaluate_episode(gru_model3, temparray)\n",
    "    \n",
    "    \n",
    "    outputlist.append(float(outputpartial))\n",
    "\n",
    "print(\"final partial data\")\n",
    "print(temparray)   \n",
    "print(\"\")\n",
    "print(\"full data\")\n",
    "print(exampledata)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"prediction from\",x,\" timesteps\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "print(\"predictions:\",outputlist)\n",
    "\n",
    "\n",
    "#print(\"full data\")\n",
    "#print(exampledata)\n",
    "print(\"\")\n",
    "#print(\"evaluating all 10 timesteps\")\n",
    "\n",
    "outputfull=evaluate_episode(gru_model3, exampledata)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "#print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "#print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "print(\"prediction from 10 timesteps\",float(outputfull),\"actual\",test_y[randomindex])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classifying progression of 10 actual forces and torques in a sucessful sequence longer than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7200, 30)\n",
      "['header0', 'header1', 'header2', 'header3', 'header4', 'header5', 'header6', 'header7', 'header8', 'header9', 'header10', 'header11', 'header12', 'header13', 'header14', 'header15', 'header16', 'header17', 'header18', 'header19', 'header20', 'header21', 'header22', 'header23', 'header24', 'header25', 'header26', 'header27', 'header28', 'header29']\n"
     ]
    }
   ],
   "source": [
    "originaldata=pd.read_csv('forcetorquebuttonresults_renormalized_10_06_2021_newrange.csv')#.head()\n",
    "print(originaldata.shape)\n",
    "headers=[]\n",
    "lookback=30 #save only the last 11 timesteps\n",
    "for i in range(lookback):  \n",
    "    label=str(i)\n",
    "    headers.append(\"header\"+label)\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header0</th>\n",
       "      <th>header1</th>\n",
       "      <th>header2</th>\n",
       "      <th>header3</th>\n",
       "      <th>header4</th>\n",
       "      <th>header5</th>\n",
       "      <th>header6</th>\n",
       "      <th>header7</th>\n",
       "      <th>header8</th>\n",
       "      <th>header9</th>\n",
       "      <th>...</th>\n",
       "      <th>header20</th>\n",
       "      <th>header21</th>\n",
       "      <th>header22</th>\n",
       "      <th>header23</th>\n",
       "      <th>header24</th>\n",
       "      <th>header25</th>\n",
       "      <th>header26</th>\n",
       "      <th>header27</th>\n",
       "      <th>header28</th>\n",
       "      <th>header29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4039</th>\n",
       "      <td>-0.146118</td>\n",
       "      <td>-0.150491</td>\n",
       "      <td>-0.161489</td>\n",
       "      <td>-0.145119</td>\n",
       "      <td>-0.144571</td>\n",
       "      <td>-0.139811</td>\n",
       "      <td>-0.140801</td>\n",
       "      <td>-0.155982</td>\n",
       "      <td>-0.166506</td>\n",
       "      <td>-0.181792</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4040</th>\n",
       "      <td>0.855510</td>\n",
       "      <td>0.854350</td>\n",
       "      <td>0.856338</td>\n",
       "      <td>0.850147</td>\n",
       "      <td>0.851591</td>\n",
       "      <td>0.854438</td>\n",
       "      <td>0.850040</td>\n",
       "      <td>0.839254</td>\n",
       "      <td>0.842253</td>\n",
       "      <td>0.845896</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4041</th>\n",
       "      <td>0.186981</td>\n",
       "      <td>0.186524</td>\n",
       "      <td>0.187637</td>\n",
       "      <td>0.185199</td>\n",
       "      <td>0.188515</td>\n",
       "      <td>0.183551</td>\n",
       "      <td>0.182902</td>\n",
       "      <td>0.192211</td>\n",
       "      <td>0.219140</td>\n",
       "      <td>0.220496</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4042</th>\n",
       "      <td>0.077426</td>\n",
       "      <td>0.079701</td>\n",
       "      <td>0.079563</td>\n",
       "      <td>0.080320</td>\n",
       "      <td>0.082692</td>\n",
       "      <td>0.082281</td>\n",
       "      <td>0.082844</td>\n",
       "      <td>0.103996</td>\n",
       "      <td>0.197891</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4043</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       header0   header1   header2   header3   header4   header5   header6  \\\n",
       "4039 -0.146118 -0.150491 -0.161489 -0.145119 -0.144571 -0.139811 -0.140801   \n",
       "4040  0.855510  0.854350  0.856338  0.850147  0.851591  0.854438  0.850040   \n",
       "4041  0.186981  0.186524  0.187637  0.185199  0.188515  0.183551  0.182902   \n",
       "4042  0.077426  0.079701  0.079563  0.080320  0.082692  0.082281  0.082844   \n",
       "4043  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       header7   header8   header9  ...  header20  header21  header22  \\\n",
       "4039 -0.155982 -0.166506 -0.181792  ...       NaN       NaN       NaN   \n",
       "4040  0.839254  0.842253  0.845896  ...       NaN       NaN       NaN   \n",
       "4041  0.192211  0.219140  0.220496  ...       NaN       NaN       NaN   \n",
       "4042  0.103996  0.197891  0.189500  ...       NaN       NaN       NaN   \n",
       "4043  0.000000  0.000000  0.000000  ...       NaN       NaN       NaN   \n",
       "\n",
       "      header23  header24  header25  header26  header27  header28  header29  \n",
       "4039       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "4040       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "4041       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "4042       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "4043       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originaldata.iloc[4039:4044]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0731408   0.03829234  0.0469334   0.00194419 -0.01112242 -0.02011151\n",
      "  -0.03633799 -0.03225345 -0.0420291   0.00937499]\n",
      " [-0.11749066 -0.23484093 -0.26258131 -0.25717197 -0.26656799 -0.25038209\n",
      "  -0.26268438 -0.26090061 -0.26164099 -0.21694467]\n",
      " [ 0.86082529  0.77558722  0.85436662  0.84721256  0.85877484  0.84311893\n",
      "   0.864341    0.85094293  0.84540413  0.70251442]\n",
      " [ 0.176776    0.27154119  0.30495647  0.30333233  0.30492832  0.29572228\n",
      "   0.30752579  0.3070787   0.3079597   0.27827674]\n",
      " [ 0.07638625  0.02011034 -0.00378486 -0.02415284 -0.03190367 -0.04353291\n",
      "  -0.05766036 -0.05307872 -0.05883769 -0.04239337]]\n",
      "(1, 5, 10)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gru_model3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5706/3011891858.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelstest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0moutputfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gru_model3' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(originaldata[headers[0:30]].iloc[4039:4044])\n",
    "#print(originaldata[headers[0:30]].iloc[4039:4044].to_numpy()\n",
    "classifytest=originaldata[headers[19:29]].iloc[4038:4043].to_numpy()\n",
    "labelstest=originaldata[headers[19:29]].iloc[4043].to_numpy()\n",
    "print(classifytest)\n",
    "classifytest=np.expand_dims(classifytest, axis=0)\n",
    "print(classifytest.shape)\n",
    "print(labelstest)\n",
    "\n",
    "outputfull=evaluate_episode(gru_model3, classifytest)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "#print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "#print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "print(\"prediction from 10 timesteps\",float(outputfull),\"actual\",labelstest[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction from timestep 0 - 10  : -0.032343629747629166 actual 0.0 OK\n",
      "prediction from timestep 1 - 11  : 0.06366002559661865 actual 0.0 OK\n",
      "prediction from timestep 2 - 12  : 0.051990147680044174 actual 0.0 OK\n",
      "prediction from timestep 3 - 13  : 0.023980792611837387 actual 0.0 OK\n",
      "prediction from timestep 4 - 14  : -0.040336642414331436 actual 0.0 OK\n",
      "prediction from timestep 5 - 15  : 0.23271429538726807 actual 0.0 OK\n",
      "prediction from timestep 6 - 16  : 0.08097636699676514 actual 0.0 OK\n",
      "prediction from timestep 7 - 17  : 0.031633224338293076 actual 0.0 OK\n",
      "prediction from timestep 8 - 18  : -0.0510486401617527 actual 0.0 OK\n",
      "prediction from timestep 9 - 19  : 0.26394492387771606 actual 0.0 OK\n",
      "prediction from timestep 10 - 20  : 0.07988288998603821 actual 0.0 OK\n",
      "prediction from timestep 11 - 21  : 0.05816278234124184 actual 0.0 OK\n",
      "prediction from timestep 12 - 22  : -0.032187577337026596 actual 0.0 OK\n",
      "prediction from timestep 13 - 23  : -0.08134518563747406 actual 0.0 OK\n",
      "prediction from timestep 14 - 24  : -0.03597566857933998 actual 0.0 OK\n",
      "prediction from timestep 15 - 25  : 0.11897647380828857 actual 0.0 OK\n",
      "prediction from timestep 16 - 26  : 0.7946897149085999 actual 0.0 X\n",
      "prediction from timestep 17 - 27  : 0.8307268619537354 actual 0.0 X\n",
      "prediction from timestep 18 - 28  : 0.65999436378479 actual 0.0 X\n",
      "prediction from timestep 19 - 29  : 1.045872688293457 actual 1.0 OK\n",
      "okcounter 17\n"
     ]
    }
   ],
   "source": [
    "\n",
    "okcounter=0\n",
    "for i in range(20):\n",
    "    #classifytest=originaldata[headers[i:10+i]].iloc[4296:4301].to_numpy()\n",
    "    #labelstest=originaldata[headers[i:10+i]].iloc[4301].to_numpy()\n",
    "    classifytest=originaldata[headers[i:10+i]].iloc[4296:4301].to_numpy()\n",
    "    labelstest=originaldata[headers[i:10+i]].iloc[4301].to_numpy()\n",
    "    \n",
    "    #print(classifytest)\n",
    "    classifytest=np.expand_dims(classifytest, axis=0)\n",
    "    #print(classifytest.shape)\n",
    "    #print(labelstest)\n",
    "\n",
    "    outputfull=evaluate_episode(gru_model1, classifytest)\n",
    "\n",
    "    #print(\"\")\n",
    "\n",
    "    #print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "    #print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "    \n",
    "    if abs(float(outputfull)-labelstest[9])>0.3:\n",
    "        result=\"X\"\n",
    "    else:\n",
    "        result=\"OK\"\n",
    "        okcounter+=1\n",
    "    print(\"prediction from timestep\",i,\"-\",i+10,\" :\",float(outputfull),\"actual\",labelstest[9], result)\n",
    "print(\"okcounter\",okcounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header0</th>\n",
       "      <th>header1</th>\n",
       "      <th>header2</th>\n",
       "      <th>header3</th>\n",
       "      <th>header4</th>\n",
       "      <th>header5</th>\n",
       "      <th>header6</th>\n",
       "      <th>header7</th>\n",
       "      <th>header8</th>\n",
       "      <th>header9</th>\n",
       "      <th>...</th>\n",
       "      <th>header20</th>\n",
       "      <th>header21</th>\n",
       "      <th>header22</th>\n",
       "      <th>header23</th>\n",
       "      <th>header24</th>\n",
       "      <th>header25</th>\n",
       "      <th>header26</th>\n",
       "      <th>header27</th>\n",
       "      <th>header28</th>\n",
       "      <th>header29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4890</th>\n",
       "      <td>0.519653</td>\n",
       "      <td>0.629009</td>\n",
       "      <td>0.666283</td>\n",
       "      <td>0.757858</td>\n",
       "      <td>0.748447</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.751999</td>\n",
       "      <td>0.743304</td>\n",
       "      <td>0.741959</td>\n",
       "      <td>0.748569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785070</td>\n",
       "      <td>0.768524</td>\n",
       "      <td>0.756693</td>\n",
       "      <td>0.763045</td>\n",
       "      <td>0.771942</td>\n",
       "      <td>0.774374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4891</th>\n",
       "      <td>0.372140</td>\n",
       "      <td>0.333817</td>\n",
       "      <td>0.319136</td>\n",
       "      <td>0.330614</td>\n",
       "      <td>0.324397</td>\n",
       "      <td>0.318553</td>\n",
       "      <td>0.308498</td>\n",
       "      <td>0.310825</td>\n",
       "      <td>0.340429</td>\n",
       "      <td>0.380643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510981</td>\n",
       "      <td>0.545773</td>\n",
       "      <td>0.534438</td>\n",
       "      <td>0.555681</td>\n",
       "      <td>0.578675</td>\n",
       "      <td>0.561716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4892</th>\n",
       "      <td>0.932075</td>\n",
       "      <td>0.880805</td>\n",
       "      <td>0.871212</td>\n",
       "      <td>0.782250</td>\n",
       "      <td>0.917737</td>\n",
       "      <td>0.913229</td>\n",
       "      <td>0.930457</td>\n",
       "      <td>0.932578</td>\n",
       "      <td>0.922336</td>\n",
       "      <td>0.936276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951116</td>\n",
       "      <td>0.928739</td>\n",
       "      <td>0.959949</td>\n",
       "      <td>0.949016</td>\n",
       "      <td>0.937812</td>\n",
       "      <td>0.899633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>0.641091</td>\n",
       "      <td>0.669016</td>\n",
       "      <td>0.684142</td>\n",
       "      <td>0.675920</td>\n",
       "      <td>0.699291</td>\n",
       "      <td>0.686433</td>\n",
       "      <td>0.692765</td>\n",
       "      <td>0.690845</td>\n",
       "      <td>0.670727</td>\n",
       "      <td>0.643720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498684</td>\n",
       "      <td>0.474195</td>\n",
       "      <td>0.481877</td>\n",
       "      <td>0.466092</td>\n",
       "      <td>0.447252</td>\n",
       "      <td>0.446521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>0.550714</td>\n",
       "      <td>0.634439</td>\n",
       "      <td>0.686677</td>\n",
       "      <td>0.743846</td>\n",
       "      <td>0.772609</td>\n",
       "      <td>0.768783</td>\n",
       "      <td>0.769648</td>\n",
       "      <td>0.771199</td>\n",
       "      <td>0.775574</td>\n",
       "      <td>0.782100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835276</td>\n",
       "      <td>0.823710</td>\n",
       "      <td>0.817117</td>\n",
       "      <td>0.822949</td>\n",
       "      <td>0.825044</td>\n",
       "      <td>0.824857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       header0   header1   header2   header3   header4   header5   header6  \\\n",
       "4890  0.519653  0.629009  0.666283  0.757858  0.748447  0.748698  0.751999   \n",
       "4891  0.372140  0.333817  0.319136  0.330614  0.324397  0.318553  0.308498   \n",
       "4892  0.932075  0.880805  0.871212  0.782250  0.917737  0.913229  0.930457   \n",
       "4893  0.641091  0.669016  0.684142  0.675920  0.699291  0.686433  0.692765   \n",
       "4894  0.550714  0.634439  0.686677  0.743846  0.772609  0.768783  0.769648   \n",
       "4895  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       header7   header8   header9  ...  header20  header21  header22  \\\n",
       "4890  0.743304  0.741959  0.748569  ...  0.785070  0.768524  0.756693   \n",
       "4891  0.310825  0.340429  0.380643  ...  0.510981  0.545773  0.534438   \n",
       "4892  0.932578  0.922336  0.936276  ...  0.951116  0.928739  0.959949   \n",
       "4893  0.690845  0.670727  0.643720  ...  0.498684  0.474195  0.481877   \n",
       "4894  0.771199  0.775574  0.782100  ...  0.835276  0.823710  0.817117   \n",
       "4895  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "      header23  header24  header25  header26  header27  header28  header29  \n",
       "4890  0.763045  0.771942  0.774374       NaN       NaN       NaN       NaN  \n",
       "4891  0.555681  0.578675  0.561716       NaN       NaN       NaN       NaN  \n",
       "4892  0.949016  0.937812  0.899633       NaN       NaN       NaN       NaN  \n",
       "4893  0.466092  0.447252  0.446521       NaN       NaN       NaN       NaN  \n",
       "4894  0.822949  0.825044  0.824857       NaN       NaN       NaN       NaN  \n",
       "4895  0.000000  0.000000  1.000000       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[6 rows x 30 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originaldata.iloc[4890:4896]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction from timestep 0 - 10  : 0.028200116008520126 actual 0.0 OK\n",
      "prediction from timestep 1 - 11  : -0.014303509145975113 actual 0.0 OK\n",
      "prediction from timestep 2 - 12  : 0.14375820755958557 actual 0.0 OK\n",
      "prediction from timestep 3 - 13  : 0.028781067579984665 actual 0.0 OK\n",
      "prediction from timestep 4 - 14  : 0.09958063066005707 actual 0.0 OK\n",
      "prediction from timestep 5 - 15  : 0.20534682273864746 actual 0.0 OK\n",
      "prediction from timestep 6 - 16  : 0.24032628536224365 actual 0.0 OK\n",
      "prediction from timestep 7 - 17  : 0.3120570778846741 actual 0.0 X\n",
      "prediction from timestep 8 - 18  : 0.20618976652622223 actual 0.0 OK\n",
      "prediction from timestep 9 - 19  : 0.21796914935112 actual 0.0 OK\n",
      "prediction from timestep 10 - 20  : 0.497882217168808 actual 0.0 X\n",
      "prediction from timestep 11 - 21  : 0.3194980025291443 actual 0.0 X\n",
      "prediction from timestep 12 - 22  : 0.667169451713562 actual 0.0 X\n",
      "prediction from timestep 13 - 23  : 0.4396326541900635 actual 0.0 X\n",
      "prediction from timestep 14 - 24  : 0.3643774092197418 actual 0.0 X\n",
      "prediction from timestep 15 - 25  : 0.8191363215446472 actual 0.0 X\n",
      "prediction from timestep 16 - 26  : 0.7762025594711304 actual 1.0 OK\n",
      "prediction from timestep 17 - 27  : nan actual nan OK\n",
      "prediction from timestep 18 - 28  : nan actual nan OK\n",
      "prediction from timestep 19 - 29  : nan actual nan OK\n",
      "okcounter 13\n"
     ]
    }
   ],
   "source": [
    "okcounter=0\n",
    "for i in range(20):\n",
    "    classifytest=originaldata[headers[i:10+i]].iloc[4890:4895].to_numpy()\n",
    "    labelstest=originaldata[headers[i:10+i]].iloc[4895].to_numpy()\n",
    "    #print(classifytest)\n",
    "    classifytest=np.expand_dims(classifytest, axis=0)\n",
    "    #print(classifytest.shape)\n",
    "    #print(labelstest)\n",
    "\n",
    "    outputfull=evaluate_episode(gru_model1, classifytest)\n",
    "\n",
    "    #print(\"\")\n",
    "\n",
    "    #print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "    #print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "    \n",
    "    if abs(float(outputfull)-labelstest[9])>0.3:\n",
    "        result=\"X\"\n",
    "    else:\n",
    "        result=\"OK\"\n",
    "        okcounter+=1\n",
    "    print(\"prediction from timestep\",i,\"-\",i+10,\" :\",float(outputfull),\"actual\",labelstest[9], result)\n",
    "print(\"okcounter\",okcounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction from timestep 0 - 10  : 0.008580457419157028 actual 0.0 OK\n",
      "prediction from timestep 1 - 11  : 0.0635090172290802 actual 0.0 OK\n",
      "prediction from timestep 2 - 12  : 0.0438377670943737 actual 0.0 OK\n",
      "prediction from timestep 3 - 13  : 0.025556694716215134 actual 0.0 OK\n",
      "prediction from timestep 4 - 14  : 0.019277315586805344 actual 0.0 OK\n",
      "prediction from timestep 5 - 15  : -0.027621407061815262 actual 0.0 OK\n",
      "prediction from timestep 6 - 16  : 0.003315012902021408 actual 0.0 OK\n",
      "prediction from timestep 7 - 17  : 0.05670307204127312 actual 0.0 OK\n",
      "prediction from timestep 8 - 18  : 0.058597173541784286 actual 0.0 OK\n",
      "prediction from timestep 9 - 19  : 0.03477386757731438 actual 0.0 OK\n",
      "prediction from timestep 10 - 20  : 0.021829035133123398 actual 0.0 OK\n",
      "prediction from timestep 11 - 21  : 0.027187403291463852 actual 0.0 OK\n",
      "prediction from timestep 12 - 22  : 0.05785646662116051 actual 0.0 OK\n",
      "prediction from timestep 13 - 23  : 0.09505438804626465 actual 0.0 OK\n",
      "prediction from timestep 14 - 24  : -0.10971000790596008 actual 0.0 OK\n",
      "prediction from timestep 15 - 25  : 0.13245484232902527 actual 0.0 OK\n",
      "prediction from timestep 16 - 26  : 0.1284477859735489 actual 0.0 OK\n",
      "prediction from timestep 17 - 27  : 0.07165920734405518 actual 0.0 OK\n",
      "prediction from timestep 18 - 28  : 0.20184975862503052 actual 0.0 OK\n",
      "prediction from timestep 19 - 29  : 0.3096734881401062 actual 0.0 X\n",
      "okcounter 19\n"
     ]
    }
   ],
   "source": [
    "okcounter=0\n",
    "for i in range(20):\n",
    "    classifytest=originaldata[headers[i:10+i]].iloc[0+12:5+12].to_numpy()\n",
    "    labelstest=originaldata[headers[i:10+i]].iloc[5+12].to_numpy()\n",
    "    #print(classifytest)\n",
    "    classifytest=np.expand_dims(classifytest, axis=0)\n",
    "    #print(classifytest.shape)\n",
    "    #print(labelstest)\n",
    "\n",
    "    outputfull=evaluate_episode(gru_model1, classifytest)\n",
    "\n",
    "    #print(\"\")\n",
    "\n",
    "    #print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "    #print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "    \n",
    "    if abs(float(outputfull)-labelstest[9])>0.3:\n",
    "        result=\"X\"\n",
    "    else:\n",
    "        result=\"OK\"\n",
    "        okcounter+=1\n",
    "    print(\"prediction from timestep\",i,\"-\",i+10,\" :\",float(outputfull),\"actual\",labelstest[9], result)\n",
    "print(\"okcounter\",okcounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_episode(model, data, verbose=False):\n",
    "\n",
    "   \n",
    "    model.eval()\n",
    "    inp = torch.from_numpy(np.array(data)) # should be 5x1\n",
    "    h = model.init_hidden(inp.shape[0])\n",
    "    #print(\"inp\",inp)\n",
    "    #print(\"labs\",labs)\n",
    "    #print(\"h\",h)\n",
    "    out, h = model(inp.to(device).float(), h)\n",
    "    #print(\"model output\",out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8454625996709277"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(278+13082)/(278+13082+2410+32)  #evaluation on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15802"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(278+13082+2410+32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate2(model, test_x, test_y):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []  #labels\n",
    "    #start_time = time.clock()\n",
    "    #for i in test_x.keys():\n",
    "    #for i in range( len( test_x ) ):    \n",
    "    inp = torch.from_numpy(np.array(test_x)) # should be 5x1\n",
    "    labs = torch.from_numpy(np.array(test_y)) #should be 1x1\n",
    "    h = model.init_hidden(inp.shape[0])\n",
    "    #print(\"inp\",inp)\n",
    "    #print(\"labs\",labs)\n",
    "    #print(\"h\",h)\n",
    "    out, h = model(inp.to(device).float(), h)\n",
    "    #outputs.append(label_scalers[i].inverse_transform(out.cpu().detach().numpy()).reshape(-1))\n",
    "    #targets.append(label_scalers[i].inverse_transform(labs.numpy()).reshape(-1))\n",
    "    outputs.append( out.cpu().detach().numpy().reshape(-1) )\n",
    "    targets.append( labs.numpy().reshape(-1) )\n",
    "\n",
    "    #print(\"Evaluation Time: {}\".format(str(time.clock()-start_time)))\n",
    "    sMAPE = 0\n",
    "    #for i in range(len(outputs)):\n",
    "    #    sMAPE += np.mean(abs(outputs[i]-targets[i])/(targets[i]+outputs[i])/2)/len(outputs)\n",
    "    #print(\"sMAPE: {}%\".format(sMAPE*100))\n",
    "    return outputs, targets#, sMAPE       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluatedataset(model,dataset,cutofflist=[0.2,0.3,0.4,0.5,0.6,0.7,0.75,0.8,0.9,1.0]):\n",
    "    headers=[]\n",
    "    counter_truepositive=[0] * len(cutofflist)\n",
    "    counter_falsenegative=[0] * len(cutofflist)\n",
    "    counter_truenegative=[0] * len(cutofflist)\n",
    "    counter_falsepositive=[0] * len(cutofflist)\n",
    "    \n",
    "    for i in range(30):  \n",
    "        label=str(i)\n",
    "        headers.append(\"header\"+label)\n",
    "\n",
    "    choppedheaders=[]\n",
    "    GRUoutputlist=[]\n",
    "    lookback=10 #save only the last 11 timesteps\n",
    "    for i in range(10):  \n",
    "        label=str(i)\n",
    "        choppedheaders.append(\"header\"+label)\n",
    "    #print(\"headers\",headers)    #header0 to header29\n",
    "    #print(\"choppedheaders\",choppedheaders)\n",
    "    for i in range(0,int((dataset.shape[0])-1),6):\n",
    "    #for i in range(0,12,6):    \n",
    "        #print(\"\")\n",
    "       \n",
    "        for h in range(10,len(headers)+1):\n",
    "            successflag=False\n",
    "            #print(headers[h-10:h])\n",
    "            if dataset[headers[h-1]].iloc[i+5]==0 or dataset[headers[h-1]].iloc[i+5]==1: #if label is 0 or 1  (ignores n/a values)\n",
    "\n",
    "                classifytest=dataset[headers[h-10:h]].iloc[i:i+5].to_numpy()\n",
    "                \n",
    "                labelstest=dataset[headers[h-1]].iloc[i+5]\n",
    "                \"\"\"\n",
    "                try:\n",
    "                    labelstest=dataset[headers[h-1]].iloc[i+5]\n",
    "                except IndexError:\n",
    "                    print(\"IndexError. headers[h-1]:\",headers[h-1],\"i+5:\",i+5, \"h=\",h, \"i=\",i)\n",
    "                    print(\"classifytest\",classifytest)\n",
    "                    print(\"labelstest\",labelstest)\n",
    "                \"\"\"  \n",
    "                    \n",
    "                #print(classifytest)\n",
    "                #print(labelstest)\n",
    "               \n",
    "                #print(classifytest)\n",
    "                classifytest=np.expand_dims(classifytest, axis=0)\n",
    "                #print(classifytest.shape)\n",
    "                #print(labelstest)\n",
    "\n",
    "                outputfull=evaluate2(gru_model3, classifytest,labelstest)\n",
    "                GRUoutputlist.append(outputfull[0][0])\n",
    "                #print(\"GRU output\",float(outputfull[0]))\n",
    "                #print(\"GRU output\",outputfull[0][0])\n",
    "\n",
    "                cutoff=0.5\n",
    "                for k in range(len(cutofflist)):\n",
    "                    if labelstest==1  and outputfull[0][0]>= cutofflist[k]:\n",
    "                        counter_truepositive[k]+=1\n",
    "                    elif labelstest==1  and outputfull[0][0]< cutofflist[k]:\n",
    "                        counter_falsenegative[k]+=1\n",
    "                    elif labelstest==0 and outputfull[0][0]<= cutofflist[k]:\n",
    "                        counter_truenegative[k]+=1\n",
    "                    elif labelstest==0 and outputfull[0][0]> cutofflist[k]:\n",
    "                        counter_falsepositive[k]+=1\n",
    "       \n",
    "    for k in range(len(cutofflist)):\n",
    "        totalevalqty=counter_truepositive[k]+counter_falsenegative[k]+counter_truenegative[k]+counter_falsepositive[k]\n",
    "        print(\"At cuttoff of\",cutofflist[k],\" truepositive\",counter_truepositive[k],\"truenegative\",counter_truenegative[k],\"falsepositive\",counter_falsepositive[k],\"falsenegative\",counter_falsenegative[k],\n",
    "             \"Accuracy\",100*(counter_truepositive[k]+counter_truenegative[k])/totalevalqty,\"%\")\n",
    "   \n",
    "    GRUoutputlist.sort()\n",
    "    plt.plot(GRUoutputlist)\n",
    "    plt.show()\n",
    "         \n",
    "\n",
    "def evaluatedatasetlookahead(model,dataset,cutofflist=[0.2,0.3,0.4,0.5,0.6,0.7,0.75,0.8,0.9,1.0]):\n",
    "    headers=[]\n",
    "    counter_truepositive=[0] * len(cutofflist)\n",
    "    counter_falsenegative=[0] * len(cutofflist)\n",
    "    counter_truenegative=[0] * len(cutofflist)\n",
    "    counter_falsepositive=[0] * len(cutofflist)\n",
    "    \n",
    "    for i in range(30):  \n",
    "        label=str(i)\n",
    "        headers.append(\"header\"+label)\n",
    "\n",
    "    choppedheaders=[]\n",
    "    GRUoutputlist=[]\n",
    "    lookback=10 #save only the last 11 timesteps\n",
    "    for i in range(10):  \n",
    "        label=str(i)\n",
    "        choppedheaders.append(\"header\"+label)\n",
    "    #print(\"headers\",headers)    #header0 to header29\n",
    "    #print(\"choppedheaders\",choppedheaders)\n",
    "    for i in range(0,int((dataset.shape[0])-1),6):\n",
    "    #for i in range(0,12,6):    \n",
    "        #print(\"\")\n",
    "       \n",
    "        for h in range(10,len(headers)+1):\n",
    "            successflag=False\n",
    "            #print(headers[h-10:h])\n",
    "            if dataset[headers[h-1]].iloc[i+5]==0 or dataset[headers[h-1]].iloc[i+5]==1: #if label is 0 or 1  (ignores n/a values)\n",
    "\n",
    "                classifytest=dataset[headers[h-10:h-1]].iloc[i:i+5].to_numpy()\n",
    "                labelstest=dataset[headers[h-1]].iloc[i+5]\n",
    "                #print(classifytest)\n",
    "                #print(labelstest)\n",
    "               \n",
    "                #print(classifytest)\n",
    "                classifytest=np.expand_dims(classifytest, axis=0)\n",
    "                #print(classifytest.shape)\n",
    "                #print(labelstest)\n",
    "\n",
    "                outputfull=evaluate2(gru_model3, classifytest,labelstest)\n",
    "                GRUoutputlist.append(outputfull[0][0])\n",
    "                #print(\"GRU output\",float(outputfull[0]))\n",
    "                #print(\"GRU output\",outputfull[0][0])\n",
    "\n",
    "               \n",
    "                for k in range(len(cutofflist)):\n",
    "                    if labelstest==1  and outputfull[0][0]>= cutofflist[k]:\n",
    "                        counter_truepositive[k]+=1\n",
    "                    elif labelstest==1  and outputfull[0][0]< cutofflist[k]:\n",
    "                        counter_falsenegative[k]+=1\n",
    "                    elif labelstest==0 and outputfull[0][0]<= cutofflist[k]:\n",
    "                        counter_truenegative[k]+=1\n",
    "                    elif labelstest==0 and outputfull[0][0]> cutofflist[k]:\n",
    "                        counter_falsepositive[k]+=1\n",
    "       \n",
    "    for k in range(len(cutofflist)):\n",
    "        totalevalqty=counter_truepositive[k]+counter_falsenegative[k]+counter_truenegative[k]+counter_falsepositive[k]\n",
    "        print(\"At cuttoff of\",cutofflist[k],\" truepositive\",counter_truepositive[k],\"truenegative\",counter_truenegative[k],\"falsepositive\",counter_falsepositive[k],\"falsenegative\",counter_falsenegative[k],\n",
    "             \"Accuracy\",100*(counter_truepositive[k]+counter_truenegative[k])/totalevalqty,\"%\")\n",
    "   \n",
    "\n",
    "    #GRUoutputlist.sort()\n",
    "    #GRUoutputlist.sort()\n",
    "    plt.plot(sorted(GRUoutputlist))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n",
      "loaded\n",
      "loaded\n",
      "loaded\n",
      "loaded\n"
     ]
    }
   ],
   "source": [
    "gru_model1=torch.load('currentmodel_3datasets_1steplookhead_model1_10_24_2021.pt',map_location=torch.device('cpu'))\n",
    "gru_model1.eval()\n",
    "print(\"loaded\")\n",
    "gru_model2=torch.load('currentmodel_3datasets_1steplookhead_model2_10_24_2021.pt',map_location=torch.device('cpu'))\n",
    "gru_model2.eval()\n",
    "print(\"loaded\")\n",
    "gru_model3=torch.load('currentmodel_3datasets_1steplookhead_model3_10_24_2021.pt',map_location=torch.device('cpu'))\n",
    "gru_model3.eval()\n",
    "print(\"loaded\")\n",
    "gru_model4=torch.load('currentmodel_3datasets_1steplookhead_model4_10_24_2021.pt',map_location=torch.device('cpu'))\n",
    "gru_model4.eval()\n",
    "print(\"loaded\")\n",
    "gru_model_old=torch.load('currentmodel_9steplookhead10_23_2021.pt',map_location=torch.device('cpu'))\n",
    "gru_model_old.eval()\n",
    "print(\"loaded\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test sets-model1\n",
      "At cuttoff of 0.2  truepositive 25 truenegative 7578 falsepositive 2218 falsenegative 1 Accuracy 77.40785990633272 %\n",
      "At cuttoff of 0.3  truepositive 24 truenegative 8190 falsepositive 1606 falsenegative 2 Accuracy 83.62858888210141 %\n",
      "At cuttoff of 0.4  truepositive 24 truenegative 8611 falsepositive 1185 falsenegative 2 Accuracy 87.91488495214824 %\n",
      "At cuttoff of 0.5  truepositive 21 truenegative 8940 falsepositive 856 falsenegative 5 Accuracy 91.23396456933415 %\n",
      "At cuttoff of 0.6  truepositive 20 truenegative 9181 falsepositive 615 falsenegative 6 Accuracy 93.67745876603543 %\n",
      "At cuttoff of 0.7  truepositive 19 truenegative 9393 falsepositive 403 falsenegative 7 Accuracy 95.82569741396864 %\n",
      "At cuttoff of 0.75  truepositive 17 truenegative 9486 falsepositive 310 falsenegative 9 Accuracy 96.7521889635512 %\n",
      "At cuttoff of 0.8  truepositive 16 truenegative 9551 falsepositive 245 falsenegative 10 Accuracy 97.40378741600489 %\n",
      "At cuttoff of 0.9  truepositive 14 truenegative 9652 falsepositive 144 falsenegative 12 Accuracy 98.41172877214417 %\n",
      "At cuttoff of 1.0  truepositive 5 truenegative 9738 falsepositive 58 falsenegative 21 Accuracy 99.1956831602525 %\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD4CAYAAAD2FnFTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAj30lEQVR4nO3deXwc9X3/8dfHuu/TluXbxgaMMRgQxgTCaY7QFNOGw4EGEyDk0YakTfprC83vl4P01wehbUj4lTS4QAJJuAnEoQlgjpxgsIyNL3wI28KSbUnWad3X5/fHjswiJFu21tqV9v18PPahme/M7H5mx573znxnd8zdERER6W9ctAsQEZHYpIAQEZEBKSBERGRACggRERmQAkJERAaUGO0CjkZhYaHPmDEj2mWIiIwqa9as2e/u44c6/6gMiBkzZlBaWhrtMkRERhUzKz+S+XWKSUREBqSAEBGRASkgRERkQAoIEREZkAJCREQGFJGAMLOHzazazDYOMv0GM1tvZhvM7A0zOzVs2q6gfZ2Z6dIkEZEYEakjiJ8Alx9i+k7gfHefD3wHWN5v+oXuvsDdSyJUj4iIDFNEAsLdfw/UHWL6G+5eH4yuAqZE4nVFROLFln1NfO/lrexv7hix14xGH8QtwG/Cxh142czWmNltgy1kZreZWamZldbU1BzzIkVEYsnWfQe477UyGtu6Ruw1R/Sb1GZ2IaGAODes+Vx3rzSzCcBKM9sSHJF8hLsvJzg1VVJSorsciUhc6ezuBSA5YeQ+14/YK5nZKcCDwBJ3r+1rd/fK4G818BywcKRqEhEZLbp7Q5+LExNsxF5zRALCzKYBvwA+5+7bwtozzCyrbxi4FBjwSigRkXjW3RM6gkgcN3JHEBE5xWRmjwMXAIVmVgF8E0gCcPcfAd8ACoAfmhlAd3DFUhHwXNCWCDzm7i9GoiYRkbGksyd0BJE0gkcQEQkId//sYabfCtw6QPsO4NSPLyEiIuHaOrsBSEtOGLHX1DepRURGgZbOHpISjJREBYSIiIRp6egmI2Vkb+GjgBARGQWaO7rJSFZAiIhIPy0d3WTqCEJERPpr6eghI2Xk+h9AASEiMio0qw9CREQGUtXUrj4IERH5uOaObnp9ZH+GTgEhIhLj3J3Wzh6Om5A5oq+rgBARiXHNHd309Dr56ckj+roKCBGRGNfQGroHRE560oi+rgJCRCTG1bZ0AlCYqSMIEREJU3MgdJvR8ZmpI/q6CggRkRh3MCCyUkb0dRUQIiIxri8gCnSKSUREwtU0t5OXnkTSCN6PGhQQIiIxr+ZAx4ifXgIFhIhIzBvVAWFmD5tZtZltHGS6mdl9ZlZmZuvN7PSwacvMbHvwWBaJekRExpKa5g7GZ47SgAB+Alx+iOmfAuYEj9uA/wIws3zgm8BZwELgm2aWF6GaRERGva6eXvY2tFOUPbKXuEKEAsLdfw/UHWKWJcCjHrIKyDWzYuAyYKW717l7PbCSQweNiEhcWbWjlu5eZ/6UnBF/7ZHqg5gM7A4brwjaBmv/GDO7zcxKzay0pqbmmBUqIhJL3ilvwAzOP378iL/2qOmkdvfl7l7i7iXjx4/8GyUiEg2b9jQyszCDrNSR/R0mGLmAqASmho1PCdoGaxcRiXu9vU5peT0LpuRG5fVHKiBWADcGVzMtAhrdfS/wEnCpmeUFndOXBm0iInFv054m6lo6OS8Kp5cAInL/OjN7HLgAKDSzCkJXJiUBuPuPgF8DVwBlQCvw+WBanZl9B1gdPNVd7n6ozm4RkbixcvM+zOCc2YVRef2IBIS7f/Yw0x340iDTHgYejkQdIiJjydNrKjhvzviofEkORlEntYhIPKluamdvY3tUrl7qo4AQEYlBGyobATixOCtqNSggRERi0JOrd5OfkcyCqblRq0EBISISY5rau3jlvSquOWMK6ckR6So+KgoIEZEYs2ZXPb1O1C5v7aOAEBGJMX/Yvp/kxHGcMT26v12qgBARiTF/LKth4Yx8UpMSolqHAkJEJIbUHOhgW1Vz1L4cF04BISISQ9aUh35MYuHM/ChXooAQEYkppbvqSUkcx/zJI3//h/4UECIiMeS322o4dUouyYnR3z1HvwIREQFgd10rZdXNXDx3QrRLARQQIiIx4ydv7CIpwfj0qZOiXQqggBARiQm9vc5vNuzl/OPHMzk3LdrlAAoIEZGYsGpHLXsa2/nzGDl6AAWEiEhMeHpNBVmpiVw2b2K0SzlIASEiEmV7Gtp4Yf0e/uK0yVH/9nS4iASEmV1uZlvNrMzM7hhg+r1mti54bDOzhrBpPWHTVkSiHhGR0eRnq8rp6nFuPmdmtEv5iGH/jqyZJQD3A5cAFcBqM1vh7pv75nH3r4bN/2XgtLCnaHP3BcOtQ0RkNGrv6uGxtz/g4hMnMKMwI9rlfEQkjiAWAmXuvsPdO4EngCWHmP+zwOMReF0RkVFvfUUjDa1dXFMyNdqlfEwkAmIysDtsvCJo+xgzmw7MBF4La041s1IzW2VmVw32ImZ2WzBfaU1NTQTKFhGJvsff/oDkhHF8YnZBtEv5mJHupF4KPOPuPWFt0929BLge+L6ZHTfQgu6+3N1L3L1k/Pjo3kRDRCQSyqqbeW5tJTefO5Ps1KRol/MxkQiISiD82GhK0DaQpfQ7veTulcHfHcBv+Wj/hIjImHX/62UkJRi3nBtbndN9IhEQq4E5ZjbTzJIJhcDHrkYysxOBPODNsLY8M0sJhguBc4DN/ZcVERlr3vmgnufWVrLs7BmMz0qJdjkDGvZVTO7ebWa3Ay8BCcDD7r7JzO4CSt29LyyWAk+4u4ctPhd4wMx6CYXV3eFXP4mIjEU9vc63VmyiMDOFv108J9rlDGrYAQHg7r8Gft2v7Rv9xr81wHJvAPMjUYOIyGjxs1XlrK9o5AdLF5AVg30PffRNahGREdTR3cO/v7yVc2cXcmUM/e7SQBQQIiIj6MWN+zjQ3s2tn5yJmUW7nENSQIiIjKBH3tjFzMIMzpsT+5frKyBEREbIS5v28c4HDdz0iRmMGxfbRw+ggBARGRGrd9Xx5cfWMm9SNksXxt7PagxEASEicoxVNbXzhUdLmZiTyk9vOYuUxNj5Se9DichlriIiMrj//fxG2rt6ePqLZ5OfkRztcoZMRxAiIsfQ77bVsHJzFV+6YDZzirKiXc4RUUCIiBwju+ta+crjazmhKIsvnDcr2uUcMQWEiMgx8s/PbaCn11l+4xkxdSvRoVJAiIgcA7/bVsMftu/nKxfPZnpBbN0pbqgUECIiEdbY2sU/PvMus8ZncOPZM6JdzlFTQIiIRNi9r2yj5kAH9y09bVSeWuqjgBARiaA336/l52+Vc+Wpkzh5ck60yxkWBYSISIQ0tXfxlSfWMjUvnW9feXK0yxk2fVFORCQCunp6uePZ9dQ2d/DwsjPJSY/d+zwMlQJCRGSYunt6+dLP3+HlzVX88xUnMn/K6D611EcBISIyTPe9VsbLm6v4xqdP4uZzZ0a7nIiJSB+EmV1uZlvNrMzM7hhg+k1mVmNm64LHrWHTlpnZ9uCxLBL1iIiMlC37mvjh62VctWDSmAoHiMARhJklAPcDlwAVwGozW+Hum/vN+qS7395v2Xzgm0AJ4MCaYNn64dYlInKstXf18PdPvUtmaiLf/PN50S4n4iJxBLEQKHP3He7eCTwBLBnispcBK929LgiFlcDlEahJROSYe+B3O9i0p4nvLDmZvFH0K61DFYmAmAzsDhuvCNr6+4yZrTezZ8ys724ZQ10WM7vNzErNrLSmpiYCZYuIHL3Xt1Rz7yvbuGL+RD59SnG0yzkmRup7EL8CZrj7KYSOEh450idw9+XuXuLuJePHx/69XEVk7Nrb2MbXnlrH3OJsvnftAsxi//ahRyMSAVEJhN8/b0rQdpC717p7RzD6IHDGUJcVEYklbZ09fP7Hq+no7uX+60f3T2kcTiQCYjUwx8xmmlkysBRYET6DmYUff10JvBcMvwRcamZ5ZpYHXBq0iYjEnN5e545frGfLvgN8/7oFzBqfGe2SjqlhX8Xk7t1mdjuhHXsC8LC7bzKzu4BSd18BfMXMrgS6gTrgpmDZOjP7DqGQAbjL3euGW5OIyLFw7yvb+OW6PfzDZSdw6byJ0S7nmDN3j3YNR6ykpMRLS0ujXYaIxIneXue+17bz/Ve2c80ZU7jn6lNGZb+Dma1x95Khzq9vUouIHEJHdw//5/mNPFVawZ/NL+Zf/3L+qAyHo6GAEBEZRF1LJ19+/B3+VFbLVy6azVcvOT5uwgEUECIiA6pr6eSaH73BrtpW7rn6FK4tmXr4hcYYBYSISD/bqw7wt0+sY3d9Gw8tK+GCEyZEu6SoUECIiIR5d3cDN/34bcyM/7rh9LgNB1BAiIgctLuulS/+dA0J44xn//oTTC/IiHZJUaVbjoqIEAqHpctX0drZzY9vWhj34QA6ghARYdOeRm75SSltXT089oVFnDx5bNwRbrh0BCEice3J1R/wlz98A4AnblM4hNMRhIjEpd5e519//R4P/nEn584u5N7rFjA+KyXaZcUUBYSIxJ3qA+3c+ewGXt1SzecWTed/f3ouKYlj91dZj5YCQkTihrvzq/V7ufPZ9XT29PLtK+dx49nT4+rb0UdCASEicaGzu5evP7eBp9dUcMqUHP7jmlOZU5QV7bJimgJCRMa8ivpW/v6pd3lrZx1fvmg2f7f4eBLG6ajhcBQQIjJm9fY6D/1xJ99buQ3Hueczp3DtmfH3m0pHSwEhImNSWXUzf//0u7y7u4HFcyfwrSvnMSUvPdpljSoKCBEZc954fz+3P7YWd+eeq0/hmjOmqCP6KEQkIMzscuAHhG45+qC7391v+teAWwndcrQGuNndy4NpPcCGYNYP3P3KSNQkIvFnTXk9D/9xJ/+zYS/T8tP57xtLOGGiOqKP1rADwswSgPuBS4AKYLWZrXD3zWGzrQVK3L3VzP4auAe4LpjW5u4LhluHiMSvrp5e7v7NFh76406yUhL50oXHcfuFc0hL1ncbhiMSRxALgTJ33wFgZk8AS4CDAeHur4fNvwr4qwi8rojEOXfnxY37+I+V2yirbua6kql888qTSE/W2fNIiMS7OBnYHTZeAZx1iPlvAX4TNp5qZqWETj/d7e7PD7SQmd0G3AYwbdq04dQrIqNcb6/z8uZ9/PcfdrKmvJ5Z4zN48MYSFp9UFO3SxpQRjVkz+yugBDg/rHm6u1ea2SzgNTPb4O7v91/W3ZcDywFKSkp8RAoWkZjS1dPL82sreeD3OyirbqY4J5W7/3I+15RM1fcajoFIBEQlEH5h8ZSg7SPMbDHwdeB8d+/oa3f3yuDvDjP7LXAa8LGAEJH4tmpHLf/07HrKa1s5cWIW/++zp3HF/GIFwzEUiYBYDcwxs5mEgmEpcH34DGZ2GvAAcLm7V4e15wGt7t5hZoXAOYQ6sEVEcHfWlNez/Pc7eHlz1cErkxbPnaDLVkfAsAPC3bvN7HbgJUKXuT7s7pvM7C6g1N1XAP8GZAJPBxu173LWucADZtZL6N4Ud/e7+klE4lB7Vw8r1u3h529/wLu7G8hNT+IrF83mi+cfR0aKOqBHirmPvtP5JSUlXlpaGu0yRCTC2rt6eG5tJT/63fuU17Yye0ImN549nc+cPkXBEAFmtsbdS4Y6v95xEYmq9q4e3t3dwK/W72HFuj00tXdz8uRsHlpWwkUn6lRSNCkgRGTEdXb38rttNTy3toJX3qums7uXlMRxfOrkiVx75lTOnlWgYIgBCggRGRHuzjsf1PPC+r08v7aS+tYuCjKSuX7hND5xXAGLjisgOzUp2mVKGAWEiBxTLR3dPLe2kkff3MW2qmaSEozL5k3kM6dP4dw5hSQljIt2iTIIBYSIRFxlQxt/2r6fP5Tt57X3qmjp7GFucTb3XH0Ki+cWkZ+RHO0SZQgUECISEe/tbeKF9Xt4ceM+3q9pAWB8VgpXzC/mujOncsb0PPUrjDIKCBE5Kh3dPayvaOTN92t5fl0lO2paGGdw9nEFXH/WdD45p5A5EzIVCqOYAkJEhsTd2Vp1gNe2VPP7bTWs/aCBju5eAM6Ynsd3rprJFSdPpCAzJcqVSqQoIERkUJUNbby2pZrVO+t454N6KurbADipOJsbzprOwpn5LJqVT266+hTGIgWEiBxU1dTOys1VvFNez9u76g4GwsTsVOZPyeFvLpjNxXMnUJSdGuVKZSQoIETikLtT2dDGxspGtuw7wKY9Tby3t+lgIBRmpnDmjDxuPmcmn5xTyGz1JcQlBYTIGOfuVDV18N6+UAhs2XuA9RUN7KptBcAMZhRkcNq0PD63aDoXnjhBncsCKCBExpTunl527m9h054mNu358OigrqXz4DyTc9OYW5zNTZ+YwalTczlxYrbu3SwDUkCIjELuTm1LJ2XVzWzdd4At+w6wJThCaO8KXVmUnDiO44syWTx3AvMm5TC3OJsTJmaRk6afs5ChUUCIxKj2rh72NLSxp6GdyoZWPqhrpby2lV21LZTvb+VAR/fBeXPSkjhhYhY3nDWdeZOymVuczewJmfoZCxkWBYRIFPT0OtUH2g8GwL7GdvY1hcYrG9rY09DG/ubOjyyTMM6YkpfG9IIMzpiWx/SCDI6bkMkJRVkUZaeoz0AiTgEhEkHuTlN7N7XNHexraqfmQAdVTe3sa+xgX1MbexvbqWpsp/pAB929H71ZV3pyApNy05iUm8a8SdlMDoYn5aYxOTeNiTmpOiKQEaWAEDmErp5e6ls6qWvtpK65k9qWTupbO6lt7qQurL2+NZjW0vmxHT9AWlICxbmpFOeksui4AiZmpx7c8U/KTWNidirZaYk6CpCYEpGAMLPLgR8Quif1g+5+d7/pKcCjwBlALXCdu+8Kpt0J3AL0AF9x95ciUZNIf+5OS2cP9S2hnXldSwd1LV39/nYefNS2dHKgvXvQ58tJS6IgI5n8jGSm5qezYGoueRnJB9smZqcyITuVCdkpus+BjErDDggzSwDuBy4BKoDVZrbC3TeHzXYLUO/us81sKfBd4DozOwlYCswDJgGvmNnx7t4z3Lpk7OvpdRpaP9yZ1/f7Wxf2ab/vE35n8NtB/SUlGPkZyeRnpFCQkczkvHQKMpLJS08mPzOZ/PTQTr8gM9SWl55Eok73yBgXiSOIhUCZu+8AMLMngCVAeEAsAb4VDD8D/KeFjqWXAE+4ewew08zKgud7MwJ1ySjS1dNLY1sXDa1dNLZ10tAaGq5v/XBHH/7pvq6lk4a2LvzjZ3MAyEpNDHb4yRTnpDJvUvZHdvR9j4KMFPIykshM0ekdkf4iERCTgd1h4xXAWYPN4+7dZtYIFATtq/otO3mgFzGz24DbAKZNmxaBsuVY6O11GttCO/b61k7qW7qoa+2ksbWLhr4df1vXwfH6li4a27po7hj8VE7iOCMv48Od+4kTs8nPSP7I6ZzwR156MsmJ+nQvMlyjppPa3ZcDywFKSkoG+dwokdR3zn7/gQ72N4ceNc2d1BzooKG1k6a2Lprau2lo7Tz4af9Qn+oTxxm56UlkpyWRm5bEhKxUjp+QRU56ErlpyeSmJ5GbnkROWhK56cnkpiWRn5lMlj7di0RFJAKiEpgaNj4laBtongozSwRyCHVWD2VZibC+b+H2XYNfcyB0OWZNc+eHQRCEQt+3csOZhTpoc9KSyE5NIjstkeLcNPLSk8hPTyY3+KSfm5508BN9TnqSdvQio0wkAmI1MMfMZhLauS8Fru83zwpgGaG+hauB19zdzWwF8JiZfY9QJ/Uc4O0I1BTX2rt62Nv40S9d9YVBX1tHv85aMyjISKYwM4XxWSnMKMigMDM03tdWmJlCYVboVI86aEXGvmEHRNCncDvwEqHLXB92901mdhdQ6u4rgIeAnwad0HWEQoRgvqcIdWh3A1/SFUyH1vdFrL2NbextaGdPYxu769rYXd9KRX0blfVt7G/u+NhyE7JSmJSbxtxJ2Sw+qYhJOakHv4Q1ITuFgowUEsbp072IfMh8sBPGMaykpMRLS0ujXcYx19TexfaqA2yrCv0g2/bqA2zd1/yxAEhKMCbnpjE1P/3gF6/C/xblpJCSqF/rFIl3ZrbG3UuGOv+o6aQey9ydXbWtbNrTyPqK0E80b686wN7G9oPzpCcnMGdCJhecMJ7jizKZlJtGcU4qxTlpFGWn6tO/iEScAiIKenud7dXNvL2zllU763invP5gGCQnjmPOhEzOmpnP8ROzOKEoi+OLspicm8Y4hYCIjCAFxAhwd96vaeZPZbX8YXsNa8rrqW/tAkL3+i2ZkceiWQUsmJrL8UVZuoZfRGKCAuIYKq9t4Werynl5cxXlwe0dZxSkc/HcIs6amc9ZMwuYmp+mSz9FJCYpICKssbWLFzftZcW7e3jz/VoSxhnnzC7kC5+cxXlzxjOtID3aJYqIDIkCIkJ217Vy92+2sHJzFZ09vcwoSOf2C2dzw6LpFGWnRrs8EZEjpoAYpi37mnj4jzt5Yf1eDLhh0TT+4rTJzJ+co1NHIjKqKSCO0u66Vu57dTtPr6kgLSmBPz+1mL+5YDYzCjOiXZqISEQoII6Qu/Pom+V898UtdPc4t5w7ky9fNJvc9ORolyYiElEKiCPwQW0rdz63nj+V1XLO7AL+5ar5zNQRg4iMUQqIIXB3Vry7hzue3cA4g7uWzOOGs6br28siMqYpIA7jnQ/q+favNvPu7gZOmZLDA587g+KctGiXJSJyzCkgBtHT6zz2Vjl3vbCZ/Ixk/vUv5nNtyRT9zLWIxA0FxACqmtr58uNreXtnHefOLuQ/rz9NndAiEncUEP28sD7U19Drzr9dfQpXnzFF32cQkbikgAjz+pZqvvrkOk6alMO9157KrPGZ0S5JRCRqFBCBN8r288WfreGEiVk8evNCctKSol2SiEhUqccV2NvYxlefWsfE7FR+evNZCgcREYYZEGaWb2YrzWx78DdvgHkWmNmbZrbJzNab2XVh035iZjvNbF3wWDCceo6Gu/ONX26ivqWLH95wOnkZ6owWEYHhH0HcAbzq7nOAV4Px/lqBG919HnA58H0zyw2b/g/uviB4rBtmPUdsTXk9KzdX8cXzZ3Hy5JyRfnkRkZg13IBYAjwSDD8CXNV/Bnff5u7bg+E9QDUwfpivGzH//YcdZKUk8oXzZkW7FBGRmDLcgChy973B8D6g6FAzm9lCIBl4P6z5/wannu41s5RDLHubmZWaWWlNTc0wyw7Ztb+FlzZVsewTM8hOVb+DiEi4wwaEmb1iZhsHeCwJn8/dHfBDPE8x8FPg8+7eGzTfCZwInAnkA/802PLuvtzdS9y9ZPz4yByAPLF6NwnjjBsWTYvI84mIjCWHvczV3RcPNs3Mqsys2N33BgFQPch82cD/AF9391Vhz9139NFhZj8G/tcRVT8M3T29PPtOBReeMF6/rSQiMoDhnmJaASwLhpcBv+w/g5klA88Bj7r7M/2mFQd/jVD/xcZh1jNkL27aR82BDpaeqaMHEZGBDDcg7gYuMbPtwOJgHDMrMbMHg3muBc4Dbhrgctafm9kGYANQCPzLMOsZsidX72ZqfhoXnjhhpF5SRGRUGdY3qd29Frh4gPZS4NZg+GfAzwZZ/qLhvP7R6u11NlQ28qmTJ+qeDiIig4jLb1K/uqWahtYuFs0qiHYpIiIxKy4D4qVN+8hITuDP5hdHuxQRkZgVlwGxbncDp0/P081/REQOIe72kG2dPbxf08yCqbnRLkVEJKbFXUCU17XgDnOKsqJdiohITIu7gNi1vxWAmQUZUa5ERCS2xV1AlNe2ADCtID3KlYiIxLa4C4hdta3kZyTrpkAiIocRdwFRXtvCDB09iIgcVtwFRFl1MzMLM6NdhohIzIurgHB36lo6Kcoe9LYTIiISiKuAaOnsobvXyU1X/4OIyOHEVUDUt3QCkJuWHOVKRERiX1wFRGtnDwAZKcP6EVsRkbgQVwHR2R2602lyYlyttojIUYmrPWVHd+gIIkUBISJyWHG1p9QRhIjI0A1rT2lm+Wa20sy2B3/zBpmvJ+x2oyvC2mea2VtmVmZmTwb3rz5mOoKA0BGEiMjhDXdPeQfwqrvPAV4NxgfS5u4LgseVYe3fBe5199lAPXDLMOs5pA4dQYiIDNlw95RLgEeC4UeAq4a6oJkZcBHwzNEsfzQ+7INIOJYvIyIyJgw3IIrcfW8wvA8oGmS+VDMrNbNVZnZV0FYANLh7dzBeAUwe7IXM7LbgOUpramqOqthOnWISERmyw34hwMxeASYOMOnr4SPu7mbmgzzNdHevNLNZwGtmtgFoPJJC3X05sBygpKRksNc5JPVBiIgM3WEDwt0XDzbNzKrMrNjd95pZMVA9yHNUBn93mNlvgdOAZ4FcM0sMjiKmAJVHsQ5D9uERhE4xiYgcznA/Sq8AlgXDy4Bf9p/BzPLMLCUYLgTOATa7uwOvA1cfavlIUie1iMjQDXdPeTdwiZltBxYH45hZiZk9GMwzFyg1s3cJBcLd7r45mPZPwNfMrIxQn8RDw6znkPQ9CBGRoRvWjxK5ey1w8QDtpcCtwfAbwPxBlt8BLBxODUeis6eHxHFGwjgbqZcUERm14uqjdEdXrzqoRUSGKK72lp09vTq9JCIyRHG1twwdQegKJhGRoYirgNARhIjI0MXV3rKju0d9ECIiQxRXe8vObh1BiIgMVVzde/O0aXnM6eg+/IwiIhJfAfGlC2dHuwQRkVFD51tERGRACggRERmQAkJERAakgBARkQEpIEREZEAKCBERGZACQkREBqSAEBGRAVnozp+ji5nVAOVHuXghsD+C5YwWWu/4ovWOL0Nd7+nuPn6oTzoqA2I4zKzU3UuiXcdI03rHF613fDlW661TTCIiMiAFhIiIDCgeA2J5tAuIEq13fNF6x5djst5x1wchIiJDE49HECIiMgQKCBERGVBcBYSZXW5mW82szMzuiHY9w2FmU83sdTPbbGabzOxvg/Z8M1tpZtuDv3lBu5nZfcG6rzez08Oea1kw/3YzWxatdToSZpZgZmvN7IVgfKaZvRWs35Nmlhy0pwTjZcH0GWHPcWfQvtXMLovSqgyZmeWa2TNmtsXM3jOzs+Nhe5vZV4N/4xvN7HEzSx2L29vMHjazajPbGNYWse1rZmeY2YZgmfvMzA5blLvHxQNIAN4HZgHJwLvASdGuaxjrUwycHgxnAduAk4B7gDuC9juA7wbDVwC/AQxYBLwVtOcDO4K/ecFwXrTXbwjr/zXgMeCFYPwpYGkw/CPgr4PhvwF+FAwvBZ4Mhk8K/g2kADODfxsJ0V6vw6zzI8CtwXAykDvWtzcwGdgJpIVt55vG4vYGzgNOBzaGtUVs+wJvB/NasOynDltTtN+UEXzzzwZeChu/E7gz2nVFcP1+CVwCbAWKg7ZiYGsw/ADw2bD5twbTPws8ENb+kfli8QFMAV4FLgJeCP7B7wcS+29r4CXg7GA4MZjP+m//8Pli8QHkBDtK69c+prd3EBC7gx1eYrC9Lxur2xuY0S8gIrJ9g2lbwto/Mt9gj3g6xdT3D61PRdA26gWH0acBbwFF7r43mLQPKAqGB1v/0fi+fB/4R6A3GC8AGty9OxgPX4eD6xdMbwzmH23rPROoAX4cnFp70MwyGOPb290rgX8HPgD2Etp+axj727tPpLbv5GC4f/shxVNAjElmlgk8C/yduzeFT/PQR4UxdR2zmX0aqHb3NdGuZYQlEjr98F/ufhrQQuiUw0FjdHvnAUsIBeQkIAO4PKpFRUk0tm88BUQlMDVsfErQNmqZWRKhcPi5u/8iaK4ys+JgejFQHbQPtv6j7X05B7jSzHYBTxA6zfQDINfMEoN5wtfh4PoF03OAWkbfelcAFe7+VjD+DKHAGOvbezGw091r3L0L+AWhfwNjfXv3idT2rQyG+7cfUjwFxGpgTnD1QzKhDqwVUa7pqAVXIDwEvOfu3wubtALou3JhGaG+ib72G4OrHxYBjcGh60vApWaWF3xauzRoi0nufqe7T3H3GYS24WvufgPwOnB1MFv/9e57P64O5vegfWlw1ctMYA6hTryY5O77gN1mdkLQdDGwmTG+vQmdWlpkZunBv/m+9R7T2ztMRLZvMK3JzBYF7+ONYc81uGh3yoxwB9AVhK72eR/4erTrGea6nEvocHM9sC54XEHofOurwHbgFSA/mN+A+4N13wCUhD3XzUBZ8Ph8tNftCN6DC/jwKqZZhP7DlwFPAylBe2owXhZMnxW2/NeD92MrQ7iiI9oPYAFQGmzz5wldpTLmtzfwbWALsBH4KaErkcbc9gYeJ9TP0kXoiPGWSG5foCR4D98H/pN+FzwM9NBPbYiIyIDi6RSTiIgcAQWEiIgMSAEhIiIDUkCIiMiAFBAiIjIgBYSIiAxIASEiIgP6/wDF/fYvhKO4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At cuttoff of 0.2  truepositive 45 truenegative 7659 falsepositive 2614 falsenegative 7 Accuracy 74.61501210653753 %\n",
      "At cuttoff of 0.3  truepositive 42 truenegative 8418 falsepositive 1855 falsenegative 10 Accuracy 81.93704600484261 %\n",
      "At cuttoff of 0.4  truepositive 40 truenegative 8891 falsepositive 1382 falsenegative 12 Accuracy 86.49878934624698 %\n",
      "At cuttoff of 0.5  truepositive 38 truenegative 9259 falsepositive 1014 falsenegative 14 Accuracy 90.04358353510897 %\n",
      "At cuttoff of 0.6  truepositive 37 truenegative 9558 falsepositive 715 falsenegative 15 Accuracy 92.92978208232445 %\n",
      "At cuttoff of 0.7  truepositive 31 truenegative 9792 falsepositive 481 falsenegative 21 Accuracy 95.13801452784503 %\n",
      "At cuttoff of 0.75  truepositive 30 truenegative 9877 falsepositive 396 falsenegative 22 Accuracy 95.95157384987894 %\n",
      "At cuttoff of 0.8  truepositive 26 truenegative 9957 falsepositive 316 falsenegative 26 Accuracy 96.68765133171912 %\n",
      "At cuttoff of 0.9  truepositive 15 truenegative 10101 falsepositive 172 falsenegative 37 Accuracy 97.97578692493947 %\n",
      "At cuttoff of 1.0  truepositive 9 truenegative 10192 falsepositive 81 falsenegative 43 Accuracy 98.79903147699758 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test sets-model_old\n",
      "At cuttoff of 0.2  truepositive 25 truenegative 7578 falsepositive 2218 falsenegative 1 Accuracy 77.40785990633272 %\n",
      "At cuttoff of 0.3  truepositive 24 truenegative 8190 falsepositive 1606 falsenegative 2 Accuracy 83.62858888210141 %\n",
      "At cuttoff of 0.4  truepositive 24 truenegative 8611 falsepositive 1185 falsenegative 2 Accuracy 87.91488495214824 %\n",
      "At cuttoff of 0.5  truepositive 21 truenegative 8940 falsepositive 856 falsenegative 5 Accuracy 91.23396456933415 %\n",
      "At cuttoff of 0.6  truepositive 20 truenegative 9181 falsepositive 615 falsenegative 6 Accuracy 93.67745876603543 %\n",
      "At cuttoff of 0.7  truepositive 19 truenegative 9393 falsepositive 403 falsenegative 7 Accuracy 95.82569741396864 %\n",
      "At cuttoff of 0.75  truepositive 17 truenegative 9486 falsepositive 310 falsenegative 9 Accuracy 96.7521889635512 %\n",
      "At cuttoff of 0.8  truepositive 16 truenegative 9551 falsepositive 245 falsenegative 10 Accuracy 97.40378741600489 %\n",
      "At cuttoff of 0.9  truepositive 14 truenegative 9652 falsepositive 144 falsenegative 12 Accuracy 98.41172877214417 %\n",
      "At cuttoff of 1.0  truepositive 5 truenegative 9738 falsepositive 58 falsenegative 21 Accuracy 99.1956831602525 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At cuttoff of 0.2  truepositive 45 truenegative 7659 falsepositive 2614 falsenegative 7 Accuracy 74.61501210653753 %\n",
      "At cuttoff of 0.3  truepositive 42 truenegative 8418 falsepositive 1855 falsenegative 10 Accuracy 81.93704600484261 %\n",
      "At cuttoff of 0.4  truepositive 40 truenegative 8891 falsepositive 1382 falsenegative 12 Accuracy 86.49878934624698 %\n",
      "At cuttoff of 0.5  truepositive 38 truenegative 9259 falsepositive 1014 falsenegative 14 Accuracy 90.04358353510897 %\n",
      "At cuttoff of 0.6  truepositive 37 truenegative 9558 falsepositive 715 falsenegative 15 Accuracy 92.92978208232445 %\n",
      "At cuttoff of 0.7  truepositive 31 truenegative 9792 falsepositive 481 falsenegative 21 Accuracy 95.13801452784503 %\n",
      "At cuttoff of 0.75  truepositive 30 truenegative 9877 falsepositive 396 falsenegative 22 Accuracy 95.95157384987894 %\n",
      "At cuttoff of 0.8  truepositive 26 truenegative 9957 falsepositive 316 falsenegative 26 Accuracy 96.68765133171912 %\n",
      "At cuttoff of 0.9  truepositive 15 truenegative 10101 falsepositive 172 falsenegative 37 Accuracy 97.97578692493947 %\n",
      "At cuttoff of 1.0  truepositive 9 truenegative 10192 falsepositive 81 falsenegative 43 Accuracy 98.79903147699758 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nprint(\"test sets-model2\")\\nevaluatedatasetlookahead(gru_model2,originaldata1)\\nevaluatedatasetlookahead(gru_model2,originaldata2)\\nprint(\"\")\\n\\nprint(\"test sets-model3\")\\nevaluatedatasetlookahead(gru_model3,originaldata1)\\nevaluatedatasetlookahead(gru_model3,originaldata2)\\nprint(\"\")\\n\\nprint(\"test sets-model4\")\\nevaluatedatasetlookahead(gru_model4,originaldata1)\\nevaluatedatasetlookahead(gru_model4,originaldata2)\\nprint(\"\")\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "#device = torch.device(\"cuda\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Training sets\")\n",
    "originaldata=pd.read_csv('forcetorquebuttonresults_renormalized_10_04_2021_newrange.csv')#.head()\n",
    "evaluatedatasetlookahead(gru_model1,originaldata)\n",
    "print(\"\")\n",
    "\n",
    "originaldata=pd.read_csv('forcetorquebuttonresults_renormalized_10_06_2021_newrange.csv')#.head()\n",
    "evaluatedatasetlookahead(gru_model1,originaldata)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "originaldata=pd.read_csv('forcetorquebuttonresults_10_13_2021.csv')\n",
    "evaluatedatasetlookahead(gru_model1,originaldata)\n",
    "\n",
    "print(\"\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"test sets-model1\")\n",
    "originaldata1=pd.read_csv('forcetorquebuttonresults_cylinder_withbutton_train_noposeobs_GRUrewards_10-4_13-2021GRU_lookahead10_23_2021.csv')#.head()\n",
    "evaluatedatasetlookahead(gru_model1,originaldata1)\n",
    "originaldata2=pd.read_csv('forcetorquebuttonresults_cylinder_withbutton_train_noposeobs_GRUrewards_10-4_13-2021GRU_lookahead_pos2rewardifbuttonpress10_23_2021.csv')#.head()\n",
    "evaluatedatasetlookahead(gru_model1,originaldata2)\n",
    "print(\"\")\n",
    "\n",
    "print(\"test sets-model_old\")\n",
    "originaldata1=pd.read_csv('forcetorquebuttonresults_cylinder_withbutton_train_noposeobs_GRUrewards_10-4_13-2021GRU_lookahead10_23_2021.csv')#.head()\n",
    "evaluatedatasetlookahead(gru_model_old,originaldata1)\n",
    "originaldata2=pd.read_csv('forcetorquebuttonresults_cylinder_withbutton_train_noposeobs_GRUrewards_10-4_13-2021GRU_lookahead_pos2rewardifbuttonpress10_23_2021.csv')#.head()\n",
    "evaluatedatasetlookahead(gru_model_old,originaldata2)\n",
    "print(\"\")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\"test sets-model2\")\n",
    "evaluatedatasetlookahead(gru_model2,originaldata1)\n",
    "evaluatedatasetlookahead(gru_model2,originaldata2)\n",
    "print(\"\")\n",
    "\n",
    "print(\"test sets-model3\")\n",
    "evaluatedatasetlookahead(gru_model3,originaldata1)\n",
    "evaluatedatasetlookahead(gru_model3,originaldata2)\n",
    "print(\"\")\n",
    "\n",
    "print(\"test sets-model4\")\n",
    "evaluatedatasetlookahead(gru_model4,originaldata1)\n",
    "evaluatedatasetlookahead(gru_model4,originaldata2)\n",
    "print(\"\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5454, 30)\n"
     ]
    }
   ],
   "source": [
    "originaldata=pd.read_csv('forcetorquebuttonresults_cylindernobutton_10_19_2021.csv')\n",
    "print(originaldata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8742799265683358"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " (310+13501)/(310+13501+1986)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22696/705497413.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mclassifytest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginaldata1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#print(classifytest)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mlabelstest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginaldata1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelstest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#print(classifytest)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1498\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "row=897\n",
    "\n",
    "headers=[]\n",
    "for i in range(30):  \n",
    "    label=str(i)\n",
    "    headers.append(\"header\"+label)\n",
    "\n",
    "choppedheaders=[]\n",
    "lookback=10 #save only the last 11 timesteps\n",
    "for i in range(10):  \n",
    "    label=str(i)\n",
    "    choppedheaders.append(\"header\"+label)\n",
    "\n",
    "okcounter=0\n",
    "for i in range(20):\n",
    "    classifytest=originaldata1[headers[i:10+i]].iloc[row*6:(row*6)+5].to_numpy()\n",
    "    #print(classifytest)\n",
    "    labelstest=originaldata1[headers[i:10+i]].iloc[(row*6)+5].to_numpy()\n",
    "    print(labelstest)\n",
    "    #print(classifytest)\n",
    "    classifytest=np.expand_dims(classifytest, axis=0)\n",
    "    #print(classifytest.shape)\n",
    "    #print(labelstest)\n",
    "\n",
    "    outputfull=evaluate_episode(gru_model3, classifytest)\n",
    "\n",
    "    #print(\"\")\n",
    "\n",
    "    #print(\"evaluating 1st timestep repeated 10 times\")\n",
    "\n",
    "\n",
    "    #print(\"prediction from 1 timestep\",float(outputpartial),\"actual\",test_y[randomindex])\n",
    "    \n",
    "    if abs(float(outputfull)-labelstest[9])>0.3:\n",
    "        result=\"X\"\n",
    "    else:\n",
    "        result=\"OK\"\n",
    "        okcounter+=1\n",
    "    print(\"prediction from timestep\",i,\"-\",i+10,\" :\",float(outputfull),\"actual\",labelstest[9], result)\n",
    "print(\"okcounter\",okcounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
